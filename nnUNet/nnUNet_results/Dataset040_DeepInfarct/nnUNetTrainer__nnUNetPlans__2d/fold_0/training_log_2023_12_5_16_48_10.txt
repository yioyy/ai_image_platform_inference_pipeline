
This is the configuration used by this training:
Configuration name: 2d
 {'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 66, 'patch_size': [192, 160], 'median_image_size_in_voxels': [186.0, 152.0], 'spacing': [0.8984000086784363, 0.8984000086784363], 'normalization_schemes': ['ADCNormalization', 'ZScoreBrainNormalization'], 'use_mask_for_norm': [False, False], 'UNet_class_name': 'ResidualEncoderUNet', 'UNet_base_num_features': 32, 'n_conv_per_stage_encoder': [2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2], 'num_pool_per_axis': [5, 5], 'pool_op_kernel_sizes': [[1, 1], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'conv_kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'unet_max_num_features': 512, 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'batch_dice': True} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset040_DeepInfarct', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [7.0, 0.8984000086784363, 0.8984000086784363], 'original_median_shape_after_transp': [21, 185, 150], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 4094.0, 'mean': 646.7350463867188, 'median': 593.0, 'min': -256.0, 'percentile_00_5': 240.0, 'percentile_99_5': 1732.0, 'std': 255.5416259765625}, '1': {'max': 13016.0, 'mean': 1477.8349609375, 'median': 1439.0, 'min': 0.0, 'percentile_00_5': 225.0, 'percentile_99_5': 3925.0, 'std': 756.8840942382812}}} 
 
2023-12-05 16:48:15.823827: unpacking dataset... 
2023-12-05 16:48:16.192515: unpacking done... 
2023-12-05 16:48:16.194053: do_dummy_2d_data_aug: False 
2023-12-05 16:48:16.197137: Using splits from existing split file: /data/chuan/nnUNet/nnUNet_preprocessed/Dataset040_DeepInfarct/splits_final.json 
2023-12-05 16:48:16.197826: The split file contains 5 splits. 
2023-12-05 16:48:16.197925: Desired fold for training: 0 
2023-12-05 16:48:16.197995: This split has 142 training and 36 validation cases. 
2023-12-05 16:48:21.916873:  
2023-12-05 16:48:21.917063: Epoch 0 
2023-12-05 16:48:21.917321: Current learning rate: 0.01 
2023-12-05 16:49:18.516314: train_loss 1.664 
2023-12-05 16:49:18.516583: val_loss 1.2179 
2023-12-05 16:49:18.516669: Pseudo dice [0.8172] 
2023-12-05 16:49:18.516751: Epoch time: 56.6 s 
2023-12-05 16:49:18.516819: Yayy! New best EMA pseudo Dice: 0.8172 
2023-12-05 16:49:20.081223:  
2023-12-05 16:49:20.081344: Epoch 1 
2023-12-05 16:49:20.081435: Current learning rate: 0.00999 
2023-12-05 16:50:11.065579: train_loss 1.2226 
2023-12-05 16:50:11.065835: val_loss 1.1836 
2023-12-05 16:50:11.065903: Pseudo dice [0.8425] 
2023-12-05 16:50:11.065969: Epoch time: 50.99 s 
2023-12-05 16:50:11.066021: Yayy! New best EMA pseudo Dice: 0.8198 
2023-12-05 16:50:13.767046:  
2023-12-05 16:50:13.767222: Epoch 2 
2023-12-05 16:50:13.767309: Current learning rate: 0.00998 
2023-12-05 16:51:04.397773: train_loss 1.1905 
2023-12-05 16:51:04.398019: val_loss 1.1902 
2023-12-05 16:51:04.398095: Pseudo dice [0.839] 
2023-12-05 16:51:04.398174: Epoch time: 50.63 s 
2023-12-05 16:51:04.398234: Yayy! New best EMA pseudo Dice: 0.8217 
2023-12-05 16:51:07.277233:  
2023-12-05 16:51:07.277500: Epoch 3 
2023-12-05 16:51:07.277610: Current learning rate: 0.00997 
2023-12-05 16:51:57.984650: train_loss 1.1719 
2023-12-05 16:51:57.984874: val_loss 1.1671 
2023-12-05 16:51:57.984942: Pseudo dice [0.8527] 
2023-12-05 16:51:57.985009: Epoch time: 50.71 s 
2023-12-05 16:51:57.985059: Yayy! New best EMA pseudo Dice: 0.8248 
2023-12-05 16:52:00.260089:  
2023-12-05 16:52:00.260225: Epoch 4 
2023-12-05 16:52:00.260317: Current learning rate: 0.00996 
2023-12-05 16:52:51.316737: train_loss 1.1709 
2023-12-05 16:52:51.317266: val_loss 1.1708 
2023-12-05 16:52:51.317359: Pseudo dice [0.8491] 
2023-12-05 16:52:51.317455: Epoch time: 51.06 s 
2023-12-05 16:52:51.317508: Yayy! New best EMA pseudo Dice: 0.8272 
2023-12-05 16:52:54.213908:  
2023-12-05 16:52:54.214130: Epoch 5 
2023-12-05 16:52:54.214229: Current learning rate: 0.00995 
2023-12-05 16:53:45.530079: train_loss 1.1659 
2023-12-05 16:53:45.530350: val_loss 1.1582 
2023-12-05 16:53:45.530431: Pseudo dice [0.8622] 
2023-12-05 16:53:45.530519: Epoch time: 51.32 s 
2023-12-05 16:53:45.530586: Yayy! New best EMA pseudo Dice: 0.8307 
2023-12-05 16:53:47.968011:  
2023-12-05 16:53:47.968156: Epoch 6 
2023-12-05 16:53:47.968249: Current learning rate: 0.00995 
2023-12-05 16:54:39.477220: train_loss 1.1517 
2023-12-05 16:54:39.477433: val_loss 1.1532 
2023-12-05 16:54:39.477496: Pseudo dice [0.8659] 
2023-12-05 16:54:39.477570: Epoch time: 51.51 s 
2023-12-05 16:54:39.477621: Yayy! New best EMA pseudo Dice: 0.8342 
2023-12-05 16:54:41.863051:  
2023-12-05 16:54:41.863202: Epoch 7 
2023-12-05 16:54:41.863294: Current learning rate: 0.00994 
2023-12-05 16:55:33.376320: train_loss 1.1482 
2023-12-05 16:55:33.376595: val_loss 1.148 
2023-12-05 16:55:33.376692: Pseudo dice [0.8687] 
2023-12-05 16:55:33.376788: Epoch time: 51.51 s 
2023-12-05 16:55:33.376860: Yayy! New best EMA pseudo Dice: 0.8377 
2023-12-05 16:55:36.111987:  
2023-12-05 16:55:36.112324: Epoch 8 
2023-12-05 16:55:36.112498: Current learning rate: 0.00993 
2023-12-05 16:56:28.059748: train_loss 1.1511 
2023-12-05 16:56:28.060006: val_loss 1.1502 
2023-12-05 16:56:28.060094: Pseudo dice [0.8693] 
2023-12-05 16:56:28.060191: Epoch time: 51.95 s 
2023-12-05 16:56:28.060257: Yayy! New best EMA pseudo Dice: 0.8408 
2023-12-05 16:56:30.983659:  
2023-12-05 16:56:30.983813: Epoch 9 
2023-12-05 16:56:30.983927: Current learning rate: 0.00992 
2023-12-05 16:57:22.456050: train_loss 1.1452 
2023-12-05 16:57:22.456455: val_loss 1.1494 
2023-12-05 16:57:22.456537: Pseudo dice [0.8675] 
2023-12-05 16:57:22.456620: Epoch time: 51.47 s 
2023-12-05 16:57:22.456689: Yayy! New best EMA pseudo Dice: 0.8435 
2023-12-05 16:57:25.387770:  
2023-12-05 16:57:25.387996: Epoch 10 
2023-12-05 16:57:25.388104: Current learning rate: 0.00991 
2023-12-05 16:58:16.618256: train_loss 1.1391 
2023-12-05 16:58:16.618474: val_loss 1.1678 
2023-12-05 16:58:16.618540: Pseudo dice [0.8536] 
2023-12-05 16:58:16.618606: Epoch time: 51.23 s 
2023-12-05 16:58:16.618657: Yayy! New best EMA pseudo Dice: 0.8445 
2023-12-05 16:58:19.080027:  
2023-12-05 16:58:19.080484: Epoch 11 
2023-12-05 16:58:19.080575: Current learning rate: 0.0099 
2023-12-05 16:59:10.374342: train_loss 1.1387 
2023-12-05 16:59:10.374920: val_loss 1.1452 
2023-12-05 16:59:10.375043: Pseudo dice [0.872] 
2023-12-05 16:59:10.375161: Epoch time: 51.3 s 
2023-12-05 16:59:10.375228: Yayy! New best EMA pseudo Dice: 0.8473 
2023-12-05 16:59:13.351979:  
2023-12-05 16:59:13.352289: Epoch 12 
2023-12-05 16:59:13.352399: Current learning rate: 0.00989 
2023-12-05 17:00:04.393146: train_loss 1.1341 
2023-12-05 17:00:04.393366: val_loss 1.1612 
2023-12-05 17:00:04.393427: Pseudo dice [0.8584] 
2023-12-05 17:00:04.393491: Epoch time: 51.04 s 
2023-12-05 17:00:04.393539: Yayy! New best EMA pseudo Dice: 0.8484 
2023-12-05 17:00:07.127941:  
2023-12-05 17:00:07.128075: Epoch 13 
2023-12-05 17:00:07.128178: Current learning rate: 0.00988 
2023-12-05 17:00:58.697054: train_loss 1.1347 
2023-12-05 17:00:58.697254: val_loss 1.1567 
2023-12-05 17:00:58.697318: Pseudo dice [0.8627] 
2023-12-05 17:00:58.697384: Epoch time: 51.57 s 
2023-12-05 17:00:58.697434: Yayy! New best EMA pseudo Dice: 0.8498 
2023-12-05 17:01:01.441708:  
2023-12-05 17:01:01.442151: Epoch 14 
2023-12-05 17:01:01.442285: Current learning rate: 0.00987 
2023-12-05 17:01:52.416120: train_loss 1.1402 
2023-12-05 17:01:52.416375: val_loss 1.1734 
2023-12-05 17:01:52.416467: Pseudo dice [0.8467] 
2023-12-05 17:01:52.416551: Epoch time: 50.98 s 
2023-12-05 17:01:54.002729:  
2023-12-05 17:01:54.002874: Epoch 15 
2023-12-05 17:01:54.002996: Current learning rate: 0.00986 
2023-12-05 17:02:45.378482: train_loss 1.159 
2023-12-05 17:02:45.378745: val_loss 1.1692 
2023-12-05 17:02:45.378828: Pseudo dice [0.8524] 
2023-12-05 17:02:45.378909: Epoch time: 51.38 s 
2023-12-05 17:02:46.517531:  
2023-12-05 17:02:46.517666: Epoch 16 
2023-12-05 17:02:46.517749: Current learning rate: 0.00986 
2023-12-05 17:03:37.985867: train_loss 1.1348 
2023-12-05 17:03:37.986077: val_loss 1.1625 
2023-12-05 17:03:37.986140: Pseudo dice [0.8546] 
2023-12-05 17:03:37.986204: Epoch time: 51.47 s 
2023-12-05 17:03:37.986255: Yayy! New best EMA pseudo Dice: 0.8503 
2023-12-05 17:03:40.472090:  
2023-12-05 17:03:40.472284: Epoch 17 
2023-12-05 17:03:40.472369: Current learning rate: 0.00985 
2023-12-05 17:04:31.733860: train_loss 1.1316 
2023-12-05 17:04:31.734216: val_loss 1.1675 
2023-12-05 17:04:31.734321: Pseudo dice [0.853] 
2023-12-05 17:04:31.734432: Epoch time: 51.26 s 
2023-12-05 17:04:31.734516: Yayy! New best EMA pseudo Dice: 0.8506 
2023-12-05 17:04:34.754595:  
2023-12-05 17:04:34.754760: Epoch 18 
2023-12-05 17:04:34.754871: Current learning rate: 0.00984 
2023-12-05 17:05:25.982006: train_loss 1.127 
2023-12-05 17:05:25.982231: val_loss 1.1449 
2023-12-05 17:05:25.982296: Pseudo dice [0.8688] 
2023-12-05 17:05:25.982362: Epoch time: 51.23 s 
2023-12-05 17:05:25.982413: Yayy! New best EMA pseudo Dice: 0.8524 
2023-12-05 17:05:28.397807:  
2023-12-05 17:05:28.397928: Epoch 19 
2023-12-05 17:05:28.398020: Current learning rate: 0.00983 
2023-12-05 17:06:19.887351: train_loss 1.1234 
2023-12-05 17:06:19.887573: val_loss 1.1499 
2023-12-05 17:06:19.887633: Pseudo dice [0.867] 
2023-12-05 17:06:19.887701: Epoch time: 51.49 s 
2023-12-05 17:06:19.887750: Yayy! New best EMA pseudo Dice: 0.8538 
2023-12-05 17:06:22.734886:  
2023-12-05 17:06:22.735144: Epoch 20 
2023-12-05 17:06:22.735335: Current learning rate: 0.00982 
2023-12-05 17:07:14.100159: train_loss 1.1194 
2023-12-05 17:07:14.100408: val_loss 1.1582 
2023-12-05 17:07:14.100492: Pseudo dice [0.8603] 
2023-12-05 17:07:14.100575: Epoch time: 51.37 s 
2023-12-05 17:07:14.100638: Yayy! New best EMA pseudo Dice: 0.8545 
2023-12-05 17:07:17.186450:  
2023-12-05 17:07:17.186631: Epoch 21 
2023-12-05 17:07:17.186744: Current learning rate: 0.00981 
2023-12-05 17:08:08.814666: train_loss 1.1171 
2023-12-05 17:08:08.814919: val_loss 1.1538 
2023-12-05 17:08:08.815001: Pseudo dice [0.8628] 
2023-12-05 17:08:08.815094: Epoch time: 51.63 s 
2023-12-05 17:08:08.815157: Yayy! New best EMA pseudo Dice: 0.8553 
2023-12-05 17:08:11.527468:  
2023-12-05 17:08:11.527729: Epoch 22 
2023-12-05 17:08:11.527822: Current learning rate: 0.0098 
2023-12-05 17:09:02.713843: train_loss 1.1181 
2023-12-05 17:09:02.714093: val_loss 1.1505 
2023-12-05 17:09:02.714172: Pseudo dice [0.8652] 
2023-12-05 17:09:02.714252: Epoch time: 51.19 s 
2023-12-05 17:09:02.714313: Yayy! New best EMA pseudo Dice: 0.8563 
2023-12-05 17:09:05.367550:  
2023-12-05 17:09:05.367831: Epoch 23 
2023-12-05 17:09:05.367921: Current learning rate: 0.00979 
2023-12-05 17:09:56.728626: train_loss 1.1139 
2023-12-05 17:09:56.728863: val_loss 1.1494 
2023-12-05 17:09:56.728926: Pseudo dice [0.8674] 
2023-12-05 17:09:56.728992: Epoch time: 51.36 s 
2023-12-05 17:09:56.729041: Yayy! New best EMA pseudo Dice: 0.8574 
2023-12-05 17:09:59.020990:  
2023-12-05 17:09:59.021124: Epoch 24 
2023-12-05 17:09:59.021215: Current learning rate: 0.00978 
2023-12-05 17:10:50.359649: train_loss 1.1097 
2023-12-05 17:10:50.359976: val_loss 1.145 
2023-12-05 17:10:50.360085: Pseudo dice [0.8701] 
2023-12-05 17:10:50.360200: Epoch time: 51.34 s 
2023-12-05 17:10:50.360291: Yayy! New best EMA pseudo Dice: 0.8587 
2023-12-05 17:10:52.936171:  
2023-12-05 17:10:52.936342: Epoch 25 
2023-12-05 17:10:52.936431: Current learning rate: 0.00977 
2023-12-05 17:11:44.432692: train_loss 1.1106 
2023-12-05 17:11:44.432994: val_loss 1.1601 
2023-12-05 17:11:44.433105: Pseudo dice [0.8574] 
2023-12-05 17:11:44.433194: Epoch time: 51.5 s 
2023-12-05 17:11:46.129968:  
2023-12-05 17:11:46.130520: Epoch 26 
2023-12-05 17:11:46.130662: Current learning rate: 0.00977 
2023-12-05 17:12:37.674492: train_loss 1.109 
2023-12-05 17:12:37.674710: val_loss 1.161 
2023-12-05 17:12:37.674775: Pseudo dice [0.8583] 
2023-12-05 17:12:37.674844: Epoch time: 51.55 s 
2023-12-05 17:12:39.144804:  
2023-12-05 17:12:39.145154: Epoch 27 
2023-12-05 17:12:39.145330: Current learning rate: 0.00976 
2023-12-05 17:13:30.614480: train_loss 1.1067 
2023-12-05 17:13:30.615141: val_loss 1.1469 
2023-12-05 17:13:30.615263: Pseudo dice [0.8679] 
2023-12-05 17:13:30.615378: Epoch time: 51.47 s 
2023-12-05 17:13:30.615446: Yayy! New best EMA pseudo Dice: 0.8595 
2023-12-05 17:13:33.165931:  
2023-12-05 17:13:33.166221: Epoch 28 
2023-12-05 17:13:33.166570: Current learning rate: 0.00975 
2023-12-05 17:14:24.710443: train_loss 1.1072 
2023-12-05 17:14:24.710670: val_loss 1.164 
2023-12-05 17:14:24.710735: Pseudo dice [0.854] 
2023-12-05 17:14:24.710799: Epoch time: 51.55 s 
2023-12-05 17:14:25.867548:  
2023-12-05 17:14:25.867701: Epoch 29 
2023-12-05 17:14:25.867790: Current learning rate: 0.00974 
2023-12-05 17:15:17.503217: train_loss 1.1073 
2023-12-05 17:15:17.503489: val_loss 1.142 
2023-12-05 17:15:17.503574: Pseudo dice [0.8706] 
2023-12-05 17:15:17.503659: Epoch time: 51.64 s 
2023-12-05 17:15:17.503727: Yayy! New best EMA pseudo Dice: 0.8601 
2023-12-05 17:15:20.221216:  
2023-12-05 17:15:20.221632: Epoch 30 
2023-12-05 17:15:20.221757: Current learning rate: 0.00973 
2023-12-05 17:16:12.025043: train_loss 1.1032 
2023-12-05 17:16:12.025649: val_loss 1.1627 
2023-12-05 17:16:12.025853: Pseudo dice [0.8567] 
2023-12-05 17:16:12.026052: Epoch time: 51.81 s 
2023-12-05 17:16:13.203657:  
2023-12-05 17:16:13.203798: Epoch 31 
2023-12-05 17:16:13.203902: Current learning rate: 0.00972 
2023-12-05 17:17:04.926310: train_loss 1.1031 
2023-12-05 17:17:04.926633: val_loss 1.154 
2023-12-05 17:17:04.926703: Pseudo dice [0.8625] 
2023-12-05 17:17:04.926780: Epoch time: 51.72 s 
2023-12-05 17:17:06.309069:  
2023-12-05 17:17:06.309208: Epoch 32 
2023-12-05 17:17:06.309304: Current learning rate: 0.00971 
2023-12-05 17:17:58.143943: train_loss 1.0995 
2023-12-05 17:17:58.144199: val_loss 1.1473 
2023-12-05 17:17:58.144284: Pseudo dice [0.866] 
2023-12-05 17:17:58.144360: Epoch time: 51.84 s 
2023-12-05 17:17:58.144427: Yayy! New best EMA pseudo Dice: 0.8606 
2023-12-05 17:18:00.501903:  
2023-12-05 17:18:00.502065: Epoch 33 
2023-12-05 17:18:00.502157: Current learning rate: 0.0097 
2023-12-05 17:18:51.986757: train_loss 1.1014 
2023-12-05 17:18:51.987300: val_loss 1.1537 
2023-12-05 17:18:51.987406: Pseudo dice [0.8621] 
2023-12-05 17:18:51.987511: Epoch time: 51.49 s 
2023-12-05 17:18:51.987578: Yayy! New best EMA pseudo Dice: 0.8608 
2023-12-05 17:18:54.527162:  
2023-12-05 17:18:54.527319: Epoch 34 
2023-12-05 17:18:54.527409: Current learning rate: 0.00969 
2023-12-05 17:19:46.184001: train_loss 1.0983 
2023-12-05 17:19:46.184292: val_loss 1.1442 
2023-12-05 17:19:46.184376: Pseudo dice [0.8696] 
2023-12-05 17:19:46.184459: Epoch time: 51.66 s 
2023-12-05 17:19:46.184524: Yayy! New best EMA pseudo Dice: 0.8616 
2023-12-05 17:19:49.072953:  
2023-12-05 17:19:49.073125: Epoch 35 
2023-12-05 17:19:49.073231: Current learning rate: 0.00968 
2023-12-05 17:20:40.637741: train_loss 1.0986 
2023-12-05 17:20:40.638341: val_loss 1.1492 
2023-12-05 17:20:40.638452: Pseudo dice [0.8652] 
2023-12-05 17:20:40.638556: Epoch time: 51.57 s 
2023-12-05 17:20:40.638621: Yayy! New best EMA pseudo Dice: 0.862 
2023-12-05 17:20:43.563749:  
2023-12-05 17:20:43.564206: Epoch 36 
2023-12-05 17:20:43.564332: Current learning rate: 0.00968 
2023-12-05 17:21:35.146039: train_loss 1.0977 
2023-12-05 17:21:35.146304: val_loss 1.1508 
2023-12-05 17:21:35.146388: Pseudo dice [0.8632] 
2023-12-05 17:21:35.146468: Epoch time: 51.59 s 
2023-12-05 17:21:35.146533: Yayy! New best EMA pseudo Dice: 0.8621 
2023-12-05 17:21:38.020993:  
2023-12-05 17:21:38.021399: Epoch 37 
2023-12-05 17:21:38.021783: Current learning rate: 0.00967 
2023-12-05 17:22:29.448169: train_loss 1.0938 
2023-12-05 17:22:29.448480: val_loss 1.1657 
2023-12-05 17:22:29.448557: Pseudo dice [0.8511] 
2023-12-05 17:22:29.448634: Epoch time: 51.43 s 
2023-12-05 17:22:30.881226:  
2023-12-05 17:22:30.882332: Epoch 38 
2023-12-05 17:22:30.882855: Current learning rate: 0.00966 
2023-12-05 17:23:22.546183: train_loss 1.0938 
2023-12-05 17:23:22.546417: val_loss 1.1601 
2023-12-05 17:23:22.546485: Pseudo dice [0.8563] 
2023-12-05 17:23:22.546551: Epoch time: 51.67 s 
2023-12-05 17:23:23.710617:  
2023-12-05 17:23:23.710755: Epoch 39 
2023-12-05 17:23:23.710849: Current learning rate: 0.00965 
2023-12-05 17:24:15.513925: train_loss 1.0935 
2023-12-05 17:24:15.514298: val_loss 1.1522 
2023-12-05 17:24:15.514396: Pseudo dice [0.8623] 
2023-12-05 17:24:15.514498: Epoch time: 51.81 s 
2023-12-05 17:24:17.130543:  
2023-12-05 17:24:17.130763: Epoch 40 
2023-12-05 17:24:17.130997: Current learning rate: 0.00964 
2023-12-05 17:25:08.902404: train_loss 1.0945 
2023-12-05 17:25:08.902669: val_loss 1.1468 
2023-12-05 17:25:08.902752: Pseudo dice [0.8679] 
2023-12-05 17:25:08.902834: Epoch time: 51.77 s 
2023-12-05 17:25:10.464894:  
2023-12-05 17:25:10.465431: Epoch 41 
2023-12-05 17:25:10.465666: Current learning rate: 0.00963 
2023-12-05 17:26:02.148678: train_loss 1.0963 
2023-12-05 17:26:02.148916: val_loss 1.1443 
2023-12-05 17:26:02.148983: Pseudo dice [0.8697] 
2023-12-05 17:26:02.149051: Epoch time: 51.69 s 
2023-12-05 17:26:02.149103: Yayy! New best EMA pseudo Dice: 0.8623 
2023-12-05 17:26:04.995872:  
2023-12-05 17:26:04.996125: Epoch 42 
2023-12-05 17:26:04.996238: Current learning rate: 0.00962 
2023-12-05 17:26:56.709927: train_loss 1.0953 
2023-12-05 17:26:56.710168: val_loss 1.1455 
2023-12-05 17:26:56.710236: Pseudo dice [0.8689] 
2023-12-05 17:26:56.710302: Epoch time: 51.72 s 
2023-12-05 17:26:56.710354: Yayy! New best EMA pseudo Dice: 0.8629 
2023-12-05 17:26:59.327835:  
2023-12-05 17:26:59.328214: Epoch 43 
2023-12-05 17:26:59.328566: Current learning rate: 0.00961 
2023-12-05 17:27:50.766633: train_loss 1.092 
2023-12-05 17:27:50.767117: val_loss 1.1509 
2023-12-05 17:27:50.767206: Pseudo dice [0.8639] 
2023-12-05 17:27:50.767293: Epoch time: 51.44 s 
2023-12-05 17:27:50.767343: Yayy! New best EMA pseudo Dice: 0.863 
2023-12-05 17:27:53.645150:  
2023-12-05 17:27:53.645540: Epoch 44 
2023-12-05 17:27:53.645649: Current learning rate: 0.0096 
2023-12-05 17:28:45.473407: train_loss 1.0926 
2023-12-05 17:28:45.473687: val_loss 1.1508 
2023-12-05 17:28:45.473774: Pseudo dice [0.865] 
2023-12-05 17:28:45.473848: Epoch time: 51.83 s 
2023-12-05 17:28:45.473901: Yayy! New best EMA pseudo Dice: 0.8632 
2023-12-05 17:28:48.264577:  
2023-12-05 17:28:48.265238: Epoch 45 
2023-12-05 17:28:48.265366: Current learning rate: 0.00959 
2023-12-05 17:29:39.985395: train_loss 1.0915 
2023-12-05 17:29:39.986036: val_loss 1.1479 
2023-12-05 17:29:39.986148: Pseudo dice [0.867] 
2023-12-05 17:29:39.986262: Epoch time: 51.72 s 
2023-12-05 17:29:39.986329: Yayy! New best EMA pseudo Dice: 0.8636 
2023-12-05 17:29:42.540551:  
2023-12-05 17:29:42.540712: Epoch 46 
2023-12-05 17:29:42.540803: Current learning rate: 0.00959 
2023-12-05 17:30:34.053219: train_loss 1.0893 
2023-12-05 17:30:34.053502: val_loss 1.1635 
2023-12-05 17:30:34.053573: Pseudo dice [0.8524] 
2023-12-05 17:30:34.053659: Epoch time: 51.51 s 
2023-12-05 17:30:35.264664:  
2023-12-05 17:30:35.265083: Epoch 47 
2023-12-05 17:30:35.265307: Current learning rate: 0.00958 
2023-12-05 17:31:26.974876: train_loss 1.0864 
2023-12-05 17:31:26.975128: val_loss 1.1445 
2023-12-05 17:31:26.975192: Pseudo dice [0.8689] 
2023-12-05 17:31:26.975257: Epoch time: 51.71 s 
2023-12-05 17:31:28.120757:  
2023-12-05 17:31:28.121141: Epoch 48 
2023-12-05 17:31:28.121304: Current learning rate: 0.00957 
2023-12-05 17:32:19.556506: train_loss 1.0873 
2023-12-05 17:32:19.556743: val_loss 1.1476 
2023-12-05 17:32:19.556811: Pseudo dice [0.8661] 
2023-12-05 17:32:19.556889: Epoch time: 51.44 s 
2023-12-05 17:32:20.914027:  
2023-12-05 17:32:20.914176: Epoch 49 
2023-12-05 17:32:20.914264: Current learning rate: 0.00956 
2023-12-05 17:33:12.677081: train_loss 1.0869 
2023-12-05 17:33:12.677703: val_loss 1.1493 
2023-12-05 17:33:12.678213: Pseudo dice [0.8648] 
2023-12-05 17:33:12.678327: Epoch time: 51.76 s 
2023-12-05 17:33:14.707058:  
2023-12-05 17:33:14.707227: Epoch 50 
2023-12-05 17:33:14.707335: Current learning rate: 0.00955 
2023-12-05 17:34:06.320671: train_loss 1.0863 
2023-12-05 17:34:06.321009: val_loss 1.1541 
2023-12-05 17:34:06.321139: Pseudo dice [0.86] 
2023-12-05 17:34:06.321276: Epoch time: 51.62 s 
2023-12-05 17:34:07.905732:  
2023-12-05 17:34:07.905963: Epoch 51 
2023-12-05 17:34:07.906077: Current learning rate: 0.00954 
2023-12-05 17:34:59.569868: train_loss 1.0854 
2023-12-05 17:34:59.570134: val_loss 1.1462 
2023-12-05 17:34:59.570210: Pseudo dice [0.8684] 
2023-12-05 17:34:59.570289: Epoch time: 51.67 s 
2023-12-05 17:34:59.570344: Yayy! New best EMA pseudo Dice: 0.8637 
2023-12-05 17:35:02.052915:  
2023-12-05 17:35:02.053208: Epoch 52 
2023-12-05 17:35:02.053313: Current learning rate: 0.00953 
2023-12-05 17:35:53.648154: train_loss 1.0884 
2023-12-05 17:35:53.648414: val_loss 1.1505 
2023-12-05 17:35:53.648494: Pseudo dice [0.8642] 
2023-12-05 17:35:53.648575: Epoch time: 51.6 s 
2023-12-05 17:35:53.648636: Yayy! New best EMA pseudo Dice: 0.8638 
2023-12-05 17:35:56.561877:  
2023-12-05 17:35:56.562190: Epoch 53 
2023-12-05 17:35:56.562321: Current learning rate: 0.00952 
2023-12-05 17:36:48.178171: train_loss 1.0863 
2023-12-05 17:36:48.178428: val_loss 1.1551 
2023-12-05 17:36:48.178512: Pseudo dice [0.8602] 
2023-12-05 17:36:48.178594: Epoch time: 51.62 s 
2023-12-05 17:36:49.750217:  
2023-12-05 17:36:49.750677: Epoch 54 
2023-12-05 17:36:49.750868: Current learning rate: 0.00951 
2023-12-05 17:37:41.001596: train_loss 1.0864 
2023-12-05 17:37:41.001816: val_loss 1.146 
2023-12-05 17:37:41.001881: Pseudo dice [0.8687] 
2023-12-05 17:37:41.001949: Epoch time: 51.26 s 
2023-12-05 17:37:41.002002: Yayy! New best EMA pseudo Dice: 0.864 
2023-12-05 17:37:43.967115:  
2023-12-05 17:37:43.967400: Epoch 55 
2023-12-05 17:37:43.967527: Current learning rate: 0.0095 
2023-12-05 17:38:35.343695: train_loss 1.0862 
2023-12-05 17:38:35.344110: val_loss 1.1481 
2023-12-05 17:38:35.344190: Pseudo dice [0.8677] 
2023-12-05 17:38:35.344272: Epoch time: 51.38 s 
2023-12-05 17:38:35.344329: Yayy! New best EMA pseudo Dice: 0.8643 
2023-12-05 17:38:37.685472:  
2023-12-05 17:38:37.685609: Epoch 56 
2023-12-05 17:38:37.685701: Current learning rate: 0.00949 
2023-12-05 17:39:28.958949: train_loss 1.0853 
2023-12-05 17:39:28.959240: val_loss 1.1467 
2023-12-05 17:39:28.959330: Pseudo dice [0.8667] 
2023-12-05 17:39:28.959425: Epoch time: 51.27 s 
2023-12-05 17:39:28.959498: Yayy! New best EMA pseudo Dice: 0.8646 
2023-12-05 17:39:31.669682:  
2023-12-05 17:39:31.669832: Epoch 57 
2023-12-05 17:39:31.669918: Current learning rate: 0.00949 
2023-12-05 17:40:23.196119: train_loss 1.0892 
2023-12-05 17:40:23.196370: val_loss 1.1555 
2023-12-05 17:40:23.196450: Pseudo dice [0.8596] 
2023-12-05 17:40:23.196533: Epoch time: 51.53 s 
2023-12-05 17:40:24.717817:  
2023-12-05 17:40:24.718013: Epoch 58 
2023-12-05 17:40:24.718155: Current learning rate: 0.00948 
2023-12-05 17:41:16.199291: train_loss 1.087 
2023-12-05 17:41:16.199992: val_loss 1.1597 
2023-12-05 17:41:16.200104: Pseudo dice [0.8567] 
2023-12-05 17:41:16.200219: Epoch time: 51.48 s 
2023-12-05 17:41:17.796225:  
2023-12-05 17:41:17.796504: Epoch 59 
2023-12-05 17:41:17.796638: Current learning rate: 0.00947 
2023-12-05 17:42:09.357863: train_loss 1.0844 
2023-12-05 17:42:09.358321: val_loss 1.1366 
2023-12-05 17:42:09.358395: Pseudo dice [0.8744] 
2023-12-05 17:42:09.358468: Epoch time: 51.56 s 
2023-12-05 17:42:10.583596:  
2023-12-05 17:42:10.584086: Epoch 60 
2023-12-05 17:42:10.584285: Current learning rate: 0.00946 
2023-12-05 17:43:02.248795: train_loss 1.0802 
2023-12-05 17:43:02.249042: val_loss 1.1521 
2023-12-05 17:43:02.249115: Pseudo dice [0.8609] 
2023-12-05 17:43:02.249186: Epoch time: 51.67 s 
2023-12-05 17:43:03.623619:  
2023-12-05 17:43:03.623765: Epoch 61 
2023-12-05 17:43:03.623862: Current learning rate: 0.00945 
2023-12-05 17:43:55.290291: train_loss 1.0839 
2023-12-05 17:43:55.290563: val_loss 1.1551 
2023-12-05 17:43:55.290644: Pseudo dice [0.8608] 
2023-12-05 17:43:55.290726: Epoch time: 51.67 s 
2023-12-05 17:43:56.816842:  
2023-12-05 17:43:56.817127: Epoch 62 
2023-12-05 17:43:56.817238: Current learning rate: 0.00944 
2023-12-05 17:44:48.597337: train_loss 1.0813 
2023-12-05 17:44:48.597557: val_loss 1.1428 
2023-12-05 17:44:48.597627: Pseudo dice [0.8694] 
2023-12-05 17:44:48.597696: Epoch time: 51.78 s 
2023-12-05 17:44:49.886400:  
2023-12-05 17:44:49.886535: Epoch 63 
2023-12-05 17:44:49.886626: Current learning rate: 0.00943 
2023-12-05 17:45:41.668135: train_loss 1.079 
2023-12-05 17:45:41.668402: val_loss 1.1591 
2023-12-05 17:45:41.668484: Pseudo dice [0.8573] 
2023-12-05 17:45:41.668568: Epoch time: 51.78 s 
2023-12-05 17:45:43.236200:  
2023-12-05 17:45:43.236392: Epoch 64 
2023-12-05 17:45:43.236504: Current learning rate: 0.00942 
2023-12-05 17:46:34.895689: train_loss 1.0769 
2023-12-05 17:46:34.895947: val_loss 1.1564 
2023-12-05 17:46:34.896014: Pseudo dice [0.8582] 
2023-12-05 17:46:34.896096: Epoch time: 51.66 s 
2023-12-05 17:46:36.033866:  
2023-12-05 17:46:36.034227: Epoch 65 
2023-12-05 17:46:36.034315: Current learning rate: 0.00941 
2023-12-05 17:47:27.662993: train_loss 1.0767 
2023-12-05 17:47:27.663240: val_loss 1.1518 
2023-12-05 17:47:27.663309: Pseudo dice [0.8616] 
2023-12-05 17:47:27.663377: Epoch time: 51.63 s 
2023-12-05 17:47:28.858263:  
2023-12-05 17:47:28.858752: Epoch 66 
2023-12-05 17:47:28.858912: Current learning rate: 0.0094 
2023-12-05 17:48:20.513314: train_loss 1.0804 
2023-12-05 17:48:20.513628: val_loss 1.1529 
2023-12-05 17:48:20.513723: Pseudo dice [0.8621] 
2023-12-05 17:48:20.513803: Epoch time: 51.66 s 
2023-12-05 17:48:21.937346:  
2023-12-05 17:48:21.937510: Epoch 67 
2023-12-05 17:48:21.937602: Current learning rate: 0.00939 
2023-12-05 17:49:13.655277: train_loss 1.0787 
2023-12-05 17:49:13.655529: val_loss 1.1562 
2023-12-05 17:49:13.655614: Pseudo dice [0.8581] 
2023-12-05 17:49:13.655691: Epoch time: 51.72 s 
2023-12-05 17:49:14.838840:  
2023-12-05 17:49:14.838996: Epoch 68 
2023-12-05 17:49:14.839111: Current learning rate: 0.00939 
2023-12-05 17:50:06.459982: train_loss 1.0785 
2023-12-05 17:50:06.460282: val_loss 1.1479 
2023-12-05 17:50:06.460357: Pseudo dice [0.8652] 
2023-12-05 17:50:06.460453: Epoch time: 51.62 s 
2023-12-05 17:50:07.640117:  
2023-12-05 17:50:07.640363: Epoch 69 
2023-12-05 17:50:07.640457: Current learning rate: 0.00938 
2023-12-05 17:50:58.943789: train_loss 1.077 
2023-12-05 17:50:58.944271: val_loss 1.1436 
2023-12-05 17:50:58.944358: Pseudo dice [0.8685] 
2023-12-05 17:50:58.944441: Epoch time: 51.31 s 
2023-12-05 17:51:00.124665:  
2023-12-05 17:51:00.125216: Epoch 70 
2023-12-05 17:51:00.125361: Current learning rate: 0.00937 
2023-12-05 17:51:51.525832: train_loss 1.0766 
2023-12-05 17:51:51.526078: val_loss 1.1651 
2023-12-05 17:51:51.526145: Pseudo dice [0.8524] 
2023-12-05 17:51:51.526217: Epoch time: 51.4 s 
2023-12-05 17:51:52.735214:  
2023-12-05 17:51:52.735371: Epoch 71 
2023-12-05 17:51:52.735466: Current learning rate: 0.00936 
2023-12-05 17:52:44.246108: train_loss 1.0778 
2023-12-05 17:52:44.246368: val_loss 1.1596 
2023-12-05 17:52:44.246447: Pseudo dice [0.8562] 
2023-12-05 17:52:44.246528: Epoch time: 51.51 s 
2023-12-05 17:52:45.851832:  
2023-12-05 17:52:45.852453: Epoch 72 
2023-12-05 17:52:45.852847: Current learning rate: 0.00935 
2023-12-05 17:53:37.324787: train_loss 1.0784 
2023-12-05 17:53:37.325539: val_loss 1.161 
2023-12-05 17:53:37.325660: Pseudo dice [0.856] 
2023-12-05 17:53:37.325782: Epoch time: 51.47 s 
2023-12-05 17:53:39.102948:  
2023-12-05 17:53:39.103835: Epoch 73 
2023-12-05 17:53:39.104028: Current learning rate: 0.00934 
2023-12-05 17:54:30.735936: train_loss 1.0752 
2023-12-05 17:54:30.736537: val_loss 1.1524 
2023-12-05 17:54:30.736619: Pseudo dice [0.8626] 
2023-12-05 17:54:30.736702: Epoch time: 51.63 s 
2023-12-05 17:54:31.873820:  
2023-12-05 17:54:31.873969: Epoch 74 
2023-12-05 17:54:31.874060: Current learning rate: 0.00933 
2023-12-05 17:55:23.766695: train_loss 1.0741 
2023-12-05 17:55:23.767095: val_loss 1.1508 
2023-12-05 17:55:23.767202: Pseudo dice [0.8633] 
2023-12-05 17:55:23.767313: Epoch time: 51.89 s 
2023-12-05 17:55:25.027827:  
2023-12-05 17:55:25.028008: Epoch 75 
2023-12-05 17:55:25.028102: Current learning rate: 0.00932 
2023-12-05 17:56:16.506471: train_loss 1.0756 
2023-12-05 17:56:16.506732: val_loss 1.1406 
2023-12-05 17:56:16.506814: Pseudo dice [0.8716] 
2023-12-05 17:56:16.506897: Epoch time: 51.48 s 
2023-12-05 17:56:18.133317:  
2023-12-05 17:56:18.133620: Epoch 76 
2023-12-05 17:56:18.133777: Current learning rate: 0.00931 
2023-12-05 17:57:09.679883: train_loss 1.073 
2023-12-05 17:57:09.680147: val_loss 1.1537 
2023-12-05 17:57:09.680230: Pseudo dice [0.8605] 
2023-12-05 17:57:09.680312: Epoch time: 51.55 s 
2023-12-05 17:57:11.284336:  
2023-12-05 17:57:11.285043: Epoch 77 
2023-12-05 17:57:11.285165: Current learning rate: 0.0093 
2023-12-05 17:58:03.011261: train_loss 1.0774 
2023-12-05 17:58:03.011515: val_loss 1.1591 
2023-12-05 17:58:03.011593: Pseudo dice [0.8571] 
2023-12-05 17:58:03.011676: Epoch time: 51.73 s 
2023-12-05 17:58:04.613921:  
2023-12-05 17:58:04.614267: Epoch 78 
2023-12-05 17:58:04.614391: Current learning rate: 0.0093 
2023-12-05 17:58:56.204664: train_loss 1.076 
2023-12-05 17:58:56.204917: val_loss 1.16 
2023-12-05 17:58:56.205002: Pseudo dice [0.8556] 
2023-12-05 17:58:56.205090: Epoch time: 51.59 s 
2023-12-05 17:58:58.010621:  
2023-12-05 17:58:58.011109: Epoch 79 
2023-12-05 17:58:58.011230: Current learning rate: 0.00929 
2023-12-05 17:59:49.722648: train_loss 1.0744 
2023-12-05 17:59:49.722878: val_loss 1.1491 
2023-12-05 17:59:49.722945: Pseudo dice [0.8659] 
2023-12-05 17:59:49.723027: Epoch time: 51.71 s 
2023-12-05 17:59:51.106354:  
2023-12-05 17:59:51.106517: Epoch 80 
2023-12-05 17:59:51.106616: Current learning rate: 0.00928 
2023-12-05 18:00:42.830806: train_loss 1.0726 
2023-12-05 18:00:42.831471: val_loss 1.1679 
2023-12-05 18:00:42.831585: Pseudo dice [0.8487] 
2023-12-05 18:00:42.831694: Epoch time: 51.73 s 
2023-12-05 18:00:44.444786:  
2023-12-05 18:00:44.444960: Epoch 81 
2023-12-05 18:00:44.445084: Current learning rate: 0.00927 
2023-12-05 18:01:36.170327: train_loss 1.0741 
2023-12-05 18:01:36.170639: val_loss 1.1427 
2023-12-05 18:01:36.170730: Pseudo dice [0.8701] 
2023-12-05 18:01:36.170821: Epoch time: 51.73 s 
2023-12-05 18:01:37.790266:  
2023-12-05 18:01:37.790570: Epoch 82 
2023-12-05 18:01:37.790679: Current learning rate: 0.00926 
2023-12-05 18:02:29.510137: train_loss 1.0737 
2023-12-05 18:02:29.510903: val_loss 1.1598 
2023-12-05 18:02:29.511036: Pseudo dice [0.8559] 
2023-12-05 18:02:29.511161: Epoch time: 51.72 s 
2023-12-05 18:02:31.051077:  
2023-12-05 18:02:31.051398: Epoch 83 
2023-12-05 18:02:31.051495: Current learning rate: 0.00925 
2023-12-05 18:03:22.342442: train_loss 1.0743 
2023-12-05 18:03:22.342811: val_loss 1.1549 
2023-12-05 18:03:22.342876: Pseudo dice [0.8595] 
2023-12-05 18:03:22.342938: Epoch time: 51.29 s 
2023-12-05 18:03:23.993678:  
2023-12-05 18:03:23.993942: Epoch 84 
2023-12-05 18:03:23.994037: Current learning rate: 0.00924 
2023-12-05 18:04:15.644633: train_loss 1.0776 
2023-12-05 18:04:15.644873: val_loss 1.1536 
2023-12-05 18:04:15.644945: Pseudo dice [0.8627] 
2023-12-05 18:04:15.645013: Epoch time: 51.65 s 
2023-12-05 18:04:16.801936:  
2023-12-05 18:04:16.802296: Epoch 85 
2023-12-05 18:04:16.802439: Current learning rate: 0.00923 
2023-12-05 18:05:08.211673: train_loss 1.0724 
2023-12-05 18:05:08.211930: val_loss 1.1496 
2023-12-05 18:05:08.212000: Pseudo dice [0.8636] 
2023-12-05 18:05:08.212071: Epoch time: 51.41 s 
2023-12-05 18:05:09.379699:  
2023-12-05 18:05:09.380023: Epoch 86 
2023-12-05 18:05:09.380126: Current learning rate: 0.00922 
2023-12-05 18:06:00.904439: train_loss 1.0713 
2023-12-05 18:06:00.905010: val_loss 1.1534 
2023-12-05 18:06:00.905108: Pseudo dice [0.8617] 
2023-12-05 18:06:00.905205: Epoch time: 51.53 s 
2023-12-05 18:06:02.114419:  
2023-12-05 18:06:02.114585: Epoch 87 
2023-12-05 18:06:02.114695: Current learning rate: 0.00921 
2023-12-05 18:06:53.775699: train_loss 1.0688 
2023-12-05 18:06:53.775939: val_loss 1.1483 
2023-12-05 18:06:53.776009: Pseudo dice [0.8657] 
2023-12-05 18:06:53.776081: Epoch time: 51.66 s 
2023-12-05 18:06:54.911343:  
2023-12-05 18:06:54.911486: Epoch 88 
2023-12-05 18:06:54.911576: Current learning rate: 0.0092 
2023-12-05 18:07:46.563749: train_loss 1.0684 
2023-12-05 18:07:46.563995: val_loss 1.1562 
2023-12-05 18:07:46.564058: Pseudo dice [0.8587] 
2023-12-05 18:07:46.564119: Epoch time: 51.65 s 
2023-12-05 18:07:48.085425:  
2023-12-05 18:07:48.086105: Epoch 89 
2023-12-05 18:07:48.086549: Current learning rate: 0.0092 
2023-12-05 18:08:39.950674: train_loss 1.0668 
2023-12-05 18:08:39.950951: val_loss 1.1454 
2023-12-05 18:08:39.951042: Pseudo dice [0.8693] 
2023-12-05 18:08:39.951128: Epoch time: 51.87 s 
2023-12-05 18:08:41.478887:  
2023-12-05 18:08:41.479403: Epoch 90 
2023-12-05 18:08:41.479519: Current learning rate: 0.00919 
2023-12-05 18:09:33.196151: train_loss 1.0681 
2023-12-05 18:09:33.196394: val_loss 1.1391 
2023-12-05 18:09:33.196471: Pseudo dice [0.8737] 
2023-12-05 18:09:33.196547: Epoch time: 51.72 s 
2023-12-05 18:09:34.756857:  
2023-12-05 18:09:34.757162: Epoch 91 
2023-12-05 18:09:34.757257: Current learning rate: 0.00918 
2023-12-05 18:10:26.394617: train_loss 1.0682 
2023-12-05 18:10:26.394864: val_loss 1.1563 
2023-12-05 18:10:26.394934: Pseudo dice [0.8585] 
2023-12-05 18:10:26.395006: Epoch time: 51.64 s 
2023-12-05 18:10:27.534689:  
2023-12-05 18:10:27.535108: Epoch 92 
2023-12-05 18:10:27.535243: Current learning rate: 0.00917 
2023-12-05 18:11:19.254504: train_loss 1.0691 
2023-12-05 18:11:19.255032: val_loss 1.148 
2023-12-05 18:11:19.255141: Pseudo dice [0.867] 
2023-12-05 18:11:19.255245: Epoch time: 51.72 s 
2023-12-05 18:11:20.674658:  
2023-12-05 18:11:20.674828: Epoch 93 
2023-12-05 18:11:20.674930: Current learning rate: 0.00916 
2023-12-05 18:12:12.329085: train_loss 1.0677 
2023-12-05 18:12:12.329368: val_loss 1.1509 
2023-12-05 18:12:12.329452: Pseudo dice [0.8616] 
2023-12-05 18:12:12.329540: Epoch time: 51.66 s 
2023-12-05 18:12:13.752341:  
2023-12-05 18:12:13.752484: Epoch 94 
2023-12-05 18:12:13.752573: Current learning rate: 0.00915 
2023-12-05 18:13:05.539335: train_loss 1.0691 
2023-12-05 18:13:05.539742: val_loss 1.154 
2023-12-05 18:13:05.539905: Pseudo dice [0.8609] 
2023-12-05 18:13:05.540020: Epoch time: 51.79 s 
2023-12-05 18:13:06.753374:  
2023-12-05 18:13:06.753547: Epoch 95 
2023-12-05 18:13:06.753644: Current learning rate: 0.00914 
2023-12-05 18:13:58.398419: train_loss 1.0685 
2023-12-05 18:13:58.398864: val_loss 1.1558 
2023-12-05 18:13:58.398936: Pseudo dice [0.8586] 
2023-12-05 18:13:58.399007: Epoch time: 51.65 s 
2023-12-05 18:13:59.499677:  
2023-12-05 18:13:59.499923: Epoch 96 
2023-12-05 18:13:59.500007: Current learning rate: 0.00913 
2023-12-05 18:14:51.049953: train_loss 1.0684 
2023-12-05 18:14:51.050758: val_loss 1.1541 
2023-12-05 18:14:51.050860: Pseudo dice [0.8609] 
2023-12-05 18:14:51.050956: Epoch time: 51.55 s 
2023-12-05 18:14:52.580043:  
2023-12-05 18:14:52.580174: Epoch 97 
2023-12-05 18:14:52.580275: Current learning rate: 0.00912 
2023-12-05 18:15:44.310535: train_loss 1.0656 
2023-12-05 18:15:44.310763: val_loss 1.1601 
2023-12-05 18:15:44.310830: Pseudo dice [0.8547] 
2023-12-05 18:15:44.310899: Epoch time: 51.73 s 
2023-12-05 18:15:45.492960:  
2023-12-05 18:15:45.493287: Epoch 98 
2023-12-05 18:15:45.493482: Current learning rate: 0.00911 
2023-12-05 18:16:37.298851: train_loss 1.0657 
2023-12-05 18:16:37.299408: val_loss 1.1547 
2023-12-05 18:16:37.299502: Pseudo dice [0.8614] 
2023-12-05 18:16:37.299606: Epoch time: 51.81 s 
2023-12-05 18:16:38.463729:  
2023-12-05 18:16:38.463888: Epoch 99 
2023-12-05 18:16:38.463997: Current learning rate: 0.0091 
2023-12-05 18:17:30.233197: train_loss 1.0656 
2023-12-05 18:17:30.233422: val_loss 1.1556 
2023-12-05 18:17:30.233484: Pseudo dice [0.8616] 
2023-12-05 18:17:30.233548: Epoch time: 51.77 s 
2023-12-05 18:17:32.550306:  
2023-12-05 18:17:32.550442: Epoch 100 
2023-12-05 18:17:32.550522: Current learning rate: 0.0091 
2023-12-05 18:18:23.940588: train_loss 1.0661 
2023-12-05 18:18:23.940816: val_loss 1.1491 
2023-12-05 18:18:23.940886: Pseudo dice [0.865] 
2023-12-05 18:18:23.940956: Epoch time: 51.39 s 
2023-12-05 18:18:25.068634:  
2023-12-05 18:18:25.069069: Epoch 101 
2023-12-05 18:18:25.069160: Current learning rate: 0.00909 
2023-12-05 18:19:16.457789: train_loss 1.0676 
2023-12-05 18:19:16.458006: val_loss 1.145 
2023-12-05 18:19:16.458076: Pseudo dice [0.868] 
2023-12-05 18:19:16.458158: Epoch time: 51.39 s 
2023-12-05 18:19:17.567075:  
2023-12-05 18:19:17.567339: Epoch 102 
2023-12-05 18:19:17.567436: Current learning rate: 0.00908 
2023-12-05 18:20:09.397265: train_loss 1.0665 
2023-12-05 18:20:09.397552: val_loss 1.1438 
2023-12-05 18:20:09.397637: Pseudo dice [0.8694] 
2023-12-05 18:20:09.397722: Epoch time: 51.83 s 
2023-12-05 18:20:11.214464:  
2023-12-05 18:20:11.215001: Epoch 103 
2023-12-05 18:20:11.215281: Current learning rate: 0.00907 
2023-12-05 18:21:02.777446: train_loss 1.065 
2023-12-05 18:21:02.777850: val_loss 1.1513 
2023-12-05 18:21:02.777963: Pseudo dice [0.8631] 
2023-12-05 18:21:02.778077: Epoch time: 51.57 s 
2023-12-05 18:21:04.111545:  
2023-12-05 18:21:04.111694: Epoch 104 
2023-12-05 18:21:04.111799: Current learning rate: 0.00906 
2023-12-05 18:21:56.005726: train_loss 1.0655 
2023-12-05 18:21:56.005965: val_loss 1.1482 
2023-12-05 18:21:56.006036: Pseudo dice [0.8642] 
2023-12-05 18:21:56.006102: Epoch time: 51.9 s 
2023-12-05 18:21:57.546942:  
2023-12-05 18:21:57.547137: Epoch 105 
2023-12-05 18:21:57.547250: Current learning rate: 0.00905 
2023-12-05 18:22:49.151706: train_loss 1.0671 
2023-12-05 18:22:49.151936: val_loss 1.1557 
2023-12-05 18:22:49.152004: Pseudo dice [0.8587] 
2023-12-05 18:22:49.152071: Epoch time: 51.61 s 
2023-12-05 18:22:50.292482:  
2023-12-05 18:22:50.292653: Epoch 106 
2023-12-05 18:22:50.292750: Current learning rate: 0.00904 
2023-12-05 18:23:41.794100: train_loss 1.0654 
2023-12-05 18:23:41.794400: val_loss 1.145 
2023-12-05 18:23:41.794485: Pseudo dice [0.867] 
2023-12-05 18:23:41.794572: Epoch time: 51.5 s 
2023-12-05 18:23:43.360552:  
2023-12-05 18:23:43.360997: Epoch 107 
2023-12-05 18:23:43.361133: Current learning rate: 0.00903 
2023-12-05 18:24:35.316234: train_loss 1.0631 
2023-12-05 18:24:35.316671: val_loss 1.1472 
2023-12-05 18:24:35.317109: Pseudo dice [0.8668] 
2023-12-05 18:24:35.317446: Epoch time: 51.96 s 
2023-12-05 18:24:36.854978:  
2023-12-05 18:24:36.855142: Epoch 108 
2023-12-05 18:24:36.855250: Current learning rate: 0.00902 
2023-12-05 18:25:28.803674: train_loss 1.0683 
2023-12-05 18:25:28.803949: val_loss 1.1481 
2023-12-05 18:25:28.804037: Pseudo dice [0.8646] 
2023-12-05 18:25:28.804140: Epoch time: 51.95 s 
2023-12-05 18:25:30.320967:  
2023-12-05 18:25:30.321521: Epoch 109 
2023-12-05 18:25:30.321631: Current learning rate: 0.00901 
2023-12-05 18:26:22.252907: train_loss 1.0708 
2023-12-05 18:26:22.253188: val_loss 1.1534 
2023-12-05 18:26:22.253274: Pseudo dice [0.8626] 
2023-12-05 18:26:22.253356: Epoch time: 51.93 s 
2023-12-05 18:26:23.445062:  
2023-12-05 18:26:23.445215: Epoch 110 
2023-12-05 18:26:23.445310: Current learning rate: 0.009 
2023-12-05 18:27:15.120629: train_loss 1.0677 
2023-12-05 18:27:15.120858: val_loss 1.1501 
2023-12-05 18:27:15.120928: Pseudo dice [0.8624] 
2023-12-05 18:27:15.120996: Epoch time: 51.68 s 
2023-12-05 18:27:16.266286:  
2023-12-05 18:27:16.266423: Epoch 111 
2023-12-05 18:27:16.266517: Current learning rate: 0.009 
2023-12-05 18:28:08.137706: train_loss 1.0663 
2023-12-05 18:28:08.137979: val_loss 1.1511 
2023-12-05 18:28:08.138063: Pseudo dice [0.8621] 
2023-12-05 18:28:08.138144: Epoch time: 51.87 s 
2023-12-05 18:28:09.686354:  
2023-12-05 18:28:09.686515: Epoch 112 
2023-12-05 18:28:09.686626: Current learning rate: 0.00899 
2023-12-05 18:29:01.720664: train_loss 1.0656 
2023-12-05 18:29:01.720883: val_loss 1.1506 
2023-12-05 18:29:01.721357: Pseudo dice [0.8647] 
2023-12-05 18:29:01.721418: Epoch time: 52.04 s 
2023-12-05 18:29:02.863478:  
2023-12-05 18:29:02.863626: Epoch 113 
2023-12-05 18:29:02.863708: Current learning rate: 0.00898 
2023-12-05 18:29:54.785547: train_loss 1.0639 
2023-12-05 18:29:54.785781: val_loss 1.1509 
2023-12-05 18:29:54.785850: Pseudo dice [0.862] 
2023-12-05 18:29:54.785917: Epoch time: 51.92 s 
2023-12-05 18:29:55.941277:  
2023-12-05 18:29:55.941431: Epoch 114 
2023-12-05 18:29:55.941535: Current learning rate: 0.00897 
2023-12-05 18:30:47.773904: train_loss 1.0626 
2023-12-05 18:30:47.774176: val_loss 1.1505 
2023-12-05 18:30:47.774257: Pseudo dice [0.8628] 
2023-12-05 18:30:47.774337: Epoch time: 51.83 s 
2023-12-05 18:30:49.526417:  
2023-12-05 18:30:49.526753: Epoch 115 
2023-12-05 18:30:49.526869: Current learning rate: 0.00896 
2023-12-05 18:31:41.375590: train_loss 1.0649 
2023-12-05 18:31:41.375849: val_loss 1.1536 
2023-12-05 18:31:41.375932: Pseudo dice [0.8616] 
2023-12-05 18:31:41.376009: Epoch time: 51.85 s 
2023-12-05 18:31:42.943383:  
2023-12-05 18:31:42.943941: Epoch 116 
2023-12-05 18:31:42.944060: Current learning rate: 0.00895 
2023-12-05 18:32:34.836224: train_loss 1.0631 
2023-12-05 18:32:34.836565: val_loss 1.1443 
2023-12-05 18:32:34.836648: Pseudo dice [0.8682] 
2023-12-05 18:32:34.836732: Epoch time: 51.9 s 
2023-12-05 18:32:36.387876:  
2023-12-05 18:32:36.388094: Epoch 117 
2023-12-05 18:32:36.388259: Current learning rate: 0.00894 
2023-12-05 18:33:28.310168: train_loss 1.0621 
2023-12-05 18:33:28.310407: val_loss 1.1573 
2023-12-05 18:33:28.310478: Pseudo dice [0.858] 
2023-12-05 18:33:28.310546: Epoch time: 51.92 s 
2023-12-05 18:33:29.578917:  
2023-12-05 18:33:29.579074: Epoch 118 
2023-12-05 18:33:29.579168: Current learning rate: 0.00893 
2023-12-05 18:34:21.383463: train_loss 1.0622 
2023-12-05 18:34:21.383742: val_loss 1.1481 
2023-12-05 18:34:21.383828: Pseudo dice [0.8644] 
2023-12-05 18:34:21.383911: Epoch time: 51.81 s 
2023-12-05 18:34:22.975979:  
2023-12-05 18:34:22.976196: Epoch 119 
2023-12-05 18:34:22.976374: Current learning rate: 0.00892 
2023-12-05 18:35:14.648770: train_loss 1.0623 
2023-12-05 18:35:14.649048: val_loss 1.1422 
2023-12-05 18:35:14.649134: Pseudo dice [0.8704] 
2023-12-05 18:35:14.649220: Epoch time: 51.68 s 
2023-12-05 18:35:15.849574:  
2023-12-05 18:35:15.849700: Epoch 120 
2023-12-05 18:35:15.849786: Current learning rate: 0.00891 
2023-12-05 18:36:07.689478: train_loss 1.0609 
2023-12-05 18:36:07.689712: val_loss 1.1481 
2023-12-05 18:36:07.689775: Pseudo dice [0.8659] 
2023-12-05 18:36:07.689838: Epoch time: 51.84 s 
2023-12-05 18:36:08.842231:  
2023-12-05 18:36:08.842633: Epoch 121 
2023-12-05 18:36:08.842731: Current learning rate: 0.0089 
2023-12-05 18:37:00.591985: train_loss 1.0601 
2023-12-05 18:37:00.592253: val_loss 1.1533 
2023-12-05 18:37:00.592334: Pseudo dice [0.8616] 
2023-12-05 18:37:00.592416: Epoch time: 51.75 s 
2023-12-05 18:37:02.378719:  
2023-12-05 18:37:02.378868: Epoch 122 
2023-12-05 18:37:02.378979: Current learning rate: 0.00889 
2023-12-05 18:37:54.266732: train_loss 1.0589 
2023-12-05 18:37:54.266998: val_loss 1.1486 
2023-12-05 18:37:54.267094: Pseudo dice [0.8644] 
2023-12-05 18:37:54.267179: Epoch time: 51.89 s 
2023-12-05 18:37:55.819351:  
2023-12-05 18:37:55.819511: Epoch 123 
2023-12-05 18:37:55.819618: Current learning rate: 0.00889 
2023-12-05 18:38:47.571704: train_loss 1.0596 
2023-12-05 18:38:47.572274: val_loss 1.1629 
2023-12-05 18:38:47.572562: Pseudo dice [0.8537] 
2023-12-05 18:38:47.572814: Epoch time: 51.75 s 
2023-12-05 18:38:49.120442:  
2023-12-05 18:38:49.120736: Epoch 124 
2023-12-05 18:38:49.120853: Current learning rate: 0.00888 
2023-12-05 18:39:41.047204: train_loss 1.0595 
2023-12-05 18:39:41.047463: val_loss 1.1465 
2023-12-05 18:39:41.047543: Pseudo dice [0.8676] 
2023-12-05 18:39:41.047636: Epoch time: 51.93 s 
2023-12-05 18:39:42.679623:  
2023-12-05 18:39:42.680045: Epoch 125 
2023-12-05 18:39:42.680202: Current learning rate: 0.00887 
2023-12-05 18:40:34.480963: train_loss 1.0585 
2023-12-05 18:40:34.481201: val_loss 1.1601 
2023-12-05 18:40:34.481267: Pseudo dice [0.855] 
2023-12-05 18:40:34.481332: Epoch time: 51.8 s 
2023-12-05 18:40:35.652361:  
2023-12-05 18:40:35.652516: Epoch 126 
2023-12-05 18:40:35.652606: Current learning rate: 0.00886 
2023-12-05 18:41:27.346092: train_loss 1.06 
2023-12-05 18:41:27.346439: val_loss 1.1527 
2023-12-05 18:41:27.346524: Pseudo dice [0.8612] 
2023-12-05 18:41:27.346609: Epoch time: 51.7 s 
2023-12-05 18:41:28.948007:  
2023-12-05 18:41:28.948155: Epoch 127 
2023-12-05 18:41:28.948268: Current learning rate: 0.00885 
2023-12-05 18:42:20.709461: train_loss 1.0596 
2023-12-05 18:42:20.710008: val_loss 1.1514 
2023-12-05 18:42:20.710207: Pseudo dice [0.8632] 
2023-12-05 18:42:20.710407: Epoch time: 51.76 s 
2023-12-05 18:42:22.067818:  
2023-12-05 18:42:22.068187: Epoch 128 
2023-12-05 18:42:22.068357: Current learning rate: 0.00884 
2023-12-05 18:43:13.659729: train_loss 1.0592 
2023-12-05 18:43:13.659971: val_loss 1.1521 
2023-12-05 18:43:13.660039: Pseudo dice [0.8615] 
2023-12-05 18:43:13.660109: Epoch time: 51.59 s 
2023-12-05 18:43:14.864327:  
2023-12-05 18:43:14.864478: Epoch 129 
2023-12-05 18:43:14.864563: Current learning rate: 0.00883 
2023-12-05 18:44:06.592518: train_loss 1.0578 
2023-12-05 18:44:06.592797: val_loss 1.1444 
2023-12-05 18:44:06.592895: Pseudo dice [0.8682] 
2023-12-05 18:44:06.592998: Epoch time: 51.73 s 
2023-12-05 18:44:08.172658:  
2023-12-05 18:44:08.172826: Epoch 130 
2023-12-05 18:44:08.172944: Current learning rate: 0.00882 
2023-12-05 18:44:59.973992: train_loss 1.0589 
2023-12-05 18:44:59.974229: val_loss 1.1729 
2023-12-05 18:44:59.974294: Pseudo dice [0.8464] 
2023-12-05 18:44:59.974364: Epoch time: 51.8 s 
2023-12-05 18:45:01.169621:  
2023-12-05 18:45:01.169760: Epoch 131 
2023-12-05 18:45:01.169857: Current learning rate: 0.00881 
2023-12-05 18:45:52.985426: train_loss 1.0576 
2023-12-05 18:45:52.985697: val_loss 1.1564 
2023-12-05 18:45:52.985776: Pseudo dice [0.8572] 
2023-12-05 18:45:52.985857: Epoch time: 51.82 s 
2023-12-05 18:45:54.552479:  
2023-12-05 18:45:54.552657: Epoch 132 
2023-12-05 18:45:54.552768: Current learning rate: 0.0088 
2023-12-05 18:46:46.220469: train_loss 1.0575 
2023-12-05 18:46:46.220699: val_loss 1.1434 
2023-12-05 18:46:46.220768: Pseudo dice [0.8695] 
2023-12-05 18:46:46.220838: Epoch time: 51.67 s 
2023-12-05 18:46:47.739936:  
2023-12-05 18:46:47.740441: Epoch 133 
2023-12-05 18:46:47.740559: Current learning rate: 0.00879 
2023-12-05 18:47:39.259780: train_loss 1.0584 
2023-12-05 18:47:39.260044: val_loss 1.1514 
2023-12-05 18:47:39.260123: Pseudo dice [0.862] 
2023-12-05 18:47:39.260205: Epoch time: 51.52 s 
2023-12-05 18:47:40.971804:  
2023-12-05 18:47:40.971932: Epoch 134 
2023-12-05 18:47:40.972027: Current learning rate: 0.00879 
2023-12-05 18:48:32.634289: train_loss 1.0584 
2023-12-05 18:48:32.634550: val_loss 1.1448 
2023-12-05 18:48:32.634631: Pseudo dice [0.8678] 
2023-12-05 18:48:32.634712: Epoch time: 51.66 s 
2023-12-05 18:48:33.915497:  
2023-12-05 18:48:33.915749: Epoch 135 
2023-12-05 18:48:33.915843: Current learning rate: 0.00878 
2023-12-05 18:49:25.789953: train_loss 1.0586 
2023-12-05 18:49:25.790232: val_loss 1.1543 
2023-12-05 18:49:25.790312: Pseudo dice [0.8608] 
2023-12-05 18:49:25.790394: Epoch time: 51.88 s 
2023-12-05 18:49:27.000291:  
2023-12-05 18:49:27.000533: Epoch 136 
2023-12-05 18:49:27.000628: Current learning rate: 0.00877 
2023-12-05 18:50:18.964336: train_loss 1.0574 
2023-12-05 18:50:18.964606: val_loss 1.1457 
2023-12-05 18:50:18.964686: Pseudo dice [0.8679] 
2023-12-05 18:50:18.964768: Epoch time: 51.97 s 
2023-12-05 18:50:20.552738:  
2023-12-05 18:50:20.553037: Epoch 137 
2023-12-05 18:50:20.553145: Current learning rate: 0.00876 
2023-12-05 18:51:12.109555: train_loss 1.0575 
2023-12-05 18:51:12.110122: val_loss 1.1498 
2023-12-05 18:51:12.110348: Pseudo dice [0.8626] 
2023-12-05 18:51:12.110550: Epoch time: 51.56 s 
2023-12-05 18:51:13.706400:  
2023-12-05 18:51:13.706695: Epoch 138 
2023-12-05 18:51:13.706813: Current learning rate: 0.00875 
2023-12-05 18:52:05.303228: train_loss 1.0567 
2023-12-05 18:52:05.303495: val_loss 1.1516 
2023-12-05 18:52:05.303579: Pseudo dice [0.8627] 
2023-12-05 18:52:05.303661: Epoch time: 51.6 s 
2023-12-05 18:52:06.842031:  
2023-12-05 18:52:06.842188: Epoch 139 
2023-12-05 18:52:06.842299: Current learning rate: 0.00874 
2023-12-05 18:52:58.820187: train_loss 1.0569 
2023-12-05 18:52:58.820459: val_loss 1.1524 
2023-12-05 18:52:58.820543: Pseudo dice [0.8612] 
2023-12-05 18:52:58.820624: Epoch time: 51.98 s 
2023-12-05 18:53:00.525965:  
2023-12-05 18:53:00.526104: Epoch 140 
2023-12-05 18:53:00.526197: Current learning rate: 0.00873 
2023-12-05 18:53:52.508201: train_loss 1.0568 
2023-12-05 18:53:52.508469: val_loss 1.1538 
2023-12-05 18:53:52.508554: Pseudo dice [0.8621] 
2023-12-05 18:53:52.508640: Epoch time: 51.98 s 
2023-12-05 18:53:54.017334:  
2023-12-05 18:53:54.017472: Epoch 141 
2023-12-05 18:53:54.017566: Current learning rate: 0.00872 
2023-12-05 18:54:45.618905: train_loss 1.0562 
2023-12-05 18:54:45.619193: val_loss 1.1417 
2023-12-05 18:54:45.619277: Pseudo dice [0.8705] 
2023-12-05 18:54:45.619359: Epoch time: 51.6 s 
2023-12-05 18:54:47.187635:  
2023-12-05 18:54:47.187801: Epoch 142 
2023-12-05 18:54:47.187915: Current learning rate: 0.00871 
2023-12-05 18:55:39.165397: train_loss 1.0559 
2023-12-05 18:55:39.165663: val_loss 1.1517 
2023-12-05 18:55:39.165746: Pseudo dice [0.8626] 
2023-12-05 18:55:39.165827: Epoch time: 51.98 s 
2023-12-05 18:55:40.756493:  
2023-12-05 18:55:40.756917: Epoch 143 
2023-12-05 18:55:40.757091: Current learning rate: 0.0087 
2023-12-05 18:56:32.596977: train_loss 1.056 
2023-12-05 18:56:32.597236: val_loss 1.1537 
2023-12-05 18:56:32.597317: Pseudo dice [0.8594] 
2023-12-05 18:56:32.597398: Epoch time: 51.84 s 
2023-12-05 18:56:34.176932:  
2023-12-05 18:56:34.177197: Epoch 144 
2023-12-05 18:56:34.177309: Current learning rate: 0.00869 
2023-12-05 18:57:25.973720: train_loss 1.0561 
2023-12-05 18:57:25.973973: val_loss 1.1545 
2023-12-05 18:57:25.974051: Pseudo dice [0.8601] 
2023-12-05 18:57:25.974129: Epoch time: 51.8 s 
2023-12-05 18:57:27.767867:  
2023-12-05 18:57:27.768423: Epoch 145 
2023-12-05 18:57:27.768548: Current learning rate: 0.00868 
2023-12-05 18:58:19.581191: train_loss 1.0556 
2023-12-05 18:58:19.581464: val_loss 1.1534 
2023-12-05 18:58:19.581542: Pseudo dice [0.8599] 
2023-12-05 18:58:19.581621: Epoch time: 51.82 s 
2023-12-05 18:58:21.185271:  
2023-12-05 18:58:21.185498: Epoch 146 
2023-12-05 18:58:21.185632: Current learning rate: 0.00868 
2023-12-05 18:59:13.049161: train_loss 1.0552 
2023-12-05 18:59:13.049428: val_loss 1.1553 
2023-12-05 18:59:13.049535: Pseudo dice [0.8569] 
2023-12-05 18:59:13.049640: Epoch time: 51.87 s 
2023-12-05 18:59:14.643205:  
2023-12-05 18:59:14.643600: Epoch 147 
2023-12-05 18:59:14.643782: Current learning rate: 0.00867 
2023-12-05 19:00:06.453143: train_loss 1.0567 
2023-12-05 19:00:06.453402: val_loss 1.1531 
2023-12-05 19:00:06.453492: Pseudo dice [0.8615] 
2023-12-05 19:00:06.453572: Epoch time: 51.81 s 
2023-12-05 19:00:07.859102:  
2023-12-05 19:00:07.859221: Epoch 148 
2023-12-05 19:00:07.859311: Current learning rate: 0.00866 
2023-12-05 19:00:59.710568: train_loss 1.0566 
2023-12-05 19:00:59.710931: val_loss 1.1664 
2023-12-05 19:00:59.711076: Pseudo dice [0.8505] 
2023-12-05 19:00:59.711195: Epoch time: 51.85 s 
2023-12-05 19:01:01.289886:  
2023-12-05 19:01:01.290175: Epoch 149 
2023-12-05 19:01:01.290293: Current learning rate: 0.00865 
2023-12-05 19:01:53.176220: train_loss 1.0562 
2023-12-05 19:01:53.176481: val_loss 1.1589 
2023-12-05 19:01:53.176564: Pseudo dice [0.8563] 
2023-12-05 19:01:53.176644: Epoch time: 51.89 s 
2023-12-05 19:01:55.857797:  
2023-12-05 19:01:55.858078: Epoch 150 
2023-12-05 19:01:55.858181: Current learning rate: 0.00864 
2023-12-05 19:02:47.491658: train_loss 1.0566 
2023-12-05 19:02:47.491932: val_loss 1.1496 
2023-12-05 19:02:47.492013: Pseudo dice [0.8661] 
2023-12-05 19:02:47.492092: Epoch time: 51.64 s 
2023-12-05 19:02:48.874193:  
2023-12-05 19:02:48.874594: Epoch 151 
2023-12-05 19:02:48.874866: Current learning rate: 0.00863 
2023-12-05 19:03:40.705267: train_loss 1.0574 
2023-12-05 19:03:40.705517: val_loss 1.1424 
2023-12-05 19:03:40.705587: Pseudo dice [0.8701] 
2023-12-05 19:03:40.705654: Epoch time: 51.83 s 
2023-12-05 19:03:41.925045:  
2023-12-05 19:03:41.925214: Epoch 152 
2023-12-05 19:03:41.925307: Current learning rate: 0.00862 
2023-12-05 19:04:33.726765: train_loss 1.057 
2023-12-05 19:04:33.727051: val_loss 1.1509 
2023-12-05 19:04:33.727139: Pseudo dice [0.8627] 
2023-12-05 19:04:33.727216: Epoch time: 51.8 s 
2023-12-05 19:04:35.308937:  
2023-12-05 19:04:35.309114: Epoch 153 
2023-12-05 19:04:35.309224: Current learning rate: 0.00861 
2023-12-05 19:05:26.871751: train_loss 1.0574 
2023-12-05 19:05:26.872033: val_loss 1.1524 
2023-12-05 19:05:26.872133: Pseudo dice [0.863] 
2023-12-05 19:05:26.872225: Epoch time: 51.57 s 
2023-12-05 19:05:28.390730:  
2023-12-05 19:05:28.391062: Epoch 154 
2023-12-05 19:05:28.391157: Current learning rate: 0.0086 
2023-12-05 19:06:20.138827: train_loss 1.0573 
2023-12-05 19:06:20.139119: val_loss 1.1644 
2023-12-05 19:06:20.139205: Pseudo dice [0.8504] 
2023-12-05 19:06:20.139286: Epoch time: 51.75 s 
2023-12-05 19:06:21.773499:  
2023-12-05 19:06:21.773816: Epoch 155 
2023-12-05 19:06:21.773937: Current learning rate: 0.00859 
2023-12-05 19:07:13.641719: train_loss 1.0652 
2023-12-05 19:07:13.641972: val_loss 1.1585 
2023-12-05 19:07:13.642055: Pseudo dice [0.8574] 
2023-12-05 19:07:13.642133: Epoch time: 51.87 s 
2023-12-05 19:07:15.248688:  
2023-12-05 19:07:15.248840: Epoch 156 
2023-12-05 19:07:15.248953: Current learning rate: 0.00858 
2023-12-05 19:08:07.068853: train_loss 1.0745 
2023-12-05 19:08:07.069113: val_loss 1.1673 
2023-12-05 19:08:07.069193: Pseudo dice [0.8499] 
2023-12-05 19:08:07.069273: Epoch time: 51.82 s 
2023-12-05 19:08:08.861577:  
2023-12-05 19:08:08.861809: Epoch 157 
2023-12-05 19:08:08.861924: Current learning rate: 0.00858 
2023-12-05 19:09:00.810031: train_loss 1.0717 
2023-12-05 19:09:00.810293: val_loss 1.153 
2023-12-05 19:09:00.810374: Pseudo dice [0.8608] 
2023-12-05 19:09:00.810453: Epoch time: 51.95 s 
2023-12-05 19:09:02.254407:  
2023-12-05 19:09:02.254553: Epoch 158 
2023-12-05 19:09:02.254650: Current learning rate: 0.00857 
2023-12-05 19:09:54.188786: train_loss 1.066 
2023-12-05 19:09:54.189570: val_loss 1.1414 
2023-12-05 19:09:54.189661: Pseudo dice [0.8712] 
2023-12-05 19:09:54.189743: Epoch time: 51.94 s 
2023-12-05 19:09:55.800560:  
2023-12-05 19:09:55.800884: Epoch 159 
2023-12-05 19:09:55.800994: Current learning rate: 0.00856 
2023-12-05 19:10:47.713612: train_loss 1.0639 
2023-12-05 19:10:47.713878: val_loss 1.1529 
2023-12-05 19:10:47.713961: Pseudo dice [0.8604] 
2023-12-05 19:10:47.714045: Epoch time: 51.92 s 
2023-12-05 19:10:49.153321:  
2023-12-05 19:10:49.153460: Epoch 160 
2023-12-05 19:10:49.153550: Current learning rate: 0.00855 
2023-12-05 19:11:41.013154: train_loss 1.0589 
2023-12-05 19:11:41.013419: val_loss 1.1506 
2023-12-05 19:11:41.013488: Pseudo dice [0.8627] 
2023-12-05 19:11:41.013553: Epoch time: 51.86 s 
2023-12-05 19:11:42.251962:  
2023-12-05 19:11:42.252108: Epoch 161 
2023-12-05 19:11:42.252200: Current learning rate: 0.00854 
2023-12-05 19:12:33.938925: train_loss 1.0582 
2023-12-05 19:12:33.939153: val_loss 1.1448 
2023-12-05 19:12:33.939220: Pseudo dice [0.8678] 
2023-12-05 19:12:33.939286: Epoch time: 51.69 s 
2023-12-05 19:12:35.289361:  
2023-12-05 19:12:35.289492: Epoch 162 
2023-12-05 19:12:35.289590: Current learning rate: 0.00853 
2023-12-05 19:13:26.994211: train_loss 1.0577 
2023-12-05 19:13:26.994476: val_loss 1.1445 
2023-12-05 19:13:26.994646: Pseudo dice [0.8686] 
2023-12-05 19:13:26.994774: Epoch time: 51.71 s 
2023-12-05 19:13:28.600505:  
2023-12-05 19:13:28.600676: Epoch 163 
2023-12-05 19:13:28.600807: Current learning rate: 0.00852 
2023-12-05 19:14:20.607901: train_loss 1.0561 
2023-12-05 19:14:20.608126: val_loss 1.1556 
2023-12-05 19:14:20.608196: Pseudo dice [0.8591] 
2023-12-05 19:14:20.608262: Epoch time: 52.01 s 
2023-12-05 19:14:21.844404:  
2023-12-05 19:14:21.844562: Epoch 164 
2023-12-05 19:14:21.844661: Current learning rate: 0.00851 
2023-12-05 19:15:13.464609: train_loss 1.0561 
2023-12-05 19:15:13.464877: val_loss 1.1518 
2023-12-05 19:15:13.464959: Pseudo dice [0.861] 
2023-12-05 19:15:13.465040: Epoch time: 51.62 s 
2023-12-05 19:15:15.029946:  
2023-12-05 19:15:15.030111: Epoch 165 
2023-12-05 19:15:15.030221: Current learning rate: 0.0085 
2023-12-05 19:16:06.720685: train_loss 1.0564 
2023-12-05 19:16:06.720911: val_loss 1.1604 
2023-12-05 19:16:06.720976: Pseudo dice [0.8544] 
2023-12-05 19:16:06.721043: Epoch time: 51.69 s 
2023-12-05 19:16:08.277072:  
2023-12-05 19:16:08.277371: Epoch 166 
2023-12-05 19:16:08.277492: Current learning rate: 0.00849 
2023-12-05 19:17:00.147084: train_loss 1.0575 
2023-12-05 19:17:00.147312: val_loss 1.1502 
2023-12-05 19:17:00.147379: Pseudo dice [0.8626] 
2023-12-05 19:17:00.147444: Epoch time: 51.87 s 
2023-12-05 19:17:01.336200:  
2023-12-05 19:17:01.336350: Epoch 167 
2023-12-05 19:17:01.336440: Current learning rate: 0.00848 
2023-12-05 19:17:53.004048: train_loss 1.0558 
2023-12-05 19:17:53.004319: val_loss 1.1431 
2023-12-05 19:17:53.004399: Pseudo dice [0.8703] 
2023-12-05 19:17:53.004479: Epoch time: 51.67 s 
2023-12-05 19:17:54.405656:  
2023-12-05 19:17:54.406008: Epoch 168 
2023-12-05 19:17:54.406116: Current learning rate: 0.00847 
2023-12-05 19:18:46.004209: train_loss 1.0538 
2023-12-05 19:18:46.004443: val_loss 1.1507 
2023-12-05 19:18:46.004514: Pseudo dice [0.8633] 
2023-12-05 19:18:46.004586: Epoch time: 51.6 s 
2023-12-05 19:18:47.225294:  
2023-12-05 19:18:47.225469: Epoch 169 
2023-12-05 19:18:47.225557: Current learning rate: 0.00847 
2023-12-05 19:19:39.096678: train_loss 1.054 
2023-12-05 19:19:39.096942: val_loss 1.1514 
2023-12-05 19:19:39.097025: Pseudo dice [0.8628] 
2023-12-05 19:19:39.097107: Epoch time: 51.87 s 
2023-12-05 19:19:40.353428:  
2023-12-05 19:19:40.353562: Epoch 170 
2023-12-05 19:19:40.353683: Current learning rate: 0.00846 
2023-12-05 19:20:32.039771: train_loss 1.0537 
2023-12-05 19:20:32.040028: val_loss 1.1506 
2023-12-05 19:20:32.040111: Pseudo dice [0.8639] 
2023-12-05 19:20:32.040191: Epoch time: 51.69 s 
2023-12-05 19:20:33.667246:  
2023-12-05 19:20:33.667431: Epoch 171 
2023-12-05 19:20:33.667545: Current learning rate: 0.00845 
2023-12-05 19:21:25.396078: train_loss 1.0534 
2023-12-05 19:21:25.396339: val_loss 1.1534 
2023-12-05 19:21:25.396417: Pseudo dice [0.8593] 
2023-12-05 19:21:25.396495: Epoch time: 51.73 s 
2023-12-05 19:21:26.999146:  
2023-12-05 19:21:26.999410: Epoch 172 
2023-12-05 19:21:26.999519: Current learning rate: 0.00844 
2023-12-05 19:22:18.935565: train_loss 1.0527 
2023-12-05 19:22:18.935823: val_loss 1.1545 
2023-12-05 19:22:18.935905: Pseudo dice [0.8586] 
2023-12-05 19:22:18.935987: Epoch time: 51.94 s 
2023-12-05 19:22:20.540275:  
2023-12-05 19:22:20.540574: Epoch 173 
2023-12-05 19:22:20.540720: Current learning rate: 0.00843 
2023-12-05 19:23:12.060543: train_loss 1.0521 
2023-12-05 19:23:12.060817: val_loss 1.1586 
2023-12-05 19:23:12.060899: Pseudo dice [0.8561] 
2023-12-05 19:23:12.060978: Epoch time: 51.52 s 
2023-12-05 19:23:13.945691:  
2023-12-05 19:23:13.945881: Epoch 174 
2023-12-05 19:23:13.945998: Current learning rate: 0.00842 
2023-12-05 19:24:05.847615: train_loss 1.0518 
2023-12-05 19:24:05.847885: val_loss 1.1527 
2023-12-05 19:24:05.847967: Pseudo dice [0.8621] 
2023-12-05 19:24:05.848046: Epoch time: 51.9 s 
2023-12-05 19:24:07.014815:  
2023-12-05 19:24:07.015320: Epoch 175 
2023-12-05 19:24:07.015413: Current learning rate: 0.00841 
2023-12-05 19:24:58.599616: train_loss 1.0515 
2023-12-05 19:24:58.599931: val_loss 1.1532 
2023-12-05 19:24:58.600034: Pseudo dice [0.861] 
2023-12-05 19:24:58.600134: Epoch time: 51.59 s 
2023-12-05 19:25:00.272795:  
2023-12-05 19:25:00.273264: Epoch 176 
2023-12-05 19:25:00.273458: Current learning rate: 0.0084 
2023-12-05 19:25:51.989465: train_loss 1.0533 
2023-12-05 19:25:51.990095: val_loss 1.1491 
2023-12-05 19:25:51.990187: Pseudo dice [0.8618] 
2023-12-05 19:25:51.990290: Epoch time: 51.72 s 
2023-12-05 19:25:53.223407:  
2023-12-05 19:25:53.223678: Epoch 177 
2023-12-05 19:25:53.223909: Current learning rate: 0.00839 
2023-12-05 19:26:44.772303: train_loss 1.0531 
2023-12-05 19:26:44.772539: val_loss 1.1538 
2023-12-05 19:26:44.772603: Pseudo dice [0.8588] 
2023-12-05 19:26:44.772671: Epoch time: 51.55 s 
2023-12-05 19:26:45.934591:  
2023-12-05 19:26:45.934914: Epoch 178 
2023-12-05 19:26:45.935004: Current learning rate: 0.00838 
2023-12-05 19:27:37.818417: train_loss 1.0531 
2023-12-05 19:27:37.818788: val_loss 1.156 
2023-12-05 19:27:37.818878: Pseudo dice [0.8585] 
2023-12-05 19:27:37.818964: Epoch time: 51.89 s 
2023-12-05 19:27:39.423770:  
2023-12-05 19:27:39.424306: Epoch 179 
2023-12-05 19:27:39.424454: Current learning rate: 0.00837 
2023-12-05 19:28:31.318451: train_loss 1.0529 
2023-12-05 19:28:31.318887: val_loss 1.1567 
2023-12-05 19:28:31.318974: Pseudo dice [0.8573] 
2023-12-05 19:28:31.319103: Epoch time: 51.9 s 
2023-12-05 19:28:33.151900:  
2023-12-05 19:28:33.152072: Epoch 180 
2023-12-05 19:28:33.152189: Current learning rate: 0.00836 
2023-12-05 19:29:24.968618: train_loss 1.0525 
2023-12-05 19:29:24.968888: val_loss 1.1506 
2023-12-05 19:29:24.968969: Pseudo dice [0.8623] 
2023-12-05 19:29:24.969056: Epoch time: 51.82 s 
2023-12-05 19:29:26.571067:  
2023-12-05 19:29:26.571388: Epoch 181 
2023-12-05 19:29:26.571564: Current learning rate: 0.00836 
2023-12-05 19:30:18.511300: train_loss 1.0524 
2023-12-05 19:30:18.511536: val_loss 1.1456 
2023-12-05 19:30:18.511607: Pseudo dice [0.8677] 
2023-12-05 19:30:18.511677: Epoch time: 51.94 s 
2023-12-05 19:30:19.691317:  
2023-12-05 19:30:19.691464: Epoch 182 
2023-12-05 19:30:19.691552: Current learning rate: 0.00835 
2023-12-05 19:31:11.362159: train_loss 1.0512 
2023-12-05 19:31:11.362536: val_loss 1.1508 
2023-12-05 19:31:11.362603: Pseudo dice [0.8624] 
2023-12-05 19:31:11.362671: Epoch time: 51.67 s 
2023-12-05 19:31:12.580109:  
2023-12-05 19:31:12.580660: Epoch 183 
2023-12-05 19:31:12.580836: Current learning rate: 0.00834 
2023-12-05 19:32:04.371334: train_loss 1.0507 
2023-12-05 19:32:04.371618: val_loss 1.1528 
2023-12-05 19:32:04.371702: Pseudo dice [0.8615] 
2023-12-05 19:32:04.371789: Epoch time: 51.79 s 
2023-12-05 19:32:05.714944:  
2023-12-05 19:32:05.715129: Epoch 184 
2023-12-05 19:32:05.715256: Current learning rate: 0.00833 
2023-12-05 19:32:57.394447: train_loss 1.0514 
2023-12-05 19:32:57.394738: val_loss 1.1478 
2023-12-05 19:32:57.394810: Pseudo dice [0.8646] 
2023-12-05 19:32:57.394886: Epoch time: 51.68 s 
2023-12-05 19:32:58.866357:  
2023-12-05 19:32:58.866516: Epoch 185 
2023-12-05 19:32:58.866608: Current learning rate: 0.00832 
2023-12-05 19:33:50.865678: train_loss 1.0513 
2023-12-05 19:33:50.865906: val_loss 1.1568 
2023-12-05 19:33:50.865970: Pseudo dice [0.8583] 
2023-12-05 19:33:50.866035: Epoch time: 52.0 s 
2023-12-05 19:33:52.080052:  
2023-12-05 19:33:52.080204: Epoch 186 
2023-12-05 19:33:52.080294: Current learning rate: 0.00831 
2023-12-05 19:34:43.794885: train_loss 1.0515 
2023-12-05 19:34:43.795165: val_loss 1.1549 
2023-12-05 19:34:43.795248: Pseudo dice [0.8603] 
2023-12-05 19:34:43.795340: Epoch time: 51.72 s 
2023-12-05 19:34:45.102838:  
2023-12-05 19:34:45.102980: Epoch 187 
2023-12-05 19:34:45.103086: Current learning rate: 0.0083 
2023-12-05 19:35:36.884683: train_loss 1.0521 
2023-12-05 19:35:36.884956: val_loss 1.1481 
2023-12-05 19:35:36.885040: Pseudo dice [0.866] 
2023-12-05 19:35:36.885124: Epoch time: 51.78 s 
2023-12-05 19:35:38.479889:  
2023-12-05 19:35:38.480235: Epoch 188 
2023-12-05 19:35:38.480363: Current learning rate: 0.00829 
2023-12-05 19:36:30.525226: train_loss 1.0517 
2023-12-05 19:36:30.525490: val_loss 1.1482 
2023-12-05 19:36:30.525583: Pseudo dice [0.8647] 
2023-12-05 19:36:30.525679: Epoch time: 52.05 s 
2023-12-05 19:36:32.136481:  
2023-12-05 19:36:32.136902: Epoch 189 
2023-12-05 19:36:32.137053: Current learning rate: 0.00828 
2023-12-05 19:37:23.841416: train_loss 1.0511 
2023-12-05 19:37:23.841644: val_loss 1.144 
2023-12-05 19:37:23.841713: Pseudo dice [0.8672] 
2023-12-05 19:37:23.841782: Epoch time: 51.71 s 
2023-12-05 19:37:25.066234:  
2023-12-05 19:37:25.066449: Epoch 190 
2023-12-05 19:37:25.066696: Current learning rate: 0.00827 
2023-12-05 19:38:16.841342: train_loss 1.0503 
2023-12-05 19:38:16.841617: val_loss 1.1592 
2023-12-05 19:38:16.841711: Pseudo dice [0.8575] 
2023-12-05 19:38:16.841803: Epoch time: 51.78 s 
2023-12-05 19:38:18.437994:  
2023-12-05 19:38:18.438322: Epoch 191 
2023-12-05 19:38:18.438449: Current learning rate: 0.00826 
2023-12-05 19:39:10.120587: train_loss 1.0501 
2023-12-05 19:39:10.120844: val_loss 1.1524 
2023-12-05 19:39:10.120923: Pseudo dice [0.8613] 
2023-12-05 19:39:10.121003: Epoch time: 51.68 s 
2023-12-05 19:39:11.943719:  
2023-12-05 19:39:11.943928: Epoch 192 
2023-12-05 19:39:11.944065: Current learning rate: 0.00825 
2023-12-05 19:40:03.853477: train_loss 1.0502 
2023-12-05 19:40:03.853742: val_loss 1.1507 
2023-12-05 19:40:03.853825: Pseudo dice [0.8636] 
2023-12-05 19:40:03.853906: Epoch time: 51.91 s 
2023-12-05 19:40:05.166104:  
2023-12-05 19:40:05.166366: Epoch 193 
2023-12-05 19:40:05.166458: Current learning rate: 0.00824 
2023-12-05 19:40:56.922001: train_loss 1.0501 
2023-12-05 19:40:56.922225: val_loss 1.1527 
2023-12-05 19:40:56.922293: Pseudo dice [0.8621] 
2023-12-05 19:40:56.922362: Epoch time: 51.76 s 
2023-12-05 19:40:58.145102:  
2023-12-05 19:40:58.145308: Epoch 194 
2023-12-05 19:40:58.145409: Current learning rate: 0.00824 
2023-12-05 19:41:50.014600: train_loss 1.0513 
2023-12-05 19:41:50.014858: val_loss 1.1582 
2023-12-05 19:41:50.014937: Pseudo dice [0.8558] 
2023-12-05 19:41:50.015039: Epoch time: 51.87 s 
2023-12-05 19:41:51.621085:  
2023-12-05 19:41:51.621365: Epoch 195 
2023-12-05 19:41:51.621478: Current learning rate: 0.00823 
2023-12-05 19:42:43.500299: train_loss 1.0506 
2023-12-05 19:42:43.500645: val_loss 1.1508 
2023-12-05 19:42:43.500736: Pseudo dice [0.8637] 
2023-12-05 19:42:43.500821: Epoch time: 51.88 s 
2023-12-05 19:42:45.072894:  
2023-12-05 19:42:45.073137: Epoch 196 
2023-12-05 19:42:45.073236: Current learning rate: 0.00822 
2023-12-05 19:43:37.096884: train_loss 1.0508 
2023-12-05 19:43:37.097146: val_loss 1.1702 
2023-12-05 19:43:37.097227: Pseudo dice [0.846] 
2023-12-05 19:43:37.097309: Epoch time: 52.03 s 
2023-12-05 19:43:38.895253:  
2023-12-05 19:43:38.895961: Epoch 197 
2023-12-05 19:43:38.896140: Current learning rate: 0.00821 
2023-12-05 19:44:30.852110: train_loss 1.0515 
2023-12-05 19:44:30.852379: val_loss 1.1492 
2023-12-05 19:44:30.852464: Pseudo dice [0.864] 
2023-12-05 19:44:30.852545: Epoch time: 51.96 s 
2023-12-05 19:44:32.495681:  
2023-12-05 19:44:32.495846: Epoch 198 
2023-12-05 19:44:32.495953: Current learning rate: 0.0082 
2023-12-05 19:45:24.361391: train_loss 1.0513 
2023-12-05 19:45:24.361665: val_loss 1.1392 
2023-12-05 19:45:24.361748: Pseudo dice [0.8726] 
2023-12-05 19:45:24.361831: Epoch time: 51.87 s 
2023-12-05 19:45:25.943555:  
2023-12-05 19:45:25.943738: Epoch 199 
2023-12-05 19:45:25.943833: Current learning rate: 0.00819 
2023-12-05 19:46:17.687274: train_loss 1.0486 
2023-12-05 19:46:17.687546: val_loss 1.1526 
2023-12-05 19:46:17.687631: Pseudo dice [0.8611] 
2023-12-05 19:46:17.687715: Epoch time: 51.75 s 
2023-12-05 19:46:20.343182:  
2023-12-05 19:46:20.343332: Epoch 200 
2023-12-05 19:46:20.343422: Current learning rate: 0.00818 
2023-12-05 19:47:12.070243: train_loss 1.0506 
2023-12-05 19:47:12.070503: val_loss 1.1526 
2023-12-05 19:47:12.070583: Pseudo dice [0.8608] 
2023-12-05 19:47:12.070664: Epoch time: 51.73 s 
2023-12-05 19:47:13.686004:  
2023-12-05 19:47:13.686256: Epoch 201 
2023-12-05 19:47:13.686374: Current learning rate: 0.00817 
2023-12-05 19:48:05.538080: train_loss 1.051 
2023-12-05 19:48:05.538416: val_loss 1.1477 
2023-12-05 19:48:05.538513: Pseudo dice [0.8664] 
2023-12-05 19:48:05.538599: Epoch time: 51.85 s 
2023-12-05 19:48:07.154027:  
2023-12-05 19:48:07.154527: Epoch 202 
2023-12-05 19:48:07.154638: Current learning rate: 0.00816 
2023-12-05 19:48:59.074854: train_loss 1.0503 
2023-12-05 19:48:59.075136: val_loss 1.1523 
2023-12-05 19:48:59.075218: Pseudo dice [0.8605] 
2023-12-05 19:48:59.075301: Epoch time: 51.92 s 
2023-12-05 19:49:00.927795:  
2023-12-05 19:49:00.927990: Epoch 203 
2023-12-05 19:49:00.928231: Current learning rate: 0.00815 
2023-12-05 19:49:52.498157: train_loss 1.0499 
2023-12-05 19:49:52.498387: val_loss 1.1521 
2023-12-05 19:49:52.498455: Pseudo dice [0.8606] 
2023-12-05 19:49:52.498533: Epoch time: 51.57 s 
2023-12-05 19:49:53.726365:  
2023-12-05 19:49:53.726514: Epoch 204 
2023-12-05 19:49:53.726608: Current learning rate: 0.00814 
2023-12-05 19:50:45.386628: train_loss 1.0496 
2023-12-05 19:50:45.386895: val_loss 1.1564 
2023-12-05 19:50:45.386980: Pseudo dice [0.8576] 
2023-12-05 19:50:45.387116: Epoch time: 51.66 s 
2023-12-05 19:50:46.714256:  
2023-12-05 19:50:46.714682: Epoch 205 
2023-12-05 19:50:46.714792: Current learning rate: 0.00813 
2023-12-05 19:51:38.487605: train_loss 1.0499 
2023-12-05 19:51:38.488014: val_loss 1.1384 
2023-12-05 19:51:38.488144: Pseudo dice [0.8727] 
2023-12-05 19:51:38.488271: Epoch time: 51.78 s 
2023-12-05 19:51:39.673595:  
2023-12-05 19:51:39.673733: Epoch 206 
2023-12-05 19:51:39.673830: Current learning rate: 0.00813 
2023-12-05 19:52:31.585338: train_loss 1.0481 
2023-12-05 19:52:31.585578: val_loss 1.1441 
2023-12-05 19:52:31.585648: Pseudo dice [0.868] 
2023-12-05 19:52:31.585719: Epoch time: 51.91 s 
2023-12-05 19:52:32.781617:  
2023-12-05 19:52:32.781767: Epoch 207 
2023-12-05 19:52:32.781870: Current learning rate: 0.00812 
2023-12-05 19:53:24.644792: train_loss 1.0477 
2023-12-05 19:53:24.645053: val_loss 1.1523 
2023-12-05 19:53:24.645136: Pseudo dice [0.8618] 
2023-12-05 19:53:24.645220: Epoch time: 51.86 s 
2023-12-05 19:53:26.083138:  
2023-12-05 19:53:26.083575: Epoch 208 
2023-12-05 19:53:26.083674: Current learning rate: 0.00811 
2023-12-05 19:54:18.051406: train_loss 1.0477 
2023-12-05 19:54:18.051630: val_loss 1.1432 
2023-12-05 19:54:18.051695: Pseudo dice [0.8687] 
2023-12-05 19:54:18.051762: Epoch time: 51.97 s 
2023-12-05 19:54:19.741456:  
2023-12-05 19:54:19.741772: Epoch 209 
2023-12-05 19:54:19.741913: Current learning rate: 0.0081 
2023-12-05 19:55:11.613833: train_loss 1.0485 
2023-12-05 19:55:11.614099: val_loss 1.1473 
2023-12-05 19:55:11.614180: Pseudo dice [0.866] 
2023-12-05 19:55:11.614263: Epoch time: 51.87 s 
2023-12-05 19:55:12.800985:  
2023-12-05 19:55:12.801141: Epoch 210 
2023-12-05 19:55:12.801229: Current learning rate: 0.00809 
2023-12-05 19:56:04.798124: train_loss 1.051 
2023-12-05 19:56:04.798393: val_loss 1.151 
2023-12-05 19:56:04.798499: Pseudo dice [0.8634] 
2023-12-05 19:56:04.798601: Epoch time: 52.0 s 
2023-12-05 19:56:06.210501:  
2023-12-05 19:56:06.210655: Epoch 211 
2023-12-05 19:56:06.210748: Current learning rate: 0.00808 
2023-12-05 19:56:57.684973: train_loss 1.0503 
2023-12-05 19:56:57.685259: val_loss 1.1422 
2023-12-05 19:56:57.685345: Pseudo dice [0.8689] 
2023-12-05 19:56:57.685428: Epoch time: 51.48 s 
2023-12-05 19:56:59.226631:  
2023-12-05 19:56:59.226985: Epoch 212 
2023-12-05 19:56:59.227125: Current learning rate: 0.00807 
2023-12-05 19:57:51.069639: train_loss 1.0513 
2023-12-05 19:57:51.069898: val_loss 1.159 
2023-12-05 19:57:51.069978: Pseudo dice [0.8571] 
2023-12-05 19:57:51.070057: Epoch time: 51.85 s 
2023-12-05 19:57:52.610226:  
2023-12-05 19:57:52.610403: Epoch 213 
2023-12-05 19:57:52.610512: Current learning rate: 0.00806 
2023-12-05 19:58:44.563433: train_loss 1.0502 
2023-12-05 19:58:44.563688: val_loss 1.1502 
2023-12-05 19:58:44.563767: Pseudo dice [0.8632] 
2023-12-05 19:58:44.563844: Epoch time: 51.96 s 
2023-12-05 19:58:46.107882:  
2023-12-05 19:58:46.108570: Epoch 214 
2023-12-05 19:58:46.109189: Current learning rate: 0.00805 
2023-12-05 19:59:38.112260: train_loss 1.0489 
2023-12-05 19:59:38.112537: val_loss 1.1478 
2023-12-05 19:59:38.112622: Pseudo dice [0.8643] 
2023-12-05 19:59:38.112704: Epoch time: 52.01 s 
2023-12-05 19:59:39.858384:  
2023-12-05 19:59:39.858536: Epoch 215 
2023-12-05 19:59:39.858645: Current learning rate: 0.00804 
2023-12-05 20:00:31.697334: train_loss 1.0492 
2023-12-05 20:00:31.697571: val_loss 1.1405 
2023-12-05 20:00:31.697654: Pseudo dice [0.8702] 
2023-12-05 20:00:31.697749: Epoch time: 51.84 s 
2023-12-05 20:00:33.242050:  
2023-12-05 20:00:33.242375: Epoch 216 
2023-12-05 20:00:33.242583: Current learning rate: 0.00803 
2023-12-05 20:01:25.039562: train_loss 1.054 
2023-12-05 20:01:25.040184: val_loss 1.1575 
2023-12-05 20:01:25.040299: Pseudo dice [0.8569] 
2023-12-05 20:01:25.040422: Epoch time: 51.8 s 
2023-12-05 20:01:26.646035:  
2023-12-05 20:01:26.646545: Epoch 217 
2023-12-05 20:01:26.646847: Current learning rate: 0.00802 
2023-12-05 20:02:18.554106: train_loss 1.0533 
2023-12-05 20:02:18.554347: val_loss 1.149 
2023-12-05 20:02:18.554411: Pseudo dice [0.8635] 
2023-12-05 20:02:18.554479: Epoch time: 51.91 s 
2023-12-05 20:02:19.667763:  
2023-12-05 20:02:19.668055: Epoch 218 
2023-12-05 20:02:19.668143: Current learning rate: 0.00801 
2023-12-05 20:03:11.533581: train_loss 1.051 
2023-12-05 20:03:11.533843: val_loss 1.1538 
2023-12-05 20:03:11.533909: Pseudo dice [0.8606] 
2023-12-05 20:03:11.533978: Epoch time: 51.87 s 
2023-12-05 20:03:12.718788:  
2023-12-05 20:03:12.718957: Epoch 219 
2023-12-05 20:03:12.719060: Current learning rate: 0.00801 
2023-12-05 20:04:04.602179: train_loss 1.0494 
2023-12-05 20:04:04.602483: val_loss 1.1542 
2023-12-05 20:04:04.602568: Pseudo dice [0.861] 
2023-12-05 20:04:04.602658: Epoch time: 51.89 s 
2023-12-05 20:04:06.025116:  
2023-12-05 20:04:06.025387: Epoch 220 
2023-12-05 20:04:06.025568: Current learning rate: 0.008 
2023-12-05 20:04:57.612817: train_loss 1.0507 
2023-12-05 20:04:57.613080: val_loss 1.1479 
2023-12-05 20:04:57.613160: Pseudo dice [0.8658] 
2023-12-05 20:04:57.613245: Epoch time: 51.59 s 
2023-12-05 20:04:59.258470:  
2023-12-05 20:04:59.258788: Epoch 221 
2023-12-05 20:04:59.258891: Current learning rate: 0.00799 
2023-12-05 20:05:51.076257: train_loss 1.0503 
2023-12-05 20:05:51.076917: val_loss 1.1531 
2023-12-05 20:05:51.077036: Pseudo dice [0.8596] 
2023-12-05 20:05:51.077152: Epoch time: 51.82 s 
2023-12-05 20:05:52.595683:  
2023-12-05 20:05:52.595847: Epoch 222 
2023-12-05 20:05:52.595949: Current learning rate: 0.00798 
2023-12-05 20:06:44.458822: train_loss 1.0492 
2023-12-05 20:06:44.459084: val_loss 1.1515 
2023-12-05 20:06:44.459152: Pseudo dice [0.8636] 
2023-12-05 20:06:44.459223: Epoch time: 51.87 s 
2023-12-05 20:06:45.698570:  
2023-12-05 20:06:45.698875: Epoch 223 
2023-12-05 20:06:45.699049: Current learning rate: 0.00797 
2023-12-05 20:07:37.604943: train_loss 1.0501 
2023-12-05 20:07:37.605206: val_loss 1.1485 
2023-12-05 20:07:37.605285: Pseudo dice [0.8658] 
2023-12-05 20:07:37.605374: Epoch time: 51.91 s 
2023-12-05 20:07:39.149588:  
2023-12-05 20:07:39.149932: Epoch 224 
2023-12-05 20:07:39.150319: Current learning rate: 0.00796 
2023-12-05 20:08:31.165212: train_loss 1.0494 
2023-12-05 20:08:31.165499: val_loss 1.1438 
2023-12-05 20:08:31.165579: Pseudo dice [0.8677] 
2023-12-05 20:08:31.165662: Epoch time: 52.02 s 
2023-12-05 20:08:32.733390:  
2023-12-05 20:08:32.733580: Epoch 225 
2023-12-05 20:08:32.733756: Current learning rate: 0.00795 
2023-12-05 20:09:24.358480: train_loss 1.0491 
2023-12-05 20:09:24.358737: val_loss 1.1461 
2023-12-05 20:09:24.358848: Pseudo dice [0.8655] 
2023-12-05 20:09:24.358953: Epoch time: 51.63 s 
2023-12-05 20:09:25.930216:  
2023-12-05 20:09:25.930429: Epoch 226 
2023-12-05 20:09:25.930537: Current learning rate: 0.00794 
2023-12-05 20:10:17.961354: train_loss 1.0483 
2023-12-05 20:10:17.961640: val_loss 1.1673 
2023-12-05 20:10:17.961733: Pseudo dice [0.8501] 
2023-12-05 20:10:17.961824: Epoch time: 52.03 s 
2023-12-05 20:10:19.734322:  
2023-12-05 20:10:19.734847: Epoch 227 
2023-12-05 20:10:19.734968: Current learning rate: 0.00793 
2023-12-05 20:11:11.776906: train_loss 1.0499 
2023-12-05 20:11:11.777200: val_loss 1.1328 
2023-12-05 20:11:11.777286: Pseudo dice [0.8773] 
2023-12-05 20:11:11.777371: Epoch time: 52.04 s 
2023-12-05 20:11:13.310330:  
2023-12-05 20:11:13.310641: Epoch 228 
2023-12-05 20:11:13.310755: Current learning rate: 0.00792 
2023-12-05 20:12:05.047032: train_loss 1.0506 
2023-12-05 20:12:05.047491: val_loss 1.1469 
2023-12-05 20:12:05.047659: Pseudo dice [0.8674] 
2023-12-05 20:12:05.047772: Epoch time: 51.74 s 
2023-12-05 20:12:06.592963:  
2023-12-05 20:12:06.593548: Epoch 229 
2023-12-05 20:12:06.594053: Current learning rate: 0.00791 
2023-12-05 20:12:58.416026: train_loss 1.0496 
2023-12-05 20:12:58.416291: val_loss 1.1444 
2023-12-05 20:12:58.416380: Pseudo dice [0.8688] 
2023-12-05 20:12:58.416464: Epoch time: 51.83 s 
2023-12-05 20:12:58.416533: Yayy! New best EMA pseudo Dice: 0.8648 
2023-12-05 20:13:01.160191:  
2023-12-05 20:13:01.160408: Epoch 230 
2023-12-05 20:13:01.160502: Current learning rate: 0.0079 
2023-12-05 20:13:52.896353: train_loss 1.0487 
2023-12-05 20:13:52.896609: val_loss 1.1516 
2023-12-05 20:13:52.896688: Pseudo dice [0.8616] 
2023-12-05 20:13:52.896765: Epoch time: 51.74 s 
2023-12-05 20:13:54.428447:  
2023-12-05 20:13:54.428740: Epoch 231 
2023-12-05 20:13:54.428856: Current learning rate: 0.00789 
2023-12-05 20:14:46.425318: train_loss 1.0492 
2023-12-05 20:14:46.425576: val_loss 1.1481 
2023-12-05 20:14:46.425658: Pseudo dice [0.865] 
2023-12-05 20:14:46.425737: Epoch time: 52.0 s 
2023-12-05 20:14:47.971743:  
2023-12-05 20:14:47.972065: Epoch 232 
2023-12-05 20:14:47.972211: Current learning rate: 0.00789 
2023-12-05 20:15:39.824800: train_loss 1.0485 
2023-12-05 20:15:39.825043: val_loss 1.1459 
2023-12-05 20:15:39.825125: Pseudo dice [0.8675] 
2023-12-05 20:15:39.825198: Epoch time: 51.86 s 
2023-12-05 20:15:39.825256: Yayy! New best EMA pseudo Dice: 0.8648 
2023-12-05 20:15:42.937922:  
2023-12-05 20:15:42.938246: Epoch 233 
2023-12-05 20:15:42.938370: Current learning rate: 0.00788 
2023-12-05 20:16:34.546238: train_loss 1.0475 
2023-12-05 20:16:34.546509: val_loss 1.1458 
2023-12-05 20:16:34.546606: Pseudo dice [0.866] 
2023-12-05 20:16:34.546702: Epoch time: 51.61 s 
2023-12-05 20:16:34.546780: Yayy! New best EMA pseudo Dice: 0.8649 
2023-12-05 20:16:37.498094:  
2023-12-05 20:16:37.498262: Epoch 234 
2023-12-05 20:16:37.498372: Current learning rate: 0.00787 
2023-12-05 20:17:29.151358: train_loss 1.0488 
2023-12-05 20:17:29.151716: val_loss 1.1445 
2023-12-05 20:17:29.151814: Pseudo dice [0.8677] 
2023-12-05 20:17:29.151905: Epoch time: 51.66 s 
2023-12-05 20:17:29.151971: Yayy! New best EMA pseudo Dice: 0.8652 
2023-12-05 20:17:31.794093:  
2023-12-05 20:17:31.794369: Epoch 235 
2023-12-05 20:17:31.794456: Current learning rate: 0.00786 
2023-12-05 20:18:23.603417: train_loss 1.047 
2023-12-05 20:18:23.603683: val_loss 1.1534 
2023-12-05 20:18:23.603764: Pseudo dice [0.8614] 
2023-12-05 20:18:23.603842: Epoch time: 51.81 s 
2023-12-05 20:18:25.148845:  
2023-12-05 20:18:25.149022: Epoch 236 
2023-12-05 20:18:25.149133: Current learning rate: 0.00785 
2023-12-05 20:19:16.971547: train_loss 1.0483 
2023-12-05 20:19:16.971822: val_loss 1.1575 
2023-12-05 20:19:16.971907: Pseudo dice [0.8581] 
2023-12-05 20:19:16.971987: Epoch time: 51.82 s 
2023-12-05 20:19:18.506645:  
2023-12-05 20:19:18.506808: Epoch 237 
2023-12-05 20:19:18.506916: Current learning rate: 0.00784 
2023-12-05 20:20:10.460925: train_loss 1.0461 
2023-12-05 20:20:10.461232: val_loss 1.1496 
2023-12-05 20:20:10.461317: Pseudo dice [0.8653] 
2023-12-05 20:20:10.461401: Epoch time: 51.96 s 
2023-12-05 20:20:11.683869:  
2023-12-05 20:20:11.684038: Epoch 238 
2023-12-05 20:20:11.684131: Current learning rate: 0.00783 
2023-12-05 20:21:03.351819: train_loss 1.0461 
2023-12-05 20:21:03.352083: val_loss 1.1497 
2023-12-05 20:21:03.352167: Pseudo dice [0.8638] 
2023-12-05 20:21:03.352251: Epoch time: 51.67 s 
2023-12-05 20:21:04.776687:  
2023-12-05 20:21:04.776817: Epoch 239 
2023-12-05 20:21:04.776916: Current learning rate: 0.00782 
2023-12-05 20:21:56.563231: train_loss 1.0482 
2023-12-05 20:21:56.563485: val_loss 1.1723 
2023-12-05 20:21:56.563566: Pseudo dice [0.8456] 
2023-12-05 20:21:56.563648: Epoch time: 51.79 s 
2023-12-05 20:21:58.112986:  
2023-12-05 20:21:58.113393: Epoch 240 
2023-12-05 20:21:58.113567: Current learning rate: 0.00781 
2023-12-05 20:22:50.033687: train_loss 1.0536 
2023-12-05 20:22:50.033957: val_loss 1.1417 
2023-12-05 20:22:50.034043: Pseudo dice [0.8699] 
2023-12-05 20:22:50.034125: Epoch time: 51.92 s 
2023-12-05 20:22:51.560694:  
2023-12-05 20:22:51.560842: Epoch 241 
2023-12-05 20:22:51.560936: Current learning rate: 0.0078 
2023-12-05 20:23:43.544036: train_loss 1.0492 
2023-12-05 20:23:43.544261: val_loss 1.1498 
2023-12-05 20:23:43.544327: Pseudo dice [0.8648] 
2023-12-05 20:23:43.544392: Epoch time: 51.99 s 
2023-12-05 20:23:45.040775:  
2023-12-05 20:23:45.040920: Epoch 242 
2023-12-05 20:23:45.041032: Current learning rate: 0.00779 
2023-12-05 20:24:36.848367: train_loss 1.0479 
2023-12-05 20:24:36.848637: val_loss 1.1583 
2023-12-05 20:24:36.848721: Pseudo dice [0.8565] 
2023-12-05 20:24:36.848806: Epoch time: 51.81 s 
2023-12-05 20:24:38.418203:  
2023-12-05 20:24:38.418409: Epoch 243 
2023-12-05 20:24:38.418521: Current learning rate: 0.00778 
2023-12-05 20:25:30.400300: train_loss 1.049 
2023-12-05 20:25:30.400527: val_loss 1.1647 
2023-12-05 20:25:30.400598: Pseudo dice [0.85] 
2023-12-05 20:25:30.400667: Epoch time: 51.98 s 
2023-12-05 20:25:31.569143:  
2023-12-05 20:25:31.569289: Epoch 244 
2023-12-05 20:25:31.569383: Current learning rate: 0.00777 
2023-12-05 20:26:23.308688: train_loss 1.0483 
2023-12-05 20:26:23.308934: val_loss 1.1464 
2023-12-05 20:26:23.309001: Pseudo dice [0.8663] 
2023-12-05 20:26:23.309068: Epoch time: 51.74 s 
2023-12-05 20:26:24.497053:  
2023-12-05 20:26:24.497208: Epoch 245 
2023-12-05 20:26:24.497303: Current learning rate: 0.00777 
2023-12-05 20:27:16.495046: train_loss 1.0481 
2023-12-05 20:27:16.495327: val_loss 1.1459 
2023-12-05 20:27:16.495410: Pseudo dice [0.8658] 
2023-12-05 20:27:16.495493: Epoch time: 52.0 s 
2023-12-05 20:27:18.268133:  
2023-12-05 20:27:18.268313: Epoch 246 
2023-12-05 20:27:18.268421: Current learning rate: 0.00776 
2023-12-05 20:28:10.233894: train_loss 1.0464 
2023-12-05 20:28:10.234155: val_loss 1.1563 
2023-12-05 20:28:10.234240: Pseudo dice [0.8572] 
2023-12-05 20:28:10.234324: Epoch time: 51.97 s 
2023-12-05 20:28:11.800491:  
2023-12-05 20:28:11.800940: Epoch 247 
2023-12-05 20:28:11.801058: Current learning rate: 0.00775 
2023-12-05 20:29:03.884553: train_loss 1.0462 
2023-12-05 20:29:03.884831: val_loss 1.1477 
2023-12-05 20:29:03.884912: Pseudo dice [0.8642] 
2023-12-05 20:29:03.884996: Epoch time: 52.09 s 
2023-12-05 20:29:05.469022:  
2023-12-05 20:29:05.469388: Epoch 248 
2023-12-05 20:29:05.469517: Current learning rate: 0.00774 
2023-12-05 20:29:57.298937: train_loss 1.0476 
2023-12-05 20:29:57.299628: val_loss 1.1557 
2023-12-05 20:29:57.299721: Pseudo dice [0.8575] 
2023-12-05 20:29:57.299826: Epoch time: 51.83 s 
2023-12-05 20:29:58.468423:  
2023-12-05 20:29:58.468594: Epoch 249 
2023-12-05 20:29:58.468695: Current learning rate: 0.00773 
2023-12-05 20:30:50.223940: train_loss 1.0482 
2023-12-05 20:30:50.224219: val_loss 1.1549 
2023-12-05 20:30:50.224303: Pseudo dice [0.8588] 
2023-12-05 20:30:50.224389: Epoch time: 51.76 s 
2023-12-05 20:30:52.620790:  
2023-12-05 20:30:52.620928: Epoch 250 
2023-12-05 20:30:52.621025: Current learning rate: 0.00772 
2023-12-05 20:31:44.475513: train_loss 1.0481 
2023-12-05 20:31:44.476136: val_loss 1.1549 
2023-12-05 20:31:44.476262: Pseudo dice [0.8594] 
2023-12-05 20:31:44.476425: Epoch time: 51.86 s 
2023-12-05 20:31:46.171759:  
2023-12-05 20:31:46.171910: Epoch 251 
2023-12-05 20:31:46.172009: Current learning rate: 0.00771 
2023-12-05 20:32:38.215195: train_loss 1.0487 
2023-12-05 20:32:38.215465: val_loss 1.1613 
2023-12-05 20:32:38.215548: Pseudo dice [0.8527] 
2023-12-05 20:32:38.215630: Epoch time: 52.05 s 
2023-12-05 20:32:39.810986:  
2023-12-05 20:32:39.811170: Epoch 252 
2023-12-05 20:32:39.811287: Current learning rate: 0.0077 
2023-12-05 20:33:31.900141: train_loss 1.0529 
2023-12-05 20:33:31.900413: val_loss 1.1583 
2023-12-05 20:33:31.900498: Pseudo dice [0.8579] 
2023-12-05 20:33:31.900580: Epoch time: 52.09 s 
2023-12-05 20:33:33.468273:  
2023-12-05 20:33:33.468437: Epoch 253 
2023-12-05 20:33:33.468552: Current learning rate: 0.00769 
2023-12-05 20:34:25.485419: train_loss 1.0593 
2023-12-05 20:34:25.485656: val_loss 1.156 
2023-12-05 20:34:25.485735: Pseudo dice [0.8587] 
2023-12-05 20:34:25.485809: Epoch time: 52.02 s 
2023-12-05 20:34:26.621118:  
2023-12-05 20:34:26.621493: Epoch 254 
2023-12-05 20:34:26.621672: Current learning rate: 0.00768 
2023-12-05 20:35:18.597773: train_loss 1.0601 
2023-12-05 20:35:18.598038: val_loss 1.142 
2023-12-05 20:35:18.598120: Pseudo dice [0.8708] 
2023-12-05 20:35:18.598204: Epoch time: 51.98 s 
2023-12-05 20:35:19.951132:  
2023-12-05 20:35:19.951327: Epoch 255 
2023-12-05 20:35:19.951473: Current learning rate: 0.00767 
2023-12-05 20:36:11.944216: train_loss 1.0543 
2023-12-05 20:36:11.944461: val_loss 1.1479 
2023-12-05 20:36:11.944527: Pseudo dice [0.8653] 
2023-12-05 20:36:11.944592: Epoch time: 52.0 s 
2023-12-05 20:36:13.140823:  
2023-12-05 20:36:13.141266: Epoch 256 
2023-12-05 20:36:13.141363: Current learning rate: 0.00766 
2023-12-05 20:37:05.058701: train_loss 1.0533 
2023-12-05 20:37:05.058963: val_loss 1.1487 
2023-12-05 20:37:05.059055: Pseudo dice [0.8654] 
2023-12-05 20:37:05.059141: Epoch time: 51.92 s 
2023-12-05 20:37:06.613810:  
2023-12-05 20:37:06.613972: Epoch 257 
2023-12-05 20:37:06.614077: Current learning rate: 0.00765 
2023-12-05 20:37:58.503548: train_loss 1.0501 
2023-12-05 20:37:58.503807: val_loss 1.1512 
2023-12-05 20:37:58.503885: Pseudo dice [0.863] 
2023-12-05 20:37:58.503964: Epoch time: 51.89 s 
2023-12-05 20:38:00.264763:  
2023-12-05 20:38:00.264930: Epoch 258 
2023-12-05 20:38:00.265038: Current learning rate: 0.00764 
2023-12-05 20:38:52.392667: train_loss 1.0485 
2023-12-05 20:38:52.392927: val_loss 1.1417 
2023-12-05 20:38:52.393012: Pseudo dice [0.8699] 
2023-12-05 20:38:52.393090: Epoch time: 52.13 s 
2023-12-05 20:38:53.976651:  
2023-12-05 20:38:53.976842: Epoch 259 
2023-12-05 20:38:53.976955: Current learning rate: 0.00764 
2023-12-05 20:39:45.817264: train_loss 1.0466 
2023-12-05 20:39:45.817527: val_loss 1.1513 
2023-12-05 20:39:45.817606: Pseudo dice [0.8624] 
2023-12-05 20:39:45.817690: Epoch time: 51.84 s 
2023-12-05 20:39:47.371082:  
2023-12-05 20:39:47.371249: Epoch 260 
2023-12-05 20:39:47.371368: Current learning rate: 0.00763 
2023-12-05 20:40:39.109456: train_loss 1.0474 
2023-12-05 20:40:39.109684: val_loss 1.1522 
2023-12-05 20:40:39.109750: Pseudo dice [0.8622] 
2023-12-05 20:40:39.109818: Epoch time: 51.74 s 
2023-12-05 20:40:40.654372:  
2023-12-05 20:40:40.654805: Epoch 261 
2023-12-05 20:40:40.655067: Current learning rate: 0.00762 
2023-12-05 20:41:32.646471: train_loss 1.047 
2023-12-05 20:41:32.646733: val_loss 1.149 
2023-12-05 20:41:32.646827: Pseudo dice [0.8642] 
2023-12-05 20:41:32.646919: Epoch time: 51.99 s 
2023-12-05 20:41:34.251314:  
2023-12-05 20:41:34.251480: Epoch 262 
2023-12-05 20:41:34.251594: Current learning rate: 0.00761 
2023-12-05 20:42:26.156761: train_loss 1.0469 
2023-12-05 20:42:26.157030: val_loss 1.1533 
2023-12-05 20:42:26.157210: Pseudo dice [0.8613] 
2023-12-05 20:42:26.157299: Epoch time: 51.91 s 
2023-12-05 20:42:27.498361:  
2023-12-05 20:42:27.498867: Epoch 263 
2023-12-05 20:42:27.499086: Current learning rate: 0.0076 
2023-12-05 20:43:19.524478: train_loss 1.0453 
2023-12-05 20:43:19.524749: val_loss 1.1518 
2023-12-05 20:43:19.524828: Pseudo dice [0.8619] 
2023-12-05 20:43:19.524909: Epoch time: 52.03 s 
2023-12-05 20:43:21.277229:  
2023-12-05 20:43:21.277403: Epoch 264 
2023-12-05 20:43:21.277511: Current learning rate: 0.00759 
2023-12-05 20:44:13.382859: train_loss 1.0475 
2023-12-05 20:44:13.383144: val_loss 1.1474 
2023-12-05 20:44:13.383228: Pseudo dice [0.8652] 
2023-12-05 20:44:13.383308: Epoch time: 52.11 s 
2023-12-05 20:44:14.978544:  
2023-12-05 20:44:14.978719: Epoch 265 
2023-12-05 20:44:14.978827: Current learning rate: 0.00758 
2023-12-05 20:45:06.892615: train_loss 1.0469 
2023-12-05 20:45:06.893106: val_loss 1.1433 
2023-12-05 20:45:06.893196: Pseudo dice [0.8697] 
2023-12-05 20:45:06.893282: Epoch time: 51.92 s 
2023-12-05 20:45:08.290318:  
2023-12-05 20:45:08.290456: Epoch 266 
2023-12-05 20:45:08.290550: Current learning rate: 0.00757 
2023-12-05 20:46:00.296729: train_loss 1.0462 
2023-12-05 20:46:00.296996: val_loss 1.1473 
2023-12-05 20:46:00.297077: Pseudo dice [0.8676] 
2023-12-05 20:46:00.297162: Epoch time: 52.01 s 
2023-12-05 20:46:01.859837:  
2023-12-05 20:46:01.860019: Epoch 267 
2023-12-05 20:46:01.860140: Current learning rate: 0.00756 
2023-12-05 20:46:53.750706: train_loss 1.045 
2023-12-05 20:46:53.750929: val_loss 1.1487 
2023-12-05 20:46:53.750996: Pseudo dice [0.8615] 
2023-12-05 20:46:53.751082: Epoch time: 51.89 s 
2023-12-05 20:46:54.928819:  
2023-12-05 20:46:54.928948: Epoch 268 
2023-12-05 20:46:54.929047: Current learning rate: 0.00755 
2023-12-05 20:47:46.841139: train_loss 1.0455 
2023-12-05 20:47:46.841392: val_loss 1.144 
2023-12-05 20:47:46.841469: Pseudo dice [0.8681] 
2023-12-05 20:47:46.841546: Epoch time: 51.91 s 
2023-12-05 20:47:48.411485:  
2023-12-05 20:47:48.411927: Epoch 269 
2023-12-05 20:47:48.412082: Current learning rate: 0.00754 
2023-12-05 20:48:40.431637: train_loss 1.0442 
2023-12-05 20:48:40.431929: val_loss 1.149 
2023-12-05 20:48:40.432021: Pseudo dice [0.8644] 
2023-12-05 20:48:40.432113: Epoch time: 52.02 s 
2023-12-05 20:48:42.194437:  
2023-12-05 20:48:42.194681: Epoch 270 
2023-12-05 20:48:42.194851: Current learning rate: 0.00753 
2023-12-05 20:49:33.950804: train_loss 1.0448 
2023-12-05 20:49:33.951047: val_loss 1.1422 
2023-12-05 20:49:33.951124: Pseudo dice [0.8698] 
2023-12-05 20:49:33.951191: Epoch time: 51.76 s 
2023-12-05 20:49:35.502544:  
2023-12-05 20:49:35.503167: Epoch 271 
2023-12-05 20:49:35.503512: Current learning rate: 0.00752 
2023-12-05 20:50:27.443691: train_loss 1.0454 
2023-12-05 20:50:27.443923: val_loss 1.1606 
2023-12-05 20:50:27.443991: Pseudo dice [0.8553] 
2023-12-05 20:50:27.444055: Epoch time: 51.94 s 
2023-12-05 20:50:28.941444:  
2023-12-05 20:50:28.941849: Epoch 272 
2023-12-05 20:50:28.942493: Current learning rate: 0.00751 
2023-12-05 20:51:20.854293: train_loss 1.0448 
2023-12-05 20:51:20.854558: val_loss 1.1529 
2023-12-05 20:51:20.854640: Pseudo dice [0.8606] 
2023-12-05 20:51:20.854721: Epoch time: 51.92 s 
2023-12-05 20:51:22.415106:  
2023-12-05 20:51:22.415319: Epoch 273 
2023-12-05 20:51:22.415426: Current learning rate: 0.00751 
2023-12-05 20:52:14.433254: train_loss 1.0438 
2023-12-05 20:52:14.433530: val_loss 1.1509 
2023-12-05 20:52:14.433613: Pseudo dice [0.8627] 
2023-12-05 20:52:14.433859: Epoch time: 52.02 s 
2023-12-05 20:52:15.641894:  
2023-12-05 20:52:15.642031: Epoch 274 
2023-12-05 20:52:15.642127: Current learning rate: 0.0075 
2023-12-05 20:53:07.690314: train_loss 1.0445 
2023-12-05 20:53:07.690569: val_loss 1.1443 
2023-12-05 20:53:07.690645: Pseudo dice [0.8667] 
2023-12-05 20:53:07.690724: Epoch time: 52.05 s 
2023-12-05 20:53:09.248263:  
2023-12-05 20:53:09.248435: Epoch 275 
2023-12-05 20:53:09.248549: Current learning rate: 0.00749 
2023-12-05 20:54:01.238548: train_loss 1.0491 
2023-12-05 20:54:01.238774: val_loss 1.1437 
2023-12-05 20:54:01.238837: Pseudo dice [0.8699] 
2023-12-05 20:54:01.238903: Epoch time: 51.99 s 
2023-12-05 20:54:02.550952:  
2023-12-05 20:54:02.551218: Epoch 276 
2023-12-05 20:54:02.551323: Current learning rate: 0.00748 
2023-12-05 20:54:54.455544: train_loss 1.0467 
2023-12-05 20:54:54.455800: val_loss 1.1328 
2023-12-05 20:54:54.455883: Pseudo dice [0.8778] 
2023-12-05 20:54:54.455964: Epoch time: 51.91 s 
2023-12-05 20:54:54.456031: Yayy! New best EMA pseudo Dice: 0.8657 
2023-12-05 20:54:57.363614:  
2023-12-05 20:54:57.364218: Epoch 277 
2023-12-05 20:54:57.364491: Current learning rate: 0.00747 
2023-12-05 20:55:49.088796: train_loss 1.0449 
2023-12-05 20:55:49.089035: val_loss 1.149 
2023-12-05 20:55:49.089102: Pseudo dice [0.8637] 
2023-12-05 20:55:49.089170: Epoch time: 51.73 s 
2023-12-05 20:55:50.258872:  
2023-12-05 20:55:50.259253: Epoch 278 
2023-12-05 20:55:50.259341: Current learning rate: 0.00746 
2023-12-05 20:56:42.259772: train_loss 1.0467 
2023-12-05 20:56:42.260111: val_loss 1.1407 
2023-12-05 20:56:42.260218: Pseudo dice [0.8696] 
2023-12-05 20:56:42.260325: Epoch time: 52.0 s 
2023-12-05 20:56:42.260410: Yayy! New best EMA pseudo Dice: 0.8659 
2023-12-05 20:56:45.204864:  
2023-12-05 20:56:45.205225: Epoch 279 
2023-12-05 20:56:45.205377: Current learning rate: 0.00745 
2023-12-05 20:57:36.904351: train_loss 1.0451 
2023-12-05 20:57:36.904628: val_loss 1.1459 
2023-12-05 20:57:36.904709: Pseudo dice [0.8663] 
2023-12-05 20:57:36.904795: Epoch time: 51.7 s 
2023-12-05 20:57:36.904865: Yayy! New best EMA pseudo Dice: 0.8659 
2023-12-05 20:57:39.543449:  
2023-12-05 20:57:39.543585: Epoch 280 
2023-12-05 20:57:39.543688: Current learning rate: 0.00744 
2023-12-05 20:58:31.134961: train_loss 1.044 
2023-12-05 20:58:31.135357: val_loss 1.1466 
2023-12-05 20:58:31.135442: Pseudo dice [0.8665] 
2023-12-05 20:58:31.135529: Epoch time: 51.59 s 
2023-12-05 20:58:31.135594: Yayy! New best EMA pseudo Dice: 0.866 
2023-12-05 20:58:34.290850:  
2023-12-05 20:58:34.291040: Epoch 281 
2023-12-05 20:58:34.291162: Current learning rate: 0.00743 
2023-12-05 20:59:26.196088: train_loss 1.0436 
2023-12-05 20:59:26.196314: val_loss 1.1387 
2023-12-05 20:59:26.196379: Pseudo dice [0.8723] 
2023-12-05 20:59:26.196445: Epoch time: 51.91 s 
2023-12-05 20:59:26.196494: Yayy! New best EMA pseudo Dice: 0.8666 
2023-12-05 20:59:28.661571:  
2023-12-05 20:59:28.661795: Epoch 282 
2023-12-05 20:59:28.661897: Current learning rate: 0.00742 
2023-12-05 21:00:20.391164: train_loss 1.0436 
2023-12-05 21:00:20.391401: val_loss 1.1585 
2023-12-05 21:00:20.391469: Pseudo dice [0.8574] 
2023-12-05 21:00:20.391540: Epoch time: 51.73 s 
2023-12-05 21:00:21.954772:  
2023-12-05 21:00:21.954941: Epoch 283 
2023-12-05 21:00:21.955068: Current learning rate: 0.00741 
2023-12-05 21:01:13.821177: train_loss 1.0444 
2023-12-05 21:01:13.821415: val_loss 1.1341 
2023-12-05 21:01:13.821484: Pseudo dice [0.8766] 
2023-12-05 21:01:13.821552: Epoch time: 51.87 s 
2023-12-05 21:01:13.821604: Yayy! New best EMA pseudo Dice: 0.8668 
2023-12-05 21:01:16.681354:  
2023-12-05 21:01:16.681518: Epoch 284 
2023-12-05 21:01:16.681633: Current learning rate: 0.0074 
2023-12-05 21:02:08.635852: train_loss 1.045 
2023-12-05 21:02:08.636117: val_loss 1.1489 
2023-12-05 21:02:08.636199: Pseudo dice [0.8644] 
2023-12-05 21:02:08.636281: Epoch time: 51.96 s 
2023-12-05 21:02:10.241598:  
2023-12-05 21:02:10.241899: Epoch 285 
2023-12-05 21:02:10.242263: Current learning rate: 0.00739 
2023-12-05 21:03:02.096777: train_loss 1.0446 
2023-12-05 21:03:02.097037: val_loss 1.1649 
2023-12-05 21:03:02.097120: Pseudo dice [0.8514] 
2023-12-05 21:03:02.097203: Epoch time: 51.86 s 
2023-12-05 21:03:03.387468:  
2023-12-05 21:03:03.387599: Epoch 286 
2023-12-05 21:03:03.387692: Current learning rate: 0.00738 
2023-12-05 21:03:55.392371: train_loss 1.0458 
2023-12-05 21:03:55.392634: val_loss 1.1421 
2023-12-05 21:03:55.392715: Pseudo dice [0.8701] 
2023-12-05 21:03:55.392797: Epoch time: 52.01 s 
2023-12-05 21:03:56.774053:  
2023-12-05 21:03:56.774201: Epoch 287 
2023-12-05 21:03:56.774298: Current learning rate: 0.00738 
2023-12-05 21:04:48.720861: train_loss 1.0455 
2023-12-05 21:04:48.721270: val_loss 1.1516 
2023-12-05 21:04:48.721357: Pseudo dice [0.8631] 
2023-12-05 21:04:48.721441: Epoch time: 51.95 s 
2023-12-05 21:04:50.110884:  
2023-12-05 21:04:50.111296: Epoch 288 
2023-12-05 21:04:50.111392: Current learning rate: 0.00737 
2023-12-05 21:05:42.069443: train_loss 1.0453 
2023-12-05 21:05:42.069700: val_loss 1.1456 
2023-12-05 21:05:42.069783: Pseudo dice [0.8672] 
2023-12-05 21:05:42.069868: Epoch time: 51.96 s 
2023-12-05 21:05:43.503633:  
2023-12-05 21:05:43.503769: Epoch 289 
2023-12-05 21:05:43.503860: Current learning rate: 0.00736 
2023-12-05 21:06:35.085112: train_loss 1.0441 
2023-12-05 21:06:35.085341: val_loss 1.1479 
2023-12-05 21:06:35.085406: Pseudo dice [0.8661] 
2023-12-05 21:06:35.085467: Epoch time: 51.58 s 
2023-12-05 21:06:36.235888:  
2023-12-05 21:06:36.236283: Epoch 290 
2023-12-05 21:06:36.236375: Current learning rate: 0.00735 
2023-12-05 21:07:28.262144: train_loss 1.0433 
2023-12-05 21:07:28.262513: val_loss 1.1454 
2023-12-05 21:07:28.262642: Pseudo dice [0.8682] 
2023-12-05 21:07:28.262772: Epoch time: 52.03 s 
2023-12-05 21:07:29.500376:  
2023-12-05 21:07:29.500511: Epoch 291 
2023-12-05 21:07:29.500609: Current learning rate: 0.00734 
2023-12-05 21:08:21.384295: train_loss 1.0434 
2023-12-05 21:08:21.384580: val_loss 1.1409 
2023-12-05 21:08:21.384677: Pseudo dice [0.8703] 
2023-12-05 21:08:21.384774: Epoch time: 51.89 s 
2023-12-05 21:08:22.962866:  
2023-12-05 21:08:22.963104: Epoch 292 
2023-12-05 21:08:22.963197: Current learning rate: 0.00733 
2023-12-05 21:09:14.831105: train_loss 1.0442 
2023-12-05 21:09:14.831612: val_loss 1.1468 
2023-12-05 21:09:14.831807: Pseudo dice [0.8659] 
2023-12-05 21:09:14.832005: Epoch time: 51.87 s 
2023-12-05 21:09:16.636962:  
2023-12-05 21:09:16.637186: Epoch 293 
2023-12-05 21:09:16.637388: Current learning rate: 0.00732 
2023-12-05 21:10:08.291549: train_loss 1.0435 
2023-12-05 21:10:08.291786: val_loss 1.1432 
2023-12-05 21:10:08.291861: Pseudo dice [0.8683] 
2023-12-05 21:10:08.291929: Epoch time: 51.66 s 
2023-12-05 21:10:09.478481:  
2023-12-05 21:10:09.478675: Epoch 294 
2023-12-05 21:10:09.478765: Current learning rate: 0.00731 
2023-12-05 21:11:01.138397: train_loss 1.0435 
2023-12-05 21:11:01.138662: val_loss 1.1538 
2023-12-05 21:11:01.138750: Pseudo dice [0.86] 
2023-12-05 21:11:01.138834: Epoch time: 51.66 s 
2023-12-05 21:11:02.740257:  
2023-12-05 21:11:02.740482: Epoch 295 
2023-12-05 21:11:02.740596: Current learning rate: 0.0073 
2023-12-05 21:11:54.452596: train_loss 1.0442 
2023-12-05 21:11:54.452828: val_loss 1.155 
2023-12-05 21:11:54.452896: Pseudo dice [0.8591] 
2023-12-05 21:11:54.452965: Epoch time: 51.71 s 
2023-12-05 21:11:55.638511:  
2023-12-05 21:11:55.638794: Epoch 296 
2023-12-05 21:11:55.638891: Current learning rate: 0.00729 
2023-12-05 21:12:47.550448: train_loss 1.0442 
2023-12-05 21:12:47.550674: val_loss 1.1448 
2023-12-05 21:12:47.550745: Pseudo dice [0.8665] 
2023-12-05 21:12:47.550814: Epoch time: 51.91 s 
2023-12-05 21:12:48.756868:  
2023-12-05 21:12:48.757029: Epoch 297 
2023-12-05 21:12:48.757124: Current learning rate: 0.00728 
2023-12-05 21:13:40.805731: train_loss 1.0431 
2023-12-05 21:13:40.805959: val_loss 1.1425 
2023-12-05 21:13:40.806028: Pseudo dice [0.8695] 
2023-12-05 21:13:40.806098: Epoch time: 52.05 s 
2023-12-05 21:13:42.007630:  
2023-12-05 21:13:42.007765: Epoch 298 
2023-12-05 21:13:42.007857: Current learning rate: 0.00727 
2023-12-05 21:14:33.825148: train_loss 1.0421 
2023-12-05 21:14:33.825380: val_loss 1.1459 
2023-12-05 21:14:33.825446: Pseudo dice [0.8657] 
2023-12-05 21:14:33.825517: Epoch time: 51.82 s 
2023-12-05 21:14:35.146459:  
2023-12-05 21:14:35.146596: Epoch 299 
2023-12-05 21:14:35.146690: Current learning rate: 0.00726 
2023-12-05 21:15:27.066214: train_loss 1.0444 
2023-12-05 21:15:27.066433: val_loss 1.1536 
2023-12-05 21:15:27.066498: Pseudo dice [0.8612] 
2023-12-05 21:15:27.066564: Epoch time: 51.92 s 
2023-12-05 21:15:29.660763:  
2023-12-05 21:15:29.660902: Epoch 300 
2023-12-05 21:15:29.661005: Current learning rate: 0.00725 
2023-12-05 21:16:21.387040: train_loss 1.0449 
2023-12-05 21:16:21.387295: val_loss 1.1477 
2023-12-05 21:16:21.387381: Pseudo dice [0.8648] 
2023-12-05 21:16:21.387477: Epoch time: 51.73 s 
2023-12-05 21:16:22.970761:  
2023-12-05 21:16:22.970928: Epoch 301 
2023-12-05 21:16:22.971047: Current learning rate: 0.00724 
2023-12-05 21:17:14.882304: train_loss 1.0433 
2023-12-05 21:17:14.882622: val_loss 1.1516 
2023-12-05 21:17:14.882713: Pseudo dice [0.861] 
2023-12-05 21:17:14.882795: Epoch time: 51.91 s 
2023-12-05 21:17:16.469231:  
2023-12-05 21:17:16.469410: Epoch 302 
2023-12-05 21:17:16.469526: Current learning rate: 0.00724 
2023-12-05 21:18:08.479949: train_loss 1.0457 
2023-12-05 21:18:08.480216: val_loss 1.151 
2023-12-05 21:18:08.480297: Pseudo dice [0.862] 
2023-12-05 21:18:08.480378: Epoch time: 52.01 s 
2023-12-05 21:18:09.779471:  
2023-12-05 21:18:09.779598: Epoch 303 
2023-12-05 21:18:09.779689: Current learning rate: 0.00723 
2023-12-05 21:19:01.765114: train_loss 1.046 
2023-12-05 21:19:01.765402: val_loss 1.1452 
2023-12-05 21:19:01.765484: Pseudo dice [0.8682] 
2023-12-05 21:19:01.765569: Epoch time: 51.99 s 
2023-12-05 21:19:03.344993:  
2023-12-05 21:19:03.345163: Epoch 304 
2023-12-05 21:19:03.345277: Current learning rate: 0.00722 
2023-12-05 21:19:55.271127: train_loss 1.0434 
2023-12-05 21:19:55.271405: val_loss 1.1432 
2023-12-05 21:19:55.271484: Pseudo dice [0.8693] 
2023-12-05 21:19:55.271567: Epoch time: 51.93 s 
2023-12-05 21:19:57.102507:  
2023-12-05 21:19:57.103067: Epoch 305 
2023-12-05 21:19:57.103199: Current learning rate: 0.00721 
2023-12-05 21:20:49.032632: train_loss 1.0442 
2023-12-05 21:20:49.032905: val_loss 1.1432 
2023-12-05 21:20:49.032985: Pseudo dice [0.8684] 
2023-12-05 21:20:49.033064: Epoch time: 51.93 s 
2023-12-05 21:20:50.391451:  
2023-12-05 21:20:50.391659: Epoch 306 
2023-12-05 21:20:50.391756: Current learning rate: 0.0072 
2023-12-05 21:21:42.090248: train_loss 1.043 
2023-12-05 21:21:42.090488: val_loss 1.1456 
2023-12-05 21:21:42.090554: Pseudo dice [0.867] 
2023-12-05 21:21:42.090622: Epoch time: 51.7 s 
2023-12-05 21:21:43.695025:  
2023-12-05 21:21:43.695250: Epoch 307 
2023-12-05 21:21:43.695364: Current learning rate: 0.00719 
2023-12-05 21:22:35.500952: train_loss 1.0429 
2023-12-05 21:22:35.501230: val_loss 1.136 
2023-12-05 21:22:35.501314: Pseudo dice [0.8735] 
2023-12-05 21:22:35.501415: Epoch time: 51.81 s 
2023-12-05 21:22:37.086185:  
2023-12-05 21:22:37.086397: Epoch 308 
2023-12-05 21:22:37.086498: Current learning rate: 0.00718 
2023-12-05 21:23:28.943329: train_loss 1.0448 
2023-12-05 21:23:28.943590: val_loss 1.1475 
2023-12-05 21:23:28.943681: Pseudo dice [0.8664] 
2023-12-05 21:23:28.943778: Epoch time: 51.86 s 
2023-12-05 21:23:30.535554:  
2023-12-05 21:23:30.535708: Epoch 309 
2023-12-05 21:23:30.535824: Current learning rate: 0.00717 
2023-12-05 21:24:22.498095: train_loss 1.0443 
2023-12-05 21:24:22.498316: val_loss 1.1504 
2023-12-05 21:24:22.498381: Pseudo dice [0.8639] 
2023-12-05 21:24:22.498446: Epoch time: 51.96 s 
2023-12-05 21:24:23.667844:  
2023-12-05 21:24:23.668126: Epoch 310 
2023-12-05 21:24:23.668216: Current learning rate: 0.00716 
2023-12-05 21:25:15.618489: train_loss 1.0473 
2023-12-05 21:25:15.618759: val_loss 1.154 
2023-12-05 21:25:15.618841: Pseudo dice [0.8599] 
2023-12-05 21:25:15.618924: Epoch time: 51.95 s 
2023-12-05 21:25:17.408838:  
2023-12-05 21:25:17.409004: Epoch 311 
2023-12-05 21:25:17.409113: Current learning rate: 0.00715 
2023-12-05 21:26:09.469217: train_loss 1.0461 
2023-12-05 21:26:09.469559: val_loss 1.1429 
2023-12-05 21:26:09.469640: Pseudo dice [0.8682] 
2023-12-05 21:26:09.469724: Epoch time: 52.06 s 
2023-12-05 21:26:10.951400:  
2023-12-05 21:26:10.951541: Epoch 312 
2023-12-05 21:26:10.951637: Current learning rate: 0.00714 
2023-12-05 21:27:02.882885: train_loss 1.0454 
2023-12-05 21:27:02.883142: val_loss 1.1435 
2023-12-05 21:27:02.883210: Pseudo dice [0.8678] 
2023-12-05 21:27:02.883277: Epoch time: 51.93 s 
2023-12-05 21:27:04.091727:  
2023-12-05 21:27:04.091865: Epoch 313 
2023-12-05 21:27:04.091956: Current learning rate: 0.00713 
2023-12-05 21:27:56.083142: train_loss 1.0432 
2023-12-05 21:27:56.083404: val_loss 1.1398 
2023-12-05 21:27:56.083489: Pseudo dice [0.873] 
2023-12-05 21:27:56.083570: Epoch time: 51.99 s 
2023-12-05 21:27:57.691438:  
2023-12-05 21:27:57.691656: Epoch 314 
2023-12-05 21:27:57.691789: Current learning rate: 0.00712 
2023-12-05 21:28:49.492294: train_loss 1.0428 
2023-12-05 21:28:49.492798: val_loss 1.1622 
2023-12-05 21:28:49.492941: Pseudo dice [0.8525] 
2023-12-05 21:28:49.493054: Epoch time: 51.8 s 
2023-12-05 21:28:51.103978:  
2023-12-05 21:28:51.104126: Epoch 315 
2023-12-05 21:28:51.104501: Current learning rate: 0.00711 
2023-12-05 21:29:42.918558: train_loss 1.0418 
2023-12-05 21:29:42.918821: val_loss 1.1586 
2023-12-05 21:29:42.918900: Pseudo dice [0.8565] 
2023-12-05 21:29:42.918979: Epoch time: 51.82 s 
2023-12-05 21:29:44.519530:  
2023-12-05 21:29:44.519680: Epoch 316 
2023-12-05 21:29:44.519794: Current learning rate: 0.0071 
2023-12-05 21:30:36.426053: train_loss 1.0441 
2023-12-05 21:30:36.426390: val_loss 1.1654 
2023-12-05 21:30:36.426500: Pseudo dice [0.8513] 
2023-12-05 21:30:36.426632: Epoch time: 51.91 s 
2023-12-05 21:30:37.791885:  
2023-12-05 21:30:37.792029: Epoch 317 
2023-12-05 21:30:37.792115: Current learning rate: 0.0071 
2023-12-05 21:31:29.659116: train_loss 1.0438 
2023-12-05 21:31:29.659384: val_loss 1.1563 
2023-12-05 21:31:29.659467: Pseudo dice [0.8583] 
2023-12-05 21:31:29.659553: Epoch time: 51.87 s 
2023-12-05 21:31:31.189745:  
2023-12-05 21:31:31.189875: Epoch 318 
2023-12-05 21:31:31.189961: Current learning rate: 0.00709 
2023-12-05 21:32:23.166428: train_loss 1.0435 
2023-12-05 21:32:23.166661: val_loss 1.1449 
2023-12-05 21:32:23.166727: Pseudo dice [0.8663] 
2023-12-05 21:32:23.166793: Epoch time: 51.98 s 
2023-12-05 21:32:24.340297:  
2023-12-05 21:32:24.340441: Epoch 319 
2023-12-05 21:32:24.340543: Current learning rate: 0.00708 
2023-12-05 21:33:16.110961: train_loss 1.0449 
2023-12-05 21:33:16.111204: val_loss 1.1538 
2023-12-05 21:33:16.111293: Pseudo dice [0.8586] 
2023-12-05 21:33:16.111362: Epoch time: 51.77 s 
2023-12-05 21:33:17.296510:  
2023-12-05 21:33:17.296788: Epoch 320 
2023-12-05 21:33:17.296885: Current learning rate: 0.00707 
2023-12-05 21:34:09.101603: train_loss 1.0448 
2023-12-05 21:34:09.101867: val_loss 1.1444 
2023-12-05 21:34:09.101944: Pseudo dice [0.867] 
2023-12-05 21:34:09.102024: Epoch time: 51.81 s 
2023-12-05 21:34:10.949951:  
2023-12-05 21:34:10.950173: Epoch 321 
2023-12-05 21:34:10.950292: Current learning rate: 0.00706 
2023-12-05 21:35:02.790057: train_loss 1.0447 
2023-12-05 21:35:02.790299: val_loss 1.1437 
2023-12-05 21:35:02.790366: Pseudo dice [0.868] 
2023-12-05 21:35:02.790437: Epoch time: 51.84 s 
2023-12-05 21:35:04.033127:  
2023-12-05 21:35:04.033263: Epoch 322 
2023-12-05 21:35:04.033366: Current learning rate: 0.00705 
2023-12-05 21:35:55.742615: train_loss 1.0439 
2023-12-05 21:35:55.742884: val_loss 1.1451 
2023-12-05 21:35:55.742952: Pseudo dice [0.8668] 
2023-12-05 21:35:55.743032: Epoch time: 51.71 s 
2023-12-05 21:35:57.098644:  
2023-12-05 21:35:57.098870: Epoch 323 
2023-12-05 21:35:57.098969: Current learning rate: 0.00704 
2023-12-05 21:36:48.950734: train_loss 1.0443 
2023-12-05 21:36:48.950998: val_loss 1.1446 
2023-12-05 21:36:48.951099: Pseudo dice [0.8676] 
2023-12-05 21:36:48.951178: Epoch time: 51.85 s 
2023-12-05 21:36:50.559006:  
2023-12-05 21:36:50.559180: Epoch 324 
2023-12-05 21:36:50.559295: Current learning rate: 0.00703 
2023-12-05 21:37:42.646741: train_loss 1.0426 
2023-12-05 21:37:42.647003: val_loss 1.1406 
2023-12-05 21:37:42.647096: Pseudo dice [0.8709] 
2023-12-05 21:37:42.647175: Epoch time: 52.09 s 
2023-12-05 21:37:44.235223:  
2023-12-05 21:37:44.235492: Epoch 325 
2023-12-05 21:37:44.235608: Current learning rate: 0.00702 
2023-12-05 21:38:36.178294: train_loss 1.042 
2023-12-05 21:38:36.178530: val_loss 1.1535 
2023-12-05 21:38:36.178736: Pseudo dice [0.8596] 
2023-12-05 21:38:36.178807: Epoch time: 51.95 s 
2023-12-05 21:38:37.388724:  
2023-12-05 21:38:37.389180: Epoch 326 
2023-12-05 21:38:37.389278: Current learning rate: 0.00701 
2023-12-05 21:39:29.170976: train_loss 1.0421 
2023-12-05 21:39:29.171256: val_loss 1.1467 
2023-12-05 21:39:29.171339: Pseudo dice [0.8658] 
2023-12-05 21:39:29.171423: Epoch time: 51.78 s 
2023-12-05 21:39:30.604763:  
2023-12-05 21:39:30.604959: Epoch 327 
2023-12-05 21:39:30.605050: Current learning rate: 0.007 
2023-12-05 21:40:22.402972: train_loss 1.0427 
2023-12-05 21:40:22.403198: val_loss 1.155 
2023-12-05 21:40:22.403267: Pseudo dice [0.8583] 
2023-12-05 21:40:22.403345: Epoch time: 51.8 s 
2023-12-05 21:40:23.994913:  
2023-12-05 21:40:23.995089: Epoch 328 
2023-12-05 21:40:23.995208: Current learning rate: 0.00699 
2023-12-05 21:41:15.921043: train_loss 1.0415 
2023-12-05 21:41:15.921319: val_loss 1.148 
2023-12-05 21:41:15.921401: Pseudo dice [0.8646] 
2023-12-05 21:41:15.921483: Epoch time: 51.93 s 
2023-12-05 21:41:17.644454:  
2023-12-05 21:41:17.644614: Epoch 329 
2023-12-05 21:41:17.644711: Current learning rate: 0.00698 
2023-12-05 21:42:09.490901: train_loss 1.0416 
2023-12-05 21:42:09.491175: val_loss 1.1437 
2023-12-05 21:42:09.491261: Pseudo dice [0.8695] 
2023-12-05 21:42:09.491342: Epoch time: 51.85 s 
2023-12-05 21:42:11.076001:  
2023-12-05 21:42:11.076165: Epoch 330 
2023-12-05 21:42:11.076277: Current learning rate: 0.00697 
2023-12-05 21:43:03.072618: train_loss 1.0421 
2023-12-05 21:43:03.072888: val_loss 1.1502 
2023-12-05 21:43:03.072975: Pseudo dice [0.8625] 
2023-12-05 21:43:03.073054: Epoch time: 52.0 s 
2023-12-05 21:43:04.679314:  
2023-12-05 21:43:04.679599: Epoch 331 
2023-12-05 21:43:04.679719: Current learning rate: 0.00696 
2023-12-05 21:43:56.504830: train_loss 1.0411 
2023-12-05 21:43:56.505142: val_loss 1.1483 
2023-12-05 21:43:56.505215: Pseudo dice [0.8647] 
2023-12-05 21:43:56.505284: Epoch time: 51.83 s 
2023-12-05 21:43:57.694658:  
2023-12-05 21:43:57.694798: Epoch 332 
2023-12-05 21:43:57.694895: Current learning rate: 0.00696 
2023-12-05 21:44:49.466600: train_loss 1.0402 
2023-12-05 21:44:49.466829: val_loss 1.1501 
2023-12-05 21:44:49.466897: Pseudo dice [0.8624] 
2023-12-05 21:44:49.466964: Epoch time: 51.77 s 
2023-12-05 21:44:50.698376:  
2023-12-05 21:44:50.698639: Epoch 333 
2023-12-05 21:44:50.698756: Current learning rate: 0.00695 
2023-12-05 21:45:42.416754: train_loss 1.0414 
2023-12-05 21:45:42.416984: val_loss 1.1485 
2023-12-05 21:45:42.417048: Pseudo dice [0.8641] 
2023-12-05 21:45:42.417113: Epoch time: 51.72 s 
2023-12-05 21:45:43.616975:  
2023-12-05 21:45:43.617108: Epoch 334 
2023-12-05 21:45:43.617196: Current learning rate: 0.00694 
2023-12-05 21:46:35.309384: train_loss 1.0413 
2023-12-05 21:46:35.309612: val_loss 1.155 
2023-12-05 21:46:35.309678: Pseudo dice [0.8579] 
2023-12-05 21:46:35.309743: Epoch time: 51.69 s 
2023-12-05 21:46:36.703548:  
2023-12-05 21:46:36.703680: Epoch 335 
2023-12-05 21:46:36.703771: Current learning rate: 0.00693 
2023-12-05 21:47:28.421882: train_loss 1.0412 
2023-12-05 21:47:28.422148: val_loss 1.15 
2023-12-05 21:47:28.422228: Pseudo dice [0.862] 
2023-12-05 21:47:28.422308: Epoch time: 51.72 s 
2023-12-05 21:47:29.691656:  
2023-12-05 21:47:29.691800: Epoch 336 
2023-12-05 21:47:29.691896: Current learning rate: 0.00692 
2023-12-05 21:48:21.201351: train_loss 1.0416 
2023-12-05 21:48:21.201605: val_loss 1.1507 
2023-12-05 21:48:21.201685: Pseudo dice [0.8629] 
2023-12-05 21:48:21.201765: Epoch time: 51.51 s 
2023-12-05 21:48:22.808869:  
2023-12-05 21:48:22.809020: Epoch 337 
2023-12-05 21:48:22.809111: Current learning rate: 0.00691 
2023-12-05 21:49:14.631246: train_loss 1.0434 
2023-12-05 21:49:14.631503: val_loss 1.15 
2023-12-05 21:49:14.631585: Pseudo dice [0.8631] 
2023-12-05 21:49:14.631669: Epoch time: 51.82 s 
2023-12-05 21:49:15.859005:  
2023-12-05 21:49:15.859168: Epoch 338 
2023-12-05 21:49:15.859260: Current learning rate: 0.0069 
2023-12-05 21:50:07.338948: train_loss 1.0414 
2023-12-05 21:50:07.339218: val_loss 1.15 
2023-12-05 21:50:07.339286: Pseudo dice [0.8634] 
2023-12-05 21:50:07.339355: Epoch time: 51.48 s 
2023-12-05 21:50:08.565675:  
2023-12-05 21:50:08.565857: Epoch 339 
2023-12-05 21:50:08.565956: Current learning rate: 0.00689 
2023-12-05 21:51:00.103495: train_loss 1.0409 
2023-12-05 21:51:00.103726: val_loss 1.152 
2023-12-05 21:51:00.103815: Pseudo dice [0.862] 
2023-12-05 21:51:00.103909: Epoch time: 51.54 s 
2023-12-05 21:51:01.444786:  
2023-12-05 21:51:01.445067: Epoch 340 
2023-12-05 21:51:01.445165: Current learning rate: 0.00688 
2023-12-05 21:51:53.463462: train_loss 1.0408 
2023-12-05 21:51:53.463723: val_loss 1.1413 
2023-12-05 21:51:53.463820: Pseudo dice [0.8689] 
2023-12-05 21:51:53.463904: Epoch time: 52.02 s 
2023-12-05 21:51:54.917976:  
2023-12-05 21:51:54.918118: Epoch 341 
2023-12-05 21:51:54.918205: Current learning rate: 0.00687 
2023-12-05 21:52:46.669268: train_loss 1.0414 
2023-12-05 21:52:46.669490: val_loss 1.1453 
2023-12-05 21:52:46.669555: Pseudo dice [0.8672] 
2023-12-05 21:52:46.669618: Epoch time: 51.75 s 
2023-12-05 21:52:47.876845:  
2023-12-05 21:52:47.877003: Epoch 342 
2023-12-05 21:52:47.877097: Current learning rate: 0.00686 
2023-12-05 21:53:39.541417: train_loss 1.0419 
2023-12-05 21:53:39.541679: val_loss 1.1493 
2023-12-05 21:53:39.541758: Pseudo dice [0.8632] 
2023-12-05 21:53:39.541839: Epoch time: 51.67 s 
2023-12-05 21:53:40.837187:  
2023-12-05 21:53:40.837321: Epoch 343 
2023-12-05 21:53:40.837412: Current learning rate: 0.00685 
2023-12-05 21:54:32.825040: train_loss 1.0409 
2023-12-05 21:54:32.825267: val_loss 1.1456 
2023-12-05 21:54:32.825332: Pseudo dice [0.8673] 
2023-12-05 21:54:32.825398: Epoch time: 51.99 s 
2023-12-05 21:54:34.325207:  
2023-12-05 21:54:34.325384: Epoch 344 
2023-12-05 21:54:34.325491: Current learning rate: 0.00684 
2023-12-05 21:55:26.192676: train_loss 1.0403 
2023-12-05 21:55:26.192935: val_loss 1.1456 
2023-12-05 21:55:26.193021: Pseudo dice [0.8678] 
2023-12-05 21:55:26.193113: Epoch time: 51.87 s 
2023-12-05 21:55:27.685929:  
2023-12-05 21:55:27.686276: Epoch 345 
2023-12-05 21:55:27.686377: Current learning rate: 0.00683 
2023-12-05 21:56:19.595625: train_loss 1.0412 
2023-12-05 21:56:19.595866: val_loss 1.142 
2023-12-05 21:56:19.595935: Pseudo dice [0.8692] 
2023-12-05 21:56:19.596002: Epoch time: 51.91 s 
2023-12-05 21:56:20.775420:  
2023-12-05 21:56:20.775860: Epoch 346 
2023-12-05 21:56:20.775949: Current learning rate: 0.00682 
2023-12-05 21:57:12.743814: train_loss 1.0408 
2023-12-05 21:57:12.744034: val_loss 1.1413 
2023-12-05 21:57:12.744098: Pseudo dice [0.8705] 
2023-12-05 21:57:12.744162: Epoch time: 51.97 s 
2023-12-05 21:57:14.153174:  
2023-12-05 21:57:14.153490: Epoch 347 
2023-12-05 21:57:14.153588: Current learning rate: 0.00681 
2023-12-05 21:58:05.707435: train_loss 1.0423 
2023-12-05 21:58:05.707717: val_loss 1.1479 
2023-12-05 21:58:05.707808: Pseudo dice [0.865] 
2023-12-05 21:58:05.707896: Epoch time: 51.56 s 
2023-12-05 21:58:07.319545:  
2023-12-05 21:58:07.319959: Epoch 348 
2023-12-05 21:58:07.320077: Current learning rate: 0.0068 
2023-12-05 21:58:59.257678: train_loss 1.0411 
2023-12-05 21:58:59.257952: val_loss 1.148 
2023-12-05 21:58:59.258037: Pseudo dice [0.8656] 
2023-12-05 21:58:59.258121: Epoch time: 51.94 s 
2023-12-05 21:59:00.899937:  
2023-12-05 21:59:00.900100: Epoch 349 
2023-12-05 21:59:00.900210: Current learning rate: 0.0068 
2023-12-05 21:59:52.823470: train_loss 1.0405 
2023-12-05 21:59:52.823738: val_loss 1.1478 
2023-12-05 21:59:52.823824: Pseudo dice [0.864] 
2023-12-05 21:59:52.823904: Epoch time: 51.93 s 
2023-12-05 21:59:55.805552:  
2023-12-05 21:59:55.805838: Epoch 350 
2023-12-05 21:59:55.805954: Current learning rate: 0.00679 
2023-12-05 22:00:47.682208: train_loss 1.0418 
2023-12-05 22:00:47.682435: val_loss 1.1457 
2023-12-05 22:00:47.682502: Pseudo dice [0.8655] 
2023-12-05 22:00:47.682567: Epoch time: 51.88 s 
2023-12-05 22:00:48.903042:  
2023-12-05 22:00:48.903182: Epoch 351 
2023-12-05 22:00:48.903286: Current learning rate: 0.00678 
2023-12-05 22:01:40.583364: train_loss 1.0412 
2023-12-05 22:01:40.583645: val_loss 1.1415 
2023-12-05 22:01:40.583724: Pseudo dice [0.8702] 
2023-12-05 22:01:40.583805: Epoch time: 51.68 s 
2023-12-05 22:01:42.371886:  
2023-12-05 22:01:42.372038: Epoch 352 
2023-12-05 22:01:42.372147: Current learning rate: 0.00677 
2023-12-05 22:02:34.167713: train_loss 1.0415 
2023-12-05 22:02:34.167984: val_loss 1.1468 
2023-12-05 22:02:34.168066: Pseudo dice [0.8666] 
2023-12-05 22:02:34.168149: Epoch time: 51.8 s 
2023-12-05 22:02:35.788546:  
2023-12-05 22:02:35.788710: Epoch 353 
2023-12-05 22:02:35.788820: Current learning rate: 0.00676 
2023-12-05 22:03:27.536260: train_loss 1.0408 
2023-12-05 22:03:27.536522: val_loss 1.1537 
2023-12-05 22:03:27.536609: Pseudo dice [0.8615] 
2023-12-05 22:03:27.536695: Epoch time: 51.75 s 
2023-12-05 22:03:29.142396:  
2023-12-05 22:03:29.142568: Epoch 354 
2023-12-05 22:03:29.142684: Current learning rate: 0.00675 
2023-12-05 22:04:20.721560: train_loss 1.0401 
2023-12-05 22:04:20.721828: val_loss 1.1481 
2023-12-05 22:04:20.721908: Pseudo dice [0.8645] 
2023-12-05 22:04:20.721989: Epoch time: 51.58 s 
2023-12-05 22:04:22.321065:  
2023-12-05 22:04:22.321224: Epoch 355 
2023-12-05 22:04:22.321336: Current learning rate: 0.00674 
2023-12-05 22:05:14.193508: train_loss 1.0397 
2023-12-05 22:05:14.193770: val_loss 1.1564 
2023-12-05 22:05:14.193853: Pseudo dice [0.8563] 
2023-12-05 22:05:14.193935: Epoch time: 51.87 s 
2023-12-05 22:05:15.813226:  
2023-12-05 22:05:15.813463: Epoch 356 
2023-12-05 22:05:15.813584: Current learning rate: 0.00673 
2023-12-05 22:06:07.663731: train_loss 1.0409 
2023-12-05 22:06:07.664012: val_loss 1.15 
2023-12-05 22:06:07.664097: Pseudo dice [0.8631] 
2023-12-05 22:06:07.664180: Epoch time: 51.85 s 
2023-12-05 22:06:09.270057:  
2023-12-05 22:06:09.270225: Epoch 357 
2023-12-05 22:06:09.270333: Current learning rate: 0.00672 
2023-12-05 22:07:01.172253: train_loss 1.0407 
2023-12-05 22:07:01.172515: val_loss 1.1598 
2023-12-05 22:07:01.172595: Pseudo dice [0.8548] 
2023-12-05 22:07:01.172675: Epoch time: 51.9 s 
2023-12-05 22:07:02.707171:  
2023-12-05 22:07:02.707315: Epoch 358 
2023-12-05 22:07:02.707414: Current learning rate: 0.00671 
2023-12-05 22:07:54.684451: train_loss 1.0413 
2023-12-05 22:07:54.684725: val_loss 1.1531 
2023-12-05 22:07:54.684806: Pseudo dice [0.8618] 
2023-12-05 22:07:54.684887: Epoch time: 51.98 s 
2023-12-05 22:07:56.208726:  
2023-12-05 22:07:56.208996: Epoch 359 
2023-12-05 22:07:56.209099: Current learning rate: 0.0067 
2023-12-05 22:08:48.067620: train_loss 1.0412 
2023-12-05 22:08:48.067880: val_loss 1.1405 
2023-12-05 22:08:48.067961: Pseudo dice [0.8708] 
2023-12-05 22:08:48.068044: Epoch time: 51.86 s 
2023-12-05 22:08:49.671658:  
2023-12-05 22:08:49.671820: Epoch 360 
2023-12-05 22:08:49.671929: Current learning rate: 0.00669 
2023-12-05 22:09:41.538709: train_loss 1.0422 
2023-12-05 22:09:41.538977: val_loss 1.1536 
2023-12-05 22:09:41.539086: Pseudo dice [0.8603] 
2023-12-05 22:09:41.539175: Epoch time: 51.87 s 
2023-12-05 22:09:43.169157:  
2023-12-05 22:09:43.169325: Epoch 361 
2023-12-05 22:09:43.169430: Current learning rate: 0.00668 
2023-12-05 22:10:35.078768: train_loss 1.0418 
2023-12-05 22:10:35.079045: val_loss 1.1535 
2023-12-05 22:10:35.079130: Pseudo dice [0.8607] 
2023-12-05 22:10:35.079211: Epoch time: 51.91 s 
2023-12-05 22:10:36.707197:  
2023-12-05 22:10:36.707382: Epoch 362 
2023-12-05 22:10:36.707488: Current learning rate: 0.00667 
2023-12-05 22:11:28.622023: train_loss 1.0408 
2023-12-05 22:11:28.622307: val_loss 1.1421 
2023-12-05 22:11:28.622391: Pseudo dice [0.8693] 
2023-12-05 22:11:28.622475: Epoch time: 51.92 s 
2023-12-05 22:11:30.242655:  
2023-12-05 22:11:30.242969: Epoch 363 
2023-12-05 22:11:30.243092: Current learning rate: 0.00666 
2023-12-05 22:12:22.073539: train_loss 1.0411 
2023-12-05 22:12:22.073812: val_loss 1.144 
2023-12-05 22:12:22.073892: Pseudo dice [0.8686] 
2023-12-05 22:12:22.073973: Epoch time: 51.83 s 
2023-12-05 22:12:23.903243:  
2023-12-05 22:12:23.903736: Epoch 364 
2023-12-05 22:12:23.904129: Current learning rate: 0.00665 
2023-12-05 22:13:15.794203: train_loss 1.0409 
2023-12-05 22:13:15.794461: val_loss 1.1422 
2023-12-05 22:13:15.794543: Pseudo dice [0.8702] 
2023-12-05 22:13:15.794625: Epoch time: 51.89 s 
2023-12-05 22:13:17.414983:  
2023-12-05 22:13:17.415204: Epoch 365 
2023-12-05 22:13:17.415314: Current learning rate: 0.00665 
2023-12-05 22:14:09.475095: train_loss 1.0404 
2023-12-05 22:14:09.475366: val_loss 1.1355 
2023-12-05 22:14:09.475451: Pseudo dice [0.8756] 
2023-12-05 22:14:09.475536: Epoch time: 52.06 s 
2023-12-05 22:14:11.123171:  
2023-12-05 22:14:11.123364: Epoch 366 
2023-12-05 22:14:11.123478: Current learning rate: 0.00664 
2023-12-05 22:15:03.006613: train_loss 1.0412 
2023-12-05 22:15:03.006984: val_loss 1.1578 
2023-12-05 22:15:03.007071: Pseudo dice [0.8557] 
2023-12-05 22:15:03.007146: Epoch time: 51.89 s 
2023-12-05 22:15:04.233814:  
2023-12-05 22:15:04.234494: Epoch 367 
2023-12-05 22:15:04.234665: Current learning rate: 0.00663 
2023-12-05 22:15:55.973650: train_loss 1.0411 
2023-12-05 22:15:55.973866: val_loss 1.1449 
2023-12-05 22:15:55.973928: Pseudo dice [0.8664] 
2023-12-05 22:15:55.973992: Epoch time: 51.74 s 
2023-12-05 22:15:57.220743:  
2023-12-05 22:15:57.220900: Epoch 368 
2023-12-05 22:15:57.220987: Current learning rate: 0.00662 
2023-12-05 22:16:48.910766: train_loss 1.0417 
2023-12-05 22:16:48.911052: val_loss 1.1559 
2023-12-05 22:16:48.911137: Pseudo dice [0.8586] 
2023-12-05 22:16:48.911219: Epoch time: 51.69 s 
2023-12-05 22:16:50.144259:  
2023-12-05 22:16:50.144392: Epoch 369 
2023-12-05 22:16:50.144484: Current learning rate: 0.00661 
2023-12-05 22:17:42.163615: train_loss 1.0416 
2023-12-05 22:17:42.163985: val_loss 1.149 
2023-12-05 22:17:42.164074: Pseudo dice [0.8628] 
2023-12-05 22:17:42.164163: Epoch time: 52.02 s 
2023-12-05 22:17:43.666621:  
2023-12-05 22:17:43.666967: Epoch 370 
2023-12-05 22:17:43.667083: Current learning rate: 0.0066 
2023-12-05 22:18:35.650682: train_loss 1.0397 
2023-12-05 22:18:35.650971: val_loss 1.1528 
2023-12-05 22:18:35.651080: Pseudo dice [0.8611] 
2023-12-05 22:18:35.651168: Epoch time: 51.99 s 
2023-12-05 22:18:37.266382:  
2023-12-05 22:18:37.266852: Epoch 371 
2023-12-05 22:18:37.267174: Current learning rate: 0.00659 
2023-12-05 22:19:29.281994: train_loss 1.0403 
2023-12-05 22:19:29.282266: val_loss 1.1621 
2023-12-05 22:19:29.282344: Pseudo dice [0.853] 
2023-12-05 22:19:29.282579: Epoch time: 52.02 s 
2023-12-05 22:19:30.904715:  
2023-12-05 22:19:30.905298: Epoch 372 
2023-12-05 22:19:30.905696: Current learning rate: 0.00658 
2023-12-05 22:20:22.686006: train_loss 1.04 
2023-12-05 22:20:22.686273: val_loss 1.1537 
2023-12-05 22:20:22.686724: Pseudo dice [0.8611] 
2023-12-05 22:20:22.686811: Epoch time: 51.79 s 
2023-12-05 22:20:24.133548:  
2023-12-05 22:20:24.133685: Epoch 373 
2023-12-05 22:20:24.133776: Current learning rate: 0.00657 
2023-12-05 22:21:15.953347: train_loss 1.0392 
2023-12-05 22:21:15.953621: val_loss 1.1633 
2023-12-05 22:21:15.953702: Pseudo dice [0.8508] 
2023-12-05 22:21:15.953786: Epoch time: 51.82 s 
2023-12-05 22:21:17.553177:  
2023-12-05 22:21:17.553310: Epoch 374 
2023-12-05 22:21:17.553409: Current learning rate: 0.00656 
2023-12-05 22:22:09.371363: train_loss 1.0406 
2023-12-05 22:22:09.371639: val_loss 1.1483 
2023-12-05 22:22:09.371720: Pseudo dice [0.8644] 
2023-12-05 22:22:09.371805: Epoch time: 51.82 s 
2023-12-05 22:22:10.909162:  
2023-12-05 22:22:10.909498: Epoch 375 
2023-12-05 22:22:10.909599: Current learning rate: 0.00655 
2023-12-05 22:23:02.824652: train_loss 1.0393 
2023-12-05 22:23:02.824932: val_loss 1.1495 
2023-12-05 22:23:02.825012: Pseudo dice [0.8642] 
2023-12-05 22:23:02.825097: Epoch time: 51.92 s 
2023-12-05 22:23:04.295777:  
2023-12-05 22:23:04.296265: Epoch 376 
2023-12-05 22:23:04.296367: Current learning rate: 0.00654 
2023-12-05 22:23:56.151772: train_loss 1.0404 
2023-12-05 22:23:56.152029: val_loss 1.1505 
2023-12-05 22:23:56.152154: Pseudo dice [0.8628] 
2023-12-05 22:23:56.152242: Epoch time: 51.86 s 
2023-12-05 22:23:57.390014:  
2023-12-05 22:23:57.390148: Epoch 377 
2023-12-05 22:23:57.390241: Current learning rate: 0.00653 
2023-12-05 22:24:49.317002: train_loss 1.0396 
2023-12-05 22:24:49.317289: val_loss 1.1417 
2023-12-05 22:24:49.317667: Pseudo dice [0.8706] 
2023-12-05 22:24:49.318013: Epoch time: 51.93 s 
2023-12-05 22:24:50.946894:  
2023-12-05 22:24:50.947092: Epoch 378 
2023-12-05 22:24:50.947203: Current learning rate: 0.00652 
2023-12-05 22:25:42.943360: train_loss 1.0396 
2023-12-05 22:25:42.943648: val_loss 1.1459 
2023-12-05 22:25:42.943731: Pseudo dice [0.8665] 
2023-12-05 22:25:42.943819: Epoch time: 52.0 s 
2023-12-05 22:25:44.482692:  
2023-12-05 22:25:44.482852: Epoch 379 
2023-12-05 22:25:44.482947: Current learning rate: 0.00651 
2023-12-05 22:26:36.429819: train_loss 1.0409 
2023-12-05 22:26:36.430054: val_loss 1.1492 
2023-12-05 22:26:36.430120: Pseudo dice [0.8649] 
2023-12-05 22:26:36.430185: Epoch time: 51.95 s 
2023-12-05 22:26:37.652909:  
2023-12-05 22:26:37.653122: Epoch 380 
2023-12-05 22:26:37.653220: Current learning rate: 0.0065 
2023-12-05 22:27:29.536314: train_loss 1.0417 
2023-12-05 22:27:29.536577: val_loss 1.1528 
2023-12-05 22:27:29.536657: Pseudo dice [0.8596] 
2023-12-05 22:27:29.536739: Epoch time: 51.89 s 
2023-12-05 22:27:31.173066:  
2023-12-05 22:27:31.173497: Epoch 381 
2023-12-05 22:27:31.173610: Current learning rate: 0.00649 
2023-12-05 22:28:23.149881: train_loss 1.0407 
2023-12-05 22:28:23.150153: val_loss 1.1635 
2023-12-05 22:28:23.150233: Pseudo dice [0.8542] 
2023-12-05 22:28:23.150314: Epoch time: 51.98 s 
2023-12-05 22:28:24.790315:  
2023-12-05 22:28:24.790678: Epoch 382 
2023-12-05 22:28:24.790795: Current learning rate: 0.00648 
2023-12-05 22:29:16.630105: train_loss 1.0411 
2023-12-05 22:29:16.630346: val_loss 1.1526 
2023-12-05 22:29:16.630413: Pseudo dice [0.8608] 
2023-12-05 22:29:16.630480: Epoch time: 51.84 s 
2023-12-05 22:29:18.075321:  
2023-12-05 22:29:18.075477: Epoch 383 
2023-12-05 22:29:18.075590: Current learning rate: 0.00648 
2023-12-05 22:30:09.859436: train_loss 1.0411 
2023-12-05 22:30:09.859658: val_loss 1.1545 
2023-12-05 22:30:09.859723: Pseudo dice [0.859] 
2023-12-05 22:30:09.859790: Epoch time: 51.79 s 
2023-12-05 22:30:11.100990:  
2023-12-05 22:30:11.101133: Epoch 384 
2023-12-05 22:30:11.101221: Current learning rate: 0.00647 
2023-12-05 22:31:02.995595: train_loss 1.0405 
2023-12-05 22:31:02.995861: val_loss 1.143 
2023-12-05 22:31:02.995941: Pseudo dice [0.8686] 
2023-12-05 22:31:02.996022: Epoch time: 51.9 s 
2023-12-05 22:31:04.640742:  
2023-12-05 22:31:04.641065: Epoch 385 
2023-12-05 22:31:04.641178: Current learning rate: 0.00646 
2023-12-05 22:31:56.512127: train_loss 1.0419 
2023-12-05 22:31:56.512387: val_loss 1.1613 
2023-12-05 22:31:56.512465: Pseudo dice [0.8539] 
2023-12-05 22:31:56.512545: Epoch time: 51.87 s 
2023-12-05 22:31:58.144082:  
2023-12-05 22:31:58.144252: Epoch 386 
2023-12-05 22:31:58.144358: Current learning rate: 0.00645 
2023-12-05 22:32:49.878708: train_loss 1.0424 
2023-12-05 22:32:49.878933: val_loss 1.1622 
2023-12-05 22:32:49.879009: Pseudo dice [0.8521] 
2023-12-05 22:32:49.879102: Epoch time: 51.74 s 
2023-12-05 22:32:51.696617:  
2023-12-05 22:32:51.696891: Epoch 387 
2023-12-05 22:32:51.697015: Current learning rate: 0.00644 
2023-12-05 22:33:43.363388: train_loss 1.0434 
2023-12-05 22:33:43.363648: val_loss 1.1504 
2023-12-05 22:33:43.363731: Pseudo dice [0.8627] 
2023-12-05 22:33:43.363816: Epoch time: 51.67 s 
2023-12-05 22:33:44.737789:  
2023-12-05 22:33:44.738267: Epoch 388 
2023-12-05 22:33:44.738372: Current learning rate: 0.00643 
2023-12-05 22:34:36.555018: train_loss 1.0414 
2023-12-05 22:34:36.555241: val_loss 1.1506 
2023-12-05 22:34:36.555307: Pseudo dice [0.8632] 
2023-12-05 22:34:36.555376: Epoch time: 51.82 s 
2023-12-05 22:34:37.737144:  
2023-12-05 22:34:37.737387: Epoch 389 
2023-12-05 22:34:37.737480: Current learning rate: 0.00642 
2023-12-05 22:35:29.510782: train_loss 1.0424 
2023-12-05 22:35:29.511022: val_loss 1.1533 
2023-12-05 22:35:29.511093: Pseudo dice [0.8617] 
2023-12-05 22:35:29.511164: Epoch time: 51.78 s 
2023-12-05 22:35:30.728352:  
2023-12-05 22:35:30.728558: Epoch 390 
2023-12-05 22:35:30.728653: Current learning rate: 0.00641 
2023-12-05 22:36:22.433340: train_loss 1.0416 
2023-12-05 22:36:22.433605: val_loss 1.1443 
2023-12-05 22:36:22.433692: Pseudo dice [0.8673] 
2023-12-05 22:36:22.433783: Epoch time: 51.71 s 
2023-12-05 22:36:24.070624:  
2023-12-05 22:36:24.070786: Epoch 391 
2023-12-05 22:36:24.070898: Current learning rate: 0.0064 
2023-12-05 22:37:15.869309: train_loss 1.0418 
2023-12-05 22:37:15.869569: val_loss 1.1412 
2023-12-05 22:37:15.869649: Pseudo dice [0.8704] 
2023-12-05 22:37:15.869730: Epoch time: 51.8 s 
2023-12-05 22:37:17.517301:  
2023-12-05 22:37:17.517611: Epoch 392 
2023-12-05 22:37:17.517725: Current learning rate: 0.00639 
2023-12-05 22:38:09.512975: train_loss 1.0406 
2023-12-05 22:38:09.513234: val_loss 1.1465 
2023-12-05 22:38:09.513312: Pseudo dice [0.8662] 
2023-12-05 22:38:09.513393: Epoch time: 52.0 s 
2023-12-05 22:38:11.379032:  
2023-12-05 22:38:11.379640: Epoch 393 
2023-12-05 22:38:11.379763: Current learning rate: 0.00638 
2023-12-05 22:39:03.141814: train_loss 1.04 
2023-12-05 22:39:03.142068: val_loss 1.156 
2023-12-05 22:39:03.142136: Pseudo dice [0.8587] 
2023-12-05 22:39:03.142204: Epoch time: 51.76 s 
2023-12-05 22:39:04.359044:  
2023-12-05 22:39:04.359190: Epoch 394 
2023-12-05 22:39:04.359287: Current learning rate: 0.00637 
2023-12-05 22:39:56.348354: train_loss 1.0399 
2023-12-05 22:39:56.348624: val_loss 1.1409 
2023-12-05 22:39:56.348706: Pseudo dice [0.8701] 
2023-12-05 22:39:56.348790: Epoch time: 51.99 s 
2023-12-05 22:39:57.993330:  
2023-12-05 22:39:57.993719: Epoch 395 
2023-12-05 22:39:57.993827: Current learning rate: 0.00636 
2023-12-05 22:40:49.804536: train_loss 1.0402 
2023-12-05 22:40:49.804801: val_loss 1.1506 
2023-12-05 22:40:49.804886: Pseudo dice [0.8617] 
2023-12-05 22:40:49.804968: Epoch time: 51.81 s 
2023-12-05 22:40:51.447333:  
2023-12-05 22:40:51.447615: Epoch 396 
2023-12-05 22:40:51.447806: Current learning rate: 0.00635 
2023-12-05 22:41:43.471432: train_loss 1.0405 
2023-12-05 22:41:43.471689: val_loss 1.1489 
2023-12-05 22:41:43.471767: Pseudo dice [0.8645] 
2023-12-05 22:41:43.471846: Epoch time: 52.03 s 
2023-12-05 22:41:45.108504:  
2023-12-05 22:41:45.108654: Epoch 397 
2023-12-05 22:41:45.108761: Current learning rate: 0.00634 
2023-12-05 22:42:37.086352: train_loss 1.0392 
2023-12-05 22:42:37.086584: val_loss 1.1446 
2023-12-05 22:42:37.086667: Pseudo dice [0.867] 
2023-12-05 22:42:37.086753: Epoch time: 51.98 s 
2023-12-05 22:42:38.716472:  
2023-12-05 22:42:38.716925: Epoch 398 
2023-12-05 22:42:38.717044: Current learning rate: 0.00633 
2023-12-05 22:43:30.471807: train_loss 1.0384 
2023-12-05 22:43:30.472071: val_loss 1.1502 
2023-12-05 22:43:30.472154: Pseudo dice [0.8643] 
2023-12-05 22:43:30.472230: Epoch time: 51.76 s 
2023-12-05 22:43:32.173755:  
2023-12-05 22:43:32.174010: Epoch 399 
2023-12-05 22:43:32.174101: Current learning rate: 0.00632 
2023-12-05 22:44:23.781259: train_loss 1.0391 
2023-12-05 22:44:23.781525: val_loss 1.1514 
2023-12-05 22:44:23.781616: Pseudo dice [0.8608] 
2023-12-05 22:44:23.781702: Epoch time: 51.61 s 
2023-12-05 22:44:26.298606:  
2023-12-05 22:44:26.298854: Epoch 400 
2023-12-05 22:44:26.298952: Current learning rate: 0.00631 
2023-12-05 22:45:17.762113: train_loss 1.0386 
2023-12-05 22:45:17.762366: val_loss 1.1464 
2023-12-05 22:45:17.762446: Pseudo dice [0.8656] 
2023-12-05 22:45:17.762526: Epoch time: 51.47 s 
2023-12-05 22:45:19.400809:  
2023-12-05 22:45:19.401149: Epoch 401 
2023-12-05 22:45:19.401261: Current learning rate: 0.0063 
2023-12-05 22:46:11.347908: train_loss 1.0387 
2023-12-05 22:46:11.348139: val_loss 1.1539 
2023-12-05 22:46:11.348207: Pseudo dice [0.8603] 
2023-12-05 22:46:11.348275: Epoch time: 51.95 s 
2023-12-05 22:46:12.597832:  
2023-12-05 22:46:12.597981: Epoch 402 
2023-12-05 22:46:12.598081: Current learning rate: 0.0063 
2023-12-05 22:47:04.428453: train_loss 1.0384 
2023-12-05 22:47:04.428727: val_loss 1.1404 
2023-12-05 22:47:04.428805: Pseudo dice [0.8716] 
2023-12-05 22:47:04.428887: Epoch time: 51.83 s 
2023-12-05 22:47:06.064530:  
2023-12-05 22:47:06.064689: Epoch 403 
2023-12-05 22:47:06.064930: Current learning rate: 0.00629 
2023-12-05 22:47:57.818388: train_loss 1.0408 
2023-12-05 22:47:57.818620: val_loss 1.1412 
2023-12-05 22:47:57.818687: Pseudo dice [0.8707] 
2023-12-05 22:47:57.818755: Epoch time: 51.76 s 
2023-12-05 22:47:59.250362:  
2023-12-05 22:47:59.250502: Epoch 404 
2023-12-05 22:47:59.250604: Current learning rate: 0.00628 
2023-12-05 22:48:51.080626: train_loss 1.0402 
2023-12-05 22:48:51.080853: val_loss 1.1582 
2023-12-05 22:48:51.081038: Pseudo dice [0.8575] 
2023-12-05 22:48:51.081124: Epoch time: 51.83 s 
2023-12-05 22:48:52.395132:  
2023-12-05 22:48:52.395281: Epoch 405 
2023-12-05 22:48:52.395375: Current learning rate: 0.00627 
2023-12-05 22:49:44.319329: train_loss 1.0395 
2023-12-05 22:49:44.319608: val_loss 1.1506 
2023-12-05 22:49:44.319781: Pseudo dice [0.8626] 
2023-12-05 22:49:44.319873: Epoch time: 51.93 s 
2023-12-05 22:49:45.833439:  
2023-12-05 22:49:45.833625: Epoch 406 
2023-12-05 22:49:45.833711: Current learning rate: 0.00626 
2023-12-05 22:50:37.681748: train_loss 1.04 
2023-12-05 22:50:37.682167: val_loss 1.1461 
2023-12-05 22:50:37.682255: Pseudo dice [0.8658] 
2023-12-05 22:50:37.682339: Epoch time: 51.85 s 
2023-12-05 22:50:39.328727:  
2023-12-05 22:50:39.329308: Epoch 407 
2023-12-05 22:50:39.329487: Current learning rate: 0.00625 
2023-12-05 22:51:31.366521: train_loss 1.0391 
2023-12-05 22:51:31.366791: val_loss 1.1487 
2023-12-05 22:51:31.366880: Pseudo dice [0.8635] 
2023-12-05 22:51:31.366966: Epoch time: 52.04 s 
2023-12-05 22:51:32.856240:  
2023-12-05 22:51:32.856395: Epoch 408 
2023-12-05 22:51:32.856484: Current learning rate: 0.00624 
2023-12-05 22:52:24.722632: train_loss 1.0381 
2023-12-05 22:52:24.722887: val_loss 1.1553 
2023-12-05 22:52:24.722965: Pseudo dice [0.8593] 
2023-12-05 22:52:24.723061: Epoch time: 51.87 s 
2023-12-05 22:52:26.435328:  
2023-12-05 22:52:26.435823: Epoch 409 
2023-12-05 22:52:26.435953: Current learning rate: 0.00623 
2023-12-05 22:53:18.255647: train_loss 1.0392 
2023-12-05 22:53:18.255947: val_loss 1.15 
2023-12-05 22:53:18.256034: Pseudo dice [0.8627] 
2023-12-05 22:53:18.256120: Epoch time: 51.82 s 
2023-12-05 22:53:20.089353:  
2023-12-05 22:53:20.089512: Epoch 410 
2023-12-05 22:53:20.089633: Current learning rate: 0.00622 
2023-12-05 22:54:12.004914: train_loss 1.0386 
2023-12-05 22:54:12.005168: val_loss 1.1587 
2023-12-05 22:54:12.005246: Pseudo dice [0.8554] 
2023-12-05 22:54:12.005325: Epoch time: 51.92 s 
2023-12-05 22:54:13.605862:  
2023-12-05 22:54:13.606035: Epoch 411 
2023-12-05 22:54:13.606145: Current learning rate: 0.00621 
2023-12-05 22:55:05.680125: train_loss 1.039 
2023-12-05 22:55:05.680393: val_loss 1.1528 
2023-12-05 22:55:05.680473: Pseudo dice [0.861] 
2023-12-05 22:55:05.680552: Epoch time: 52.08 s 
2023-12-05 22:55:07.211437:  
2023-12-05 22:55:07.211579: Epoch 412 
2023-12-05 22:55:07.211673: Current learning rate: 0.0062 
2023-12-05 22:55:59.082331: train_loss 1.0398 
2023-12-05 22:55:59.082588: val_loss 1.1436 
2023-12-05 22:55:59.082668: Pseudo dice [0.8686] 
2023-12-05 22:55:59.082745: Epoch time: 51.87 s 
2023-12-05 22:56:00.353904:  
2023-12-05 22:56:00.354120: Epoch 413 
2023-12-05 22:56:00.354208: Current learning rate: 0.00619 
2023-12-05 22:56:52.033128: train_loss 1.0392 
2023-12-05 22:56:52.033386: val_loss 1.1525 
2023-12-05 22:56:52.033468: Pseudo dice [0.8609] 
2023-12-05 22:56:52.033546: Epoch time: 51.68 s 
2023-12-05 22:56:53.337033:  
2023-12-05 22:56:53.337169: Epoch 414 
2023-12-05 22:56:53.337267: Current learning rate: 0.00618 
2023-12-05 22:57:45.254105: train_loss 1.0391 
2023-12-05 22:57:45.254345: val_loss 1.1631 
2023-12-05 22:57:45.254413: Pseudo dice [0.8518] 
2023-12-05 22:57:45.254481: Epoch time: 51.92 s 
2023-12-05 22:57:46.457905:  
2023-12-05 22:57:46.458111: Epoch 415 
2023-12-05 22:57:46.458205: Current learning rate: 0.00617 
2023-12-05 22:58:38.310120: train_loss 1.0453 
2023-12-05 22:58:38.310410: val_loss 1.1701 
2023-12-05 22:58:38.310508: Pseudo dice [0.8461] 
2023-12-05 22:58:38.310593: Epoch time: 51.85 s 
2023-12-05 22:58:40.074550:  
2023-12-05 22:58:40.074807: Epoch 416 
2023-12-05 22:58:40.074931: Current learning rate: 0.00616 
2023-12-05 22:59:31.989416: train_loss 1.0716 
2023-12-05 22:59:31.989634: val_loss 1.1559 
2023-12-05 22:59:31.989699: Pseudo dice [0.8606] 
2023-12-05 22:59:31.989763: Epoch time: 51.92 s 
2023-12-05 22:59:33.164012:  
2023-12-05 22:59:33.164154: Epoch 417 
2023-12-05 22:59:33.164252: Current learning rate: 0.00615 
2023-12-05 23:00:25.254179: train_loss 1.0769 
2023-12-05 23:00:25.254420: val_loss 1.1658 
2023-12-05 23:00:25.254490: Pseudo dice [0.8513] 
2023-12-05 23:00:25.254557: Epoch time: 52.09 s 
2023-12-05 23:00:26.645939:  
2023-12-05 23:00:26.646352: Epoch 418 
2023-12-05 23:00:26.646503: Current learning rate: 0.00614 
2023-12-05 23:01:18.535865: train_loss 1.0677 
2023-12-05 23:01:18.536133: val_loss 1.146 
2023-12-05 23:01:18.536212: Pseudo dice [0.8658] 
2023-12-05 23:01:18.536292: Epoch time: 51.89 s 
2023-12-05 23:01:20.102543:  
2023-12-05 23:01:20.102760: Epoch 419 
2023-12-05 23:01:20.102930: Current learning rate: 0.00613 
2023-12-05 23:02:12.085296: train_loss 1.0542 
2023-12-05 23:02:12.085794: val_loss 1.1568 
2023-12-05 23:02:12.085886: Pseudo dice [0.8588] 
2023-12-05 23:02:12.085972: Epoch time: 51.99 s 
2023-12-05 23:02:13.543263:  
2023-12-05 23:02:13.543399: Epoch 420 
2023-12-05 23:02:13.543512: Current learning rate: 0.00612 
2023-12-05 23:03:05.337949: train_loss 1.0486 
2023-12-05 23:03:05.338203: val_loss 1.1665 
2023-12-05 23:03:05.338282: Pseudo dice [0.8499] 
2023-12-05 23:03:05.338362: Epoch time: 51.8 s 
2023-12-05 23:03:06.988088:  
2023-12-05 23:03:06.988465: Epoch 421 
2023-12-05 23:03:06.988587: Current learning rate: 0.00612 
2023-12-05 23:03:58.839389: train_loss 1.0466 
2023-12-05 23:03:58.839658: val_loss 1.1395 
2023-12-05 23:03:58.839738: Pseudo dice [0.8723] 
2023-12-05 23:03:58.839821: Epoch time: 51.85 s 
2023-12-05 23:04:00.577326:  
2023-12-05 23:04:00.577484: Epoch 422 
2023-12-05 23:04:00.577603: Current learning rate: 0.00611 
2023-12-05 23:04:52.555587: train_loss 1.0458 
2023-12-05 23:04:52.555825: val_loss 1.1483 
2023-12-05 23:04:52.555890: Pseudo dice [0.8651] 
2023-12-05 23:04:52.555953: Epoch time: 51.98 s 
2023-12-05 23:04:54.124626:  
2023-12-05 23:04:54.124802: Epoch 423 
2023-12-05 23:04:54.124909: Current learning rate: 0.0061 
2023-12-05 23:05:45.822191: train_loss 1.0439 
2023-12-05 23:05:45.822448: val_loss 1.1528 
2023-12-05 23:05:45.822533: Pseudo dice [0.8605] 
2023-12-05 23:05:45.822613: Epoch time: 51.7 s 
2023-12-05 23:05:47.327998:  
2023-12-05 23:05:47.328162: Epoch 424 
2023-12-05 23:05:47.328270: Current learning rate: 0.00609 
2023-12-05 23:06:39.336993: train_loss 1.0418 
2023-12-05 23:06:39.337254: val_loss 1.1464 
2023-12-05 23:06:39.337332: Pseudo dice [0.8665] 
2023-12-05 23:06:39.337410: Epoch time: 52.01 s 
2023-12-05 23:06:40.906823:  
2023-12-05 23:06:40.907535: Epoch 425 
2023-12-05 23:06:40.907933: Current learning rate: 0.00608 
2023-12-05 23:07:32.791160: train_loss 1.0418 
2023-12-05 23:07:32.791381: val_loss 1.1437 
2023-12-05 23:07:32.791442: Pseudo dice [0.8692] 
2023-12-05 23:07:32.791502: Epoch time: 51.89 s 
2023-12-05 23:07:33.965452:  
2023-12-05 23:07:33.965858: Epoch 426 
2023-12-05 23:07:33.965957: Current learning rate: 0.00607 
2023-12-05 23:08:25.602419: train_loss 1.0406 
2023-12-05 23:08:25.602688: val_loss 1.1465 
2023-12-05 23:08:25.602768: Pseudo dice [0.8659] 
2023-12-05 23:08:25.602847: Epoch time: 51.64 s 
2023-12-05 23:08:27.179767:  
2023-12-05 23:08:27.180151: Epoch 427 
2023-12-05 23:08:27.180321: Current learning rate: 0.00606 
2023-12-05 23:09:19.076710: train_loss 1.0398 
2023-12-05 23:09:19.076968: val_loss 1.1393 
2023-12-05 23:09:19.077050: Pseudo dice [0.8707] 
2023-12-05 23:09:19.077127: Epoch time: 51.9 s 
2023-12-05 23:09:20.485795:  
2023-12-05 23:09:20.486121: Epoch 428 
2023-12-05 23:09:20.486220: Current learning rate: 0.00605 
2023-12-05 23:10:12.524947: train_loss 1.0393 
2023-12-05 23:10:12.525304: val_loss 1.1484 
2023-12-05 23:10:12.525435: Pseudo dice [0.8656] 
2023-12-05 23:10:12.525526: Epoch time: 52.04 s 
2023-12-05 23:10:14.148825:  
2023-12-05 23:10:14.149200: Epoch 429 
2023-12-05 23:10:14.149760: Current learning rate: 0.00604 
2023-12-05 23:11:06.081579: train_loss 1.0395 
2023-12-05 23:11:06.081843: val_loss 1.1538 
2023-12-05 23:11:06.081936: Pseudo dice [0.8613] 
2023-12-05 23:11:06.082019: Epoch time: 51.93 s 
2023-12-05 23:11:07.686681:  
2023-12-05 23:11:07.686989: Epoch 430 
2023-12-05 23:11:07.687221: Current learning rate: 0.00603 
2023-12-05 23:11:59.717142: train_loss 1.0391 
2023-12-05 23:11:59.717417: val_loss 1.1489 
2023-12-05 23:11:59.717500: Pseudo dice [0.8661] 
2023-12-05 23:11:59.717586: Epoch time: 52.03 s 
2023-12-05 23:12:00.965154:  
2023-12-05 23:12:00.965288: Epoch 431 
2023-12-05 23:12:00.965382: Current learning rate: 0.00602 
2023-12-05 23:12:52.867449: train_loss 1.0386 
2023-12-05 23:12:52.867720: val_loss 1.1447 
2023-12-05 23:12:52.867814: Pseudo dice [0.8688] 
2023-12-05 23:12:52.867902: Epoch time: 51.9 s 
2023-12-05 23:12:54.182074:  
2023-12-05 23:12:54.182234: Epoch 432 
2023-12-05 23:12:54.182322: Current learning rate: 0.00601 
2023-12-05 23:13:45.842585: train_loss 1.0388 
2023-12-05 23:13:45.842826: val_loss 1.1563 
2023-12-05 23:13:45.842893: Pseudo dice [0.8595] 
2023-12-05 23:13:45.842960: Epoch time: 51.66 s 
2023-12-05 23:13:47.027738:  
2023-12-05 23:13:47.028039: Epoch 433 
2023-12-05 23:13:47.028140: Current learning rate: 0.006 
2023-12-05 23:14:39.082768: train_loss 1.0384 
2023-12-05 23:14:39.083041: val_loss 1.1496 
2023-12-05 23:14:39.083128: Pseudo dice [0.8635] 
2023-12-05 23:14:39.083210: Epoch time: 52.06 s 
2023-12-05 23:14:40.854995:  
2023-12-05 23:14:40.855643: Epoch 434 
2023-12-05 23:14:40.855815: Current learning rate: 0.00599 
2023-12-05 23:15:32.917932: train_loss 1.0384 
2023-12-05 23:15:32.918175: val_loss 1.1443 
2023-12-05 23:15:32.918243: Pseudo dice [0.8672] 
2023-12-05 23:15:32.918310: Epoch time: 52.07 s 
2023-12-05 23:15:34.106775:  
2023-12-05 23:15:34.107039: Epoch 435 
2023-12-05 23:15:34.107146: Current learning rate: 0.00598 
2023-12-05 23:16:26.085702: train_loss 1.0392 
2023-12-05 23:16:26.085974: val_loss 1.1605 
2023-12-05 23:16:26.086060: Pseudo dice [0.8554] 
2023-12-05 23:16:26.086139: Epoch time: 51.98 s 
2023-12-05 23:16:27.562669:  
2023-12-05 23:16:27.562813: Epoch 436 
2023-12-05 23:16:27.562904: Current learning rate: 0.00597 
2023-12-05 23:17:19.501647: train_loss 1.0401 
2023-12-05 23:17:19.501876: val_loss 1.1444 
2023-12-05 23:17:19.501941: Pseudo dice [0.8674] 
2023-12-05 23:17:19.502006: Epoch time: 51.94 s 
2023-12-05 23:17:20.692981:  
2023-12-05 23:17:20.693133: Epoch 437 
2023-12-05 23:17:20.693223: Current learning rate: 0.00596 
2023-12-05 23:18:12.393369: train_loss 1.0389 
2023-12-05 23:18:12.393604: val_loss 1.1379 
2023-12-05 23:18:12.393683: Pseudo dice [0.8721] 
2023-12-05 23:18:12.393759: Epoch time: 51.7 s 
2023-12-05 23:18:13.609917:  
2023-12-05 23:18:13.610190: Epoch 438 
2023-12-05 23:18:13.610279: Current learning rate: 0.00595 
2023-12-05 23:19:05.332398: train_loss 1.0374 
2023-12-05 23:19:05.332650: val_loss 1.1476 
2023-12-05 23:19:05.332730: Pseudo dice [0.8664] 
2023-12-05 23:19:05.332811: Epoch time: 51.72 s 
2023-12-05 23:19:06.767758:  
2023-12-05 23:19:06.767934: Epoch 439 
2023-12-05 23:19:06.768029: Current learning rate: 0.00594 
2023-12-05 23:19:58.462039: train_loss 1.0386 
2023-12-05 23:19:58.462302: val_loss 1.1499 
2023-12-05 23:19:58.462381: Pseudo dice [0.8627] 
2023-12-05 23:19:58.462461: Epoch time: 51.7 s 
2023-12-05 23:19:59.882444:  
2023-12-05 23:19:59.882577: Epoch 440 
2023-12-05 23:19:59.882662: Current learning rate: 0.00593 
2023-12-05 23:20:51.934162: train_loss 1.0374 
2023-12-05 23:20:51.934425: val_loss 1.152 
2023-12-05 23:20:51.934509: Pseudo dice [0.8612] 
2023-12-05 23:20:51.934587: Epoch time: 52.05 s 
2023-12-05 23:20:53.731372:  
2023-12-05 23:20:53.731535: Epoch 441 
2023-12-05 23:20:53.731648: Current learning rate: 0.00592 
2023-12-05 23:21:45.704430: train_loss 1.0369 
2023-12-05 23:21:45.704698: val_loss 1.1438 
2023-12-05 23:21:45.704779: Pseudo dice [0.8683] 
2023-12-05 23:21:45.704861: Epoch time: 51.98 s 
2023-12-05 23:21:47.298742:  
2023-12-05 23:21:47.298899: Epoch 442 
2023-12-05 23:21:47.299007: Current learning rate: 0.00592 
2023-12-05 23:22:39.264076: train_loss 1.0371 
2023-12-05 23:22:39.264350: val_loss 1.1484 
2023-12-05 23:22:39.264431: Pseudo dice [0.8651] 
2023-12-05 23:22:39.264515: Epoch time: 51.97 s 
2023-12-05 23:22:40.841516:  
2023-12-05 23:22:40.841885: Epoch 443 
2023-12-05 23:22:40.842042: Current learning rate: 0.00591 
2023-12-05 23:23:32.882069: train_loss 1.0375 
2023-12-05 23:23:32.882339: val_loss 1.1545 
2023-12-05 23:23:32.882432: Pseudo dice [0.8615] 
2023-12-05 23:23:32.882518: Epoch time: 52.04 s 
2023-12-05 23:23:34.454900:  
2023-12-05 23:23:34.455266: Epoch 444 
2023-12-05 23:23:34.455381: Current learning rate: 0.0059 
2023-12-05 23:24:26.207111: train_loss 1.0376 
2023-12-05 23:24:26.207339: val_loss 1.1494 
2023-12-05 23:24:26.207401: Pseudo dice [0.8629] 
2023-12-05 23:24:26.207463: Epoch time: 51.75 s 
2023-12-05 23:24:27.366134:  
2023-12-05 23:24:27.366372: Epoch 445 
2023-12-05 23:24:27.366456: Current learning rate: 0.00589 
2023-12-05 23:25:19.316353: train_loss 1.0384 
2023-12-05 23:25:19.316576: val_loss 1.1451 
2023-12-05 23:25:19.316642: Pseudo dice [0.8661] 
2023-12-05 23:25:19.316708: Epoch time: 51.95 s 
2023-12-05 23:25:20.500082:  
2023-12-05 23:25:20.500210: Epoch 446 
2023-12-05 23:25:20.500296: Current learning rate: 0.00588 
2023-12-05 23:26:12.434968: train_loss 1.0383 
2023-12-05 23:26:12.435238: val_loss 1.1584 
2023-12-05 23:26:12.435321: Pseudo dice [0.8567] 
2023-12-05 23:26:12.435403: Epoch time: 51.94 s 
2023-12-05 23:26:14.195563:  
2023-12-05 23:26:14.195727: Epoch 447 
2023-12-05 23:26:14.195843: Current learning rate: 0.00587 
2023-12-05 23:27:06.094243: train_loss 1.0372 
2023-12-05 23:27:06.094504: val_loss 1.1432 
2023-12-05 23:27:06.094592: Pseudo dice [0.8694] 
2023-12-05 23:27:06.094674: Epoch time: 51.9 s 
2023-12-05 23:27:07.665614:  
2023-12-05 23:27:07.666073: Epoch 448 
2023-12-05 23:27:07.666269: Current learning rate: 0.00586 
2023-12-05 23:27:59.554010: train_loss 1.037 
2023-12-05 23:27:59.554238: val_loss 1.1555 
2023-12-05 23:27:59.554304: Pseudo dice [0.8606] 
2023-12-05 23:27:59.554368: Epoch time: 51.89 s 
2023-12-05 23:28:00.751265:  
2023-12-05 23:28:00.751561: Epoch 449 
2023-12-05 23:28:00.751665: Current learning rate: 0.00585 
2023-12-05 23:28:52.572291: train_loss 1.0376 
2023-12-05 23:28:52.572640: val_loss 1.1387 
2023-12-05 23:28:52.572721: Pseudo dice [0.8724] 
2023-12-05 23:28:52.572800: Epoch time: 51.82 s 
2023-12-05 23:28:54.979043:  
2023-12-05 23:28:54.979201: Epoch 450 
2023-12-05 23:28:54.979289: Current learning rate: 0.00584 
2023-12-05 23:29:46.964154: train_loss 1.0375 
2023-12-05 23:29:46.964421: val_loss 1.1493 
2023-12-05 23:29:46.964511: Pseudo dice [0.8642] 
2023-12-05 23:29:46.964595: Epoch time: 51.99 s 
2023-12-05 23:29:48.268811:  
2023-12-05 23:29:48.268946: Epoch 451 
2023-12-05 23:29:48.269034: Current learning rate: 0.00583 
2023-12-05 23:30:40.274557: train_loss 1.0374 
2023-12-05 23:30:40.274778: val_loss 1.1457 
2023-12-05 23:30:40.274846: Pseudo dice [0.8678] 
2023-12-05 23:30:40.274914: Epoch time: 52.01 s 
2023-12-05 23:30:41.459183:  
2023-12-05 23:30:41.459445: Epoch 452 
2023-12-05 23:30:41.459549: Current learning rate: 0.00582 
2023-12-05 23:31:33.387184: train_loss 1.0359 
2023-12-05 23:31:33.387449: val_loss 1.1496 
2023-12-05 23:31:33.387528: Pseudo dice [0.8619] 
2023-12-05 23:31:33.387607: Epoch time: 51.93 s 
2023-12-05 23:31:35.154650:  
2023-12-05 23:31:35.154808: Epoch 453 
2023-12-05 23:31:35.154922: Current learning rate: 0.00581 
2023-12-05 23:32:26.924947: train_loss 1.0369 
2023-12-05 23:32:26.925176: val_loss 1.1616 
2023-12-05 23:32:26.925249: Pseudo dice [0.851] 
2023-12-05 23:32:26.925322: Epoch time: 51.77 s 
2023-12-05 23:32:28.071571:  
2023-12-05 23:32:28.071710: Epoch 454 
2023-12-05 23:32:28.071809: Current learning rate: 0.0058 
2023-12-05 23:33:19.708062: train_loss 1.0363 
2023-12-05 23:33:19.708292: val_loss 1.1445 
2023-12-05 23:33:19.708358: Pseudo dice [0.8668] 
2023-12-05 23:33:19.708424: Epoch time: 51.64 s 
2023-12-05 23:33:20.878791:  
2023-12-05 23:33:20.878917: Epoch 455 
2023-12-05 23:33:20.879009: Current learning rate: 0.00579 
2023-12-05 23:34:12.871398: train_loss 1.0364 
2023-12-05 23:34:12.871675: val_loss 1.1538 
2023-12-05 23:34:12.871759: Pseudo dice [0.8607] 
2023-12-05 23:34:12.871843: Epoch time: 51.99 s 
2023-12-05 23:34:14.340867:  
2023-12-05 23:34:14.340991: Epoch 456 
2023-12-05 23:34:14.341084: Current learning rate: 0.00578 
2023-12-05 23:35:06.152101: train_loss 1.037 
2023-12-05 23:35:06.152627: val_loss 1.1429 
2023-12-05 23:35:06.152818: Pseudo dice [0.8693] 
2023-12-05 23:35:06.153013: Epoch time: 51.81 s 
2023-12-05 23:35:07.708926:  
2023-12-05 23:35:07.709226: Epoch 457 
2023-12-05 23:35:07.709361: Current learning rate: 0.00577 
2023-12-05 23:35:59.506269: train_loss 1.0372 
2023-12-05 23:35:59.506581: val_loss 1.1615 
2023-12-05 23:35:59.506655: Pseudo dice [0.8555] 
2023-12-05 23:35:59.506722: Epoch time: 51.8 s 
2023-12-05 23:36:00.707996:  
2023-12-05 23:36:00.708149: Epoch 458 
2023-12-05 23:36:00.708246: Current learning rate: 0.00576 
2023-12-05 23:36:52.407979: train_loss 1.0367 
2023-12-05 23:36:52.408252: val_loss 1.1509 
2023-12-05 23:36:52.408332: Pseudo dice [0.8625] 
2023-12-05 23:36:52.408412: Epoch time: 51.7 s 
2023-12-05 23:36:53.934770:  
2023-12-05 23:36:53.934906: Epoch 459 
2023-12-05 23:36:53.935006: Current learning rate: 0.00575 
2023-12-05 23:37:45.558330: train_loss 1.0356 
2023-12-05 23:37:45.558645: val_loss 1.1403 
2023-12-05 23:37:45.558739: Pseudo dice [0.8725] 
2023-12-05 23:37:45.558823: Epoch time: 51.63 s 
2023-12-05 23:37:46.707062:  
2023-12-05 23:37:46.707312: Epoch 460 
2023-12-05 23:37:46.707409: Current learning rate: 0.00574 
2023-12-05 23:38:38.461639: train_loss 1.0351 
2023-12-05 23:38:38.461972: val_loss 1.1432 
2023-12-05 23:38:38.462058: Pseudo dice [0.8692] 
2023-12-05 23:38:38.462141: Epoch time: 51.76 s 
2023-12-05 23:38:39.979356:  
2023-12-05 23:38:39.979629: Epoch 461 
2023-12-05 23:38:39.979735: Current learning rate: 0.00573 
2023-12-05 23:39:31.887683: train_loss 1.0359 
2023-12-05 23:39:31.887916: val_loss 1.1442 
2023-12-05 23:39:31.887997: Pseudo dice [0.8672] 
2023-12-05 23:39:31.888072: Epoch time: 51.91 s 
2023-12-05 23:39:33.053659:  
2023-12-05 23:39:33.053790: Epoch 462 
2023-12-05 23:39:33.053889: Current learning rate: 0.00572 
2023-12-05 23:40:25.079760: train_loss 1.0361 
2023-12-05 23:40:25.080021: val_loss 1.152 
2023-12-05 23:40:25.080111: Pseudo dice [0.8609] 
2023-12-05 23:40:25.080199: Epoch time: 52.03 s 
2023-12-05 23:40:26.652163:  
2023-12-05 23:40:26.652325: Epoch 463 
2023-12-05 23:40:26.652454: Current learning rate: 0.00571 
2023-12-05 23:41:18.533580: train_loss 1.0361 
2023-12-05 23:41:18.533844: val_loss 1.1608 
2023-12-05 23:41:18.533923: Pseudo dice [0.8552] 
2023-12-05 23:41:18.533998: Epoch time: 51.88 s 
2023-12-05 23:41:19.708069:  
2023-12-05 23:41:19.708245: Epoch 464 
2023-12-05 23:41:19.708347: Current learning rate: 0.0057 
2023-12-05 23:42:11.702645: train_loss 1.0359 
2023-12-05 23:42:11.702915: val_loss 1.148 
2023-12-05 23:42:11.702997: Pseudo dice [0.8647] 
2023-12-05 23:42:11.703101: Epoch time: 52.0 s 
2023-12-05 23:42:13.465911:  
2023-12-05 23:42:13.466531: Epoch 465 
2023-12-05 23:42:13.466668: Current learning rate: 0.0057 
2023-12-05 23:43:05.383118: train_loss 1.0356 
2023-12-05 23:43:05.383494: val_loss 1.1382 
2023-12-05 23:43:05.383585: Pseudo dice [0.8715] 
2023-12-05 23:43:05.383671: Epoch time: 51.92 s 
2023-12-05 23:43:06.863841:  
2023-12-05 23:43:06.864264: Epoch 466 
2023-12-05 23:43:06.864358: Current learning rate: 0.00569 
2023-12-05 23:43:58.638180: train_loss 1.0363 
2023-12-05 23:43:58.638680: val_loss 1.145 
2023-12-05 23:43:58.638869: Pseudo dice [0.8667] 
2023-12-05 23:43:58.639077: Epoch time: 51.78 s 
2023-12-05 23:44:00.210107:  
2023-12-05 23:44:00.210265: Epoch 467 
2023-12-05 23:44:00.210374: Current learning rate: 0.00568 
2023-12-05 23:44:52.057008: train_loss 1.036 
2023-12-05 23:44:52.057276: val_loss 1.1535 
2023-12-05 23:44:52.057354: Pseudo dice [0.8589] 
2023-12-05 23:44:52.057437: Epoch time: 51.85 s 
2023-12-05 23:44:53.662979:  
2023-12-05 23:44:53.663229: Epoch 468 
2023-12-05 23:44:53.663359: Current learning rate: 0.00567 
2023-12-05 23:45:45.687477: train_loss 1.0356 
2023-12-05 23:45:45.687747: val_loss 1.1478 
2023-12-05 23:45:45.687827: Pseudo dice [0.8666] 
2023-12-05 23:45:45.687921: Epoch time: 52.03 s 
2023-12-05 23:45:47.271576:  
2023-12-05 23:45:47.271735: Epoch 469 
2023-12-05 23:45:47.271841: Current learning rate: 0.00566 
2023-12-05 23:46:39.205564: train_loss 1.0351 
2023-12-05 23:46:39.205786: val_loss 1.1363 
2023-12-05 23:46:39.205851: Pseudo dice [0.8746] 
2023-12-05 23:46:39.205916: Epoch time: 51.94 s 
2023-12-05 23:46:40.770822:  
2023-12-05 23:46:40.770978: Epoch 470 
2023-12-05 23:46:40.771112: Current learning rate: 0.00565 
2023-12-05 23:47:32.796012: train_loss 1.0364 
2023-12-05 23:47:32.796243: val_loss 1.1509 
2023-12-05 23:47:32.796309: Pseudo dice [0.8617] 
2023-12-05 23:47:32.796376: Epoch time: 52.03 s 
2023-12-05 23:47:33.968584:  
2023-12-05 23:47:33.968718: Epoch 471 
2023-12-05 23:47:33.968815: Current learning rate: 0.00564 
2023-12-05 23:48:25.903398: train_loss 1.0363 
2023-12-05 23:48:25.903661: val_loss 1.1446 
2023-12-05 23:48:25.903741: Pseudo dice [0.8685] 
2023-12-05 23:48:25.903820: Epoch time: 51.94 s 
2023-12-05 23:48:27.286671:  
2023-12-05 23:48:27.286889: Epoch 472 
2023-12-05 23:48:27.286990: Current learning rate: 0.00563 
2023-12-05 23:49:19.024902: train_loss 1.037 
2023-12-05 23:49:19.025163: val_loss 1.1504 
2023-12-05 23:49:19.025244: Pseudo dice [0.8622] 
2023-12-05 23:49:19.025325: Epoch time: 51.74 s 
2023-12-05 23:49:20.493086:  
2023-12-05 23:49:20.493237: Epoch 473 
2023-12-05 23:49:20.493338: Current learning rate: 0.00562 
2023-12-05 23:50:12.381293: train_loss 1.0372 
2023-12-05 23:50:12.381525: val_loss 1.1513 
2023-12-05 23:50:12.381591: Pseudo dice [0.8621] 
2023-12-05 23:50:12.381659: Epoch time: 51.89 s 
2023-12-05 23:50:13.597215:  
2023-12-05 23:50:13.597357: Epoch 474 
2023-12-05 23:50:13.597453: Current learning rate: 0.00561 
2023-12-05 23:51:05.302722: train_loss 1.0365 
2023-12-05 23:51:05.302967: val_loss 1.1412 
2023-12-05 23:51:05.303048: Pseudo dice [0.8718] 
2023-12-05 23:51:05.303118: Epoch time: 51.71 s 
2023-12-05 23:51:06.780166:  
2023-12-05 23:51:06.780326: Epoch 475 
2023-12-05 23:51:06.780441: Current learning rate: 0.0056 
2023-12-05 23:51:58.595691: train_loss 1.0375 
2023-12-05 23:51:58.595972: val_loss 1.1512 
2023-12-05 23:51:58.596049: Pseudo dice [0.8622] 
2023-12-05 23:51:58.596130: Epoch time: 51.82 s 
2023-12-05 23:51:59.892298:  
2023-12-05 23:51:59.892853: Epoch 476 
2023-12-05 23:51:59.893008: Current learning rate: 0.00559 
2023-12-05 23:52:51.743686: train_loss 1.0363 
2023-12-05 23:52:51.743911: val_loss 1.1439 
2023-12-05 23:52:51.743973: Pseudo dice [0.8685] 
2023-12-05 23:52:51.744038: Epoch time: 51.85 s 
2023-12-05 23:52:52.953527:  
2023-12-05 23:52:52.953681: Epoch 477 
2023-12-05 23:52:52.953775: Current learning rate: 0.00558 
2023-12-05 23:53:44.871731: train_loss 1.036 
2023-12-05 23:53:44.871952: val_loss 1.147 
2023-12-05 23:53:44.872018: Pseudo dice [0.8651] 
2023-12-05 23:53:44.872084: Epoch time: 51.92 s 
2023-12-05 23:53:46.187571:  
2023-12-05 23:53:46.187701: Epoch 478 
2023-12-05 23:53:46.187792: Current learning rate: 0.00557 
2023-12-05 23:54:38.099204: train_loss 1.036 
2023-12-05 23:54:38.099470: val_loss 1.1492 
2023-12-05 23:54:38.099552: Pseudo dice [0.8634] 
2023-12-05 23:54:38.099634: Epoch time: 51.91 s 
2023-12-05 23:54:39.682321:  
2023-12-05 23:54:39.682611: Epoch 479 
2023-12-05 23:54:39.682728: Current learning rate: 0.00556 
2023-12-05 23:55:31.505746: train_loss 1.0363 
2023-12-05 23:55:31.506017: val_loss 1.1435 
2023-12-05 23:55:31.506096: Pseudo dice [0.8673] 
2023-12-05 23:55:31.506174: Epoch time: 51.83 s 
2023-12-05 23:55:32.905566:  
2023-12-05 23:55:32.905704: Epoch 480 
2023-12-05 23:55:32.905799: Current learning rate: 0.00555 
2023-12-05 23:56:24.477313: train_loss 1.035 
2023-12-05 23:56:24.477580: val_loss 1.1454 
2023-12-05 23:56:24.477659: Pseudo dice [0.8673] 
2023-12-05 23:56:24.477739: Epoch time: 51.57 s 
2023-12-05 23:56:26.069877:  
2023-12-05 23:56:26.070034: Epoch 481 
2023-12-05 23:56:26.070142: Current learning rate: 0.00554 
2023-12-05 23:57:17.974385: train_loss 1.0363 
2023-12-05 23:57:17.974642: val_loss 1.1542 
2023-12-05 23:57:17.974737: Pseudo dice [0.8617] 
2023-12-05 23:57:17.974823: Epoch time: 51.91 s 
2023-12-05 23:57:19.580270:  
2023-12-05 23:57:19.580871: Epoch 482 
2023-12-05 23:57:19.581017: Current learning rate: 0.00553 
2023-12-05 23:58:11.657891: train_loss 1.0354 
2023-12-05 23:58:11.658152: val_loss 1.1544 
2023-12-05 23:58:11.658234: Pseudo dice [0.859] 
2023-12-05 23:58:11.658314: Epoch time: 52.08 s 
2023-12-05 23:58:13.289858:  
2023-12-05 23:58:13.290198: Epoch 483 
2023-12-05 23:58:13.290316: Current learning rate: 0.00552 
2023-12-05 23:59:05.213795: train_loss 1.0357 
2023-12-05 23:59:05.214053: val_loss 1.1536 
2023-12-05 23:59:05.214130: Pseudo dice [0.8598] 
2023-12-05 23:59:05.214209: Epoch time: 51.93 s 
2023-12-05 23:59:07.000117:  
2023-12-05 23:59:07.000295: Epoch 484 
2023-12-05 23:59:07.000411: Current learning rate: 0.00551 
2023-12-05 23:59:58.499966: train_loss 1.0369 
2023-12-05 23:59:58.500235: val_loss 1.1416 
2023-12-05 23:59:58.500316: Pseudo dice [0.87] 
2023-12-05 23:59:58.500399: Epoch time: 51.5 s 
2023-12-05 23:59:59.766727:  
2023-12-05 23:59:59.766869: Epoch 485 
2023-12-05 23:59:59.766962: Current learning rate: 0.0055 
2023-12-06 00:00:51.706625: train_loss 1.035 
2023-12-06 00:00:51.706886: val_loss 1.1519 
2023-12-06 00:00:51.706968: Pseudo dice [0.8616] 
2023-12-06 00:00:51.707060: Epoch time: 51.94 s 
2023-12-06 00:00:53.296665:  
2023-12-06 00:00:53.296835: Epoch 486 
2023-12-06 00:00:53.296940: Current learning rate: 0.00549 
2023-12-06 00:01:45.349617: train_loss 1.035 
2023-12-06 00:01:45.349882: val_loss 1.1494 
2023-12-06 00:01:45.349991: Pseudo dice [0.8633] 
2023-12-06 00:01:45.350096: Epoch time: 52.06 s 
2023-12-06 00:01:46.657657:  
2023-12-06 00:01:46.657794: Epoch 487 
2023-12-06 00:01:46.657887: Current learning rate: 0.00548 
2023-12-06 00:02:38.506987: train_loss 1.0354 
2023-12-06 00:02:38.507258: val_loss 1.1487 
2023-12-06 00:02:38.507341: Pseudo dice [0.8626] 
2023-12-06 00:02:38.507425: Epoch time: 51.85 s 
2023-12-06 00:02:39.853486:  
2023-12-06 00:02:39.853626: Epoch 488 
2023-12-06 00:02:39.853722: Current learning rate: 0.00547 
2023-12-06 00:03:31.670806: train_loss 1.0358 
2023-12-06 00:03:31.671359: val_loss 1.1413 
2023-12-06 00:03:31.671449: Pseudo dice [0.8708] 
2023-12-06 00:03:31.671536: Epoch time: 51.82 s 
2023-12-06 00:03:33.253000:  
2023-12-06 00:03:33.253334: Epoch 489 
2023-12-06 00:03:33.253454: Current learning rate: 0.00546 
2023-12-06 00:04:25.160609: train_loss 1.0357 
2023-12-06 00:04:25.160837: val_loss 1.1461 
2023-12-06 00:04:25.160907: Pseudo dice [0.8657] 
2023-12-06 00:04:25.160977: Epoch time: 51.91 s 
2023-12-06 00:04:26.756011:  
2023-12-06 00:04:26.756313: Epoch 490 
2023-12-06 00:04:26.756430: Current learning rate: 0.00546 
2023-12-06 00:05:18.835761: train_loss 1.0355 
2023-12-06 00:05:18.836017: val_loss 1.1513 
2023-12-06 00:05:18.836097: Pseudo dice [0.8629] 
2023-12-06 00:05:18.836176: Epoch time: 52.08 s 
2023-12-06 00:05:20.456517:  
2023-12-06 00:05:20.457164: Epoch 491 
2023-12-06 00:05:20.457412: Current learning rate: 0.00545 
2023-12-06 00:06:12.246407: train_loss 1.0364 
2023-12-06 00:06:12.246953: val_loss 1.1441 
2023-12-06 00:06:12.247062: Pseudo dice [0.8683] 
2023-12-06 00:06:12.247156: Epoch time: 51.79 s 
2023-12-06 00:06:13.410014:  
2023-12-06 00:06:13.410190: Epoch 492 
2023-12-06 00:06:13.410281: Current learning rate: 0.00544 
2023-12-06 00:07:05.289306: train_loss 1.0347 
2023-12-06 00:07:05.289577: val_loss 1.1429 
2023-12-06 00:07:05.289662: Pseudo dice [0.8682] 
2023-12-06 00:07:05.289744: Epoch time: 51.88 s 
2023-12-06 00:07:06.902989:  
2023-12-06 00:07:06.903250: Epoch 493 
2023-12-06 00:07:06.903375: Current learning rate: 0.00543 
2023-12-06 00:07:58.831888: train_loss 1.0353 
2023-12-06 00:07:58.832542: val_loss 1.1488 
2023-12-06 00:07:58.832651: Pseudo dice [0.8652] 
2023-12-06 00:07:58.832758: Epoch time: 51.93 s 
2023-12-06 00:08:00.455276:  
2023-12-06 00:08:00.455494: Epoch 494 
2023-12-06 00:08:00.455604: Current learning rate: 0.00542 
2023-12-06 00:08:52.498255: train_loss 1.0342 
2023-12-06 00:08:52.498533: val_loss 1.1422 
2023-12-06 00:08:52.498605: Pseudo dice [0.8687] 
2023-12-06 00:08:52.498693: Epoch time: 52.05 s 
2023-12-06 00:08:53.716727:  
2023-12-06 00:08:53.717073: Epoch 495 
2023-12-06 00:08:53.717206: Current learning rate: 0.00541 
2023-12-06 00:09:45.290033: train_loss 1.0346 
2023-12-06 00:09:45.290644: val_loss 1.1474 
2023-12-06 00:09:45.290756: Pseudo dice [0.8658] 
2023-12-06 00:09:45.290873: Epoch time: 51.58 s 
2023-12-06 00:09:47.116137:  
2023-12-06 00:09:47.116309: Epoch 496 
2023-12-06 00:09:47.116432: Current learning rate: 0.0054 
2023-12-06 00:10:39.067733: train_loss 1.0353 
2023-12-06 00:10:39.068021: val_loss 1.1444 
2023-12-06 00:10:39.068106: Pseudo dice [0.8679] 
2023-12-06 00:10:39.068208: Epoch time: 51.95 s 
2023-12-06 00:10:40.661198:  
2023-12-06 00:10:40.661397: Epoch 497 
2023-12-06 00:10:40.661514: Current learning rate: 0.00539 
2023-12-06 00:11:32.712422: train_loss 1.035 
2023-12-06 00:11:32.712676: val_loss 1.1453 
2023-12-06 00:11:32.712747: Pseudo dice [0.869] 
2023-12-06 00:11:32.712823: Epoch time: 52.05 s 
2023-12-06 00:11:33.904881:  
2023-12-06 00:11:33.905192: Epoch 498 
2023-12-06 00:11:33.905288: Current learning rate: 0.00538 
2023-12-06 00:12:25.429039: train_loss 1.0352 
2023-12-06 00:12:25.429301: val_loss 1.1479 
2023-12-06 00:12:25.429385: Pseudo dice [0.8646] 
2023-12-06 00:12:25.429475: Epoch time: 51.53 s 
2023-12-06 00:12:26.650710:  
2023-12-06 00:12:26.651022: Epoch 499 
2023-12-06 00:12:26.651326: Current learning rate: 0.00537 
2023-12-06 00:13:18.143505: train_loss 1.0354 
2023-12-06 00:13:18.143718: val_loss 1.1391 
2023-12-06 00:13:18.143775: Pseudo dice [0.8716] 
2023-12-06 00:13:18.143836: Epoch time: 51.49 s 
2023-12-06 00:13:20.642469:  
2023-12-06 00:13:20.642620: Epoch 500 
2023-12-06 00:13:20.642700: Current learning rate: 0.00536 
2023-12-06 00:14:12.255936: train_loss 1.0355 
2023-12-06 00:14:12.256173: val_loss 1.142 
2023-12-06 00:14:12.256240: Pseudo dice [0.8704] 
2023-12-06 00:14:12.256312: Epoch time: 51.61 s 
2023-12-06 00:14:12.256366: Yayy! New best EMA pseudo Dice: 0.867 
2023-12-06 00:14:14.729174:  
2023-12-06 00:14:14.729762: Epoch 501 
2023-12-06 00:14:14.729895: Current learning rate: 0.00535 
2023-12-06 00:15:06.638396: train_loss 1.0347 
2023-12-06 00:15:06.639049: val_loss 1.1323 
2023-12-06 00:15:06.639169: Pseudo dice [0.8785] 
2023-12-06 00:15:06.639282: Epoch time: 51.91 s 
2023-12-06 00:15:06.639347: Yayy! New best EMA pseudo Dice: 0.8681 
2023-12-06 00:15:09.528885:  
2023-12-06 00:15:09.529180: Epoch 502 
2023-12-06 00:15:09.529311: Current learning rate: 0.00534 
2023-12-06 00:16:01.028405: train_loss 1.0362 
2023-12-06 00:16:01.028631: val_loss 1.1444 
2023-12-06 00:16:01.028699: Pseudo dice [0.8679] 
2023-12-06 00:16:01.028767: Epoch time: 51.5 s 
2023-12-06 00:16:02.423549:  
2023-12-06 00:16:02.423691: Epoch 503 
2023-12-06 00:16:02.423784: Current learning rate: 0.00533 
2023-12-06 00:16:53.979553: train_loss 1.0349 
2023-12-06 00:16:53.979830: val_loss 1.1414 
2023-12-06 00:16:53.979921: Pseudo dice [0.8705] 
2023-12-06 00:16:53.980016: Epoch time: 51.56 s 
2023-12-06 00:16:53.980083: Yayy! New best EMA pseudo Dice: 0.8683 
2023-12-06 00:16:56.937868:  
2023-12-06 00:16:56.938031: Epoch 504 
2023-12-06 00:16:56.938144: Current learning rate: 0.00532 
2023-12-06 00:17:48.849164: train_loss 1.0355 
2023-12-06 00:17:48.849423: val_loss 1.1496 
2023-12-06 00:17:48.849488: Pseudo dice [0.8638] 
2023-12-06 00:17:48.849558: Epoch time: 51.91 s 
2023-12-06 00:17:50.009456:  
2023-12-06 00:17:50.009633: Epoch 505 
2023-12-06 00:17:50.009729: Current learning rate: 0.00531 
2023-12-06 00:18:42.005663: train_loss 1.0375 
2023-12-06 00:18:42.005956: val_loss 1.1532 
2023-12-06 00:18:42.006042: Pseudo dice [0.8602] 
2023-12-06 00:18:42.006132: Epoch time: 52.0 s 
2023-12-06 00:18:43.606888:  
2023-12-06 00:18:43.607076: Epoch 506 
2023-12-06 00:18:43.607190: Current learning rate: 0.0053 
2023-12-06 00:19:35.711452: train_loss 1.0365 
2023-12-06 00:19:35.711714: val_loss 1.1488 
2023-12-06 00:19:35.711814: Pseudo dice [0.8628] 
2023-12-06 00:19:35.711903: Epoch time: 52.11 s 
2023-12-06 00:19:37.219380:  
2023-12-06 00:19:37.219539: Epoch 507 
2023-12-06 00:19:37.219637: Current learning rate: 0.00529 
2023-12-06 00:20:29.073102: train_loss 1.0352 
2023-12-06 00:20:29.073362: val_loss 1.1437 
2023-12-06 00:20:29.073444: Pseudo dice [0.8676] 
2023-12-06 00:20:29.073525: Epoch time: 51.86 s 
2023-12-06 00:20:30.878653:  
2023-12-06 00:20:30.878867: Epoch 508 
2023-12-06 00:20:30.878989: Current learning rate: 0.00528 
2023-12-06 00:21:22.896955: train_loss 1.0352 
2023-12-06 00:21:22.897213: val_loss 1.1456 
2023-12-06 00:21:22.897296: Pseudo dice [0.8673] 
2023-12-06 00:21:22.897379: Epoch time: 52.02 s 
2023-12-06 00:21:24.553593:  
2023-12-06 00:21:24.553777: Epoch 509 
2023-12-06 00:21:24.553888: Current learning rate: 0.00527 
2023-12-06 00:22:16.627247: train_loss 1.0357 
2023-12-06 00:22:16.627510: val_loss 1.142 
2023-12-06 00:22:16.627594: Pseudo dice [0.8701] 
2023-12-06 00:22:16.627678: Epoch time: 52.08 s 
2023-12-06 00:22:18.214713:  
2023-12-06 00:22:18.214871: Epoch 510 
2023-12-06 00:22:18.214984: Current learning rate: 0.00526 
2023-12-06 00:23:10.154930: train_loss 1.036 
2023-12-06 00:23:10.155167: val_loss 1.1484 
2023-12-06 00:23:10.155235: Pseudo dice [0.8663] 
2023-12-06 00:23:10.155304: Epoch time: 51.94 s 
2023-12-06 00:23:11.340552:  
2023-12-06 00:23:11.340692: Epoch 511 
2023-12-06 00:23:11.340774: Current learning rate: 0.00525 
2023-12-06 00:24:03.236288: train_loss 1.0356 
2023-12-06 00:24:03.236547: val_loss 1.1391 
2023-12-06 00:24:03.236622: Pseudo dice [0.8727] 
2023-12-06 00:24:03.236702: Epoch time: 51.9 s 
2023-12-06 00:24:04.821069:  
2023-12-06 00:24:04.821334: Epoch 512 
2023-12-06 00:24:04.821452: Current learning rate: 0.00524 
2023-12-06 00:24:56.637692: train_loss 1.0348 
2023-12-06 00:24:56.637924: val_loss 1.1493 
2023-12-06 00:24:56.637991: Pseudo dice [0.864] 
2023-12-06 00:24:56.638057: Epoch time: 51.82 s 
2023-12-06 00:24:57.845170:  
2023-12-06 00:24:57.845379: Epoch 513 
2023-12-06 00:24:57.845482: Current learning rate: 0.00523 
2023-12-06 00:25:49.481772: train_loss 1.0352 
2023-12-06 00:25:49.481996: val_loss 1.141 
2023-12-06 00:25:49.482061: Pseudo dice [0.8705] 
2023-12-06 00:25:49.482129: Epoch time: 51.64 s 
2023-12-06 00:25:50.665757:  
2023-12-06 00:25:50.666036: Epoch 514 
2023-12-06 00:25:50.666142: Current learning rate: 0.00522 
2023-12-06 00:26:42.576548: train_loss 1.0344 
2023-12-06 00:26:42.576769: val_loss 1.1478 
2023-12-06 00:26:42.576831: Pseudo dice [0.8662] 
2023-12-06 00:26:42.576893: Epoch time: 51.91 s 
2023-12-06 00:26:43.780068:  
2023-12-06 00:26:43.780220: Epoch 515 
2023-12-06 00:26:43.780315: Current learning rate: 0.00521 
2023-12-06 00:27:35.616562: train_loss 1.0345 
2023-12-06 00:27:35.616815: val_loss 1.1415 
2023-12-06 00:27:35.616898: Pseudo dice [0.87] 
2023-12-06 00:27:35.616979: Epoch time: 51.84 s 
2023-12-06 00:27:36.845393:  
2023-12-06 00:27:36.845632: Epoch 516 
2023-12-06 00:27:36.845729: Current learning rate: 0.0052 
2023-12-06 00:28:28.742122: train_loss 1.0349 
2023-12-06 00:28:28.742378: val_loss 1.1502 
2023-12-06 00:28:28.742458: Pseudo dice [0.8629] 
2023-12-06 00:28:28.742537: Epoch time: 51.9 s 
2023-12-06 00:28:30.246822:  
2023-12-06 00:28:30.246965: Epoch 517 
2023-12-06 00:28:30.247059: Current learning rate: 0.00519 
2023-12-06 00:29:22.071658: train_loss 1.0345 
2023-12-06 00:29:22.071927: val_loss 1.1438 
2023-12-06 00:29:22.072005: Pseudo dice [0.8681] 
2023-12-06 00:29:22.072086: Epoch time: 51.83 s 
2023-12-06 00:29:23.676677:  
2023-12-06 00:29:23.676870: Epoch 518 
2023-12-06 00:29:23.676984: Current learning rate: 0.00518 
2023-12-06 00:30:15.744253: train_loss 1.0343 
2023-12-06 00:30:15.744518: val_loss 1.1498 
2023-12-06 00:30:15.744599: Pseudo dice [0.8627] 
2023-12-06 00:30:15.744682: Epoch time: 52.07 s 
2023-12-06 00:30:17.386226:  
2023-12-06 00:30:17.386384: Epoch 519 
2023-12-06 00:30:17.386494: Current learning rate: 0.00518 
2023-12-06 00:31:09.454720: train_loss 1.034 
2023-12-06 00:31:09.455010: val_loss 1.1555 
2023-12-06 00:31:09.455104: Pseudo dice [0.8577] 
2023-12-06 00:31:09.455193: Epoch time: 52.07 s 
2023-12-06 00:31:11.045830:  
2023-12-06 00:31:11.045997: Epoch 520 
2023-12-06 00:31:11.046100: Current learning rate: 0.00517 
2023-12-06 00:32:02.957104: train_loss 1.0345 
2023-12-06 00:32:02.957363: val_loss 1.151 
2023-12-06 00:32:02.957456: Pseudo dice [0.8623] 
2023-12-06 00:32:02.957550: Epoch time: 51.91 s 
2023-12-06 00:32:04.795483:  
2023-12-06 00:32:04.795830: Epoch 521 
2023-12-06 00:32:04.795996: Current learning rate: 0.00516 
2023-12-06 00:32:56.674571: train_loss 1.0339 
2023-12-06 00:32:56.674830: val_loss 1.1477 
2023-12-06 00:32:56.674911: Pseudo dice [0.8665] 
2023-12-06 00:32:56.674994: Epoch time: 51.88 s 
2023-12-06 00:32:58.274362:  
2023-12-06 00:32:58.274517: Epoch 522 
2023-12-06 00:32:58.274630: Current learning rate: 0.00515 
2023-12-06 00:33:50.375051: train_loss 1.0344 
2023-12-06 00:33:50.375310: val_loss 1.1502 
2023-12-06 00:33:50.375389: Pseudo dice [0.8634] 
2023-12-06 00:33:50.375472: Epoch time: 52.1 s 
2023-12-06 00:33:51.975139:  
2023-12-06 00:33:51.975310: Epoch 523 
2023-12-06 00:33:51.975426: Current learning rate: 0.00514 
2023-12-06 00:34:43.953813: train_loss 1.0349 
2023-12-06 00:34:43.954072: val_loss 1.1412 
2023-12-06 00:34:43.954152: Pseudo dice [0.8704] 
2023-12-06 00:34:43.954233: Epoch time: 51.98 s 
2023-12-06 00:34:45.543037:  
2023-12-06 00:34:45.543196: Epoch 524 
2023-12-06 00:34:45.543308: Current learning rate: 0.00513 
2023-12-06 00:35:37.610078: train_loss 1.0343 
2023-12-06 00:35:37.610350: val_loss 1.1418 
2023-12-06 00:35:37.610430: Pseudo dice [0.8706] 
2023-12-06 00:35:37.610514: Epoch time: 52.07 s 
2023-12-06 00:35:39.214329:  
2023-12-06 00:35:39.214483: Epoch 525 
2023-12-06 00:35:39.214599: Current learning rate: 0.00512 
2023-12-06 00:36:31.203839: train_loss 1.0331 
2023-12-06 00:36:31.204115: val_loss 1.1448 
2023-12-06 00:36:31.204199: Pseudo dice [0.8672] 
2023-12-06 00:36:31.204291: Epoch time: 51.99 s 
2023-12-06 00:36:32.815818:  
2023-12-06 00:36:32.815983: Epoch 526 
2023-12-06 00:36:32.816088: Current learning rate: 0.00511 
2023-12-06 00:37:24.517303: train_loss 1.0339 
2023-12-06 00:37:24.517524: val_loss 1.1435 
2023-12-06 00:37:24.517593: Pseudo dice [0.8683] 
2023-12-06 00:37:24.517659: Epoch time: 51.7 s 
2023-12-06 00:37:25.911824:  
2023-12-06 00:37:25.911967: Epoch 527 
2023-12-06 00:37:25.912074: Current learning rate: 0.0051 
2023-12-06 00:38:17.777302: train_loss 1.0344 
2023-12-06 00:38:17.777572: val_loss 1.1414 
2023-12-06 00:38:17.777656: Pseudo dice [0.8697] 
2023-12-06 00:38:17.777739: Epoch time: 51.87 s 
2023-12-06 00:38:19.380222:  
2023-12-06 00:38:19.380399: Epoch 528 
2023-12-06 00:38:19.380512: Current learning rate: 0.00509 
2023-12-06 00:39:11.335549: train_loss 1.0342 
2023-12-06 00:39:11.335811: val_loss 1.1607 
2023-12-06 00:39:11.335895: Pseudo dice [0.8549] 
2023-12-06 00:39:11.335978: Epoch time: 51.96 s 
2023-12-06 00:39:12.937944:  
2023-12-06 00:39:12.938111: Epoch 529 
2023-12-06 00:39:12.938223: Current learning rate: 0.00508 
2023-12-06 00:40:04.931402: train_loss 1.0335 
2023-12-06 00:40:04.931666: val_loss 1.1576 
2023-12-06 00:40:04.931751: Pseudo dice [0.8567] 
2023-12-06 00:40:04.931834: Epoch time: 52.0 s 
2023-12-06 00:40:06.156665:  
2023-12-06 00:40:06.156824: Epoch 530 
2023-12-06 00:40:06.156918: Current learning rate: 0.00507 
2023-12-06 00:40:58.036045: train_loss 1.0341 
2023-12-06 00:40:58.036274: val_loss 1.1489 
2023-12-06 00:40:58.036339: Pseudo dice [0.8636] 
2023-12-06 00:40:58.036411: Epoch time: 51.88 s 
2023-12-06 00:40:59.627306:  
2023-12-06 00:40:59.627625: Epoch 531 
2023-12-06 00:40:59.627758: Current learning rate: 0.00506 
2023-12-06 00:41:51.406349: train_loss 1.0339 
2023-12-06 00:41:51.406578: val_loss 1.1421 
2023-12-06 00:41:51.406659: Pseudo dice [0.8702] 
2023-12-06 00:41:51.406730: Epoch time: 51.78 s 
2023-12-06 00:41:52.633481:  
2023-12-06 00:41:52.633611: Epoch 532 
2023-12-06 00:41:52.633697: Current learning rate: 0.00505 
2023-12-06 00:42:44.198948: train_loss 1.0342 
2023-12-06 00:42:44.199199: val_loss 1.1492 
2023-12-06 00:42:44.199265: Pseudo dice [0.8632] 
2023-12-06 00:42:44.199330: Epoch time: 51.57 s 
2023-12-06 00:42:45.505948:  
2023-12-06 00:42:45.506384: Epoch 533 
2023-12-06 00:42:45.506481: Current learning rate: 0.00504 
2023-12-06 00:43:37.376619: train_loss 1.0341 
2023-12-06 00:43:37.376934: val_loss 1.1425 
2023-12-06 00:43:37.377023: Pseudo dice [0.8682] 
2023-12-06 00:43:37.377107: Epoch time: 51.87 s 
2023-12-06 00:43:38.968169:  
2023-12-06 00:43:38.968348: Epoch 534 
2023-12-06 00:43:38.968456: Current learning rate: 0.00503 
2023-12-06 00:44:30.762988: train_loss 1.0336 
2023-12-06 00:44:30.763966: val_loss 1.1423 
2023-12-06 00:44:30.764036: Pseudo dice [0.8693] 
2023-12-06 00:44:30.764101: Epoch time: 51.8 s 
2023-12-06 00:44:31.974683:  
2023-12-06 00:44:31.974811: Epoch 535 
2023-12-06 00:44:31.974901: Current learning rate: 0.00502 
2023-12-06 00:45:23.856631: train_loss 1.0347 
2023-12-06 00:45:23.856894: val_loss 1.1514 
2023-12-06 00:45:23.857127: Pseudo dice [0.8603] 
2023-12-06 00:45:23.857217: Epoch time: 51.88 s 
2023-12-06 00:45:25.418025:  
2023-12-06 00:45:25.418195: Epoch 536 
2023-12-06 00:45:25.418301: Current learning rate: 0.00501 
2023-12-06 00:46:17.249244: train_loss 1.0333 
2023-12-06 00:46:17.249508: val_loss 1.1473 
2023-12-06 00:46:17.249593: Pseudo dice [0.8655] 
2023-12-06 00:46:17.249679: Epoch time: 51.83 s 
2023-12-06 00:46:18.874483:  
2023-12-06 00:46:18.874774: Epoch 537 
2023-12-06 00:46:18.874918: Current learning rate: 0.005 
2023-12-06 00:47:10.941599: train_loss 1.0343 
2023-12-06 00:47:10.941829: val_loss 1.1454 
2023-12-06 00:47:10.941896: Pseudo dice [0.8662] 
2023-12-06 00:47:10.941966: Epoch time: 52.07 s 
2023-12-06 00:47:12.128386:  
2023-12-06 00:47:12.128524: Epoch 538 
2023-12-06 00:47:12.128615: Current learning rate: 0.00499 
2023-12-06 00:48:04.042821: train_loss 1.0336 
2023-12-06 00:48:04.043107: val_loss 1.1447 
2023-12-06 00:48:04.043197: Pseudo dice [0.8661] 
2023-12-06 00:48:04.043282: Epoch time: 51.92 s 
2023-12-06 00:48:05.842738:  
2023-12-06 00:48:05.843084: Epoch 539 
2023-12-06 00:48:05.843210: Current learning rate: 0.00498 
2023-12-06 00:48:57.747686: train_loss 1.0347 
2023-12-06 00:48:57.747911: val_loss 1.1435 
2023-12-06 00:48:57.747977: Pseudo dice [0.868] 
2023-12-06 00:48:57.748043: Epoch time: 51.91 s 
2023-12-06 00:48:59.335161:  
2023-12-06 00:48:59.335330: Epoch 540 
2023-12-06 00:48:59.335443: Current learning rate: 0.00497 
2023-12-06 00:49:51.115171: train_loss 1.0343 
2023-12-06 00:49:51.115437: val_loss 1.1436 
2023-12-06 00:49:51.115520: Pseudo dice [0.8688] 
2023-12-06 00:49:51.115777: Epoch time: 51.78 s 
2023-12-06 00:49:52.640616:  
2023-12-06 00:49:52.640955: Epoch 541 
2023-12-06 00:49:52.641054: Current learning rate: 0.00496 
2023-12-06 00:50:44.509902: train_loss 1.0341 
2023-12-06 00:50:44.510127: val_loss 1.1499 
2023-12-06 00:50:44.510195: Pseudo dice [0.8651] 
2023-12-06 00:50:44.510260: Epoch time: 51.87 s 
2023-12-06 00:50:45.724444:  
2023-12-06 00:50:45.724577: Epoch 542 
2023-12-06 00:50:45.724666: Current learning rate: 0.00495 
2023-12-06 00:51:37.449201: train_loss 1.0336 
2023-12-06 00:51:37.449436: val_loss 1.1459 
2023-12-06 00:51:37.449504: Pseudo dice [0.8666] 
2023-12-06 00:51:37.449573: Epoch time: 51.73 s 
2023-12-06 00:51:39.047861:  
2023-12-06 00:51:39.048014: Epoch 543 
2023-12-06 00:51:39.048155: Current learning rate: 0.00494 
2023-12-06 00:52:30.658643: train_loss 1.0338 
2023-12-06 00:52:30.658874: val_loss 1.1465 
2023-12-06 00:52:30.658940: Pseudo dice [0.8649] 
2023-12-06 00:52:30.659008: Epoch time: 51.61 s 
2023-12-06 00:52:31.845233:  
2023-12-06 00:52:31.845366: Epoch 544 
2023-12-06 00:52:31.845462: Current learning rate: 0.00493 
2023-12-06 00:53:23.387600: train_loss 1.0339 
2023-12-06 00:53:23.387827: val_loss 1.1485 
2023-12-06 00:53:23.387896: Pseudo dice [0.8654] 
2023-12-06 00:53:23.387965: Epoch time: 51.54 s 
2023-12-06 00:53:24.746416:  
2023-12-06 00:53:24.746849: Epoch 545 
2023-12-06 00:53:24.746963: Current learning rate: 0.00492 
2023-12-06 00:54:16.541222: train_loss 1.0351 
2023-12-06 00:54:16.541430: val_loss 1.1558 
2023-12-06 00:54:16.541510: Pseudo dice [0.8559] 
2023-12-06 00:54:16.541586: Epoch time: 51.8 s 
2023-12-06 00:54:18.182205:  
2023-12-06 00:54:18.182368: Epoch 546 
2023-12-06 00:54:18.182476: Current learning rate: 0.00491 
2023-12-06 00:55:10.137912: train_loss 1.0346 
2023-12-06 00:55:10.138185: val_loss 1.1472 
2023-12-06 00:55:10.138265: Pseudo dice [0.8652] 
2023-12-06 00:55:10.138345: Epoch time: 51.96 s 
2023-12-06 00:55:11.453572:  
2023-12-06 00:55:11.453727: Epoch 547 
2023-12-06 00:55:11.453822: Current learning rate: 0.0049 
2023-12-06 00:56:03.340536: train_loss 1.0348 
2023-12-06 00:56:03.340766: val_loss 1.1491 
2023-12-06 00:56:03.340837: Pseudo dice [0.862] 
2023-12-06 00:56:03.340908: Epoch time: 51.89 s 
2023-12-06 00:56:04.519743:  
2023-12-06 00:56:04.520137: Epoch 548 
2023-12-06 00:56:04.520228: Current learning rate: 0.00489 
2023-12-06 00:56:56.451379: train_loss 1.0348 
2023-12-06 00:56:56.451718: val_loss 1.1559 
2023-12-06 00:56:56.451788: Pseudo dice [0.8594] 
2023-12-06 00:56:56.451856: Epoch time: 51.93 s 
2023-12-06 00:56:57.655802:  
2023-12-06 00:56:57.656235: Epoch 549 
2023-12-06 00:56:57.656346: Current learning rate: 0.00488 
2023-12-06 00:57:49.554780: train_loss 1.0343 
2023-12-06 00:57:49.555010: val_loss 1.1464 
2023-12-06 00:57:49.555087: Pseudo dice [0.8662] 
2023-12-06 00:57:49.555156: Epoch time: 51.9 s 
2023-12-06 00:57:52.016175:  
2023-12-06 00:57:52.016603: Epoch 550 
2023-12-06 00:57:52.016763: Current learning rate: 0.00487 
2023-12-06 00:58:43.689206: train_loss 1.0337 
2023-12-06 00:58:43.689503: val_loss 1.1555 
2023-12-06 00:58:43.689600: Pseudo dice [0.8567] 
2023-12-06 00:58:43.689700: Epoch time: 51.68 s 
2023-12-06 00:58:45.476837:  
2023-12-06 00:58:45.477022: Epoch 551 
2023-12-06 00:58:45.477128: Current learning rate: 0.00486 
2023-12-06 00:59:37.253370: train_loss 1.0336 
2023-12-06 00:59:37.253646: val_loss 1.1506 
2023-12-06 00:59:37.253738: Pseudo dice [0.8619] 
2023-12-06 00:59:37.253829: Epoch time: 51.78 s 
2023-12-06 00:59:38.867447:  
2023-12-06 00:59:38.867616: Epoch 552 
2023-12-06 00:59:38.867726: Current learning rate: 0.00485 
2023-12-06 01:00:30.656630: train_loss 1.0329 
2023-12-06 01:00:30.656896: val_loss 1.1437 
2023-12-06 01:00:30.656978: Pseudo dice [0.8683] 
2023-12-06 01:00:30.657059: Epoch time: 51.79 s 
2023-12-06 01:00:32.263317:  
2023-12-06 01:00:32.263593: Epoch 553 
2023-12-06 01:00:32.263707: Current learning rate: 0.00484 
2023-12-06 01:01:24.211904: train_loss 1.0333 
2023-12-06 01:01:24.212137: val_loss 1.1418 
2023-12-06 01:01:24.212202: Pseudo dice [0.87] 
2023-12-06 01:01:24.212270: Epoch time: 51.95 s 
2023-12-06 01:01:25.498764:  
2023-12-06 01:01:25.498900: Epoch 554 
2023-12-06 01:01:25.498999: Current learning rate: 0.00484 
2023-12-06 01:02:17.241256: train_loss 1.0343 
2023-12-06 01:02:17.241518: val_loss 1.1515 
2023-12-06 01:02:17.241603: Pseudo dice [0.8619] 
2023-12-06 01:02:17.241722: Epoch time: 51.74 s 
2023-12-06 01:02:18.841734:  
2023-12-06 01:02:18.842028: Epoch 555 
2023-12-06 01:02:18.842137: Current learning rate: 0.00483 
2023-12-06 01:03:10.505820: train_loss 1.0342 
2023-12-06 01:03:10.506061: val_loss 1.1498 
2023-12-06 01:03:10.506127: Pseudo dice [0.8655] 
2023-12-06 01:03:10.506196: Epoch time: 51.67 s 
2023-12-06 01:03:11.692915:  
2023-12-06 01:03:11.693056: Epoch 556 
2023-12-06 01:03:11.693151: Current learning rate: 0.00482 
2023-12-06 01:04:03.618721: train_loss 1.0333 
2023-12-06 01:04:03.618950: val_loss 1.1509 
2023-12-06 01:04:03.619035: Pseudo dice [0.8629] 
2023-12-06 01:04:03.619110: Epoch time: 51.93 s 
2023-12-06 01:04:04.936888:  
2023-12-06 01:04:04.937103: Epoch 557 
2023-12-06 01:04:04.937197: Current learning rate: 0.00481 
2023-12-06 01:04:56.835732: train_loss 1.0331 
2023-12-06 01:04:56.835964: val_loss 1.1438 
2023-12-06 01:04:56.836045: Pseudo dice [0.8694] 
2023-12-06 01:04:56.836119: Epoch time: 51.9 s 
2023-12-06 01:04:58.401616:  
2023-12-06 01:04:58.401928: Epoch 558 
2023-12-06 01:04:58.402127: Current learning rate: 0.0048 
2023-12-06 01:05:50.335270: train_loss 1.0325 
2023-12-06 01:05:50.335535: val_loss 1.1531 
2023-12-06 01:05:50.335645: Pseudo dice [0.8613] 
2023-12-06 01:05:50.335752: Epoch time: 51.94 s 
2023-12-06 01:05:51.924230:  
2023-12-06 01:05:51.924403: Epoch 559 
2023-12-06 01:05:51.924516: Current learning rate: 0.00479 
2023-12-06 01:06:43.524163: train_loss 1.0331 
2023-12-06 01:06:43.524425: val_loss 1.1491 
2023-12-06 01:06:43.524506: Pseudo dice [0.8634] 
2023-12-06 01:06:43.524589: Epoch time: 51.6 s 
2023-12-06 01:06:45.119115:  
2023-12-06 01:06:45.119302: Epoch 560 
2023-12-06 01:06:45.119415: Current learning rate: 0.00478 
2023-12-06 01:07:37.079701: train_loss 1.0339 
2023-12-06 01:07:37.079946: val_loss 1.1418 
2023-12-06 01:07:37.080012: Pseudo dice [0.8703] 
2023-12-06 01:07:37.080078: Epoch time: 51.96 s 
2023-12-06 01:07:38.339036:  
2023-12-06 01:07:38.339206: Epoch 561 
2023-12-06 01:07:38.339298: Current learning rate: 0.00477 
2023-12-06 01:08:30.135465: train_loss 1.0334 
2023-12-06 01:08:30.135730: val_loss 1.1573 
2023-12-06 01:08:30.135936: Pseudo dice [0.8573] 
2023-12-06 01:08:30.136023: Epoch time: 51.8 s 
2023-12-06 01:08:31.727665:  
2023-12-06 01:08:31.727816: Epoch 562 
2023-12-06 01:08:31.727931: Current learning rate: 0.00476 
2023-12-06 01:09:23.339194: train_loss 1.0334 
2023-12-06 01:09:23.339463: val_loss 1.1521 
2023-12-06 01:09:23.339559: Pseudo dice [0.8604] 
2023-12-06 01:09:23.339654: Epoch time: 51.61 s 
2023-12-06 01:09:25.139567:  
2023-12-06 01:09:25.139939: Epoch 563 
2023-12-06 01:09:25.140075: Current learning rate: 0.00475 
2023-12-06 01:10:16.986757: train_loss 1.0328 
2023-12-06 01:10:16.987060: val_loss 1.1525 
2023-12-06 01:10:16.987163: Pseudo dice [0.8597] 
2023-12-06 01:10:16.987246: Epoch time: 51.85 s 
2023-12-06 01:10:18.594368:  
2023-12-06 01:10:18.594650: Epoch 564 
2023-12-06 01:10:18.594767: Current learning rate: 0.00474 
2023-12-06 01:11:10.518245: train_loss 1.0333 
2023-12-06 01:11:10.518515: val_loss 1.1542 
2023-12-06 01:11:10.518598: Pseudo dice [0.8579] 
2023-12-06 01:11:10.518682: Epoch time: 51.93 s 
2023-12-06 01:11:12.122486:  
2023-12-06 01:11:12.122641: Epoch 565 
2023-12-06 01:11:12.122754: Current learning rate: 0.00473 
2023-12-06 01:12:04.050200: train_loss 1.0334 
2023-12-06 01:12:04.050483: val_loss 1.1569 
2023-12-06 01:12:04.050580: Pseudo dice [0.8563] 
2023-12-06 01:12:04.050674: Epoch time: 51.93 s 
2023-12-06 01:12:05.662599:  
2023-12-06 01:12:05.662946: Epoch 566 
2023-12-06 01:12:05.663130: Current learning rate: 0.00472 
2023-12-06 01:12:57.625125: train_loss 1.0338 
2023-12-06 01:12:57.625366: val_loss 1.1507 
2023-12-06 01:12:57.625436: Pseudo dice [0.8624] 
2023-12-06 01:12:57.625504: Epoch time: 51.96 s 
2023-12-06 01:12:59.236725:  
2023-12-06 01:12:59.236889: Epoch 567 
2023-12-06 01:12:59.237003: Current learning rate: 0.00471 
2023-12-06 01:13:50.957705: train_loss 1.0338 
2023-12-06 01:13:50.957944: val_loss 1.1623 
2023-12-06 01:13:50.958014: Pseudo dice [0.8519] 
2023-12-06 01:13:50.958084: Epoch time: 51.72 s 
2023-12-06 01:13:52.463343:  
2023-12-06 01:13:52.463499: Epoch 568 
2023-12-06 01:13:52.463613: Current learning rate: 0.0047 
2023-12-06 01:14:43.889960: train_loss 1.0332 
2023-12-06 01:14:43.890204: val_loss 1.1507 
2023-12-06 01:14:43.890273: Pseudo dice [0.8616] 
2023-12-06 01:14:43.890343: Epoch time: 51.43 s 
2023-12-06 01:14:45.072716:  
2023-12-06 01:14:45.072855: Epoch 569 
2023-12-06 01:14:45.072946: Current learning rate: 0.00469 
2023-12-06 01:15:36.911550: train_loss 1.0327 
2023-12-06 01:15:36.911810: val_loss 1.1478 
2023-12-06 01:15:36.911890: Pseudo dice [0.8638] 
2023-12-06 01:15:36.911969: Epoch time: 51.84 s 
2023-12-06 01:15:38.189134:  
2023-12-06 01:15:38.189399: Epoch 570 
2023-12-06 01:15:38.189493: Current learning rate: 0.00468 
2023-12-06 01:16:29.931484: train_loss 1.0326 
2023-12-06 01:16:29.931710: val_loss 1.1478 
2023-12-06 01:16:29.931774: Pseudo dice [0.8658] 
2023-12-06 01:16:29.931851: Epoch time: 51.74 s 
2023-12-06 01:16:31.113469:  
2023-12-06 01:16:31.113739: Epoch 571 
2023-12-06 01:16:31.113836: Current learning rate: 0.00467 
2023-12-06 01:17:23.004462: train_loss 1.0332 
2023-12-06 01:17:23.004690: val_loss 1.1479 
2023-12-06 01:17:23.004756: Pseudo dice [0.8637] 
2023-12-06 01:17:23.004822: Epoch time: 51.89 s 
2023-12-06 01:17:24.213172:  
2023-12-06 01:17:24.213308: Epoch 572 
2023-12-06 01:17:24.213402: Current learning rate: 0.00466 
2023-12-06 01:18:16.005445: train_loss 1.0338 
2023-12-06 01:18:16.005708: val_loss 1.1549 
2023-12-06 01:18:16.005788: Pseudo dice [0.858] 
2023-12-06 01:18:16.005871: Epoch time: 51.79 s 
2023-12-06 01:18:17.273616:  
2023-12-06 01:18:17.273955: Epoch 573 
2023-12-06 01:18:17.274056: Current learning rate: 0.00465 
2023-12-06 01:19:08.936269: train_loss 1.0349 
2023-12-06 01:19:08.936527: val_loss 1.1528 
2023-12-06 01:19:08.936606: Pseudo dice [0.8613] 
2023-12-06 01:19:08.936686: Epoch time: 51.66 s 
2023-12-06 01:19:10.346984:  
2023-12-06 01:19:10.347152: Epoch 574 
2023-12-06 01:19:10.347252: Current learning rate: 0.00464 
2023-12-06 01:20:01.933431: train_loss 1.0347 
2023-12-06 01:20:01.933681: val_loss 1.1452 
2023-12-06 01:20:01.933746: Pseudo dice [0.8663] 
2023-12-06 01:20:01.933815: Epoch time: 51.59 s 
2023-12-06 01:20:03.112638:  
2023-12-06 01:20:03.112782: Epoch 575 
2023-12-06 01:20:03.112878: Current learning rate: 0.00463 
2023-12-06 01:20:54.968611: train_loss 1.0342 
2023-12-06 01:20:54.968835: val_loss 1.1619 
2023-12-06 01:20:54.968904: Pseudo dice [0.8528] 
2023-12-06 01:20:54.968967: Epoch time: 51.86 s 
2023-12-06 01:20:56.180856:  
2023-12-06 01:20:56.181237: Epoch 576 
2023-12-06 01:20:56.181402: Current learning rate: 0.00462 
2023-12-06 01:21:47.883049: train_loss 1.0345 
2023-12-06 01:21:47.883380: val_loss 1.1544 
2023-12-06 01:21:47.883466: Pseudo dice [0.8597] 
2023-12-06 01:21:47.883553: Epoch time: 51.7 s 
2023-12-06 01:21:49.576747:  
2023-12-06 01:21:49.577179: Epoch 577 
2023-12-06 01:21:49.577377: Current learning rate: 0.00461 
2023-12-06 01:22:41.166163: train_loss 1.0337 
2023-12-06 01:22:41.166447: val_loss 1.1485 
2023-12-06 01:22:41.166528: Pseudo dice [0.863] 
2023-12-06 01:22:41.166609: Epoch time: 51.59 s 
2023-12-06 01:22:42.782384:  
2023-12-06 01:22:42.782547: Epoch 578 
2023-12-06 01:22:42.782662: Current learning rate: 0.0046 
2023-12-06 01:23:34.285869: train_loss 1.0344 
2023-12-06 01:23:34.286153: val_loss 1.1462 
2023-12-06 01:23:34.286360: Pseudo dice [0.868] 
2023-12-06 01:23:34.286453: Epoch time: 51.51 s 
2023-12-06 01:23:35.563777:  
2023-12-06 01:23:35.563899: Epoch 579 
2023-12-06 01:23:35.563987: Current learning rate: 0.00459 
2023-12-06 01:24:27.241064: train_loss 1.0399 
2023-12-06 01:24:27.241326: val_loss 1.1597 
2023-12-06 01:24:27.241407: Pseudo dice [0.8541] 
2023-12-06 01:24:27.241488: Epoch time: 51.68 s 
2023-12-06 01:24:28.860649:  
2023-12-06 01:24:28.860835: Epoch 580 
2023-12-06 01:24:28.860942: Current learning rate: 0.00458 
2023-12-06 01:25:20.700766: train_loss 1.0399 
2023-12-06 01:25:20.700986: val_loss 1.1491 
2023-12-06 01:25:20.701050: Pseudo dice [0.8637] 
2023-12-06 01:25:20.701112: Epoch time: 51.84 s 
2023-12-06 01:25:22.085740:  
2023-12-06 01:25:22.085895: Epoch 581 
2023-12-06 01:25:22.085982: Current learning rate: 0.00457 
2023-12-06 01:26:13.804973: train_loss 1.0368 
2023-12-06 01:26:13.805371: val_loss 1.1447 
2023-12-06 01:26:13.805460: Pseudo dice [0.8685] 
2023-12-06 01:26:13.805572: Epoch time: 51.72 s 
2023-12-06 01:26:15.042941:  
2023-12-06 01:26:15.043087: Epoch 582 
2023-12-06 01:26:15.043185: Current learning rate: 0.00456 
2023-12-06 01:27:06.886787: train_loss 1.0405 
2023-12-06 01:27:06.887058: val_loss 1.1556 
2023-12-06 01:27:06.887147: Pseudo dice [0.8587] 
2023-12-06 01:27:06.887232: Epoch time: 51.85 s 
2023-12-06 01:27:08.135804:  
2023-12-06 01:27:08.135957: Epoch 583 
2023-12-06 01:27:08.136055: Current learning rate: 0.00455 
2023-12-06 01:28:00.087310: train_loss 1.0388 
2023-12-06 01:28:00.087563: val_loss 1.1442 
2023-12-06 01:28:00.087635: Pseudo dice [0.8685] 
2023-12-06 01:28:00.087706: Epoch time: 51.95 s 
2023-12-06 01:28:01.277024:  
2023-12-06 01:28:01.277161: Epoch 584 
2023-12-06 01:28:01.277256: Current learning rate: 0.00454 
2023-12-06 01:28:53.040487: train_loss 1.0351 
2023-12-06 01:28:53.040745: val_loss 1.1513 
2023-12-06 01:28:53.040826: Pseudo dice [0.8623] 
2023-12-06 01:28:53.040906: Epoch time: 51.77 s 
2023-12-06 01:28:54.674717:  
2023-12-06 01:28:54.675006: Epoch 585 
2023-12-06 01:28:54.675134: Current learning rate: 0.00453 
2023-12-06 01:29:46.499496: train_loss 1.034 
2023-12-06 01:29:46.499740: val_loss 1.1489 
2023-12-06 01:29:46.499809: Pseudo dice [0.8635] 
2023-12-06 01:29:46.499877: Epoch time: 51.83 s 
2023-12-06 01:29:48.041797:  
2023-12-06 01:29:48.042139: Epoch 586 
2023-12-06 01:29:48.042319: Current learning rate: 0.00452 
2023-12-06 01:30:39.958373: train_loss 1.0332 
2023-12-06 01:30:39.958647: val_loss 1.146 
2023-12-06 01:30:39.958733: Pseudo dice [0.8673] 
2023-12-06 01:30:39.958824: Epoch time: 51.92 s 
2023-12-06 01:30:41.801732:  
2023-12-06 01:30:41.802214: Epoch 587 
2023-12-06 01:30:41.802338: Current learning rate: 0.00451 
2023-12-06 01:31:33.584910: train_loss 1.0333 
2023-12-06 01:31:33.585307: val_loss 1.1593 
2023-12-06 01:31:33.585397: Pseudo dice [0.8539] 
2023-12-06 01:31:33.585485: Epoch time: 51.79 s 
2023-12-06 01:31:34.854917:  
2023-12-06 01:31:34.855058: Epoch 588 
2023-12-06 01:31:34.855148: Current learning rate: 0.0045 
2023-12-06 01:32:26.739984: train_loss 1.0325 
2023-12-06 01:32:26.740258: val_loss 1.1469 
2023-12-06 01:32:26.740342: Pseudo dice [0.8676] 
2023-12-06 01:32:26.740447: Epoch time: 51.89 s 
2023-12-06 01:32:28.374692:  
2023-12-06 01:32:28.374963: Epoch 589 
2023-12-06 01:32:28.375083: Current learning rate: 0.00449 
2023-12-06 01:33:20.470772: train_loss 1.0321 
2023-12-06 01:33:20.471058: val_loss 1.1455 
2023-12-06 01:33:20.471146: Pseudo dice [0.865] 
2023-12-06 01:33:20.471230: Epoch time: 52.1 s 
2023-12-06 01:33:21.815486:  
2023-12-06 01:33:21.815680: Epoch 590 
2023-12-06 01:33:21.815825: Current learning rate: 0.00448 
2023-12-06 01:34:13.732138: train_loss 1.0325 
2023-12-06 01:34:13.732401: val_loss 1.1462 
2023-12-06 01:34:13.732480: Pseudo dice [0.8666] 
2023-12-06 01:34:13.732563: Epoch time: 51.92 s 
2023-12-06 01:34:15.357950:  
2023-12-06 01:34:15.358532: Epoch 591 
2023-12-06 01:34:15.358714: Current learning rate: 0.00447 
2023-12-06 01:35:07.341171: train_loss 1.0331 
2023-12-06 01:35:07.341444: val_loss 1.148 
2023-12-06 01:35:07.341527: Pseudo dice [0.8639] 
2023-12-06 01:35:07.341612: Epoch time: 51.99 s 
2023-12-06 01:35:08.976604:  
2023-12-06 01:35:08.976831: Epoch 592 
2023-12-06 01:35:08.977171: Current learning rate: 0.00446 
2023-12-06 01:36:00.763143: train_loss 1.0333 
2023-12-06 01:36:00.763400: val_loss 1.1479 
2023-12-06 01:36:00.763484: Pseudo dice [0.864] 
2023-12-06 01:36:00.763571: Epoch time: 51.79 s 
2023-12-06 01:36:02.585005:  
2023-12-06 01:36:02.585162: Epoch 593 
2023-12-06 01:36:02.585278: Current learning rate: 0.00445 
2023-12-06 01:36:54.503139: train_loss 1.0336 
2023-12-06 01:36:54.503361: val_loss 1.1476 
2023-12-06 01:36:54.503429: Pseudo dice [0.8658] 
2023-12-06 01:36:54.503497: Epoch time: 51.92 s 
2023-12-06 01:36:55.736314:  
2023-12-06 01:36:55.736477: Epoch 594 
2023-12-06 01:36:55.736569: Current learning rate: 0.00444 
2023-12-06 01:37:47.692866: train_loss 1.033 
2023-12-06 01:37:47.693126: val_loss 1.1469 
2023-12-06 01:37:47.693210: Pseudo dice [0.8664] 
2023-12-06 01:37:47.693294: Epoch time: 51.96 s 
2023-12-06 01:37:49.311275:  
2023-12-06 01:37:49.311428: Epoch 595 
2023-12-06 01:37:49.311545: Current learning rate: 0.00443 
2023-12-06 01:38:41.060388: train_loss 1.0336 
2023-12-06 01:38:41.060737: val_loss 1.1613 
2023-12-06 01:38:41.060807: Pseudo dice [0.8531] 
2023-12-06 01:38:41.060878: Epoch time: 51.75 s 
2023-12-06 01:38:42.312351:  
2023-12-06 01:38:42.312726: Epoch 596 
2023-12-06 01:38:42.312819: Current learning rate: 0.00442 
2023-12-06 01:39:34.086363: train_loss 1.0334 
2023-12-06 01:39:34.086630: val_loss 1.1488 
2023-12-06 01:39:34.086708: Pseudo dice [0.8641] 
2023-12-06 01:39:34.086790: Epoch time: 51.78 s 
2023-12-06 01:39:35.699086:  
2023-12-06 01:39:35.699286: Epoch 597 
2023-12-06 01:39:35.699457: Current learning rate: 0.00441 
2023-12-06 01:40:27.348014: train_loss 1.0326 
2023-12-06 01:40:27.348254: val_loss 1.1506 
2023-12-06 01:40:27.348322: Pseudo dice [0.8637] 
2023-12-06 01:40:27.348390: Epoch time: 51.65 s 
2023-12-06 01:40:28.574501:  
2023-12-06 01:40:28.574740: Epoch 598 
2023-12-06 01:40:28.574835: Current learning rate: 0.0044 
2023-12-06 01:41:20.215028: train_loss 1.0336 
2023-12-06 01:41:20.215283: val_loss 1.1514 
2023-12-06 01:41:20.215366: Pseudo dice [0.862] 
2023-12-06 01:41:20.215448: Epoch time: 51.64 s 
2023-12-06 01:41:22.014454:  
2023-12-06 01:41:22.014720: Epoch 599 
2023-12-06 01:41:22.014833: Current learning rate: 0.00439 
2023-12-06 01:42:13.745991: train_loss 1.0325 
2023-12-06 01:42:13.746254: val_loss 1.1551 
2023-12-06 01:42:13.746339: Pseudo dice [0.8584] 
2023-12-06 01:42:13.746425: Epoch time: 51.73 s 
2023-12-06 01:42:16.717808:  
2023-12-06 01:42:16.718130: Epoch 600 
2023-12-06 01:42:16.718248: Current learning rate: 0.00438 
2023-12-06 01:43:08.528788: train_loss 1.032 
2023-12-06 01:43:08.529032: val_loss 1.1466 
2023-12-06 01:43:08.529109: Pseudo dice [0.8662] 
2023-12-06 01:43:08.529186: Epoch time: 51.81 s 
2023-12-06 01:43:09.725539:  
2023-12-06 01:43:09.725790: Epoch 601 
2023-12-06 01:43:09.725908: Current learning rate: 0.00437 
2023-12-06 01:44:01.479369: train_loss 1.0319 
2023-12-06 01:44:01.479641: val_loss 1.1447 
2023-12-06 01:44:01.479722: Pseudo dice [0.8675] 
2023-12-06 01:44:01.479808: Epoch time: 51.76 s 
2023-12-06 01:44:03.182592:  
2023-12-06 01:44:03.182905: Epoch 602 
2023-12-06 01:44:03.183042: Current learning rate: 0.00436 
2023-12-06 01:44:55.138047: train_loss 1.0318 
2023-12-06 01:44:55.138313: val_loss 1.1466 
2023-12-06 01:44:55.138394: Pseudo dice [0.8643] 
2023-12-06 01:44:55.138476: Epoch time: 51.96 s 
2023-12-06 01:44:56.756440:  
2023-12-06 01:44:56.756601: Epoch 603 
2023-12-06 01:44:56.756708: Current learning rate: 0.00435 
2023-12-06 01:45:48.662635: train_loss 1.0326 
2023-12-06 01:45:48.663299: val_loss 1.1549 
2023-12-06 01:45:48.663407: Pseudo dice [0.8598] 
2023-12-06 01:45:48.663524: Epoch time: 51.91 s 
2023-12-06 01:45:50.383218:  
2023-12-06 01:45:50.383522: Epoch 604 
2023-12-06 01:45:50.383734: Current learning rate: 0.00434 
2023-12-06 01:46:42.224504: train_loss 1.033 
2023-12-06 01:46:42.225128: val_loss 1.156 
2023-12-06 01:46:42.225244: Pseudo dice [0.8572] 
2023-12-06 01:46:42.225372: Epoch time: 51.84 s 
2023-12-06 01:46:44.100187:  
2023-12-06 01:46:44.100535: Epoch 605 
2023-12-06 01:46:44.100889: Current learning rate: 0.00433 
2023-12-06 01:47:35.793890: train_loss 1.0321 
2023-12-06 01:47:35.794190: val_loss 1.1461 
2023-12-06 01:47:35.794253: Pseudo dice [0.8668] 
2023-12-06 01:47:35.794324: Epoch time: 51.7 s 
2023-12-06 01:47:37.043197:  
2023-12-06 01:47:37.043368: Epoch 606 
2023-12-06 01:47:37.043617: Current learning rate: 0.00432 
2023-12-06 01:48:28.995285: train_loss 1.0322 
2023-12-06 01:48:28.995683: val_loss 1.1497 
2023-12-06 01:48:28.995850: Pseudo dice [0.8628] 
2023-12-06 01:48:28.996019: Epoch time: 51.95 s 
2023-12-06 01:48:30.546267:  
2023-12-06 01:48:30.546405: Epoch 607 
2023-12-06 01:48:30.546505: Current learning rate: 0.00431 
2023-12-06 01:49:22.364567: train_loss 1.0324 
2023-12-06 01:49:22.364816: val_loss 1.1493 
2023-12-06 01:49:22.364883: Pseudo dice [0.8649] 
2023-12-06 01:49:22.364960: Epoch time: 51.82 s 
2023-12-06 01:49:24.009780:  
2023-12-06 01:49:24.010041: Epoch 608 
2023-12-06 01:49:24.010298: Current learning rate: 0.0043 
2023-12-06 01:50:15.767325: train_loss 1.0325 
2023-12-06 01:50:15.767595: val_loss 1.153 
2023-12-06 01:50:15.767690: Pseudo dice [0.8614] 
2023-12-06 01:50:15.767780: Epoch time: 51.76 s 
2023-12-06 01:50:17.308408:  
2023-12-06 01:50:17.308672: Epoch 609 
2023-12-06 01:50:17.308799: Current learning rate: 0.00429 
2023-12-06 01:51:09.213521: train_loss 1.0329 
2023-12-06 01:51:09.213792: val_loss 1.1548 
2023-12-06 01:51:09.213874: Pseudo dice [0.8582] 
2023-12-06 01:51:09.213959: Epoch time: 51.91 s 
2023-12-06 01:51:10.452485:  
2023-12-06 01:51:10.452662: Epoch 610 
2023-12-06 01:51:10.452798: Current learning rate: 0.00429 
2023-12-06 01:52:02.364076: train_loss 1.0321 
2023-12-06 01:52:02.364367: val_loss 1.1467 
2023-12-06 01:52:02.364455: Pseudo dice [0.8646] 
2023-12-06 01:52:02.364539: Epoch time: 51.91 s 
2023-12-06 01:52:03.942501:  
2023-12-06 01:52:03.942653: Epoch 611 
2023-12-06 01:52:03.942754: Current learning rate: 0.00428 
2023-12-06 01:52:55.949502: train_loss 1.0323 
2023-12-06 01:52:55.949766: val_loss 1.1718 
2023-12-06 01:52:55.949852: Pseudo dice [0.8468] 
2023-12-06 01:52:55.949933: Epoch time: 52.01 s 
2023-12-06 01:52:57.574043:  
2023-12-06 01:52:57.574198: Epoch 612 
2023-12-06 01:52:57.574305: Current learning rate: 0.00427 
2023-12-06 01:53:49.542587: train_loss 1.0322 
2023-12-06 01:53:49.542828: val_loss 1.1441 
2023-12-06 01:53:49.542898: Pseudo dice [0.8692] 
2023-12-06 01:53:49.542968: Epoch time: 51.97 s 
2023-12-06 01:53:50.769837:  
2023-12-06 01:53:50.770125: Epoch 613 
2023-12-06 01:53:50.770314: Current learning rate: 0.00426 
2023-12-06 01:54:42.664695: train_loss 1.0322 
2023-12-06 01:54:42.664968: val_loss 1.1496 
2023-12-06 01:54:42.665072: Pseudo dice [0.8627] 
2023-12-06 01:54:42.665179: Epoch time: 51.9 s 
2023-12-06 01:54:44.293113:  
2023-12-06 01:54:44.293373: Epoch 614 
2023-12-06 01:54:44.293489: Current learning rate: 0.00425 
2023-12-06 01:55:36.259620: train_loss 1.0316 
2023-12-06 01:55:36.259875: val_loss 1.1474 
2023-12-06 01:55:36.259958: Pseudo dice [0.8644] 
2023-12-06 01:55:36.260041: Epoch time: 51.97 s 
2023-12-06 01:55:37.899909:  
2023-12-06 01:55:37.900080: Epoch 615 
2023-12-06 01:55:37.900186: Current learning rate: 0.00424 
2023-12-06 01:56:29.725072: train_loss 1.031 
2023-12-06 01:56:29.725328: val_loss 1.1509 
2023-12-06 01:56:29.725409: Pseudo dice [0.862] 
2023-12-06 01:56:29.725488: Epoch time: 51.83 s 
2023-12-06 01:56:31.364226:  
2023-12-06 01:56:31.364582: Epoch 616 
2023-12-06 01:56:31.364709: Current learning rate: 0.00423 
2023-12-06 01:57:22.947324: train_loss 1.0317 
2023-12-06 01:57:22.947535: val_loss 1.1538 
2023-12-06 01:57:22.947600: Pseudo dice [0.8605] 
2023-12-06 01:57:22.947665: Epoch time: 51.59 s 
2023-12-06 01:57:24.334941:  
2023-12-06 01:57:24.335118: Epoch 617 
2023-12-06 01:57:24.335220: Current learning rate: 0.00422 
2023-12-06 01:58:16.135876: train_loss 1.0319 
2023-12-06 01:58:16.136119: val_loss 1.1523 
2023-12-06 01:58:16.136186: Pseudo dice [0.8628] 
2023-12-06 01:58:16.136252: Epoch time: 51.8 s 
2023-12-06 01:58:17.339658:  
2023-12-06 01:58:17.339784: Epoch 618 
2023-12-06 01:58:17.339877: Current learning rate: 0.00421 
2023-12-06 01:59:09.257117: train_loss 1.0321 
2023-12-06 01:59:09.257378: val_loss 1.1422 
2023-12-06 01:59:09.257456: Pseudo dice [0.8694] 
2023-12-06 01:59:09.257536: Epoch time: 51.92 s 
2023-12-06 01:59:10.891306:  
2023-12-06 01:59:10.891465: Epoch 619 
2023-12-06 01:59:10.891581: Current learning rate: 0.0042 
2023-12-06 02:00:02.771858: train_loss 1.0315 
2023-12-06 02:00:02.772118: val_loss 1.1571 
2023-12-06 02:00:02.772200: Pseudo dice [0.8563] 
2023-12-06 02:00:02.772284: Epoch time: 51.88 s 
2023-12-06 02:00:04.409843:  
2023-12-06 02:00:04.410340: Epoch 620 
2023-12-06 02:00:04.410479: Current learning rate: 0.00419 
2023-12-06 02:00:56.443610: train_loss 1.032 
2023-12-06 02:00:56.443880: val_loss 1.1532 
2023-12-06 02:00:56.443959: Pseudo dice [0.86] 
2023-12-06 02:00:56.444039: Epoch time: 52.04 s 
2023-12-06 02:00:57.960841:  
2023-12-06 02:00:57.960994: Epoch 621 
2023-12-06 02:00:57.961089: Current learning rate: 0.00418 
2023-12-06 02:01:49.739632: train_loss 1.0316 
2023-12-06 02:01:49.739901: val_loss 1.1527 
2023-12-06 02:01:49.739983: Pseudo dice [0.8629] 
2023-12-06 02:01:49.740065: Epoch time: 51.78 s 
2023-12-06 02:01:51.396603:  
2023-12-06 02:01:51.396769: Epoch 622 
2023-12-06 02:01:51.396881: Current learning rate: 0.00417 
2023-12-06 02:02:42.882498: train_loss 1.0316 
2023-12-06 02:02:42.882754: val_loss 1.1477 
2023-12-06 02:02:42.882833: Pseudo dice [0.865] 
2023-12-06 02:02:42.882911: Epoch time: 51.49 s 
2023-12-06 02:02:44.336298:  
2023-12-06 02:02:44.336465: Epoch 623 
2023-12-06 02:02:44.336595: Current learning rate: 0.00416 
2023-12-06 02:03:36.124195: train_loss 1.0316 
2023-12-06 02:03:36.124428: val_loss 1.1441 
2023-12-06 02:03:36.124498: Pseudo dice [0.8677] 
2023-12-06 02:03:36.124568: Epoch time: 51.79 s 
2023-12-06 02:03:37.346320:  
2023-12-06 02:03:37.346470: Epoch 624 
2023-12-06 02:03:37.346560: Current learning rate: 0.00415 
2023-12-06 02:04:29.266060: train_loss 1.0314 
2023-12-06 02:04:29.266330: val_loss 1.1505 
2023-12-06 02:04:29.266408: Pseudo dice [0.8617] 
2023-12-06 02:04:29.266489: Epoch time: 51.92 s 
2023-12-06 02:04:30.869028:  
2023-12-06 02:04:30.869175: Epoch 625 
2023-12-06 02:04:30.869267: Current learning rate: 0.00414 
2023-12-06 02:05:22.978476: train_loss 1.0318 
2023-12-06 02:05:22.978746: val_loss 1.1483 
2023-12-06 02:05:22.978825: Pseudo dice [0.8649] 
2023-12-06 02:05:22.978905: Epoch time: 52.11 s 
2023-12-06 02:05:24.577853:  
2023-12-06 02:05:24.578117: Epoch 626 
2023-12-06 02:05:24.578544: Current learning rate: 0.00413 
2023-12-06 02:06:16.353714: train_loss 1.0313 
2023-12-06 02:06:16.353986: val_loss 1.1431 
2023-12-06 02:06:16.354067: Pseudo dice [0.8691] 
2023-12-06 02:06:16.354156: Epoch time: 51.78 s 
2023-12-06 02:06:17.741166:  
2023-12-06 02:06:17.741298: Epoch 627 
2023-12-06 02:06:17.741387: Current learning rate: 0.00412 
2023-12-06 02:07:09.663151: train_loss 1.0315 
2023-12-06 02:07:09.663415: val_loss 1.1462 
2023-12-06 02:07:09.663498: Pseudo dice [0.8674] 
2023-12-06 02:07:09.663583: Epoch time: 51.92 s 
2023-12-06 02:07:11.102461:  
2023-12-06 02:07:11.102585: Epoch 628 
2023-12-06 02:07:11.102671: Current learning rate: 0.00411 
2023-12-06 02:08:03.041058: train_loss 1.0316 
2023-12-06 02:08:03.041285: val_loss 1.1516 
2023-12-06 02:08:03.041352: Pseudo dice [0.8609] 
2023-12-06 02:08:03.041422: Epoch time: 51.94 s 
2023-12-06 02:08:04.823312:  
2023-12-06 02:08:04.824029: Epoch 629 
2023-12-06 02:08:04.824270: Current learning rate: 0.0041 
2023-12-06 02:08:56.793995: train_loss 1.0311 
2023-12-06 02:08:56.794260: val_loss 1.1475 
2023-12-06 02:08:56.794343: Pseudo dice [0.8643] 
2023-12-06 02:08:56.794427: Epoch time: 51.97 s 
2023-12-06 02:08:58.425539:  
2023-12-06 02:08:58.425718: Epoch 630 
2023-12-06 02:08:58.425840: Current learning rate: 0.00409 
2023-12-06 02:09:50.325978: train_loss 1.0322 
2023-12-06 02:09:50.326270: val_loss 1.1463 
2023-12-06 02:09:50.326370: Pseudo dice [0.8664] 
2023-12-06 02:09:50.326468: Epoch time: 51.9 s 
2023-12-06 02:09:51.970901:  
2023-12-06 02:09:51.971378: Epoch 631 
2023-12-06 02:09:51.971528: Current learning rate: 0.00408 
2023-12-06 02:10:44.090244: train_loss 1.032 
2023-12-06 02:10:44.090503: val_loss 1.148 
2023-12-06 02:10:44.090584: Pseudo dice [0.8649] 
2023-12-06 02:10:44.090665: Epoch time: 52.12 s 
2023-12-06 02:10:45.489845:  
2023-12-06 02:10:45.489992: Epoch 632 
2023-12-06 02:10:45.490084: Current learning rate: 0.00407 
2023-12-06 02:11:37.245312: train_loss 1.0308 
2023-12-06 02:11:37.245552: val_loss 1.1489 
2023-12-06 02:11:37.245624: Pseudo dice [0.8632] 
2023-12-06 02:11:37.245694: Epoch time: 51.76 s 
2023-12-06 02:11:38.472894:  
2023-12-06 02:11:38.473184: Epoch 633 
2023-12-06 02:11:38.473280: Current learning rate: 0.00406 
2023-12-06 02:12:30.429509: train_loss 1.0322 
2023-12-06 02:12:30.429787: val_loss 1.1449 
2023-12-06 02:12:30.429868: Pseudo dice [0.8671] 
2023-12-06 02:12:30.429954: Epoch time: 51.96 s 
2023-12-06 02:12:31.838912:  
2023-12-06 02:12:31.839063: Epoch 634 
2023-12-06 02:12:31.839149: Current learning rate: 0.00405 
2023-12-06 02:13:23.653633: train_loss 1.031 
2023-12-06 02:13:23.653900: val_loss 1.1474 
2023-12-06 02:13:23.653998: Pseudo dice [0.8641] 
2023-12-06 02:13:23.654134: Epoch time: 51.82 s 
2023-12-06 02:13:25.477478:  
2023-12-06 02:13:25.477653: Epoch 635 
2023-12-06 02:13:25.477773: Current learning rate: 0.00404 
2023-12-06 02:14:17.469352: train_loss 1.0316 
2023-12-06 02:14:17.469616: val_loss 1.1492 
2023-12-06 02:14:17.469699: Pseudo dice [0.8644] 
2023-12-06 02:14:17.469784: Epoch time: 51.99 s 
2023-12-06 02:14:19.098761:  
2023-12-06 02:14:19.099038: Epoch 636 
2023-12-06 02:14:19.099159: Current learning rate: 0.00403 
2023-12-06 02:15:10.945142: train_loss 1.0313 
2023-12-06 02:15:10.945369: val_loss 1.1501 
2023-12-06 02:15:10.945435: Pseudo dice [0.8626] 
2023-12-06 02:15:10.945501: Epoch time: 51.85 s 
2023-12-06 02:15:12.170176:  
2023-12-06 02:15:12.170323: Epoch 637 
2023-12-06 02:15:12.170409: Current learning rate: 0.00402 
2023-12-06 02:16:04.060618: train_loss 1.0309 
2023-12-06 02:16:04.060860: val_loss 1.1497 
2023-12-06 02:16:04.060928: Pseudo dice [0.8647] 
2023-12-06 02:16:04.060996: Epoch time: 51.89 s 
2023-12-06 02:16:05.648083:  
2023-12-06 02:16:05.648262: Epoch 638 
2023-12-06 02:16:05.648387: Current learning rate: 0.00401 
2023-12-06 02:16:57.604243: train_loss 1.0307 
2023-12-06 02:16:57.604511: val_loss 1.1455 
2023-12-06 02:16:57.604615: Pseudo dice [0.8662] 
2023-12-06 02:16:57.604718: Epoch time: 51.96 s 
2023-12-06 02:16:59.260053:  
2023-12-06 02:16:59.260228: Epoch 639 
2023-12-06 02:16:59.260335: Current learning rate: 0.004 
2023-12-06 02:17:51.184912: train_loss 1.0317 
2023-12-06 02:17:51.185187: val_loss 1.1472 
2023-12-06 02:17:51.185268: Pseudo dice [0.8647] 
2023-12-06 02:17:51.185349: Epoch time: 51.93 s 
2023-12-06 02:17:52.845963:  
2023-12-06 02:17:52.846150: Epoch 640 
2023-12-06 02:17:52.846266: Current learning rate: 0.00399 
2023-12-06 02:18:44.654177: train_loss 1.0309 
2023-12-06 02:18:44.654414: val_loss 1.1541 
2023-12-06 02:18:44.654482: Pseudo dice [0.859] 
2023-12-06 02:18:44.654551: Epoch time: 51.81 s 
2023-12-06 02:18:46.171996:  
2023-12-06 02:18:46.172180: Epoch 641 
2023-12-06 02:18:46.172299: Current learning rate: 0.00398 
2023-12-06 02:19:37.788103: train_loss 1.0304 
2023-12-06 02:19:37.788380: val_loss 1.1448 
2023-12-06 02:19:37.788466: Pseudo dice [0.868] 
2023-12-06 02:19:37.788549: Epoch time: 51.62 s 
2023-12-06 02:19:39.423225:  
2023-12-06 02:19:39.423456: Epoch 642 
2023-12-06 02:19:39.423570: Current learning rate: 0.00397 
2023-12-06 02:20:31.382149: train_loss 1.0308 
2023-12-06 02:20:31.382409: val_loss 1.1468 
2023-12-06 02:20:31.382491: Pseudo dice [0.8655] 
2023-12-06 02:20:31.382574: Epoch time: 51.96 s 
2023-12-06 02:20:33.003540:  
2023-12-06 02:20:33.003686: Epoch 643 
2023-12-06 02:20:33.003781: Current learning rate: 0.00396 
2023-12-06 02:21:24.737028: train_loss 1.0302 
2023-12-06 02:21:24.737303: val_loss 1.1497 
2023-12-06 02:21:24.737520: Pseudo dice [0.8627] 
2023-12-06 02:21:24.737606: Epoch time: 51.74 s 
2023-12-06 02:21:26.356912:  
2023-12-06 02:21:26.357385: Epoch 644 
2023-12-06 02:21:26.357494: Current learning rate: 0.00395 
2023-12-06 02:22:18.018559: train_loss 1.0301 
2023-12-06 02:22:18.018805: val_loss 1.1529 
2023-12-06 02:22:18.018884: Pseudo dice [0.8615] 
2023-12-06 02:22:18.018966: Epoch time: 51.66 s 
2023-12-06 02:22:19.673139:  
2023-12-06 02:22:19.673394: Epoch 645 
2023-12-06 02:22:19.673904: Current learning rate: 0.00394 
2023-12-06 02:23:11.349447: train_loss 1.0308 
2023-12-06 02:23:11.349734: val_loss 1.16 
2023-12-06 02:23:11.349816: Pseudo dice [0.8539] 
2023-12-06 02:23:11.349899: Epoch time: 51.68 s 
2023-12-06 02:23:13.241202:  
2023-12-06 02:23:13.241746: Epoch 646 
2023-12-06 02:23:13.242010: Current learning rate: 0.00393 
2023-12-06 02:24:05.181825: train_loss 1.0315 
2023-12-06 02:24:05.182084: val_loss 1.1555 
2023-12-06 02:24:05.182165: Pseudo dice [0.8582] 
2023-12-06 02:24:05.182245: Epoch time: 51.94 s 
2023-12-06 02:24:06.417943:  
2023-12-06 02:24:06.418106: Epoch 647 
2023-12-06 02:24:06.418198: Current learning rate: 0.00392 
2023-12-06 02:24:58.156794: train_loss 1.0316 
2023-12-06 02:24:58.157083: val_loss 1.1474 
2023-12-06 02:24:58.157182: Pseudo dice [0.8659] 
2023-12-06 02:24:58.157267: Epoch time: 51.74 s 
2023-12-06 02:24:59.600782:  
2023-12-06 02:24:59.601079: Epoch 648 
2023-12-06 02:24:59.601221: Current learning rate: 0.00391 
2023-12-06 02:25:51.337644: train_loss 1.0307 
2023-12-06 02:25:51.337878: val_loss 1.1484 
2023-12-06 02:25:51.337963: Pseudo dice [0.8637] 
2023-12-06 02:25:51.338055: Epoch time: 51.74 s 
2023-12-06 02:25:52.555945:  
2023-12-06 02:25:52.556116: Epoch 649 
2023-12-06 02:25:52.556234: Current learning rate: 0.0039 
2023-12-06 02:26:44.492741: train_loss 1.0305 
2023-12-06 02:26:44.493016: val_loss 1.1572 
2023-12-06 02:26:44.493098: Pseudo dice [0.8588] 
2023-12-06 02:26:44.493180: Epoch time: 51.94 s 
2023-12-06 02:26:47.268912:  
2023-12-06 02:26:47.269069: Epoch 650 
2023-12-06 02:26:47.269160: Current learning rate: 0.00389 
2023-12-06 02:27:38.888961: train_loss 1.0311 
2023-12-06 02:27:38.889196: val_loss 1.1423 
2023-12-06 02:27:38.889261: Pseudo dice [0.8689] 
2023-12-06 02:27:38.889326: Epoch time: 51.62 s 
2023-12-06 02:27:40.154476:  
2023-12-06 02:27:40.154627: Epoch 651 
2023-12-06 02:27:40.154724: Current learning rate: 0.00388 
2023-12-06 02:28:32.201712: train_loss 1.031 
2023-12-06 02:28:32.201947: val_loss 1.1581 
2023-12-06 02:28:32.202011: Pseudo dice [0.8562] 
2023-12-06 02:28:32.202075: Epoch time: 52.05 s 
2023-12-06 02:28:33.592589:  
2023-12-06 02:28:33.592735: Epoch 652 
2023-12-06 02:28:33.592829: Current learning rate: 0.00387 
2023-12-06 02:29:25.481122: train_loss 1.0309 
2023-12-06 02:29:25.481390: val_loss 1.1507 
2023-12-06 02:29:25.481470: Pseudo dice [0.8617] 
2023-12-06 02:29:25.481552: Epoch time: 51.89 s 
2023-12-06 02:29:27.129557:  
2023-12-06 02:29:27.129728: Epoch 653 
2023-12-06 02:29:27.129838: Current learning rate: 0.00386 
2023-12-06 02:30:19.158467: train_loss 1.0304 
2023-12-06 02:30:19.158706: val_loss 1.142 
2023-12-06 02:30:19.158769: Pseudo dice [0.8691] 
2023-12-06 02:30:19.158834: Epoch time: 52.03 s 
2023-12-06 02:30:20.788007:  
2023-12-06 02:30:20.788187: Epoch 654 
2023-12-06 02:30:20.788299: Current learning rate: 0.00385 
2023-12-06 02:31:12.609666: train_loss 1.0307 
2023-12-06 02:31:12.609936: val_loss 1.1471 
2023-12-06 02:31:12.610015: Pseudo dice [0.865] 
2023-12-06 02:31:12.610100: Epoch time: 51.82 s 
2023-12-06 02:31:13.900277:  
2023-12-06 02:31:13.900463: Epoch 655 
2023-12-06 02:31:13.900567: Current learning rate: 0.00384 
2023-12-06 02:32:05.715250: train_loss 1.0313 
2023-12-06 02:32:05.715509: val_loss 1.1486 
2023-12-06 02:32:05.715589: Pseudo dice [0.8646] 
2023-12-06 02:32:05.715669: Epoch time: 51.82 s 
2023-12-06 02:32:07.366318:  
2023-12-06 02:32:07.366866: Epoch 656 
2023-12-06 02:32:07.367091: Current learning rate: 0.00383 
2023-12-06 02:32:59.058097: train_loss 1.0316 
2023-12-06 02:32:59.058357: val_loss 1.1481 
2023-12-06 02:32:59.058434: Pseudo dice [0.8636] 
2023-12-06 02:32:59.058514: Epoch time: 51.69 s 
2023-12-06 02:33:00.692575:  
2023-12-06 02:33:00.692716: Epoch 657 
2023-12-06 02:33:00.692809: Current learning rate: 0.00382 
2023-12-06 02:33:52.576580: train_loss 1.0309 
2023-12-06 02:33:52.576855: val_loss 1.1436 
2023-12-06 02:33:52.576946: Pseudo dice [0.8679] 
2023-12-06 02:33:52.577035: Epoch time: 51.89 s 
2023-12-06 02:33:54.285183:  
2023-12-06 02:33:54.285332: Epoch 658 
2023-12-06 02:33:54.285422: Current learning rate: 0.00381 
2023-12-06 02:34:46.202875: train_loss 1.0309 
2023-12-06 02:34:46.203221: val_loss 1.1443 
2023-12-06 02:34:46.203307: Pseudo dice [0.8681] 
2023-12-06 02:34:46.203398: Epoch time: 51.92 s 
2023-12-06 02:34:47.819541:  
2023-12-06 02:34:47.819688: Epoch 659 
2023-12-06 02:34:47.819788: Current learning rate: 0.0038 
2023-12-06 02:35:39.674547: train_loss 1.0308 
2023-12-06 02:35:39.674810: val_loss 1.1497 
2023-12-06 02:35:39.674890: Pseudo dice [0.8649] 
2023-12-06 02:35:39.674971: Epoch time: 51.86 s 
2023-12-06 02:35:41.166476:  
2023-12-06 02:35:41.166623: Epoch 660 
2023-12-06 02:35:41.166711: Current learning rate: 0.00379 
2023-12-06 02:36:33.008022: train_loss 1.0298 
2023-12-06 02:36:33.008300: val_loss 1.1514 
2023-12-06 02:36:33.008386: Pseudo dice [0.8619] 
2023-12-06 02:36:33.008467: Epoch time: 51.84 s 
2023-12-06 02:36:34.291347:  
2023-12-06 02:36:34.291666: Epoch 661 
2023-12-06 02:36:34.291763: Current learning rate: 0.00378 
2023-12-06 02:37:26.307474: train_loss 1.0306 
2023-12-06 02:37:26.307739: val_loss 1.148 
2023-12-06 02:37:26.307822: Pseudo dice [0.8653] 
2023-12-06 02:37:26.307903: Epoch time: 52.02 s 
2023-12-06 02:37:27.866504:  
2023-12-06 02:37:27.866656: Epoch 662 
2023-12-06 02:37:27.866745: Current learning rate: 0.00377 
2023-12-06 02:38:19.820504: train_loss 1.0303 
2023-12-06 02:38:19.820791: val_loss 1.1449 
2023-12-06 02:38:19.820878: Pseudo dice [0.867] 
2023-12-06 02:38:19.820961: Epoch time: 51.96 s 
2023-12-06 02:38:21.072084:  
2023-12-06 02:38:21.072221: Epoch 663 
2023-12-06 02:38:21.072316: Current learning rate: 0.00376 
2023-12-06 02:39:12.888195: train_loss 1.0301 
2023-12-06 02:39:12.888549: val_loss 1.1505 
2023-12-06 02:39:12.888621: Pseudo dice [0.8618] 
2023-12-06 02:39:12.888691: Epoch time: 51.82 s 
2023-12-06 02:39:14.265802:  
2023-12-06 02:39:14.265949: Epoch 664 
2023-12-06 02:39:14.266036: Current learning rate: 0.00375 
2023-12-06 02:40:06.245387: train_loss 1.0305 
2023-12-06 02:40:06.245666: val_loss 1.1463 
2023-12-06 02:40:06.245754: Pseudo dice [0.8658] 
2023-12-06 02:40:06.245836: Epoch time: 51.98 s 
2023-12-06 02:40:07.887749:  
2023-12-06 02:40:07.888000: Epoch 665 
2023-12-06 02:40:07.888110: Current learning rate: 0.00374 
2023-12-06 02:40:59.838595: train_loss 1.0302 
2023-12-06 02:40:59.838870: val_loss 1.1481 
2023-12-06 02:40:59.838952: Pseudo dice [0.8646] 
2023-12-06 02:40:59.839043: Epoch time: 51.95 s 
2023-12-06 02:41:01.480032:  
2023-12-06 02:41:01.480207: Epoch 666 
2023-12-06 02:41:01.480317: Current learning rate: 0.00373 
2023-12-06 02:41:53.672745: train_loss 1.0304 
2023-12-06 02:41:53.673025: val_loss 1.1534 
2023-12-06 02:41:53.673110: Pseudo dice [0.8602] 
2023-12-06 02:41:53.673193: Epoch time: 52.19 s 
2023-12-06 02:41:55.226152:  
2023-12-06 02:41:55.226289: Epoch 667 
2023-12-06 02:41:55.226382: Current learning rate: 0.00372 
2023-12-06 02:42:47.136883: train_loss 1.0302 
2023-12-06 02:42:47.137145: val_loss 1.156 
2023-12-06 02:42:47.137226: Pseudo dice [0.8592] 
2023-12-06 02:42:47.137306: Epoch time: 51.91 s 
2023-12-06 02:42:48.834700:  
2023-12-06 02:42:48.835068: Epoch 668 
2023-12-06 02:42:48.835194: Current learning rate: 0.00371 
2023-12-06 02:43:40.979502: train_loss 1.0303 
2023-12-06 02:43:40.979767: val_loss 1.1506 
2023-12-06 02:43:40.979846: Pseudo dice [0.8621] 
2023-12-06 02:43:40.979928: Epoch time: 52.15 s 
2023-12-06 02:43:42.649251:  
2023-12-06 02:43:42.649436: Epoch 669 
2023-12-06 02:43:42.649552: Current learning rate: 0.0037 
2023-12-06 02:44:34.692497: train_loss 1.0299 
2023-12-06 02:44:34.692776: val_loss 1.154 
2023-12-06 02:44:34.692855: Pseudo dice [0.8588] 
2023-12-06 02:44:34.692936: Epoch time: 52.05 s 
2023-12-06 02:44:36.456432:  
2023-12-06 02:44:36.456574: Epoch 670 
2023-12-06 02:44:36.456672: Current learning rate: 0.00369 
2023-12-06 02:45:27.945380: train_loss 1.031 
2023-12-06 02:45:27.945621: val_loss 1.1518 
2023-12-06 02:45:27.945683: Pseudo dice [0.8621] 
2023-12-06 02:45:27.945752: Epoch time: 51.49 s 
2023-12-06 02:45:29.194865:  
2023-12-06 02:45:29.196407: Epoch 671 
2023-12-06 02:45:29.196581: Current learning rate: 0.00368 
2023-12-06 02:46:21.058809: train_loss 1.0331 
2023-12-06 02:46:21.059083: val_loss 1.1581 
2023-12-06 02:46:21.059168: Pseudo dice [0.856] 
2023-12-06 02:46:21.059253: Epoch time: 51.87 s 
2023-12-06 02:46:22.397716:  
2023-12-06 02:46:22.397844: Epoch 672 
2023-12-06 02:46:22.397945: Current learning rate: 0.00367 
2023-12-06 02:47:14.230408: train_loss 1.0316 
2023-12-06 02:47:14.230705: val_loss 1.1426 
2023-12-06 02:47:14.230784: Pseudo dice [0.8687] 
2023-12-06 02:47:14.230864: Epoch time: 51.83 s 
2023-12-06 02:47:15.908396:  
2023-12-06 02:47:15.908685: Epoch 673 
2023-12-06 02:47:15.908798: Current learning rate: 0.00366 
2023-12-06 02:48:07.939193: train_loss 1.0308 
2023-12-06 02:48:07.939418: val_loss 1.1525 
2023-12-06 02:48:07.939484: Pseudo dice [0.8602] 
2023-12-06 02:48:07.939549: Epoch time: 52.03 s 
2023-12-06 02:48:09.145334:  
2023-12-06 02:48:09.145462: Epoch 674 
2023-12-06 02:48:09.145559: Current learning rate: 0.00365 
2023-12-06 02:49:01.097200: train_loss 1.03 
2023-12-06 02:49:01.097495: val_loss 1.1509 
2023-12-06 02:49:01.097579: Pseudo dice [0.8623] 
2023-12-06 02:49:01.097834: Epoch time: 51.95 s 
2023-12-06 02:49:02.371528:  
2023-12-06 02:49:02.371664: Epoch 675 
2023-12-06 02:49:02.371762: Current learning rate: 0.00364 
2023-12-06 02:49:54.477299: train_loss 1.0305 
2023-12-06 02:49:54.477580: val_loss 1.1555 
2023-12-06 02:49:54.477928: Pseudo dice [0.8579] 
2023-12-06 02:49:54.478013: Epoch time: 52.11 s 
2023-12-06 02:49:56.085227:  
2023-12-06 02:49:56.085390: Epoch 676 
2023-12-06 02:49:56.085490: Current learning rate: 0.00363 
2023-12-06 02:50:47.905520: train_loss 1.03 
2023-12-06 02:50:47.905794: val_loss 1.1507 
2023-12-06 02:50:47.905876: Pseudo dice [0.8636] 
2023-12-06 02:50:47.905957: Epoch time: 51.82 s 
2023-12-06 02:50:49.445820:  
2023-12-06 02:50:49.445955: Epoch 677 
2023-12-06 02:50:49.446052: Current learning rate: 0.00362 
2023-12-06 02:51:41.226896: train_loss 1.0303 
2023-12-06 02:51:41.227135: val_loss 1.1529 
2023-12-06 02:51:41.227201: Pseudo dice [0.86] 
2023-12-06 02:51:41.227268: Epoch time: 51.78 s 
2023-12-06 02:51:42.462436:  
2023-12-06 02:51:42.462577: Epoch 678 
2023-12-06 02:51:42.462671: Current learning rate: 0.00361 
2023-12-06 02:52:34.360435: train_loss 1.0297 
2023-12-06 02:52:34.360689: val_loss 1.1518 
2023-12-06 02:52:34.360769: Pseudo dice [0.8621] 
2023-12-06 02:52:34.360850: Epoch time: 51.9 s 
2023-12-06 02:52:36.008918:  
2023-12-06 02:52:36.009095: Epoch 679 
2023-12-06 02:52:36.009196: Current learning rate: 0.0036 
2023-12-06 02:53:28.010598: train_loss 1.0302 
2023-12-06 02:53:28.010865: val_loss 1.1458 
2023-12-06 02:53:28.010947: Pseudo dice [0.8663] 
2023-12-06 02:53:28.011049: Epoch time: 52.0 s 
2023-12-06 02:53:29.340180:  
2023-12-06 02:53:29.340328: Epoch 680 
2023-12-06 02:53:29.340429: Current learning rate: 0.00359 
2023-12-06 02:54:21.378301: train_loss 1.0295 
2023-12-06 02:54:21.378577: val_loss 1.1396 
2023-12-06 02:54:21.378662: Pseudo dice [0.8712] 
2023-12-06 02:54:21.378749: Epoch time: 52.04 s 
2023-12-06 02:54:23.230611:  
2023-12-06 02:54:23.231091: Epoch 681 
2023-12-06 02:54:23.231249: Current learning rate: 0.00358 
2023-12-06 02:55:14.973650: train_loss 1.0302 
2023-12-06 02:55:14.973913: val_loss 1.1677 
2023-12-06 02:55:14.973999: Pseudo dice [0.8498] 
2023-12-06 02:55:14.974087: Epoch time: 51.75 s 
2023-12-06 02:55:16.339658:  
2023-12-06 02:55:16.339908: Epoch 682 
2023-12-06 02:55:16.340070: Current learning rate: 0.00357 
2023-12-06 02:56:08.306251: train_loss 1.0304 
2023-12-06 02:56:08.306521: val_loss 1.1548 
2023-12-06 02:56:08.306601: Pseudo dice [0.8616] 
2023-12-06 02:56:08.306684: Epoch time: 51.97 s 
2023-12-06 02:56:09.748112:  
2023-12-06 02:56:09.748299: Epoch 683 
2023-12-06 02:56:09.748396: Current learning rate: 0.00356 
2023-12-06 02:57:01.669265: train_loss 1.0304 
2023-12-06 02:57:01.669536: val_loss 1.1447 
2023-12-06 02:57:01.669628: Pseudo dice [0.8683] 
2023-12-06 02:57:01.669717: Epoch time: 51.92 s 
2023-12-06 02:57:03.314426:  
2023-12-06 02:57:03.314688: Epoch 684 
2023-12-06 02:57:03.314804: Current learning rate: 0.00355 
2023-12-06 02:57:55.392318: train_loss 1.031 
2023-12-06 02:57:55.392568: val_loss 1.153 
2023-12-06 02:57:55.392636: Pseudo dice [0.8593] 
2023-12-06 02:57:55.392705: Epoch time: 52.08 s 
2023-12-06 02:57:56.996808:  
2023-12-06 02:57:56.996954: Epoch 685 
2023-12-06 02:57:56.997043: Current learning rate: 0.00354 
2023-12-06 02:58:48.950322: train_loss 1.03 
2023-12-06 02:58:48.950587: val_loss 1.145 
2023-12-06 02:58:48.950671: Pseudo dice [0.8674] 
2023-12-06 02:58:48.950755: Epoch time: 51.96 s 
2023-12-06 02:58:50.581272:  
2023-12-06 02:58:50.581409: Epoch 686 
2023-12-06 02:58:50.581508: Current learning rate: 0.00353 
2023-12-06 02:59:42.452296: train_loss 1.0302 
2023-12-06 02:59:42.452624: val_loss 1.1468 
2023-12-06 02:59:42.452714: Pseudo dice [0.8656] 
2023-12-06 02:59:42.452801: Epoch time: 51.87 s 
2023-12-06 02:59:44.274965:  
2023-12-06 02:59:44.275301: Epoch 687 
2023-12-06 02:59:44.275406: Current learning rate: 0.00352 
2023-12-06 03:00:36.277514: train_loss 1.0313 
2023-12-06 03:00:36.277789: val_loss 1.154 
2023-12-06 03:00:36.277871: Pseudo dice [0.86] 
2023-12-06 03:00:36.277951: Epoch time: 52.0 s 
2023-12-06 03:00:37.943679:  
2023-12-06 03:00:37.943847: Epoch 688 
2023-12-06 03:00:37.943965: Current learning rate: 0.00351 
2023-12-06 03:01:30.081828: train_loss 1.0304 
2023-12-06 03:01:30.082107: val_loss 1.1499 
2023-12-06 03:01:30.082189: Pseudo dice [0.8623] 
2023-12-06 03:01:30.082273: Epoch time: 52.14 s 
2023-12-06 03:01:31.747852:  
2023-12-06 03:01:31.748071: Epoch 689 
2023-12-06 03:01:31.748243: Current learning rate: 0.0035 
2023-12-06 03:02:23.547898: train_loss 1.0306 
2023-12-06 03:02:23.548183: val_loss 1.1517 
2023-12-06 03:02:23.548262: Pseudo dice [0.8625] 
2023-12-06 03:02:23.548344: Epoch time: 51.8 s 
2023-12-06 03:02:25.200615:  
2023-12-06 03:02:25.200943: Epoch 690 
2023-12-06 03:02:25.201083: Current learning rate: 0.00349 
2023-12-06 03:03:17.377331: train_loss 1.0299 
2023-12-06 03:03:17.377565: val_loss 1.1455 
2023-12-06 03:03:17.377631: Pseudo dice [0.8675] 
2023-12-06 03:03:17.377697: Epoch time: 52.18 s 
2023-12-06 03:03:18.632781:  
2023-12-06 03:03:18.632906: Epoch 691 
2023-12-06 03:03:18.632993: Current learning rate: 0.00348 
2023-12-06 03:04:10.706177: train_loss 1.0299 
2023-12-06 03:04:10.706436: val_loss 1.1501 
2023-12-06 03:04:10.706525: Pseudo dice [0.8626] 
2023-12-06 03:04:10.706622: Epoch time: 52.08 s 
2023-12-06 03:04:12.248335:  
2023-12-06 03:04:12.248700: Epoch 692 
2023-12-06 03:04:12.249084: Current learning rate: 0.00346 
2023-12-06 03:05:04.246336: train_loss 1.03 
2023-12-06 03:05:04.246562: val_loss 1.148 
2023-12-06 03:05:04.246628: Pseudo dice [0.8638] 
2023-12-06 03:05:04.246697: Epoch time: 52.0 s 
2023-12-06 03:05:05.628386:  
2023-12-06 03:05:05.628772: Epoch 693 
2023-12-06 03:05:05.628950: Current learning rate: 0.00345 
2023-12-06 03:05:57.347152: train_loss 1.0304 
2023-12-06 03:05:57.347387: val_loss 1.1519 
2023-12-06 03:05:57.347456: Pseudo dice [0.8621] 
2023-12-06 03:05:57.347523: Epoch time: 51.72 s 
2023-12-06 03:05:58.665608:  
2023-12-06 03:05:58.665844: Epoch 694 
2023-12-06 03:05:58.665938: Current learning rate: 0.00344 
2023-12-06 03:06:50.615414: train_loss 1.0296 
2023-12-06 03:06:50.615644: val_loss 1.145 
2023-12-06 03:06:50.615711: Pseudo dice [0.8678] 
2023-12-06 03:06:50.615780: Epoch time: 51.95 s 
2023-12-06 03:06:51.861567:  
2023-12-06 03:06:51.861866: Epoch 695 
2023-12-06 03:06:51.861956: Current learning rate: 0.00343 
2023-12-06 03:07:43.722096: train_loss 1.0303 
2023-12-06 03:07:43.722364: val_loss 1.1495 
2023-12-06 03:07:43.722444: Pseudo dice [0.8632] 
2023-12-06 03:07:43.722523: Epoch time: 51.86 s 
2023-12-06 03:07:45.396822:  
2023-12-06 03:07:45.397149: Epoch 696 
2023-12-06 03:07:45.397299: Current learning rate: 0.00342 
2023-12-06 03:08:37.259184: train_loss 1.0295 
2023-12-06 03:08:37.259461: val_loss 1.1357 
2023-12-06 03:08:37.259544: Pseudo dice [0.8742] 
2023-12-06 03:08:37.259635: Epoch time: 51.86 s 
2023-12-06 03:08:38.922772:  
2023-12-06 03:08:38.923169: Epoch 697 
2023-12-06 03:08:38.923426: Current learning rate: 0.00341 
2023-12-06 03:09:30.928056: train_loss 1.0297 
2023-12-06 03:09:30.928285: val_loss 1.1532 
2023-12-06 03:09:30.928351: Pseudo dice [0.8619] 
2023-12-06 03:09:30.928418: Epoch time: 52.01 s 
2023-12-06 03:09:32.359257:  
2023-12-06 03:09:32.359393: Epoch 698 
2023-12-06 03:09:32.359492: Current learning rate: 0.0034 
2023-12-06 03:10:24.358966: train_loss 1.0296 
2023-12-06 03:10:24.359253: val_loss 1.1507 
2023-12-06 03:10:24.359312: Pseudo dice [0.8624] 
2023-12-06 03:10:24.359372: Epoch time: 52.0 s 
2023-12-06 03:10:26.034127:  
2023-12-06 03:10:26.034453: Epoch 699 
2023-12-06 03:10:26.034574: Current learning rate: 0.00339 
2023-12-06 03:11:18.011769: train_loss 1.0296 
2023-12-06 03:11:18.012030: val_loss 1.1503 
2023-12-06 03:11:18.012114: Pseudo dice [0.8625] 
2023-12-06 03:11:18.012197: Epoch time: 51.98 s 
2023-12-06 03:11:21.100810:  
2023-12-06 03:11:21.101178: Epoch 700 
2023-12-06 03:11:21.101389: Current learning rate: 0.00338 
2023-12-06 03:12:13.111217: train_loss 1.0296 
2023-12-06 03:12:13.111491: val_loss 1.1468 
2023-12-06 03:12:13.111578: Pseudo dice [0.8656] 
2023-12-06 03:12:13.111663: Epoch time: 52.01 s 
2023-12-06 03:12:14.774183:  
2023-12-06 03:12:14.774511: Epoch 701 
2023-12-06 03:12:14.774748: Current learning rate: 0.00337 
2023-12-06 03:13:06.812363: train_loss 1.0295 
2023-12-06 03:13:06.812635: val_loss 1.1532 
2023-12-06 03:13:06.812719: Pseudo dice [0.8598] 
2023-12-06 03:13:06.812804: Epoch time: 52.04 s 
2023-12-06 03:13:08.290742:  
2023-12-06 03:13:08.290896: Epoch 702 
2023-12-06 03:13:08.290986: Current learning rate: 0.00336 
2023-12-06 03:14:00.203572: train_loss 1.0291 
2023-12-06 03:14:00.203844: val_loss 1.1503 
2023-12-06 03:14:00.204076: Pseudo dice [0.8638] 
2023-12-06 03:14:00.204166: Epoch time: 51.91 s 
2023-12-06 03:14:01.863294:  
2023-12-06 03:14:01.863658: Epoch 703 
2023-12-06 03:14:01.864115: Current learning rate: 0.00335 
2023-12-06 03:14:53.747613: train_loss 1.0298 
2023-12-06 03:14:53.747866: val_loss 1.1454 
2023-12-06 03:14:53.747937: Pseudo dice [0.8669] 
2023-12-06 03:14:53.748009: Epoch time: 51.89 s 
2023-12-06 03:14:55.149711:  
2023-12-06 03:14:55.149848: Epoch 704 
2023-12-06 03:14:55.149940: Current learning rate: 0.00334 
2023-12-06 03:15:47.085974: train_loss 1.0303 
2023-12-06 03:15:47.086233: val_loss 1.1477 
2023-12-06 03:15:47.086316: Pseudo dice [0.8639] 
2023-12-06 03:15:47.086398: Epoch time: 51.94 s 
2023-12-06 03:15:48.735394:  
2023-12-06 03:15:48.735558: Epoch 705 
2023-12-06 03:15:48.735674: Current learning rate: 0.00333 
2023-12-06 03:16:40.504568: train_loss 1.0294 
2023-12-06 03:16:40.504830: val_loss 1.1462 
2023-12-06 03:16:40.504914: Pseudo dice [0.8646] 
2023-12-06 03:16:40.504996: Epoch time: 51.77 s 
2023-12-06 03:16:41.916499:  
2023-12-06 03:16:41.916639: Epoch 706 
2023-12-06 03:16:41.916730: Current learning rate: 0.00332 
2023-12-06 03:17:33.569940: train_loss 1.029 
2023-12-06 03:17:33.570204: val_loss 1.147 
2023-12-06 03:17:33.570288: Pseudo dice [0.8652] 
2023-12-06 03:17:33.570373: Epoch time: 51.66 s 
2023-12-06 03:17:35.122884:  
2023-12-06 03:17:35.123326: Epoch 707 
2023-12-06 03:17:35.123429: Current learning rate: 0.00331 
2023-12-06 03:18:26.833028: train_loss 1.0297 
2023-12-06 03:18:26.833250: val_loss 1.1535 
2023-12-06 03:18:26.833312: Pseudo dice [0.8601] 
2023-12-06 03:18:26.833376: Epoch time: 51.71 s 
2023-12-06 03:18:28.070038:  
2023-12-06 03:18:28.070183: Epoch 708 
2023-12-06 03:18:28.070274: Current learning rate: 0.0033 
2023-12-06 03:19:19.725015: train_loss 1.0295 
2023-12-06 03:19:19.725286: val_loss 1.1423 
2023-12-06 03:19:19.725370: Pseudo dice [0.8691] 
2023-12-06 03:19:19.725459: Epoch time: 51.66 s 
2023-12-06 03:19:20.990404:  
2023-12-06 03:19:20.990536: Epoch 709 
2023-12-06 03:19:20.990631: Current learning rate: 0.00329 
2023-12-06 03:20:12.844123: train_loss 1.0296 
2023-12-06 03:20:12.844350: val_loss 1.1459 
2023-12-06 03:20:12.844415: Pseudo dice [0.8667] 
2023-12-06 03:20:12.844485: Epoch time: 51.86 s 
2023-12-06 03:20:14.269200:  
2023-12-06 03:20:14.269350: Epoch 710 
2023-12-06 03:20:14.269449: Current learning rate: 0.00328 
2023-12-06 03:21:06.156549: train_loss 1.0299 
2023-12-06 03:21:06.156822: val_loss 1.1482 
2023-12-06 03:21:06.156909: Pseudo dice [0.8646] 
2023-12-06 03:21:06.156994: Epoch time: 51.89 s 
2023-12-06 03:21:07.464030:  
2023-12-06 03:21:07.464168: Epoch 711 
2023-12-06 03:21:07.464262: Current learning rate: 0.00327 
2023-12-06 03:21:59.537790: train_loss 1.0295 
2023-12-06 03:21:59.538053: val_loss 1.1439 
2023-12-06 03:21:59.538132: Pseudo dice [0.868] 
2023-12-06 03:21:59.538227: Epoch time: 52.08 s 
2023-12-06 03:22:01.213234:  
2023-12-06 03:22:01.213437: Epoch 712 
2023-12-06 03:22:01.213554: Current learning rate: 0.00326 
2023-12-06 03:22:53.129799: train_loss 1.0297 
2023-12-06 03:22:53.130028: val_loss 1.1391 
2023-12-06 03:22:53.130092: Pseudo dice [0.8713] 
2023-12-06 03:22:53.130158: Epoch time: 51.92 s 
2023-12-06 03:22:54.738764:  
2023-12-06 03:22:54.738934: Epoch 713 
2023-12-06 03:22:54.739056: Current learning rate: 0.00325 
2023-12-06 03:23:46.561704: train_loss 1.0294 
2023-12-06 03:23:46.562095: val_loss 1.1467 
2023-12-06 03:23:46.562184: Pseudo dice [0.8649] 
2023-12-06 03:23:46.562272: Epoch time: 51.83 s 
2023-12-06 03:23:48.233712:  
2023-12-06 03:23:48.233874: Epoch 714 
2023-12-06 03:23:48.233987: Current learning rate: 0.00324 
2023-12-06 03:24:39.940564: train_loss 1.0294 
2023-12-06 03:24:39.940832: val_loss 1.1451 
2023-12-06 03:24:39.941017: Pseudo dice [0.8672] 
2023-12-06 03:24:39.941109: Epoch time: 51.71 s 
2023-12-06 03:24:41.434874:  
2023-12-06 03:24:41.435008: Epoch 715 
2023-12-06 03:24:41.435133: Current learning rate: 0.00323 
2023-12-06 03:25:33.348090: train_loss 1.0292 
2023-12-06 03:25:33.348319: val_loss 1.1411 
2023-12-06 03:25:33.348389: Pseudo dice [0.8701] 
2023-12-06 03:25:33.348461: Epoch time: 51.91 s 
2023-12-06 03:25:34.581833:  
2023-12-06 03:25:34.581976: Epoch 716 
2023-12-06 03:25:34.582078: Current learning rate: 0.00322 
2023-12-06 03:26:26.438008: train_loss 1.0295 
2023-12-06 03:26:26.438283: val_loss 1.1478 
2023-12-06 03:26:26.438367: Pseudo dice [0.8647] 
2023-12-06 03:26:26.438450: Epoch time: 51.86 s 
2023-12-06 03:26:28.103596:  
2023-12-06 03:26:28.103782: Epoch 717 
2023-12-06 03:26:28.103894: Current learning rate: 0.00321 
2023-12-06 03:27:20.141267: train_loss 1.0292 
2023-12-06 03:27:20.141536: val_loss 1.1461 
2023-12-06 03:27:20.141618: Pseudo dice [0.8661] 
2023-12-06 03:27:20.141699: Epoch time: 52.04 s 
2023-12-06 03:27:21.730614:  
2023-12-06 03:27:21.730812: Epoch 718 
2023-12-06 03:27:21.730902: Current learning rate: 0.0032 
2023-12-06 03:28:13.432766: train_loss 1.0291 
2023-12-06 03:28:13.432996: val_loss 1.1542 
2023-12-06 03:28:13.433063: Pseudo dice [0.8595] 
2023-12-06 03:28:13.433133: Epoch time: 51.7 s 
2023-12-06 03:28:14.693570:  
2023-12-06 03:28:14.693714: Epoch 719 
2023-12-06 03:28:14.693834: Current learning rate: 0.00319 
2023-12-06 03:29:06.528879: train_loss 1.029 
2023-12-06 03:29:06.529147: val_loss 1.142 
2023-12-06 03:29:06.529235: Pseudo dice [0.8698] 
2023-12-06 03:29:06.529345: Epoch time: 51.84 s 
2023-12-06 03:29:08.188539:  
2023-12-06 03:29:08.188873: Epoch 720 
2023-12-06 03:29:08.188987: Current learning rate: 0.00318 
2023-12-06 03:30:00.123398: train_loss 1.0289 
2023-12-06 03:30:00.123682: val_loss 1.1484 
2023-12-06 03:30:00.123764: Pseudo dice [0.8654] 
2023-12-06 03:30:00.123852: Epoch time: 51.94 s 
2023-12-06 03:30:01.990091:  
2023-12-06 03:30:01.990251: Epoch 721 
2023-12-06 03:30:01.990345: Current learning rate: 0.00317 
2023-12-06 03:30:53.870892: train_loss 1.0295 
2023-12-06 03:30:53.871198: val_loss 1.1427 
2023-12-06 03:30:53.871285: Pseudo dice [0.8693] 
2023-12-06 03:30:53.871365: Epoch time: 51.88 s 
2023-12-06 03:30:55.545692:  
2023-12-06 03:30:55.545853: Epoch 722 
2023-12-06 03:30:55.545966: Current learning rate: 0.00316 
2023-12-06 03:31:47.610927: train_loss 1.0286 
2023-12-06 03:31:47.611209: val_loss 1.1483 
2023-12-06 03:31:47.611294: Pseudo dice [0.8639] 
2023-12-06 03:31:47.611378: Epoch time: 52.07 s 
2023-12-06 03:31:49.170253:  
2023-12-06 03:31:49.170396: Epoch 723 
2023-12-06 03:31:49.170484: Current learning rate: 0.00315 
2023-12-06 03:32:41.222050: train_loss 1.0278 
2023-12-06 03:32:41.222324: val_loss 1.1472 
2023-12-06 03:32:41.222413: Pseudo dice [0.866] 
2023-12-06 03:32:41.222501: Epoch time: 52.05 s 
2023-12-06 03:32:42.733492:  
2023-12-06 03:32:42.733646: Epoch 724 
2023-12-06 03:32:42.733734: Current learning rate: 0.00314 
2023-12-06 03:33:34.480554: train_loss 1.0285 
2023-12-06 03:33:34.480817: val_loss 1.1521 
2023-12-06 03:33:34.480912: Pseudo dice [0.8619] 
2023-12-06 03:33:34.480996: Epoch time: 51.75 s 
2023-12-06 03:33:36.157799:  
2023-12-06 03:33:36.157969: Epoch 725 
2023-12-06 03:33:36.158086: Current learning rate: 0.00313 
2023-12-06 03:34:28.048069: train_loss 1.0281 
2023-12-06 03:34:28.048303: val_loss 1.1472 
2023-12-06 03:34:28.048372: Pseudo dice [0.8648] 
2023-12-06 03:34:28.048443: Epoch time: 51.89 s 
2023-12-06 03:34:29.283752:  
2023-12-06 03:34:29.283890: Epoch 726 
2023-12-06 03:34:29.283978: Current learning rate: 0.00312 
2023-12-06 03:35:21.352481: train_loss 1.0286 
2023-12-06 03:35:21.352739: val_loss 1.1506 
2023-12-06 03:35:21.352823: Pseudo dice [0.8614] 
2023-12-06 03:35:21.352906: Epoch time: 52.07 s 
2023-12-06 03:35:23.303829:  
2023-12-06 03:35:23.304031: Epoch 727 
2023-12-06 03:35:23.304147: Current learning rate: 0.00311 
2023-12-06 03:36:15.265339: train_loss 1.0286 
2023-12-06 03:36:15.265564: val_loss 1.1527 
2023-12-06 03:36:15.265631: Pseudo dice [0.8607] 
2023-12-06 03:36:15.265699: Epoch time: 51.96 s 
2023-12-06 03:36:16.973579:  
2023-12-06 03:36:16.973743: Epoch 728 
2023-12-06 03:36:16.973856: Current learning rate: 0.0031 
2023-12-06 03:37:08.884174: train_loss 1.0285 
2023-12-06 03:37:08.884476: val_loss 1.1442 
2023-12-06 03:37:08.884558: Pseudo dice [0.8684] 
2023-12-06 03:37:08.884640: Epoch time: 51.91 s 
2023-12-06 03:37:10.551426:  
2023-12-06 03:37:10.551599: Epoch 729 
2023-12-06 03:37:10.551712: Current learning rate: 0.00309 
2023-12-06 03:38:02.456281: train_loss 1.029 
2023-12-06 03:38:02.456634: val_loss 1.1543 
2023-12-06 03:38:02.456743: Pseudo dice [0.8607] 
2023-12-06 03:38:02.456858: Epoch time: 51.91 s 
2023-12-06 03:38:04.158679:  
2023-12-06 03:38:04.158960: Epoch 730 
2023-12-06 03:38:04.159089: Current learning rate: 0.00308 
2023-12-06 03:38:56.183740: train_loss 1.0284 
2023-12-06 03:38:56.184013: val_loss 1.1481 
2023-12-06 03:38:56.184092: Pseudo dice [0.8645] 
2023-12-06 03:38:56.184176: Epoch time: 52.03 s 
2023-12-06 03:38:57.734485:  
2023-12-06 03:38:57.734750: Epoch 731 
2023-12-06 03:38:57.734840: Current learning rate: 0.00307 
2023-12-06 03:39:49.754239: train_loss 1.0287 
2023-12-06 03:39:49.754519: val_loss 1.146 
2023-12-06 03:39:49.754607: Pseudo dice [0.8674] 
2023-12-06 03:39:49.754693: Epoch time: 52.02 s 
2023-12-06 03:39:51.610878:  
2023-12-06 03:39:51.611083: Epoch 732 
2023-12-06 03:39:51.611205: Current learning rate: 0.00306 
2023-12-06 03:40:43.335522: train_loss 1.0291 
2023-12-06 03:40:43.335809: val_loss 1.156 
2023-12-06 03:40:43.335894: Pseudo dice [0.858] 
2023-12-06 03:40:43.335980: Epoch time: 51.73 s 
2023-12-06 03:40:45.010155:  
2023-12-06 03:40:45.010416: Epoch 733 
2023-12-06 03:40:45.010536: Current learning rate: 0.00305 
2023-12-06 03:41:36.951026: train_loss 1.0285 
2023-12-06 03:41:36.951283: val_loss 1.144 
2023-12-06 03:41:36.951365: Pseudo dice [0.8678] 
2023-12-06 03:41:36.951443: Epoch time: 51.94 s 
2023-12-06 03:41:38.564565:  
2023-12-06 03:41:38.564724: Epoch 734 
2023-12-06 03:41:38.564814: Current learning rate: 0.00304 
2023-12-06 03:42:30.230825: train_loss 1.029 
2023-12-06 03:42:30.231252: val_loss 1.1405 
2023-12-06 03:42:30.231339: Pseudo dice [0.8703] 
2023-12-06 03:42:30.231423: Epoch time: 51.67 s 
2023-12-06 03:42:32.089058:  
2023-12-06 03:42:32.089238: Epoch 735 
2023-12-06 03:42:32.089354: Current learning rate: 0.00303 
2023-12-06 03:43:23.948008: train_loss 1.0283 
2023-12-06 03:43:23.948287: val_loss 1.1574 
2023-12-06 03:43:23.948375: Pseudo dice [0.8578] 
2023-12-06 03:43:23.948463: Epoch time: 51.86 s 
2023-12-06 03:43:25.611691:  
2023-12-06 03:43:25.611863: Epoch 736 
2023-12-06 03:43:25.611979: Current learning rate: 0.00302 
2023-12-06 03:44:17.412442: train_loss 1.0289 
2023-12-06 03:44:17.412709: val_loss 1.1555 
2023-12-06 03:44:17.412789: Pseudo dice [0.8585] 
2023-12-06 03:44:17.412873: Epoch time: 51.8 s 
2023-12-06 03:44:18.657539:  
2023-12-06 03:44:18.657681: Epoch 737 
2023-12-06 03:44:18.657769: Current learning rate: 0.00301 
2023-12-06 03:45:10.589232: train_loss 1.0284 
2023-12-06 03:45:10.589524: val_loss 1.151 
2023-12-06 03:45:10.589607: Pseudo dice [0.8632] 
2023-12-06 03:45:10.589695: Epoch time: 51.93 s 
2023-12-06 03:45:12.486680:  
2023-12-06 03:45:12.486985: Epoch 738 
2023-12-06 03:45:12.487174: Current learning rate: 0.003 
2023-12-06 03:46:04.502662: train_loss 1.0283 
2023-12-06 03:46:04.503074: val_loss 1.1511 
2023-12-06 03:46:04.503167: Pseudo dice [0.8612] 
2023-12-06 03:46:04.503253: Epoch time: 52.02 s 
2023-12-06 03:46:06.181987:  
2023-12-06 03:46:06.182168: Epoch 739 
2023-12-06 03:46:06.182283: Current learning rate: 0.00299 
2023-12-06 03:46:58.190789: train_loss 1.0285 
2023-12-06 03:46:58.191071: val_loss 1.1476 
2023-12-06 03:46:58.191155: Pseudo dice [0.865] 
2023-12-06 03:46:58.191239: Epoch time: 52.01 s 
2023-12-06 03:46:59.846271:  
2023-12-06 03:46:59.846688: Epoch 740 
2023-12-06 03:46:59.846807: Current learning rate: 0.00297 
2023-12-06 03:47:51.710815: train_loss 1.0283 
2023-12-06 03:47:51.711092: val_loss 1.1511 
2023-12-06 03:47:51.711179: Pseudo dice [0.8631] 
2023-12-06 03:47:51.711262: Epoch time: 51.87 s 
2023-12-06 03:47:53.369508:  
2023-12-06 03:47:53.369965: Epoch 741 
2023-12-06 03:47:53.370113: Current learning rate: 0.00296 
2023-12-06 03:48:45.285572: train_loss 1.0285 
2023-12-06 03:48:45.285815: val_loss 1.1468 
2023-12-06 03:48:45.285882: Pseudo dice [0.8643] 
2023-12-06 03:48:45.285949: Epoch time: 51.92 s 
2023-12-06 03:48:46.562424:  
2023-12-06 03:48:46.562562: Epoch 742 
2023-12-06 03:48:46.562657: Current learning rate: 0.00295 
2023-12-06 03:49:38.433173: train_loss 1.0286 
2023-12-06 03:49:38.433436: val_loss 1.1431 
2023-12-06 03:49:38.433519: Pseudo dice [0.8684] 
2023-12-06 03:49:38.433604: Epoch time: 51.87 s 
2023-12-06 03:49:39.942442:  
2023-12-06 03:49:39.942575: Epoch 743 
2023-12-06 03:49:39.942663: Current learning rate: 0.00294 
2023-12-06 03:50:31.889305: train_loss 1.0286 
2023-12-06 03:50:31.889575: val_loss 1.1429 
2023-12-06 03:50:31.889656: Pseudo dice [0.8707] 
2023-12-06 03:50:31.889737: Epoch time: 51.95 s 
2023-12-06 03:50:33.496324:  
2023-12-06 03:50:33.496632: Epoch 744 
2023-12-06 03:50:33.496734: Current learning rate: 0.00293 
2023-12-06 03:51:25.332629: train_loss 1.0282 
2023-12-06 03:51:25.332891: val_loss 1.1493 
2023-12-06 03:51:25.332977: Pseudo dice [0.8623] 
2023-12-06 03:51:25.333060: Epoch time: 51.84 s 
2023-12-06 03:51:26.682713:  
2023-12-06 03:51:26.682857: Epoch 745 
2023-12-06 03:51:26.682946: Current learning rate: 0.00292 
2023-12-06 03:52:18.636463: train_loss 1.0277 
2023-12-06 03:52:18.636700: val_loss 1.1557 
2023-12-06 03:52:18.636763: Pseudo dice [0.8572] 
2023-12-06 03:52:18.636830: Epoch time: 51.96 s 
2023-12-06 03:52:20.197366:  
2023-12-06 03:52:20.197570: Epoch 746 
2023-12-06 03:52:20.197685: Current learning rate: 0.00291 
2023-12-06 03:53:11.979494: train_loss 1.0272 
2023-12-06 03:53:11.979762: val_loss 1.1502 
2023-12-06 03:53:11.979844: Pseudo dice [0.8636] 
2023-12-06 03:53:11.979928: Epoch time: 51.78 s 
2023-12-06 03:53:13.702301:  
2023-12-06 03:53:13.702478: Epoch 747 
2023-12-06 03:53:13.702592: Current learning rate: 0.0029 
2023-12-06 03:54:05.576688: train_loss 1.0283 
2023-12-06 03:54:05.576962: val_loss 1.1511 
2023-12-06 03:54:05.577045: Pseudo dice [0.8617] 
2023-12-06 03:54:05.577131: Epoch time: 51.88 s 
2023-12-06 03:54:07.241692:  
2023-12-06 03:54:07.242169: Epoch 748 
2023-12-06 03:54:07.242291: Current learning rate: 0.00289 
2023-12-06 03:54:59.256198: train_loss 1.0287 
2023-12-06 03:54:59.256483: val_loss 1.1491 
2023-12-06 03:54:59.256575: Pseudo dice [0.8637] 
2023-12-06 03:54:59.256671: Epoch time: 52.02 s 
2023-12-06 03:55:00.915668:  
2023-12-06 03:55:00.915826: Epoch 749 
2023-12-06 03:55:00.915934: Current learning rate: 0.00288 
2023-12-06 03:55:53.059568: train_loss 1.0287 
2023-12-06 03:55:53.059849: val_loss 1.1576 
2023-12-06 03:55:53.059942: Pseudo dice [0.8565] 
2023-12-06 03:55:53.060032: Epoch time: 52.15 s 
2023-12-06 03:55:56.139292:  
2023-12-06 03:55:56.139518: Epoch 750 
2023-12-06 03:55:56.139632: Current learning rate: 0.00287 
2023-12-06 03:56:47.950173: train_loss 1.028 
2023-12-06 03:56:47.950409: val_loss 1.1502 
2023-12-06 03:56:47.950478: Pseudo dice [0.8635] 
2023-12-06 03:56:47.950546: Epoch time: 51.81 s 
2023-12-06 03:56:49.551803:  
2023-12-06 03:56:49.551951: Epoch 751 
2023-12-06 03:56:49.552038: Current learning rate: 0.00286 
2023-12-06 03:57:41.412666: train_loss 1.0288 
2023-12-06 03:57:41.412937: val_loss 1.1552 
2023-12-06 03:57:41.413016: Pseudo dice [0.8592] 
2023-12-06 03:57:41.413098: Epoch time: 51.86 s 
2023-12-06 03:57:42.859934:  
2023-12-06 03:57:42.860078: Epoch 752 
2023-12-06 03:57:42.860178: Current learning rate: 0.00285 
2023-12-06 03:58:34.780314: train_loss 1.0284 
2023-12-06 03:58:34.780581: val_loss 1.1465 
2023-12-06 03:58:34.780663: Pseudo dice [0.8655] 
2023-12-06 03:58:34.780745: Epoch time: 51.92 s 
2023-12-06 03:58:36.300795:  
2023-12-06 03:58:36.300992: Epoch 753 
2023-12-06 03:58:36.301145: Current learning rate: 0.00284 
2023-12-06 03:59:28.268959: train_loss 1.0284 
2023-12-06 03:59:28.269235: val_loss 1.15 
2023-12-06 03:59:28.269317: Pseudo dice [0.863] 
2023-12-06 03:59:28.269400: Epoch time: 51.97 s 
2023-12-06 03:59:29.885153:  
2023-12-06 03:59:29.885287: Epoch 754 
2023-12-06 03:59:29.885377: Current learning rate: 0.00283 
2023-12-06 04:00:21.803499: train_loss 1.0283 
2023-12-06 04:00:21.803769: val_loss 1.1419 
2023-12-06 04:00:21.803849: Pseudo dice [0.8694] 
2023-12-06 04:00:21.803933: Epoch time: 51.92 s 
2023-12-06 04:00:23.695417:  
2023-12-06 04:00:23.695685: Epoch 755 
2023-12-06 04:00:23.695812: Current learning rate: 0.00282 
2023-12-06 04:01:15.491974: train_loss 1.028 
2023-12-06 04:01:15.492197: val_loss 1.1486 
2023-12-06 04:01:15.492263: Pseudo dice [0.864] 
2023-12-06 04:01:15.492329: Epoch time: 51.8 s 
2023-12-06 04:01:16.787040:  
2023-12-06 04:01:16.787187: Epoch 756 
2023-12-06 04:01:16.787278: Current learning rate: 0.00281 
2023-12-06 04:02:08.742686: train_loss 1.0278 
2023-12-06 04:02:08.743090: val_loss 1.1553 
2023-12-06 04:02:08.743180: Pseudo dice [0.8582] 
2023-12-06 04:02:08.743267: Epoch time: 51.96 s 
2023-12-06 04:02:10.413184:  
2023-12-06 04:02:10.413370: Epoch 757 
2023-12-06 04:02:10.413482: Current learning rate: 0.0028 
2023-12-06 04:03:02.328869: train_loss 1.0281 
2023-12-06 04:03:02.329135: val_loss 1.1423 
2023-12-06 04:03:02.329215: Pseudo dice [0.8695] 
2023-12-06 04:03:02.329296: Epoch time: 51.92 s 
2023-12-06 04:03:03.990551:  
2023-12-06 04:03:03.990725: Epoch 758 
2023-12-06 04:03:03.990839: Current learning rate: 0.00279 
2023-12-06 04:03:56.050887: train_loss 1.0281 
2023-12-06 04:03:56.051207: val_loss 1.1558 
2023-12-06 04:03:56.051296: Pseudo dice [0.8576] 
2023-12-06 04:03:56.051379: Epoch time: 52.06 s 
2023-12-06 04:03:57.647519:  
2023-12-06 04:03:57.647919: Epoch 759 
2023-12-06 04:03:57.648015: Current learning rate: 0.00278 
2023-12-06 04:04:49.633819: train_loss 1.0279 
2023-12-06 04:04:49.634101: val_loss 1.1495 
2023-12-06 04:04:49.634184: Pseudo dice [0.8626] 
2023-12-06 04:04:49.634267: Epoch time: 51.99 s 
2023-12-06 04:04:51.253785:  
2023-12-06 04:04:51.254007: Epoch 760 
2023-12-06 04:04:51.254099: Current learning rate: 0.00277 
2023-12-06 04:05:43.166419: train_loss 1.028 
2023-12-06 04:05:43.166643: val_loss 1.1493 
2023-12-06 04:05:43.166711: Pseudo dice [0.8627] 
2023-12-06 04:05:43.166781: Epoch time: 51.91 s 
2023-12-06 04:05:44.586767:  
2023-12-06 04:05:44.587108: Epoch 761 
2023-12-06 04:05:44.587203: Current learning rate: 0.00276 
2023-12-06 04:06:36.747686: train_loss 1.0277 
2023-12-06 04:06:36.747970: val_loss 1.1431 
2023-12-06 04:06:36.748059: Pseudo dice [0.8682] 
2023-12-06 04:06:36.748142: Epoch time: 52.16 s 
2023-12-06 04:06:38.423358:  
2023-12-06 04:06:38.423495: Epoch 762 
2023-12-06 04:06:38.423586: Current learning rate: 0.00275 
2023-12-06 04:07:30.451213: train_loss 1.0279 
2023-12-06 04:07:30.451439: val_loss 1.1432 
2023-12-06 04:07:30.451504: Pseudo dice [0.8687] 
2023-12-06 04:07:30.451569: Epoch time: 52.03 s 
2023-12-06 04:07:31.771681:  
2023-12-06 04:07:31.771838: Epoch 763 
2023-12-06 04:07:31.771928: Current learning rate: 0.00274 
2023-12-06 04:08:23.872308: train_loss 1.0275 
2023-12-06 04:08:23.872602: val_loss 1.1471 
2023-12-06 04:08:23.872687: Pseudo dice [0.8647] 
2023-12-06 04:08:23.872772: Epoch time: 52.1 s 
2023-12-06 04:08:25.523591:  
2023-12-06 04:08:25.523873: Epoch 764 
2023-12-06 04:08:25.523968: Current learning rate: 0.00273 
2023-12-06 04:09:17.486640: train_loss 1.0278 
2023-12-06 04:09:17.486917: val_loss 1.1526 
2023-12-06 04:09:17.486999: Pseudo dice [0.8609] 
2023-12-06 04:09:17.487106: Epoch time: 51.96 s 
2023-12-06 04:09:19.167697:  
2023-12-06 04:09:19.167844: Epoch 765 
2023-12-06 04:09:19.167953: Current learning rate: 0.00272 
2023-12-06 04:10:11.221736: train_loss 1.0274 
2023-12-06 04:10:11.222010: val_loss 1.1461 
2023-12-06 04:10:11.222094: Pseudo dice [0.8664] 
2023-12-06 04:10:11.222176: Epoch time: 52.06 s 
2023-12-06 04:10:12.669441:  
2023-12-06 04:10:12.669582: Epoch 766 
2023-12-06 04:10:12.669678: Current learning rate: 0.00271 
2023-12-06 04:11:04.722110: train_loss 1.0273 
2023-12-06 04:11:04.722355: val_loss 1.1499 
2023-12-06 04:11:04.722427: Pseudo dice [0.8633] 
2023-12-06 04:11:04.722500: Epoch time: 52.05 s 
2023-12-06 04:11:06.000993:  
2023-12-06 04:11:06.001137: Epoch 767 
2023-12-06 04:11:06.001229: Current learning rate: 0.0027 
2023-12-06 04:11:58.050004: train_loss 1.0274 
2023-12-06 04:11:58.050268: val_loss 1.1556 
2023-12-06 04:11:58.050348: Pseudo dice [0.8591] 
2023-12-06 04:11:58.050432: Epoch time: 52.05 s 
2023-12-06 04:11:59.749383:  
2023-12-06 04:11:59.749733: Epoch 768 
2023-12-06 04:11:59.749853: Current learning rate: 0.00268 
2023-12-06 04:12:51.785086: train_loss 1.0271 
2023-12-06 04:12:51.785427: val_loss 1.1382 
2023-12-06 04:12:51.785536: Pseudo dice [0.8718] 
2023-12-06 04:12:51.785654: Epoch time: 52.04 s 
2023-12-06 04:12:53.471982:  
2023-12-06 04:12:53.472132: Epoch 769 
2023-12-06 04:12:53.472223: Current learning rate: 0.00267 
2023-12-06 04:13:45.486185: train_loss 1.0275 
2023-12-06 04:13:45.486446: val_loss 1.1451 
2023-12-06 04:13:45.486528: Pseudo dice [0.8673] 
2023-12-06 04:13:45.486612: Epoch time: 52.02 s 
2023-12-06 04:13:47.177037:  
2023-12-06 04:13:47.177339: Epoch 770 
2023-12-06 04:13:47.177488: Current learning rate: 0.00266 
2023-12-06 04:14:39.059713: train_loss 1.0276 
2023-12-06 04:14:39.059978: val_loss 1.1534 
2023-12-06 04:14:39.060064: Pseudo dice [0.8604] 
2023-12-06 04:14:39.060148: Epoch time: 51.88 s 
2023-12-06 04:14:40.766325:  
2023-12-06 04:14:40.766568: Epoch 771 
2023-12-06 04:14:40.766685: Current learning rate: 0.00265 
2023-12-06 04:15:32.857113: train_loss 1.027 
2023-12-06 04:15:32.857384: val_loss 1.147 
2023-12-06 04:15:32.857464: Pseudo dice [0.864] 
2023-12-06 04:15:32.857545: Epoch time: 52.09 s 
2023-12-06 04:15:34.738507:  
2023-12-06 04:15:34.738674: Epoch 772 
2023-12-06 04:15:34.738767: Current learning rate: 0.00264 
2023-12-06 04:16:26.477837: train_loss 1.0268 
2023-12-06 04:16:26.478106: val_loss 1.1533 
2023-12-06 04:16:26.478185: Pseudo dice [0.8602] 
2023-12-06 04:16:26.478267: Epoch time: 51.74 s 
2023-12-06 04:16:28.189394:  
2023-12-06 04:16:28.189575: Epoch 773 
2023-12-06 04:16:28.189682: Current learning rate: 0.00263 
2023-12-06 04:17:20.091219: train_loss 1.0271 
2023-12-06 04:17:20.091483: val_loss 1.1584 
2023-12-06 04:17:20.091566: Pseudo dice [0.8563] 
2023-12-06 04:17:20.091649: Epoch time: 51.9 s 
2023-12-06 04:17:21.770188:  
2023-12-06 04:17:21.770383: Epoch 774 
2023-12-06 04:17:21.770495: Current learning rate: 0.00262 
2023-12-06 04:18:13.787008: train_loss 1.0276 
2023-12-06 04:18:13.787286: val_loss 1.1536 
2023-12-06 04:18:13.787363: Pseudo dice [0.8611] 
2023-12-06 04:18:13.787444: Epoch time: 52.02 s 
2023-12-06 04:18:15.481655:  
2023-12-06 04:18:15.481810: Epoch 775 
2023-12-06 04:18:15.481916: Current learning rate: 0.00261 
2023-12-06 04:19:07.548432: train_loss 1.0277 
2023-12-06 04:19:07.548892: val_loss 1.1451 
2023-12-06 04:19:07.548998: Pseudo dice [0.8665] 
2023-12-06 04:19:07.549096: Epoch time: 52.07 s 
2023-12-06 04:19:09.256857:  
2023-12-06 04:19:09.257080: Epoch 776 
2023-12-06 04:19:09.257210: Current learning rate: 0.0026 
2023-12-06 04:20:01.397012: train_loss 1.028 
2023-12-06 04:20:01.397280: val_loss 1.1468 
2023-12-06 04:20:01.397371: Pseudo dice [0.8653] 
2023-12-06 04:20:01.397455: Epoch time: 52.14 s 
2023-12-06 04:20:03.083496:  
2023-12-06 04:20:03.083666: Epoch 777 
2023-12-06 04:20:03.083776: Current learning rate: 0.00259 
2023-12-06 04:20:55.023594: train_loss 1.0271 
2023-12-06 04:20:55.023860: val_loss 1.1435 
2023-12-06 04:20:55.023946: Pseudo dice [0.8682] 
2023-12-06 04:20:55.024029: Epoch time: 51.94 s 
2023-12-06 04:20:56.773096:  
2023-12-06 04:20:56.773255: Epoch 778 
2023-12-06 04:20:56.773370: Current learning rate: 0.00258 
2023-12-06 04:21:48.819136: train_loss 1.0275 
2023-12-06 04:21:48.819408: val_loss 1.1575 
2023-12-06 04:21:48.819493: Pseudo dice [0.8569] 
2023-12-06 04:21:48.819576: Epoch time: 52.05 s 
2023-12-06 04:21:50.539655:  
2023-12-06 04:21:50.539837: Epoch 779 
2023-12-06 04:21:50.539943: Current learning rate: 0.00257 
2023-12-06 04:22:42.604577: train_loss 1.0273 
2023-12-06 04:22:42.604845: val_loss 1.1447 
2023-12-06 04:22:42.604926: Pseudo dice [0.868] 
2023-12-06 04:22:42.605006: Epoch time: 52.07 s 
2023-12-06 04:22:44.113619:  
2023-12-06 04:22:44.113931: Epoch 780 
2023-12-06 04:22:44.114167: Current learning rate: 0.00256 
2023-12-06 04:23:36.031950: train_loss 1.0264 
2023-12-06 04:23:36.032220: val_loss 1.1479 
2023-12-06 04:23:36.032307: Pseudo dice [0.8649] 
2023-12-06 04:23:36.032388: Epoch time: 51.92 s 
2023-12-06 04:23:37.729211:  
2023-12-06 04:23:37.729369: Epoch 781 
2023-12-06 04:23:37.729481: Current learning rate: 0.00255 
2023-12-06 04:24:29.736104: train_loss 1.0268 
2023-12-06 04:24:29.736399: val_loss 1.1454 
2023-12-06 04:24:29.736483: Pseudo dice [0.8664] 
2023-12-06 04:24:29.736567: Epoch time: 52.01 s 
2023-12-06 04:24:31.418584:  
2023-12-06 04:24:31.418734: Epoch 782 
2023-12-06 04:24:31.418850: Current learning rate: 0.00254 
2023-12-06 04:25:23.473581: train_loss 1.0273 
2023-12-06 04:25:23.473809: val_loss 1.1406 
2023-12-06 04:25:23.473872: Pseudo dice [0.8702] 
2023-12-06 04:25:23.473938: Epoch time: 52.06 s 
2023-12-06 04:25:24.741895:  
2023-12-06 04:25:24.742394: Epoch 783 
2023-12-06 04:25:24.742579: Current learning rate: 0.00253 
2023-12-06 04:26:16.605087: train_loss 1.027 
2023-12-06 04:26:16.605349: val_loss 1.1429 
2023-12-06 04:26:16.605428: Pseudo dice [0.868] 
2023-12-06 04:26:16.605510: Epoch time: 51.86 s 
2023-12-06 04:26:18.488218:  
2023-12-06 04:26:18.488379: Epoch 784 
2023-12-06 04:26:18.488494: Current learning rate: 0.00252 
2023-12-06 04:27:10.417331: train_loss 1.0273 
2023-12-06 04:27:10.417614: val_loss 1.1513 
2023-12-06 04:27:10.417701: Pseudo dice [0.8604] 
2023-12-06 04:27:10.417790: Epoch time: 51.93 s 
2023-12-06 04:27:11.932252:  
2023-12-06 04:27:11.932507: Epoch 785 
2023-12-06 04:27:11.932614: Current learning rate: 0.00251 
2023-12-06 04:28:03.901411: train_loss 1.0273 
2023-12-06 04:28:03.901684: val_loss 1.1514 
2023-12-06 04:28:03.901765: Pseudo dice [0.8623] 
2023-12-06 04:28:03.901846: Epoch time: 51.97 s 
2023-12-06 04:28:05.582971:  
2023-12-06 04:28:05.583152: Epoch 786 
2023-12-06 04:28:05.583266: Current learning rate: 0.0025 
2023-12-06 04:28:57.160518: train_loss 1.0269 
2023-12-06 04:28:57.160748: val_loss 1.1514 
2023-12-06 04:28:57.160817: Pseudo dice [0.8615] 
2023-12-06 04:28:57.160887: Epoch time: 51.58 s 
2023-12-06 04:28:58.836702:  
2023-12-06 04:28:58.836867: Epoch 787 
2023-12-06 04:28:58.836981: Current learning rate: 0.00249 
2023-12-06 04:29:50.784157: train_loss 1.0272 
2023-12-06 04:29:50.784431: val_loss 1.1491 
2023-12-06 04:29:50.784523: Pseudo dice [0.863] 
2023-12-06 04:29:50.784633: Epoch time: 51.95 s 
2023-12-06 04:29:52.402990:  
2023-12-06 04:29:52.403224: Epoch 788 
2023-12-06 04:29:52.403405: Current learning rate: 0.00248 
2023-12-06 04:30:44.249769: train_loss 1.0286 
2023-12-06 04:30:44.250034: val_loss 1.1416 
2023-12-06 04:30:44.250117: Pseudo dice [0.8715] 
2023-12-06 04:30:44.250217: Epoch time: 51.85 s 
2023-12-06 04:30:45.800453:  
2023-12-06 04:30:45.800610: Epoch 789 
2023-12-06 04:30:45.800697: Current learning rate: 0.00247 
2023-12-06 04:31:37.623912: train_loss 1.0268 
2023-12-06 04:31:37.624188: val_loss 1.1457 
2023-12-06 04:31:37.624272: Pseudo dice [0.8653] 
2023-12-06 04:31:37.624357: Epoch time: 51.83 s 
2023-12-06 04:31:39.287194:  
2023-12-06 04:31:39.287337: Epoch 790 
2023-12-06 04:31:39.287424: Current learning rate: 0.00245 
2023-12-06 04:32:31.111215: train_loss 1.0272 
2023-12-06 04:32:31.111493: val_loss 1.1464 
2023-12-06 04:32:31.111576: Pseudo dice [0.8668] 
2023-12-06 04:32:31.111658: Epoch time: 51.83 s 
2023-12-06 04:32:32.732568:  
2023-12-06 04:32:32.732720: Epoch 791 
2023-12-06 04:32:32.732812: Current learning rate: 0.00244 
2023-12-06 04:33:24.585051: train_loss 1.0271 
2023-12-06 04:33:24.585355: val_loss 1.1521 
2023-12-06 04:33:24.585442: Pseudo dice [0.8612] 
2023-12-06 04:33:24.585536: Epoch time: 51.85 s 
2023-12-06 04:33:26.298045:  
2023-12-06 04:33:26.298205: Epoch 792 
2023-12-06 04:33:26.298329: Current learning rate: 0.00243 
2023-12-06 04:34:18.097579: train_loss 1.0271 
2023-12-06 04:34:18.097841: val_loss 1.1442 
2023-12-06 04:34:18.097920: Pseudo dice [0.8665] 
2023-12-06 04:34:18.098002: Epoch time: 51.8 s 
2023-12-06 04:34:19.791288:  
2023-12-06 04:34:19.791478: Epoch 793 
2023-12-06 04:34:19.791587: Current learning rate: 0.00242 
2023-12-06 04:35:11.787194: train_loss 1.0267 
2023-12-06 04:35:11.787461: val_loss 1.144 
2023-12-06 04:35:11.787541: Pseudo dice [0.8671] 
2023-12-06 04:35:11.787620: Epoch time: 52.0 s 
2023-12-06 04:35:13.468213:  
2023-12-06 04:35:13.468378: Epoch 794 
2023-12-06 04:35:13.468487: Current learning rate: 0.00241 
2023-12-06 04:36:05.505789: train_loss 1.0262 
2023-12-06 04:36:05.506059: val_loss 1.1472 
2023-12-06 04:36:05.506140: Pseudo dice [0.8649] 
2023-12-06 04:36:05.506222: Epoch time: 52.04 s 
2023-12-06 04:36:06.905719:  
2023-12-06 04:36:06.905856: Epoch 795 
2023-12-06 04:36:06.905945: Current learning rate: 0.0024 
2023-12-06 04:36:58.747366: train_loss 1.0265 
2023-12-06 04:36:58.747600: val_loss 1.1475 
2023-12-06 04:36:58.747666: Pseudo dice [0.8635] 
2023-12-06 04:36:58.747734: Epoch time: 51.84 s 
2023-12-06 04:37:00.209006:  
2023-12-06 04:37:00.209446: Epoch 796 
2023-12-06 04:37:00.209544: Current learning rate: 0.00239 
2023-12-06 04:37:52.298897: train_loss 1.0261 
2023-12-06 04:37:52.299162: val_loss 1.1483 
2023-12-06 04:37:52.299229: Pseudo dice [0.8641] 
2023-12-06 04:37:52.299299: Epoch time: 52.09 s 
2023-12-06 04:37:53.915749:  
2023-12-06 04:37:53.916060: Epoch 797 
2023-12-06 04:37:53.916180: Current learning rate: 0.00238 
2023-12-06 04:38:45.939055: train_loss 1.0265 
2023-12-06 04:38:45.939333: val_loss 1.1577 
2023-12-06 04:38:45.939417: Pseudo dice [0.8568] 
2023-12-06 04:38:45.939502: Epoch time: 52.03 s 
2023-12-06 04:38:47.532436:  
2023-12-06 04:38:47.532876: Epoch 798 
2023-12-06 04:38:47.532977: Current learning rate: 0.00237 
2023-12-06 04:39:39.476135: train_loss 1.0272 
2023-12-06 04:39:39.476410: val_loss 1.1461 
2023-12-06 04:39:39.476502: Pseudo dice [0.866] 
2023-12-06 04:39:39.476618: Epoch time: 51.95 s 
2023-12-06 04:39:41.130917:  
2023-12-06 04:39:41.131478: Epoch 799 
2023-12-06 04:39:41.131669: Current learning rate: 0.00236 
2023-12-06 04:40:32.797997: train_loss 1.0266 
2023-12-06 04:40:32.798239: val_loss 1.1412 
2023-12-06 04:40:32.798310: Pseudo dice [0.8711] 
2023-12-06 04:40:32.798382: Epoch time: 51.67 s 
2023-12-06 04:40:35.419544:  
2023-12-06 04:40:35.419702: Epoch 800 
2023-12-06 04:40:35.419795: Current learning rate: 0.00235 
2023-12-06 04:41:27.268553: train_loss 1.027 
2023-12-06 04:41:27.268827: val_loss 1.1459 
2023-12-06 04:41:27.268910: Pseudo dice [0.8671] 
2023-12-06 04:41:27.268993: Epoch time: 51.85 s 
2023-12-06 04:41:28.896363:  
2023-12-06 04:41:28.896652: Epoch 801 
2023-12-06 04:41:28.896764: Current learning rate: 0.00234 
2023-12-06 04:42:20.719383: train_loss 1.0269 
2023-12-06 04:42:20.719665: val_loss 1.1449 
2023-12-06 04:42:20.719748: Pseudo dice [0.8672] 
2023-12-06 04:42:20.719827: Epoch time: 51.82 s 
2023-12-06 04:42:22.392398:  
2023-12-06 04:42:22.392557: Epoch 802 
2023-12-06 04:42:22.392665: Current learning rate: 0.00233 
2023-12-06 04:43:14.446324: train_loss 1.0265 
2023-12-06 04:43:14.446596: val_loss 1.148 
2023-12-06 04:43:14.446680: Pseudo dice [0.8655] 
2023-12-06 04:43:14.446760: Epoch time: 52.06 s 
2023-12-06 04:43:16.174332:  
2023-12-06 04:43:16.174740: Epoch 803 
2023-12-06 04:43:16.174865: Current learning rate: 0.00232 
2023-12-06 04:44:07.808167: train_loss 1.0267 
2023-12-06 04:44:07.808408: val_loss 1.1528 
2023-12-06 04:44:07.808475: Pseudo dice [0.86] 
2023-12-06 04:44:07.808543: Epoch time: 51.64 s 
2023-12-06 04:44:09.083422:  
2023-12-06 04:44:09.083549: Epoch 804 
2023-12-06 04:44:09.083636: Current learning rate: 0.00231 
2023-12-06 04:45:01.070180: train_loss 1.0273 
2023-12-06 04:45:01.070447: val_loss 1.1466 
2023-12-06 04:45:01.070532: Pseudo dice [0.8651] 
2023-12-06 04:45:01.070616: Epoch time: 51.99 s 
2023-12-06 04:45:02.760191:  
2023-12-06 04:45:02.760630: Epoch 805 
2023-12-06 04:45:02.760728: Current learning rate: 0.0023 
2023-12-06 04:45:54.666263: train_loss 1.0273 
2023-12-06 04:45:54.666525: val_loss 1.1462 
2023-12-06 04:45:54.666607: Pseudo dice [0.8654] 
2023-12-06 04:45:54.666691: Epoch time: 51.91 s 
2023-12-06 04:45:56.215797:  
2023-12-06 04:45:56.216299: Epoch 806 
2023-12-06 04:45:56.216392: Current learning rate: 0.00229 
2023-12-06 04:46:48.113645: train_loss 1.0265 
2023-12-06 04:46:48.113908: val_loss 1.1527 
2023-12-06 04:46:48.113987: Pseudo dice [0.8606] 
2023-12-06 04:46:48.114068: Epoch time: 51.9 s 
2023-12-06 04:46:49.856899:  
2023-12-06 04:46:49.857142: Epoch 807 
2023-12-06 04:46:49.857234: Current learning rate: 0.00228 
2023-12-06 04:47:41.586524: train_loss 1.026 
2023-12-06 04:47:41.586828: val_loss 1.1445 
2023-12-06 04:47:41.586936: Pseudo dice [0.8667] 
2023-12-06 04:47:41.587069: Epoch time: 51.73 s 
2023-12-06 04:47:43.271248:  
2023-12-06 04:47:43.271433: Epoch 808 
2023-12-06 04:47:43.271542: Current learning rate: 0.00226 
2023-12-06 04:48:35.246128: train_loss 1.0256 
2023-12-06 04:48:35.246404: val_loss 1.1538 
2023-12-06 04:48:35.246490: Pseudo dice [0.8598] 
2023-12-06 04:48:35.246576: Epoch time: 51.98 s 
2023-12-06 04:48:36.885169:  
2023-12-06 04:48:36.885458: Epoch 809 
2023-12-06 04:48:36.885656: Current learning rate: 0.00225 
2023-12-06 04:49:28.381789: train_loss 1.0261 
2023-12-06 04:49:28.382018: val_loss 1.1453 
2023-12-06 04:49:28.382087: Pseudo dice [0.8674] 
2023-12-06 04:49:28.382157: Epoch time: 51.5 s 
2023-12-06 04:49:29.674129:  
2023-12-06 04:49:29.674266: Epoch 810 
2023-12-06 04:49:29.674363: Current learning rate: 0.00224 
2023-12-06 04:50:21.577600: train_loss 1.0255 
2023-12-06 04:50:21.577876: val_loss 1.156 
2023-12-06 04:50:21.577961: Pseudo dice [0.8569] 
2023-12-06 04:50:21.578044: Epoch time: 51.91 s 
2023-12-06 04:50:22.942228:  
2023-12-06 04:50:22.942375: Epoch 811 
2023-12-06 04:50:22.942468: Current learning rate: 0.00223 
2023-12-06 04:51:14.932270: train_loss 1.0266 
2023-12-06 04:51:14.932539: val_loss 1.1471 
2023-12-06 04:51:14.932636: Pseudo dice [0.8649] 
2023-12-06 04:51:14.932729: Epoch time: 51.99 s 
2023-12-06 04:51:16.620596:  
2023-12-06 04:51:16.620754: Epoch 812 
2023-12-06 04:51:16.620864: Current learning rate: 0.00222 
2023-12-06 04:52:08.551298: train_loss 1.0268 
2023-12-06 04:52:08.551527: val_loss 1.1467 
2023-12-06 04:52:08.551594: Pseudo dice [0.8647] 
2023-12-06 04:52:08.551659: Epoch time: 51.93 s 
2023-12-06 04:52:10.067000:  
2023-12-06 04:52:10.067480: Epoch 813 
2023-12-06 04:52:10.067647: Current learning rate: 0.00221 
2023-12-06 04:53:01.932887: train_loss 1.0263 
2023-12-06 04:53:01.933157: val_loss 1.1467 
2023-12-06 04:53:01.933240: Pseudo dice [0.8652] 
2023-12-06 04:53:01.933322: Epoch time: 51.87 s 
2023-12-06 04:53:03.623067:  
2023-12-06 04:53:03.623285: Epoch 814 
2023-12-06 04:53:03.623415: Current learning rate: 0.0022 
2023-12-06 04:53:55.565160: train_loss 1.0265 
2023-12-06 04:53:55.565411: val_loss 1.1522 
2023-12-06 04:53:55.565474: Pseudo dice [0.8611] 
2023-12-06 04:53:55.565542: Epoch time: 51.94 s 
2023-12-06 04:53:56.820968:  
2023-12-06 04:53:56.821394: Epoch 815 
2023-12-06 04:53:56.821486: Current learning rate: 0.00219 
2023-12-06 04:54:48.684844: train_loss 1.0268 
2023-12-06 04:54:48.685131: val_loss 1.1557 
2023-12-06 04:54:48.685227: Pseudo dice [0.8589] 
2023-12-06 04:54:48.685313: Epoch time: 51.87 s 
2023-12-06 04:54:50.271730:  
2023-12-06 04:54:50.271865: Epoch 816 
2023-12-06 04:54:50.271954: Current learning rate: 0.00218 
2023-12-06 04:55:42.190448: train_loss 1.0257 
2023-12-06 04:55:42.190727: val_loss 1.1518 
2023-12-06 04:55:42.190813: Pseudo dice [0.8624] 
2023-12-06 04:55:42.190895: Epoch time: 51.92 s 
2023-12-06 04:55:43.887341:  
2023-12-06 04:55:43.887510: Epoch 817 
2023-12-06 04:55:43.887735: Current learning rate: 0.00217 
2023-12-06 04:56:35.868120: train_loss 1.0259 
2023-12-06 04:56:35.868385: val_loss 1.1483 
2023-12-06 04:56:35.868466: Pseudo dice [0.8651] 
2023-12-06 04:56:35.868548: Epoch time: 51.98 s 
2023-12-06 04:56:37.485722:  
2023-12-06 04:56:37.485864: Epoch 818 
2023-12-06 04:56:37.485961: Current learning rate: 0.00216 
2023-12-06 04:57:29.360629: train_loss 1.0261 
2023-12-06 04:57:29.360900: val_loss 1.1443 
2023-12-06 04:57:29.360983: Pseudo dice [0.8674] 
2023-12-06 04:57:29.361063: Epoch time: 51.88 s 
2023-12-06 04:57:31.256682:  
2023-12-06 04:57:31.256964: Epoch 819 
2023-12-06 04:57:31.257067: Current learning rate: 0.00215 
2023-12-06 04:58:22.987314: train_loss 1.0268 
2023-12-06 04:58:22.987649: val_loss 1.1522 
2023-12-06 04:58:22.987776: Pseudo dice [0.8605] 
2023-12-06 04:58:22.987850: Epoch time: 51.73 s 
2023-12-06 04:58:24.477820:  
2023-12-06 04:58:24.478382: Epoch 820 
2023-12-06 04:58:24.478486: Current learning rate: 0.00214 
2023-12-06 04:59:16.530982: train_loss 1.0263 
2023-12-06 04:59:16.531270: val_loss 1.1484 
2023-12-06 04:59:16.531353: Pseudo dice [0.8635] 
2023-12-06 04:59:16.531433: Epoch time: 52.05 s 
2023-12-06 04:59:18.158644:  
2023-12-06 04:59:18.158806: Epoch 821 
2023-12-06 04:59:18.158918: Current learning rate: 0.00213 
2023-12-06 05:00:10.119992: train_loss 1.0262 
2023-12-06 05:00:10.120279: val_loss 1.1459 
2023-12-06 05:00:10.120360: Pseudo dice [0.8652] 
2023-12-06 05:00:10.120440: Epoch time: 51.96 s 
2023-12-06 05:00:11.754692:  
2023-12-06 05:00:11.754847: Epoch 822 
2023-12-06 05:00:11.754954: Current learning rate: 0.00212 
2023-12-06 05:01:03.654458: train_loss 1.0258 
2023-12-06 05:01:03.654739: val_loss 1.1525 
2023-12-06 05:01:03.654833: Pseudo dice [0.8595] 
2023-12-06 05:01:03.654920: Epoch time: 51.9 s 
2023-12-06 05:01:05.270226:  
2023-12-06 05:01:05.270395: Epoch 823 
2023-12-06 05:01:05.270499: Current learning rate: 0.0021 
2023-12-06 05:01:57.147621: train_loss 1.0259 
2023-12-06 05:01:57.147897: val_loss 1.1459 
2023-12-06 05:01:57.147994: Pseudo dice [0.8661] 
2023-12-06 05:01:57.148087: Epoch time: 51.88 s 
2023-12-06 05:01:58.562977:  
2023-12-06 05:01:58.563122: Epoch 824 
2023-12-06 05:01:58.563212: Current learning rate: 0.00209 
2023-12-06 05:02:50.561661: train_loss 1.026 
2023-12-06 05:02:50.561932: val_loss 1.1433 
2023-12-06 05:02:50.562030: Pseudo dice [0.8691] 
2023-12-06 05:02:50.562114: Epoch time: 52.0 s 
2023-12-06 05:02:52.316812:  
2023-12-06 05:02:52.316935: Epoch 825 
2023-12-06 05:02:52.317034: Current learning rate: 0.00208 
2023-12-06 05:03:44.364733: train_loss 1.0256 
2023-12-06 05:03:44.364961: val_loss 1.1551 
2023-12-06 05:03:44.365026: Pseudo dice [0.858] 
2023-12-06 05:03:44.365093: Epoch time: 52.05 s 
2023-12-06 05:03:45.573515:  
2023-12-06 05:03:45.573651: Epoch 826 
2023-12-06 05:03:45.573740: Current learning rate: 0.00207 
2023-12-06 05:04:37.401293: train_loss 1.0256 
2023-12-06 05:04:37.401566: val_loss 1.1436 
2023-12-06 05:04:37.401651: Pseudo dice [0.867] 
2023-12-06 05:04:37.401737: Epoch time: 51.83 s 
2023-12-06 05:04:38.950980:  
2023-12-06 05:04:38.951157: Epoch 827 
2023-12-06 05:04:38.951275: Current learning rate: 0.00206 
2023-12-06 05:05:30.930624: train_loss 1.0257 
2023-12-06 05:05:30.930897: val_loss 1.1447 
2023-12-06 05:05:30.930983: Pseudo dice [0.8684] 
2023-12-06 05:05:30.931100: Epoch time: 51.98 s 
2023-12-06 05:05:32.560176:  
2023-12-06 05:05:32.560368: Epoch 828 
2023-12-06 05:05:32.560472: Current learning rate: 0.00205 
2023-12-06 05:06:24.562868: train_loss 1.026 
2023-12-06 05:06:24.563120: val_loss 1.1405 
2023-12-06 05:06:24.563190: Pseudo dice [0.8711] 
2023-12-06 05:06:24.563256: Epoch time: 52.0 s 
2023-12-06 05:06:25.819896:  
2023-12-06 05:06:25.820050: Epoch 829 
2023-12-06 05:06:25.820145: Current learning rate: 0.00204 
2023-12-06 05:07:17.664287: train_loss 1.0255 
2023-12-06 05:07:17.664559: val_loss 1.1428 
2023-12-06 05:07:17.664642: Pseudo dice [0.8689] 
2023-12-06 05:07:17.664726: Epoch time: 51.85 s 
2023-12-06 05:07:19.282423:  
2023-12-06 05:07:19.282580: Epoch 830 
2023-12-06 05:07:19.282687: Current learning rate: 0.00203 
2023-12-06 05:08:11.213855: train_loss 1.0258 
2023-12-06 05:08:11.214113: val_loss 1.1461 
2023-12-06 05:08:11.214196: Pseudo dice [0.865] 
2023-12-06 05:08:11.214277: Epoch time: 51.93 s 
2023-12-06 05:08:12.720619:  
2023-12-06 05:08:12.720757: Epoch 831 
2023-12-06 05:08:12.720851: Current learning rate: 0.00202 
2023-12-06 05:09:04.553285: train_loss 1.0253 
2023-12-06 05:09:04.553555: val_loss 1.152 
2023-12-06 05:09:04.553635: Pseudo dice [0.8623] 
2023-12-06 05:09:04.553714: Epoch time: 51.83 s 
2023-12-06 05:09:06.162711:  
2023-12-06 05:09:06.162893: Epoch 832 
2023-12-06 05:09:06.163001: Current learning rate: 0.00201 
2023-12-06 05:09:58.113087: train_loss 1.0258 
2023-12-06 05:09:58.113357: val_loss 1.1486 
2023-12-06 05:09:58.113440: Pseudo dice [0.8642] 
2023-12-06 05:09:58.113522: Epoch time: 51.95 s 
2023-12-06 05:09:59.556938:  
2023-12-06 05:09:59.557085: Epoch 833 
2023-12-06 05:09:59.557179: Current learning rate: 0.002 
2023-12-06 05:10:51.568975: train_loss 1.0259 
2023-12-06 05:10:51.569254: val_loss 1.1539 
2023-12-06 05:10:51.569337: Pseudo dice [0.859] 
2023-12-06 05:10:51.569418: Epoch time: 52.01 s 
2023-12-06 05:10:53.184787:  
2023-12-06 05:10:53.184959: Epoch 834 
2023-12-06 05:10:53.185069: Current learning rate: 0.00199 
2023-12-06 05:11:45.070506: train_loss 1.0256 
2023-12-06 05:11:45.070772: val_loss 1.1482 
2023-12-06 05:11:45.070854: Pseudo dice [0.8641] 
2023-12-06 05:11:45.070936: Epoch time: 51.89 s 
2023-12-06 05:11:46.514722:  
2023-12-06 05:11:46.514878: Epoch 835 
2023-12-06 05:11:46.514980: Current learning rate: 0.00198 
2023-12-06 05:12:38.311834: train_loss 1.0252 
2023-12-06 05:12:38.312083: val_loss 1.1475 
2023-12-06 05:12:38.312154: Pseudo dice [0.8647] 
2023-12-06 05:12:38.312224: Epoch time: 51.8 s 
2023-12-06 05:12:39.537687:  
2023-12-06 05:12:39.537945: Epoch 836 
2023-12-06 05:12:39.538034: Current learning rate: 0.00196 
2023-12-06 05:13:31.585060: train_loss 1.0254 
2023-12-06 05:13:31.585327: val_loss 1.1451 
2023-12-06 05:13:31.585407: Pseudo dice [0.868] 
2023-12-06 05:13:31.585488: Epoch time: 52.05 s 
2023-12-06 05:13:33.195179:  
2023-12-06 05:13:33.195355: Epoch 837 
2023-12-06 05:13:33.195474: Current learning rate: 0.00195 
2023-12-06 05:14:25.029871: train_loss 1.0256 
2023-12-06 05:14:25.030141: val_loss 1.1447 
2023-12-06 05:14:25.030220: Pseudo dice [0.8678] 
2023-12-06 05:14:25.030421: Epoch time: 51.84 s 
2023-12-06 05:14:26.520262:  
2023-12-06 05:14:26.520564: Epoch 838 
2023-12-06 05:14:26.520672: Current learning rate: 0.00194 
2023-12-06 05:15:18.482984: train_loss 1.0255 
2023-12-06 05:15:18.483255: val_loss 1.1518 
2023-12-06 05:15:18.483336: Pseudo dice [0.8624] 
2023-12-06 05:15:18.483416: Epoch time: 51.96 s 
2023-12-06 05:15:20.035890:  
2023-12-06 05:15:20.036352: Epoch 839 
2023-12-06 05:15:20.036458: Current learning rate: 0.00193 
2023-12-06 05:16:11.960472: train_loss 1.0254 
2023-12-06 05:16:11.960742: val_loss 1.1448 
2023-12-06 05:16:11.960822: Pseudo dice [0.8664] 
2023-12-06 05:16:11.960902: Epoch time: 51.93 s 
2023-12-06 05:16:13.399571:  
2023-12-06 05:16:13.399714: Epoch 840 
2023-12-06 05:16:13.399811: Current learning rate: 0.00192 
2023-12-06 05:17:05.397115: train_loss 1.0257 
2023-12-06 05:17:05.397381: val_loss 1.1431 
2023-12-06 05:17:05.397463: Pseudo dice [0.8689] 
2023-12-06 05:17:05.397544: Epoch time: 52.0 s 
2023-12-06 05:17:06.812914:  
2023-12-06 05:17:06.813086: Epoch 841 
2023-12-06 05:17:06.813257: Current learning rate: 0.00191 
2023-12-06 05:17:58.646958: train_loss 1.0248 
2023-12-06 05:17:58.647238: val_loss 1.1482 
2023-12-06 05:17:58.647321: Pseudo dice [0.8638] 
2023-12-06 05:17:58.647403: Epoch time: 51.84 s 
2023-12-06 05:18:00.273952:  
2023-12-06 05:18:00.274115: Epoch 842 
2023-12-06 05:18:00.274229: Current learning rate: 0.0019 
2023-12-06 05:18:52.202904: train_loss 1.0249 
2023-12-06 05:18:52.203151: val_loss 1.1451 
2023-12-06 05:18:52.203223: Pseudo dice [0.8668] 
2023-12-06 05:18:52.203291: Epoch time: 51.93 s 
2023-12-06 05:18:53.384393:  
2023-12-06 05:18:53.384654: Epoch 843 
2023-12-06 05:18:53.384751: Current learning rate: 0.00189 
2023-12-06 05:19:45.425317: train_loss 1.0248 
2023-12-06 05:19:45.425581: val_loss 1.1406 
2023-12-06 05:19:45.425660: Pseudo dice [0.8703] 
2023-12-06 05:19:45.425738: Epoch time: 52.04 s 
2023-12-06 05:19:46.968606:  
2023-12-06 05:19:46.969023: Epoch 844 
2023-12-06 05:19:46.969123: Current learning rate: 0.00188 
2023-12-06 05:20:39.002588: train_loss 1.0256 
2023-12-06 05:20:39.002861: val_loss 1.1502 
2023-12-06 05:20:39.002950: Pseudo dice [0.8623] 
2023-12-06 05:20:39.003058: Epoch time: 52.04 s 
2023-12-06 05:20:40.640469:  
2023-12-06 05:20:40.640675: Epoch 845 
2023-12-06 05:20:40.640785: Current learning rate: 0.00187 
2023-12-06 05:21:32.138710: train_loss 1.025 
2023-12-06 05:21:32.138972: val_loss 1.1489 
2023-12-06 05:21:32.139071: Pseudo dice [0.8641] 
2023-12-06 05:21:32.139153: Epoch time: 51.5 s 
2023-12-06 05:21:33.474339:  
2023-12-06 05:21:33.474698: Epoch 846 
2023-12-06 05:21:33.474790: Current learning rate: 0.00186 
2023-12-06 05:22:25.386599: train_loss 1.0264 
2023-12-06 05:22:25.386876: val_loss 1.1471 
2023-12-06 05:22:25.386961: Pseudo dice [0.8665] 
2023-12-06 05:22:25.387070: Epoch time: 51.91 s 
2023-12-06 05:22:27.012102:  
2023-12-06 05:22:27.012396: Epoch 847 
2023-12-06 05:22:27.012508: Current learning rate: 0.00185 
2023-12-06 05:23:19.052455: train_loss 1.0253 
2023-12-06 05:23:19.052733: val_loss 1.1484 
2023-12-06 05:23:19.052816: Pseudo dice [0.8652] 
2023-12-06 05:23:19.052897: Epoch time: 52.04 s 
2023-12-06 05:23:20.667883:  
2023-12-06 05:23:20.668065: Epoch 848 
2023-12-06 05:23:20.668191: Current learning rate: 0.00184 
2023-12-06 05:24:12.789736: train_loss 1.0259 
2023-12-06 05:24:12.790000: val_loss 1.1514 
2023-12-06 05:24:12.790084: Pseudo dice [0.8611] 
2023-12-06 05:24:12.790168: Epoch time: 52.12 s 
2023-12-06 05:24:14.419646:  
2023-12-06 05:24:14.419802: Epoch 849 
2023-12-06 05:24:14.419908: Current learning rate: 0.00182 
2023-12-06 05:25:06.504036: train_loss 1.0252 
2023-12-06 05:25:06.504312: val_loss 1.1562 
2023-12-06 05:25:06.504394: Pseudo dice [0.8577] 
2023-12-06 05:25:06.504480: Epoch time: 52.09 s 
2023-12-06 05:25:09.482516:  
2023-12-06 05:25:09.482656: Epoch 850 
2023-12-06 05:25:09.482743: Current learning rate: 0.00181 
2023-12-06 05:26:01.157343: train_loss 1.0248 
2023-12-06 05:26:01.157615: val_loss 1.1538 
2023-12-06 05:26:01.157696: Pseudo dice [0.8599] 
2023-12-06 05:26:01.157779: Epoch time: 51.68 s 
2023-12-06 05:26:02.707848:  
2023-12-06 05:26:02.708391: Epoch 851 
2023-12-06 05:26:02.708486: Current learning rate: 0.0018 
2023-12-06 05:26:54.745202: train_loss 1.0251 
2023-12-06 05:26:54.745432: val_loss 1.1419 
2023-12-06 05:26:54.745497: Pseudo dice [0.8685] 
2023-12-06 05:26:54.745564: Epoch time: 52.04 s 
2023-12-06 05:26:55.951559:  
2023-12-06 05:26:55.951946: Epoch 852 
2023-12-06 05:26:55.952037: Current learning rate: 0.00179 
2023-12-06 05:27:47.814233: train_loss 1.0259 
2023-12-06 05:27:47.814470: val_loss 1.1619 
2023-12-06 05:27:47.814538: Pseudo dice [0.8542] 
2023-12-06 05:27:47.814619: Epoch time: 51.86 s 
2023-12-06 05:27:49.395321:  
2023-12-06 05:27:49.395486: Epoch 853 
2023-12-06 05:27:49.395601: Current learning rate: 0.00178 
2023-12-06 05:28:41.464551: train_loss 1.0252 
2023-12-06 05:28:41.464830: val_loss 1.1477 
2023-12-06 05:28:41.464920: Pseudo dice [0.8635] 
2023-12-06 05:28:41.465006: Epoch time: 52.07 s 
2023-12-06 05:28:43.089944:  
2023-12-06 05:28:43.090241: Epoch 854 
2023-12-06 05:28:43.090387: Current learning rate: 0.00177 
2023-12-06 05:29:35.023418: train_loss 1.0248 
2023-12-06 05:29:35.023659: val_loss 1.1493 
2023-12-06 05:29:35.023726: Pseudo dice [0.8619] 
2023-12-06 05:29:35.023793: Epoch time: 51.94 s 
2023-12-06 05:29:36.621540:  
2023-12-06 05:29:36.621701: Epoch 855 
2023-12-06 05:29:36.621810: Current learning rate: 0.00176 
2023-12-06 05:30:28.442229: train_loss 1.0247 
2023-12-06 05:30:28.442496: val_loss 1.1536 
2023-12-06 05:30:28.442577: Pseudo dice [0.8593] 
2023-12-06 05:30:28.442662: Epoch time: 51.82 s 
2023-12-06 05:30:30.262552:  
2023-12-06 05:30:30.262723: Epoch 856 
2023-12-06 05:30:30.262838: Current learning rate: 0.00175 
2023-12-06 05:31:22.370801: train_loss 1.025 
2023-12-06 05:31:22.371089: val_loss 1.1532 
2023-12-06 05:31:22.371175: Pseudo dice [0.861] 
2023-12-06 05:31:22.371254: Epoch time: 52.11 s 
2023-12-06 05:31:24.008970:  
2023-12-06 05:31:24.009380: Epoch 857 
2023-12-06 05:31:24.009501: Current learning rate: 0.00174 
2023-12-06 05:32:16.038862: train_loss 1.025 
2023-12-06 05:32:16.039165: val_loss 1.1487 
2023-12-06 05:32:16.039255: Pseudo dice [0.8617] 
2023-12-06 05:32:16.039339: Epoch time: 52.03 s 
2023-12-06 05:32:17.371083:  
2023-12-06 05:32:17.371497: Epoch 858 
2023-12-06 05:32:17.371589: Current learning rate: 0.00173 
2023-12-06 05:33:09.202163: train_loss 1.0243 
2023-12-06 05:33:09.202441: val_loss 1.151 
2023-12-06 05:33:09.202527: Pseudo dice [0.8608] 
2023-12-06 05:33:09.202607: Epoch time: 51.83 s 
2023-12-06 05:33:10.489996:  
2023-12-06 05:33:10.490139: Epoch 859 
2023-12-06 05:33:10.490240: Current learning rate: 0.00172 
2023-12-06 05:34:02.541552: train_loss 1.0245 
2023-12-06 05:34:02.541830: val_loss 1.1443 
2023-12-06 05:34:02.542019: Pseudo dice [0.8657] 
2023-12-06 05:34:02.542112: Epoch time: 52.05 s 
2023-12-06 05:34:04.180622:  
2023-12-06 05:34:04.180778: Epoch 860 
2023-12-06 05:34:04.180894: Current learning rate: 0.0017 
2023-12-06 05:34:56.188290: train_loss 1.0247 
2023-12-06 05:34:56.188555: val_loss 1.153 
2023-12-06 05:34:56.188638: Pseudo dice [0.8594] 
2023-12-06 05:34:56.188721: Epoch time: 52.01 s 
2023-12-06 05:34:57.803707:  
2023-12-06 05:34:57.803884: Epoch 861 
2023-12-06 05:34:57.804115: Current learning rate: 0.00169 
2023-12-06 05:35:49.767821: train_loss 1.0247 
2023-12-06 05:35:49.768249: val_loss 1.1523 
2023-12-06 05:35:49.768394: Pseudo dice [0.8596] 
2023-12-06 05:35:49.768537: Epoch time: 51.97 s 
2023-12-06 05:35:51.627733:  
2023-12-06 05:35:51.627997: Epoch 862 
2023-12-06 05:35:51.628176: Current learning rate: 0.00168 
2023-12-06 05:36:43.527116: train_loss 1.0246 
2023-12-06 05:36:43.527385: val_loss 1.1443 
2023-12-06 05:36:43.527473: Pseudo dice [0.8664] 
2023-12-06 05:36:43.527553: Epoch time: 51.9 s 
2023-12-06 05:36:45.156921:  
2023-12-06 05:36:45.157284: Epoch 863 
2023-12-06 05:36:45.157400: Current learning rate: 0.00167 
2023-12-06 05:37:37.255200: train_loss 1.0238 
2023-12-06 05:37:37.255470: val_loss 1.1491 
2023-12-06 05:37:37.255553: Pseudo dice [0.8633] 
2023-12-06 05:37:37.255636: Epoch time: 52.1 s 
2023-12-06 05:37:38.844670:  
2023-12-06 05:37:38.845006: Epoch 864 
2023-12-06 05:37:38.845122: Current learning rate: 0.00166 
2023-12-06 05:38:30.666555: train_loss 1.0242 
2023-12-06 05:38:30.666830: val_loss 1.1482 
2023-12-06 05:38:30.666923: Pseudo dice [0.8639] 
2023-12-06 05:38:30.667024: Epoch time: 51.82 s 
2023-12-06 05:38:32.271744:  
2023-12-06 05:38:32.271916: Epoch 865 
2023-12-06 05:38:32.272021: Current learning rate: 0.00165 
2023-12-06 05:39:24.116210: train_loss 1.0246 
2023-12-06 05:39:24.116465: val_loss 1.1467 
2023-12-06 05:39:24.116561: Pseudo dice [0.8664] 
2023-12-06 05:39:24.116638: Epoch time: 51.85 s 
2023-12-06 05:39:25.629043:  
2023-12-06 05:39:25.629242: Epoch 866 
2023-12-06 05:39:25.629360: Current learning rate: 0.00164 
2023-12-06 05:40:17.569517: train_loss 1.0243 
2023-12-06 05:40:17.569849: val_loss 1.1474 
2023-12-06 05:40:17.569980: Pseudo dice [0.865] 
2023-12-06 05:40:17.570114: Epoch time: 51.94 s 
2023-12-06 05:40:19.179003:  
2023-12-06 05:40:19.179171: Epoch 867 
2023-12-06 05:40:19.179285: Current learning rate: 0.00163 
2023-12-06 05:41:10.849988: train_loss 1.0245 
2023-12-06 05:41:10.850483: val_loss 1.1368 
2023-12-06 05:41:10.850558: Pseudo dice [0.8738] 
2023-12-06 05:41:10.850644: Epoch time: 51.67 s 
2023-12-06 05:41:12.309777:  
2023-12-06 05:41:12.310592: Epoch 868 
2023-12-06 05:41:12.310750: Current learning rate: 0.00162 
2023-12-06 05:42:04.332728: train_loss 1.0241 
2023-12-06 05:42:04.333006: val_loss 1.1469 
2023-12-06 05:42:04.333097: Pseudo dice [0.8652] 
2023-12-06 05:42:04.333180: Epoch time: 52.02 s 
2023-12-06 05:42:05.958744:  
2023-12-06 05:42:05.958909: Epoch 869 
2023-12-06 05:42:05.959038: Current learning rate: 0.00161 
2023-12-06 05:42:57.916862: train_loss 1.0242 
2023-12-06 05:42:57.917468: val_loss 1.1422 
2023-12-06 05:42:57.917568: Pseudo dice [0.869] 
2023-12-06 05:42:57.917676: Epoch time: 51.96 s 
2023-12-06 05:42:59.177850:  
2023-12-06 05:42:59.177992: Epoch 870 
2023-12-06 05:42:59.178082: Current learning rate: 0.00159 
2023-12-06 05:43:51.081418: train_loss 1.0244 
2023-12-06 05:43:51.081764: val_loss 1.1389 
2023-12-06 05:43:51.081863: Pseudo dice [0.8721] 
2023-12-06 05:43:51.081963: Epoch time: 51.91 s 
2023-12-06 05:43:52.762550:  
2023-12-06 05:43:52.763309: Epoch 871 
2023-12-06 05:43:52.763594: Current learning rate: 0.00158 
2023-12-06 05:44:44.802899: train_loss 1.0237 
2023-12-06 05:44:44.803218: val_loss 1.1513 
2023-12-06 05:44:44.803305: Pseudo dice [0.8618] 
2023-12-06 05:44:44.803397: Epoch time: 52.04 s 
2023-12-06 05:44:46.069338:  
2023-12-06 05:44:46.069488: Epoch 872 
2023-12-06 05:44:46.069581: Current learning rate: 0.00157 
2023-12-06 05:45:37.726955: train_loss 1.0237 
2023-12-06 05:45:37.727469: val_loss 1.1478 
2023-12-06 05:45:37.727547: Pseudo dice [0.8653] 
2023-12-06 05:45:37.727634: Epoch time: 51.66 s 
2023-12-06 05:45:38.942914:  
2023-12-06 05:45:38.943224: Epoch 873 
2023-12-06 05:45:38.943337: Current learning rate: 0.00156 
2023-12-06 05:46:30.493047: train_loss 1.0241 
2023-12-06 05:46:30.493334: val_loss 1.1458 
2023-12-06 05:46:30.493433: Pseudo dice [0.866] 
2023-12-06 05:46:30.493518: Epoch time: 51.55 s 
2023-12-06 05:46:32.107595:  
2023-12-06 05:46:32.107832: Epoch 874 
2023-12-06 05:46:32.107990: Current learning rate: 0.00155 
2023-12-06 05:47:23.757496: train_loss 1.0238 
2023-12-06 05:47:23.758003: val_loss 1.1463 
2023-12-06 05:47:23.758075: Pseudo dice [0.8669] 
2023-12-06 05:47:23.758158: Epoch time: 51.65 s 
2023-12-06 05:47:25.002216:  
2023-12-06 05:47:25.002389: Epoch 875 
2023-12-06 05:47:25.002533: Current learning rate: 0.00154 
2023-12-06 05:48:16.810187: train_loss 1.024 
2023-12-06 05:48:16.810544: val_loss 1.1442 
2023-12-06 05:48:16.810631: Pseudo dice [0.8679] 
2023-12-06 05:48:16.810732: Epoch time: 51.81 s 
2023-12-06 05:48:18.427959:  
2023-12-06 05:48:18.428109: Epoch 876 
2023-12-06 05:48:18.428218: Current learning rate: 0.00153 
2023-12-06 05:49:10.446759: train_loss 1.024 
2023-12-06 05:49:10.447040: val_loss 1.1474 
2023-12-06 05:49:10.447127: Pseudo dice [0.8658] 
2023-12-06 05:49:10.447208: Epoch time: 52.02 s 
2023-12-06 05:49:12.058391:  
2023-12-06 05:49:12.058563: Epoch 877 
2023-12-06 05:49:12.058667: Current learning rate: 0.00152 
2023-12-06 05:50:04.037522: train_loss 1.0235 
2023-12-06 05:50:04.037766: val_loss 1.1495 
2023-12-06 05:50:04.037844: Pseudo dice [0.8623] 
2023-12-06 05:50:04.037918: Epoch time: 51.98 s 
2023-12-06 05:50:05.675207:  
2023-12-06 05:50:05.675488: Epoch 878 
2023-12-06 05:50:05.675679: Current learning rate: 0.00151 
2023-12-06 05:50:57.289497: train_loss 1.0233 
2023-12-06 05:50:57.289726: val_loss 1.1401 
2023-12-06 05:50:57.289787: Pseudo dice [0.8709] 
2023-12-06 05:50:57.289845: Epoch time: 51.62 s 
2023-12-06 05:50:58.472804:  
2023-12-06 05:50:58.472992: Epoch 879 
2023-12-06 05:50:58.473083: Current learning rate: 0.00149 
2023-12-06 05:51:50.339378: train_loss 1.0248 
2023-12-06 05:51:50.339648: val_loss 1.1511 
2023-12-06 05:51:50.339728: Pseudo dice [0.8624] 
2023-12-06 05:51:50.339807: Epoch time: 51.87 s 
2023-12-06 05:51:51.949547:  
2023-12-06 05:51:51.949710: Epoch 880 
2023-12-06 05:51:51.949821: Current learning rate: 0.00148 
2023-12-06 05:52:43.807379: train_loss 1.0237 
2023-12-06 05:52:43.807766: val_loss 1.1453 
2023-12-06 05:52:43.807845: Pseudo dice [0.8656] 
2023-12-06 05:52:43.807922: Epoch time: 51.86 s 
2023-12-06 05:52:45.158010:  
2023-12-06 05:52:45.158155: Epoch 881 
2023-12-06 05:52:45.158271: Current learning rate: 0.00147 
2023-12-06 05:53:37.031987: train_loss 1.0239 
2023-12-06 05:53:37.032273: val_loss 1.1373 
2023-12-06 05:53:37.032363: Pseudo dice [0.8729] 
2023-12-06 05:53:37.032456: Epoch time: 51.88 s 
2023-12-06 05:53:38.662084:  
2023-12-06 05:53:38.662479: Epoch 882 
2023-12-06 05:53:38.662735: Current learning rate: 0.00146 
2023-12-06 05:54:30.503823: train_loss 1.0237 
2023-12-06 05:54:30.504149: val_loss 1.1508 
2023-12-06 05:54:30.504221: Pseudo dice [0.8621] 
2023-12-06 05:54:30.504290: Epoch time: 51.84 s 
2023-12-06 05:54:32.012268:  
2023-12-06 05:54:32.012574: Epoch 883 
2023-12-06 05:54:32.012698: Current learning rate: 0.00145 
2023-12-06 05:55:23.907046: train_loss 1.0243 
2023-12-06 05:55:23.907328: val_loss 1.151 
2023-12-06 05:55:23.907410: Pseudo dice [0.8619] 
2023-12-06 05:55:23.907495: Epoch time: 51.9 s 
2023-12-06 05:55:25.521469:  
2023-12-06 05:55:25.521632: Epoch 884 
2023-12-06 05:55:25.521739: Current learning rate: 0.00144 
2023-12-06 05:56:17.441924: train_loss 1.0234 
2023-12-06 05:56:17.442193: val_loss 1.1525 
2023-12-06 05:56:17.442272: Pseudo dice [0.8613] 
2023-12-06 05:56:17.442352: Epoch time: 51.92 s 
2023-12-06 05:56:19.055522:  
2023-12-06 05:56:19.055692: Epoch 885 
2023-12-06 05:56:19.055799: Current learning rate: 0.00143 
2023-12-06 05:57:10.947937: train_loss 1.0239 
2023-12-06 05:57:10.948169: val_loss 1.1451 
2023-12-06 05:57:10.948238: Pseudo dice [0.867] 
2023-12-06 05:57:10.948304: Epoch time: 51.89 s 
2023-12-06 05:57:12.170820:  
2023-12-06 05:57:12.170960: Epoch 886 
2023-12-06 05:57:12.171060: Current learning rate: 0.00142 
2023-12-06 05:58:03.991650: train_loss 1.0243 
2023-12-06 05:58:03.991934: val_loss 1.141 
2023-12-06 05:58:03.992033: Pseudo dice [0.8697] 
2023-12-06 05:58:03.992123: Epoch time: 51.82 s 
2023-12-06 05:58:05.792958:  
2023-12-06 05:58:05.793125: Epoch 887 
2023-12-06 05:58:05.793238: Current learning rate: 0.00141 
2023-12-06 05:58:57.684004: train_loss 1.0241 
2023-12-06 05:58:57.684295: val_loss 1.1514 
2023-12-06 05:58:57.684382: Pseudo dice [0.8608] 
2023-12-06 05:58:57.684464: Epoch time: 51.89 s 
2023-12-06 05:58:59.287142:  
2023-12-06 05:58:59.287327: Epoch 888 
2023-12-06 05:58:59.287442: Current learning rate: 0.00139 
2023-12-06 05:59:51.008749: train_loss 1.0234 
2023-12-06 05:59:51.009013: val_loss 1.1433 
2023-12-06 05:59:51.009101: Pseudo dice [0.8672] 
2023-12-06 05:59:51.009185: Epoch time: 51.72 s 
2023-12-06 05:59:52.618166:  
2023-12-06 05:59:52.618615: Epoch 889 
2023-12-06 05:59:52.618715: Current learning rate: 0.00138 
2023-12-06 06:00:44.235107: train_loss 1.024 
2023-12-06 06:00:44.235336: val_loss 1.1505 
2023-12-06 06:00:44.235402: Pseudo dice [0.8633] 
2023-12-06 06:00:44.235467: Epoch time: 51.62 s 
2023-12-06 06:00:45.469278:  
2023-12-06 06:00:45.469470: Epoch 890 
2023-12-06 06:00:45.469614: Current learning rate: 0.00137 
2023-12-06 06:01:37.179672: train_loss 1.0233 
2023-12-06 06:01:37.179898: val_loss 1.148 
2023-12-06 06:01:37.179963: Pseudo dice [0.8645] 
2023-12-06 06:01:37.180028: Epoch time: 51.71 s 
2023-12-06 06:01:38.785646:  
2023-12-06 06:01:38.785796: Epoch 891 
2023-12-06 06:01:38.785906: Current learning rate: 0.00136 
2023-12-06 06:02:30.529179: train_loss 1.0234 
2023-12-06 06:02:30.529424: val_loss 1.1411 
2023-12-06 06:02:30.529492: Pseudo dice [0.8704] 
2023-12-06 06:02:30.529558: Epoch time: 51.75 s 
2023-12-06 06:02:32.126208:  
2023-12-06 06:02:32.126709: Epoch 892 
2023-12-06 06:02:32.126834: Current learning rate: 0.00135 
2023-12-06 06:03:24.088301: train_loss 1.0238 
2023-12-06 06:03:24.088578: val_loss 1.1485 
2023-12-06 06:03:24.088656: Pseudo dice [0.8644] 
2023-12-06 06:03:24.088736: Epoch time: 51.96 s 
2023-12-06 06:03:25.893373:  
2023-12-06 06:03:25.893667: Epoch 893 
2023-12-06 06:03:25.893786: Current learning rate: 0.00134 
2023-12-06 06:04:17.644814: train_loss 1.0239 
2023-12-06 06:04:17.645043: val_loss 1.1473 
2023-12-06 06:04:17.645109: Pseudo dice [0.864] 
2023-12-06 06:04:17.645174: Epoch time: 51.75 s 
2023-12-06 06:04:18.870038:  
2023-12-06 06:04:18.870188: Epoch 894 
2023-12-06 06:04:18.870278: Current learning rate: 0.00133 
2023-12-06 06:05:10.798355: train_loss 1.023 
2023-12-06 06:05:10.798627: val_loss 1.1464 
2023-12-06 06:05:10.798712: Pseudo dice [0.8659] 
2023-12-06 06:05:10.798796: Epoch time: 51.93 s 
2023-12-06 06:05:12.066263:  
2023-12-06 06:05:12.066418: Epoch 895 
2023-12-06 06:05:12.066511: Current learning rate: 0.00132 
2023-12-06 06:06:03.929986: train_loss 1.0232 
2023-12-06 06:06:03.930249: val_loss 1.1536 
2023-12-06 06:06:03.930336: Pseudo dice [0.859] 
2023-12-06 06:06:03.930417: Epoch time: 51.87 s 
2023-12-06 06:06:05.536574:  
2023-12-06 06:06:05.536739: Epoch 896 
2023-12-06 06:06:05.536859: Current learning rate: 0.0013 
2023-12-06 06:06:57.375049: train_loss 1.0237 
2023-12-06 06:06:57.375324: val_loss 1.1465 
2023-12-06 06:06:57.375407: Pseudo dice [0.8663] 
2023-12-06 06:06:57.375490: Epoch time: 51.84 s 
2023-12-06 06:06:58.767938:  
2023-12-06 06:06:58.768079: Epoch 897 
2023-12-06 06:06:58.768177: Current learning rate: 0.00129 
2023-12-06 06:07:50.597501: train_loss 1.0236 
2023-12-06 06:07:50.597766: val_loss 1.1487 
2023-12-06 06:07:50.597847: Pseudo dice [0.8652] 
2023-12-06 06:07:50.597929: Epoch time: 51.83 s 
2023-12-06 06:07:52.206702:  
2023-12-06 06:07:52.206854: Epoch 898 
2023-12-06 06:07:52.206963: Current learning rate: 0.00128 
2023-12-06 06:08:44.162997: train_loss 1.0235 
2023-12-06 06:08:44.163285: val_loss 1.1501 
2023-12-06 06:08:44.163378: Pseudo dice [0.8644] 
2023-12-06 06:08:44.163472: Epoch time: 51.96 s 
2023-12-06 06:08:45.778380:  
2023-12-06 06:08:45.778534: Epoch 899 
2023-12-06 06:08:45.778648: Current learning rate: 0.00127 
2023-12-06 06:09:37.765862: train_loss 1.0228 
2023-12-06 06:09:37.766130: val_loss 1.1473 
2023-12-06 06:09:37.766231: Pseudo dice [0.8658] 
2023-12-06 06:09:37.766322: Epoch time: 51.99 s 
2023-12-06 06:09:40.936937:  
2023-12-06 06:09:40.937087: Epoch 900 
2023-12-06 06:09:40.937182: Current learning rate: 0.00126 
2023-12-06 06:10:32.496002: train_loss 1.0234 
2023-12-06 06:10:32.496221: val_loss 1.1483 
2023-12-06 06:10:32.496289: Pseudo dice [0.8644] 
2023-12-06 06:10:32.496354: Epoch time: 51.56 s 
2023-12-06 06:10:33.702646:  
2023-12-06 06:10:33.702779: Epoch 901 
2023-12-06 06:10:33.702874: Current learning rate: 0.00125 
2023-12-06 06:11:25.647969: train_loss 1.0227 
2023-12-06 06:11:25.648204: val_loss 1.1453 
2023-12-06 06:11:25.648268: Pseudo dice [0.8667] 
2023-12-06 06:11:25.648333: Epoch time: 51.95 s 
2023-12-06 06:11:26.859536:  
2023-12-06 06:11:26.859681: Epoch 902 
2023-12-06 06:11:26.859772: Current learning rate: 0.00124 
2023-12-06 06:12:18.547257: train_loss 1.0232 
2023-12-06 06:12:18.547517: val_loss 1.1459 
2023-12-06 06:12:18.547599: Pseudo dice [0.8651] 
2023-12-06 06:12:18.547680: Epoch time: 51.69 s 
2023-12-06 06:12:19.822987:  
2023-12-06 06:12:19.823265: Epoch 903 
2023-12-06 06:12:19.823359: Current learning rate: 0.00122 
2023-12-06 06:13:11.581877: train_loss 1.023 
2023-12-06 06:13:11.582107: val_loss 1.152 
2023-12-06 06:13:11.582173: Pseudo dice [0.862] 
2023-12-06 06:13:11.582237: Epoch time: 51.76 s 
2023-12-06 06:13:12.905497:  
2023-12-06 06:13:12.905801: Epoch 904 
2023-12-06 06:13:12.905911: Current learning rate: 0.00121 
2023-12-06 06:14:04.458146: train_loss 1.0235 
2023-12-06 06:14:04.458373: val_loss 1.1479 
2023-12-06 06:14:04.458440: Pseudo dice [0.8663] 
2023-12-06 06:14:04.458507: Epoch time: 51.55 s 
2023-12-06 06:14:05.776933:  
2023-12-06 06:14:05.777062: Epoch 905 
2023-12-06 06:14:05.777163: Current learning rate: 0.0012 
2023-12-06 06:14:57.480306: train_loss 1.023 
2023-12-06 06:14:57.480528: val_loss 1.1499 
2023-12-06 06:14:57.480595: Pseudo dice [0.8636] 
2023-12-06 06:14:57.480665: Epoch time: 51.7 s 
2023-12-06 06:14:58.702158:  
2023-12-06 06:14:58.702351: Epoch 906 
2023-12-06 06:14:58.702442: Current learning rate: 0.00119 
2023-12-06 06:15:50.526875: train_loss 1.0232 
2023-12-06 06:15:50.527176: val_loss 1.1455 
2023-12-06 06:15:50.527263: Pseudo dice [0.8672] 
2023-12-06 06:15:50.527346: Epoch time: 51.83 s 
2023-12-06 06:15:52.017111:  
2023-12-06 06:15:52.017249: Epoch 907 
2023-12-06 06:15:52.017339: Current learning rate: 0.00118 
2023-12-06 06:16:43.737030: train_loss 1.023 
2023-12-06 06:16:43.737293: val_loss 1.1476 
2023-12-06 06:16:43.737374: Pseudo dice [0.864] 
2023-12-06 06:16:43.737454: Epoch time: 51.72 s 
2023-12-06 06:16:45.297673:  
2023-12-06 06:16:45.297814: Epoch 908 
2023-12-06 06:16:45.297897: Current learning rate: 0.00117 
2023-12-06 06:17:36.991585: train_loss 1.0227 
2023-12-06 06:17:36.991810: val_loss 1.1501 
2023-12-06 06:17:36.991875: Pseudo dice [0.8631] 
2023-12-06 06:17:36.991941: Epoch time: 51.7 s 
2023-12-06 06:17:38.197617:  
2023-12-06 06:17:38.197752: Epoch 909 
2023-12-06 06:17:38.197860: Current learning rate: 0.00116 
2023-12-06 06:18:29.935159: train_loss 1.0231 
2023-12-06 06:18:29.935430: val_loss 1.1481 
2023-12-06 06:18:29.935514: Pseudo dice [0.8647] 
2023-12-06 06:18:29.935598: Epoch time: 51.74 s 
2023-12-06 06:18:31.201232:  
2023-12-06 06:18:31.201372: Epoch 910 
2023-12-06 06:18:31.201470: Current learning rate: 0.00115 
2023-12-06 06:19:23.030419: train_loss 1.023 
2023-12-06 06:19:23.030682: val_loss 1.141 
2023-12-06 06:19:23.030763: Pseudo dice [0.8708] 
2023-12-06 06:19:23.030842: Epoch time: 51.83 s 
2023-12-06 06:19:24.660807:  
2023-12-06 06:19:24.661137: Epoch 911 
2023-12-06 06:19:24.661258: Current learning rate: 0.00113 
2023-12-06 06:20:16.622667: train_loss 1.0228 
2023-12-06 06:20:16.622937: val_loss 1.147 
2023-12-06 06:20:16.623026: Pseudo dice [0.8653] 
2023-12-06 06:20:16.623108: Epoch time: 51.96 s 
2023-12-06 06:20:18.511755:  
2023-12-06 06:20:18.511911: Epoch 912 
2023-12-06 06:20:18.512030: Current learning rate: 0.00112 
2023-12-06 06:21:10.505266: train_loss 1.0231 
2023-12-06 06:21:10.505656: val_loss 1.1451 
2023-12-06 06:21:10.505739: Pseudo dice [0.8672] 
2023-12-06 06:21:10.505820: Epoch time: 52.0 s 
2023-12-06 06:21:11.799485:  
2023-12-06 06:21:11.799634: Epoch 913 
2023-12-06 06:21:11.799726: Current learning rate: 0.00111 
2023-12-06 06:22:03.662117: train_loss 1.0227 
2023-12-06 06:22:03.662470: val_loss 1.1442 
2023-12-06 06:22:03.662561: Pseudo dice [0.8665] 
2023-12-06 06:22:03.662646: Epoch time: 51.86 s 
2023-12-06 06:22:05.293156:  
2023-12-06 06:22:05.293331: Epoch 914 
2023-12-06 06:22:05.293442: Current learning rate: 0.0011 
2023-12-06 06:22:57.254490: train_loss 1.0224 
2023-12-06 06:22:57.254758: val_loss 1.1478 
2023-12-06 06:22:57.254840: Pseudo dice [0.8647] 
2023-12-06 06:22:57.254920: Epoch time: 51.96 s 
2023-12-06 06:22:58.867139:  
2023-12-06 06:22:58.867320: Epoch 915 
2023-12-06 06:22:58.867425: Current learning rate: 0.00109 
2023-12-06 06:23:50.852807: train_loss 1.0231 
2023-12-06 06:23:50.853089: val_loss 1.1563 
2023-12-06 06:23:50.853170: Pseudo dice [0.8586] 
2023-12-06 06:23:50.853251: Epoch time: 51.99 s 
2023-12-06 06:23:52.416880:  
2023-12-06 06:23:52.417286: Epoch 916 
2023-12-06 06:23:52.417376: Current learning rate: 0.00108 
2023-12-06 06:24:44.203510: train_loss 1.023 
2023-12-06 06:24:44.203750: val_loss 1.1394 
2023-12-06 06:24:44.203819: Pseudo dice [0.8711] 
2023-12-06 06:24:44.203886: Epoch time: 51.79 s 
2023-12-06 06:24:45.720581:  
2023-12-06 06:24:45.720734: Epoch 917 
2023-12-06 06:24:45.720843: Current learning rate: 0.00106 
2023-12-06 06:25:37.647787: train_loss 1.0229 
2023-12-06 06:25:37.648022: val_loss 1.1492 
2023-12-06 06:25:37.648089: Pseudo dice [0.8631] 
2023-12-06 06:25:37.648156: Epoch time: 51.93 s 
2023-12-06 06:25:39.004194:  
2023-12-06 06:25:39.004400: Epoch 918 
2023-12-06 06:25:39.004516: Current learning rate: 0.00105 
2023-12-06 06:26:30.838051: train_loss 1.0227 
2023-12-06 06:26:30.838318: val_loss 1.1497 
2023-12-06 06:26:30.838398: Pseudo dice [0.8628] 
2023-12-06 06:26:30.838479: Epoch time: 51.84 s 
2023-12-06 06:26:32.458590:  
2023-12-06 06:26:32.458742: Epoch 919 
2023-12-06 06:26:32.458858: Current learning rate: 0.00104 
2023-12-06 06:27:24.429801: train_loss 1.0226 
2023-12-06 06:27:24.430033: val_loss 1.1451 
2023-12-06 06:27:24.430099: Pseudo dice [0.8666] 
2023-12-06 06:27:24.430165: Epoch time: 51.97 s 
2023-12-06 06:27:25.621001:  
2023-12-06 06:27:25.621148: Epoch 920 
2023-12-06 06:27:25.621240: Current learning rate: 0.00103 
2023-12-06 06:28:17.272593: train_loss 1.022 
2023-12-06 06:28:17.272829: val_loss 1.1472 
2023-12-06 06:28:17.272899: Pseudo dice [0.8662] 
2023-12-06 06:28:17.272965: Epoch time: 51.65 s 
2023-12-06 06:28:18.492675:  
2023-12-06 06:28:18.492967: Epoch 921 
2023-12-06 06:28:18.493057: Current learning rate: 0.00102 
2023-12-06 06:29:10.104245: train_loss 1.022 
2023-12-06 06:29:10.104642: val_loss 1.1543 
2023-12-06 06:29:10.104716: Pseudo dice [0.8607] 
2023-12-06 06:29:10.104790: Epoch time: 51.61 s 
2023-12-06 06:29:11.320872:  
2023-12-06 06:29:11.321066: Epoch 922 
2023-12-06 06:29:11.321152: Current learning rate: 0.00101 
2023-12-06 06:30:02.903552: train_loss 1.0223 
2023-12-06 06:30:02.904160: val_loss 1.1501 
2023-12-06 06:30:02.904265: Pseudo dice [0.864] 
2023-12-06 06:30:02.904378: Epoch time: 51.58 s 
2023-12-06 06:30:04.251873:  
2023-12-06 06:30:04.252108: Epoch 923 
2023-12-06 06:30:04.252199: Current learning rate: 0.001 
2023-12-06 06:30:55.674485: train_loss 1.0222 
2023-12-06 06:30:55.674691: val_loss 1.1429 
2023-12-06 06:30:55.674751: Pseudo dice [0.8687] 
2023-12-06 06:30:55.674811: Epoch time: 51.42 s 
2023-12-06 06:30:57.481995:  
2023-12-06 06:30:57.482348: Epoch 924 
2023-12-06 06:30:57.482528: Current learning rate: 0.00098 
2023-12-06 06:31:49.353144: train_loss 1.0221 
2023-12-06 06:31:49.353357: val_loss 1.1477 
2023-12-06 06:31:49.353421: Pseudo dice [0.8649] 
2023-12-06 06:31:49.353487: Epoch time: 51.87 s 
2023-12-06 06:31:50.598849:  
2023-12-06 06:31:50.598988: Epoch 925 
2023-12-06 06:31:50.599083: Current learning rate: 0.00097 
2023-12-06 06:32:42.178602: train_loss 1.0219 
2023-12-06 06:32:42.178830: val_loss 1.1472 
2023-12-06 06:32:42.178899: Pseudo dice [0.8649] 
2023-12-06 06:32:42.178966: Epoch time: 51.58 s 
2023-12-06 06:32:43.365626:  
2023-12-06 06:32:43.365754: Epoch 926 
2023-12-06 06:32:43.365835: Current learning rate: 0.00096 
2023-12-06 06:33:35.148716: train_loss 1.0222 
2023-12-06 06:33:35.149112: val_loss 1.1467 
2023-12-06 06:33:35.149197: Pseudo dice [0.865] 
2023-12-06 06:33:35.149283: Epoch time: 51.78 s 
2023-12-06 06:33:36.561139:  
2023-12-06 06:33:36.561380: Epoch 927 
2023-12-06 06:33:36.561462: Current learning rate: 0.00095 
2023-12-06 06:34:28.106802: train_loss 1.0218 
2023-12-06 06:34:28.107109: val_loss 1.1486 
2023-12-06 06:34:28.107198: Pseudo dice [0.8635] 
2023-12-06 06:34:28.107285: Epoch time: 51.55 s 
2023-12-06 06:34:29.511552:  
2023-12-06 06:34:29.511684: Epoch 928 
2023-12-06 06:34:29.511760: Current learning rate: 0.00094 
2023-12-06 06:35:20.853136: train_loss 1.0221 
2023-12-06 06:35:20.853371: val_loss 1.1444 
2023-12-06 06:35:20.853435: Pseudo dice [0.8662] 
2023-12-06 06:35:20.853503: Epoch time: 51.34 s 
2023-12-06 06:35:22.069221:  
2023-12-06 06:35:22.069369: Epoch 929 
2023-12-06 06:35:22.069457: Current learning rate: 0.00092 
2023-12-06 06:36:13.439984: train_loss 1.022 
2023-12-06 06:36:13.440216: val_loss 1.1449 
2023-12-06 06:36:13.440280: Pseudo dice [0.8663] 
2023-12-06 06:36:13.440363: Epoch time: 51.37 s 
2023-12-06 06:36:14.960993:  
2023-12-06 06:36:14.961142: Epoch 930 
2023-12-06 06:36:14.961235: Current learning rate: 0.00091 
2023-12-06 06:37:06.501140: train_loss 1.0218 
2023-12-06 06:37:06.501378: val_loss 1.1396 
2023-12-06 06:37:06.501452: Pseudo dice [0.8721] 
2023-12-06 06:37:06.501528: Epoch time: 51.54 s 
2023-12-06 06:37:07.882448:  
2023-12-06 06:37:07.882699: Epoch 931 
2023-12-06 06:37:07.882818: Current learning rate: 0.0009 
2023-12-06 06:37:59.789181: train_loss 1.022 
2023-12-06 06:37:59.789548: val_loss 1.145 
2023-12-06 06:37:59.789637: Pseudo dice [0.8654] 
2023-12-06 06:37:59.789721: Epoch time: 51.91 s 
2023-12-06 06:38:01.455705:  
2023-12-06 06:38:01.456071: Epoch 932 
2023-12-06 06:38:01.456272: Current learning rate: 0.00089 
2023-12-06 06:38:53.057465: train_loss 1.0218 
2023-12-06 06:38:53.058017: val_loss 1.1426 
2023-12-06 06:38:53.058109: Pseudo dice [0.8684] 
2023-12-06 06:38:53.058197: Epoch time: 51.61 s 
2023-12-06 06:38:54.321624:  
2023-12-06 06:38:54.322203: Epoch 933 
2023-12-06 06:38:54.322304: Current learning rate: 0.00088 
2023-12-06 06:39:45.809466: train_loss 1.0216 
2023-12-06 06:39:45.809970: val_loss 1.146 
2023-12-06 06:39:45.810060: Pseudo dice [0.8672] 
2023-12-06 06:39:45.810140: Epoch time: 51.49 s 
2023-12-06 06:39:47.021416:  
2023-12-06 06:39:47.021595: Epoch 934 
2023-12-06 06:39:47.021693: Current learning rate: 0.00087 
2023-12-06 06:40:38.897336: train_loss 1.0221 
2023-12-06 06:40:38.897614: val_loss 1.1505 
2023-12-06 06:40:38.897692: Pseudo dice [0.8624] 
2023-12-06 06:40:38.897796: Epoch time: 51.88 s 
2023-12-06 06:40:40.399915:  
2023-12-06 06:40:40.400156: Epoch 935 
2023-12-06 06:40:40.400287: Current learning rate: 0.00085 
2023-12-06 06:41:32.141955: train_loss 1.022 
2023-12-06 06:41:32.142443: val_loss 1.1427 
2023-12-06 06:41:32.142861: Pseudo dice [0.8694] 
2023-12-06 06:41:32.142951: Epoch time: 51.74 s 
2023-12-06 06:41:33.768183:  
2023-12-06 06:41:33.768384: Epoch 936 
2023-12-06 06:41:33.768683: Current learning rate: 0.00084 
2023-12-06 06:42:25.728982: train_loss 1.0217 
2023-12-06 06:42:25.729256: val_loss 1.1481 
2023-12-06 06:42:25.729336: Pseudo dice [0.8636] 
2023-12-06 06:42:25.729416: Epoch time: 51.96 s 
2023-12-06 06:42:27.263584:  
2023-12-06 06:42:27.263844: Epoch 937 
2023-12-06 06:42:27.263953: Current learning rate: 0.00083 
2023-12-06 06:43:19.300891: train_loss 1.0218 
2023-12-06 06:43:19.301164: val_loss 1.1437 
2023-12-06 06:43:19.301242: Pseudo dice [0.8677] 
2023-12-06 06:43:19.301322: Epoch time: 52.04 s 
2023-12-06 06:43:20.982968:  
2023-12-06 06:43:20.983162: Epoch 938 
2023-12-06 06:43:20.983274: Current learning rate: 0.00082 
2023-12-06 06:44:12.981810: train_loss 1.0216 
2023-12-06 06:44:12.982360: val_loss 1.1463 
2023-12-06 06:44:12.982458: Pseudo dice [0.8659] 
2023-12-06 06:44:12.982552: Epoch time: 52.0 s 
2023-12-06 06:44:14.207281:  
2023-12-06 06:44:14.207619: Epoch 939 
2023-12-06 06:44:14.207815: Current learning rate: 0.00081 
2023-12-06 06:45:05.615148: train_loss 1.0213 
2023-12-06 06:45:05.615513: val_loss 1.1408 
2023-12-06 06:45:05.615596: Pseudo dice [0.8691] 
2023-12-06 06:45:05.615686: Epoch time: 51.41 s 
2023-12-06 06:45:07.247548:  
2023-12-06 06:45:07.247701: Epoch 940 
2023-12-06 06:45:07.247806: Current learning rate: 0.00079 
2023-12-06 06:45:58.913045: train_loss 1.022 
2023-12-06 06:45:58.913265: val_loss 1.153 
2023-12-06 06:45:58.913331: Pseudo dice [0.8602] 
2023-12-06 06:45:58.913399: Epoch time: 51.67 s 
2023-12-06 06:46:00.119139:  
2023-12-06 06:46:00.119292: Epoch 941 
2023-12-06 06:46:00.119384: Current learning rate: 0.00078 
2023-12-06 06:46:51.405626: train_loss 1.0221 
2023-12-06 06:46:51.405867: val_loss 1.1539 
2023-12-06 06:46:51.405934: Pseudo dice [0.8606] 
2023-12-06 06:46:51.406004: Epoch time: 51.29 s 
2023-12-06 06:46:52.988124:  
2023-12-06 06:46:52.988364: Epoch 942 
2023-12-06 06:46:52.988470: Current learning rate: 0.00077 
2023-12-06 06:47:44.895096: train_loss 1.0221 
2023-12-06 06:47:44.895357: val_loss 1.1533 
2023-12-06 06:47:44.895451: Pseudo dice [0.8609] 
2023-12-06 06:47:44.895535: Epoch time: 51.91 s 
2023-12-06 06:47:46.346654:  
2023-12-06 06:47:46.346790: Epoch 943 
2023-12-06 06:47:46.346874: Current learning rate: 0.00076 
2023-12-06 06:48:37.906169: train_loss 1.0213 
2023-12-06 06:48:37.906400: val_loss 1.1478 
2023-12-06 06:48:37.906468: Pseudo dice [0.866] 
2023-12-06 06:48:37.906534: Epoch time: 51.56 s 
2023-12-06 06:48:39.139303:  
2023-12-06 06:48:39.139464: Epoch 944 
2023-12-06 06:48:39.139564: Current learning rate: 0.00075 
2023-12-06 06:49:30.897351: train_loss 1.0221 
2023-12-06 06:49:30.897629: val_loss 1.1419 
2023-12-06 06:49:30.897714: Pseudo dice [0.8707] 
2023-12-06 06:49:30.897801: Epoch time: 51.76 s 
2023-12-06 06:49:32.290110:  
2023-12-06 06:49:32.290248: Epoch 945 
2023-12-06 06:49:32.290334: Current learning rate: 0.00074 
2023-12-06 06:50:24.069933: train_loss 1.0214 
2023-12-06 06:50:24.070223: val_loss 1.1455 
2023-12-06 06:50:24.070304: Pseudo dice [0.8664] 
2023-12-06 06:50:24.070403: Epoch time: 51.78 s 
2023-12-06 06:50:25.777272:  
2023-12-06 06:50:25.777755: Epoch 946 
2023-12-06 06:50:25.777972: Current learning rate: 0.00072 
2023-12-06 06:51:17.388712: train_loss 1.0213 
2023-12-06 06:51:17.388974: val_loss 1.1496 
2023-12-06 06:51:17.389056: Pseudo dice [0.863] 
2023-12-06 06:51:17.389138: Epoch time: 51.61 s 
2023-12-06 06:51:18.872734:  
2023-12-06 06:51:18.872890: Epoch 947 
2023-12-06 06:51:18.873001: Current learning rate: 0.00071 
2023-12-06 06:52:10.356590: train_loss 1.0213 
2023-12-06 06:52:10.356820: val_loss 1.1451 
2023-12-06 06:52:10.356887: Pseudo dice [0.867] 
2023-12-06 06:52:10.356954: Epoch time: 51.49 s 
2023-12-06 06:52:11.912934:  
2023-12-06 06:52:11.913124: Epoch 948 
2023-12-06 06:52:11.913230: Current learning rate: 0.0007 
2023-12-06 06:53:03.260580: train_loss 1.0213 
2023-12-06 06:53:03.260822: val_loss 1.1509 
2023-12-06 06:53:03.260889: Pseudo dice [0.8627] 
2023-12-06 06:53:03.260960: Epoch time: 51.35 s 
2023-12-06 06:53:04.693131:  
2023-12-06 06:53:04.693280: Epoch 949 
2023-12-06 06:53:04.693368: Current learning rate: 0.00069 
2023-12-06 06:53:56.118690: train_loss 1.0217 
2023-12-06 06:53:56.118902: val_loss 1.1446 
2023-12-06 06:53:56.118965: Pseudo dice [0.8682] 
2023-12-06 06:53:56.119042: Epoch time: 51.43 s 
2023-12-06 06:53:58.604373:  
2023-12-06 06:53:58.604533: Epoch 950 
2023-12-06 06:53:58.604619: Current learning rate: 0.00067 
2023-12-06 06:54:49.931074: train_loss 1.0206 
2023-12-06 06:54:49.931330: val_loss 1.1518 
2023-12-06 06:54:49.931401: Pseudo dice [0.8617] 
2023-12-06 06:54:49.931473: Epoch time: 51.33 s 
2023-12-06 06:54:51.111003:  
2023-12-06 06:54:51.111298: Epoch 951 
2023-12-06 06:54:51.111387: Current learning rate: 0.00066 
2023-12-06 06:55:42.805767: train_loss 1.0212 
2023-12-06 06:55:42.806024: val_loss 1.1471 
2023-12-06 06:55:42.806107: Pseudo dice [0.8642] 
2023-12-06 06:55:42.806188: Epoch time: 51.7 s 
2023-12-06 06:55:44.445419:  
2023-12-06 06:55:44.445796: Epoch 952 
2023-12-06 06:55:44.445919: Current learning rate: 0.00065 
2023-12-06 06:56:35.918551: train_loss 1.0214 
2023-12-06 06:56:35.918783: val_loss 1.1576 
2023-12-06 06:56:35.918849: Pseudo dice [0.857] 
2023-12-06 06:56:35.918914: Epoch time: 51.48 s 
2023-12-06 06:56:37.138065:  
2023-12-06 06:56:37.138208: Epoch 953 
2023-12-06 06:56:37.138297: Current learning rate: 0.00064 
2023-12-06 06:57:28.540002: train_loss 1.0215 
2023-12-06 06:57:28.540229: val_loss 1.1521 
2023-12-06 06:57:28.540296: Pseudo dice [0.8609] 
2023-12-06 06:57:28.540363: Epoch time: 51.4 s 
2023-12-06 06:57:30.098970:  
2023-12-06 06:57:30.099151: Epoch 954 
2023-12-06 06:57:30.099265: Current learning rate: 0.00063 
2023-12-06 06:58:21.458803: train_loss 1.021 
2023-12-06 06:58:21.459044: val_loss 1.14 
2023-12-06 06:58:21.459113: Pseudo dice [0.8718] 
2023-12-06 06:58:21.459180: Epoch time: 51.36 s 
2023-12-06 06:58:22.851676:  
2023-12-06 06:58:22.851810: Epoch 955 
2023-12-06 06:58:22.851898: Current learning rate: 0.00061 
2023-12-06 06:59:14.327269: train_loss 1.0214 
2023-12-06 06:59:14.327524: val_loss 1.1529 
2023-12-06 06:59:14.327592: Pseudo dice [0.859] 
2023-12-06 06:59:14.327659: Epoch time: 51.48 s 
2023-12-06 06:59:15.518103:  
2023-12-06 06:59:15.518236: Epoch 956 
2023-12-06 06:59:15.518321: Current learning rate: 0.0006 
2023-12-06 07:00:07.104307: train_loss 1.0208 
2023-12-06 07:00:07.104539: val_loss 1.1458 
2023-12-06 07:00:07.104631: Pseudo dice [0.866] 
2023-12-06 07:00:07.104713: Epoch time: 51.59 s 
2023-12-06 07:00:08.631663:  
2023-12-06 07:00:08.631826: Epoch 957 
2023-12-06 07:00:08.631931: Current learning rate: 0.00059 
2023-12-06 07:01:00.319777: train_loss 1.021 
2023-12-06 07:01:00.320260: val_loss 1.1496 
2023-12-06 07:01:00.320366: Pseudo dice [0.8637] 
2023-12-06 07:01:00.320467: Epoch time: 51.69 s 
2023-12-06 07:01:01.981739:  
2023-12-06 07:01:01.981914: Epoch 958 
2023-12-06 07:01:01.982038: Current learning rate: 0.00058 
2023-12-06 07:01:53.563478: train_loss 1.0212 
2023-12-06 07:01:53.563698: val_loss 1.1481 
2023-12-06 07:01:53.563759: Pseudo dice [0.8635] 
2023-12-06 07:01:53.563822: Epoch time: 51.58 s 
2023-12-06 07:01:55.140911:  
2023-12-06 07:01:55.141076: Epoch 959 
2023-12-06 07:01:55.141185: Current learning rate: 0.00056 
2023-12-06 07:02:46.722371: train_loss 1.0209 
2023-12-06 07:02:46.722633: val_loss 1.151 
2023-12-06 07:02:46.722699: Pseudo dice [0.8622] 
2023-12-06 07:02:46.722767: Epoch time: 51.58 s 
2023-12-06 07:02:47.946448:  
2023-12-06 07:02:47.946940: Epoch 960 
2023-12-06 07:02:47.947103: Current learning rate: 0.00055 
2023-12-06 07:03:39.495853: train_loss 1.0207 
2023-12-06 07:03:39.496506: val_loss 1.1475 
2023-12-06 07:03:39.496615: Pseudo dice [0.8656] 
2023-12-06 07:03:39.496725: Epoch time: 51.55 s 
2023-12-06 07:03:41.235126:  
2023-12-06 07:03:41.235449: Epoch 961 
2023-12-06 07:03:41.235822: Current learning rate: 0.00054 
2023-12-06 07:04:33.048012: train_loss 1.0214 
2023-12-06 07:04:33.048306: val_loss 1.1421 
2023-12-06 07:04:33.048374: Pseudo dice [0.8694] 
2023-12-06 07:04:33.048443: Epoch time: 51.82 s 
2023-12-06 07:04:34.727446:  
2023-12-06 07:04:34.727614: Epoch 962 
2023-12-06 07:04:34.727729: Current learning rate: 0.00053 
2023-12-06 07:05:26.517858: train_loss 1.0203 
2023-12-06 07:05:26.518126: val_loss 1.1459 
2023-12-06 07:05:26.518213: Pseudo dice [0.8669] 
2023-12-06 07:05:26.518312: Epoch time: 51.79 s 
2023-12-06 07:05:28.176271:  
2023-12-06 07:05:28.176587: Epoch 963 
2023-12-06 07:05:28.176708: Current learning rate: 0.00051 
2023-12-06 07:06:20.083162: train_loss 1.0209 
2023-12-06 07:06:20.083447: val_loss 1.1447 
2023-12-06 07:06:20.083530: Pseudo dice [0.8657] 
2023-12-06 07:06:20.083617: Epoch time: 51.91 s 
2023-12-06 07:06:21.670579:  
2023-12-06 07:06:21.670724: Epoch 964 
2023-12-06 07:06:21.670809: Current learning rate: 0.0005 
2023-12-06 07:07:13.325669: train_loss 1.0215 
2023-12-06 07:07:13.326086: val_loss 1.1515 
2023-12-06 07:07:13.326196: Pseudo dice [0.8618] 
2023-12-06 07:07:13.326294: Epoch time: 51.66 s 
2023-12-06 07:07:15.019910:  
2023-12-06 07:07:15.020086: Epoch 965 
2023-12-06 07:07:15.020200: Current learning rate: 0.00049 
2023-12-06 07:08:06.567086: train_loss 1.0205 
2023-12-06 07:08:06.567606: val_loss 1.1506 
2023-12-06 07:08:06.567696: Pseudo dice [0.8637] 
2023-12-06 07:08:06.567788: Epoch time: 51.55 s 
2023-12-06 07:08:07.830474:  
2023-12-06 07:08:07.830632: Epoch 966 
2023-12-06 07:08:07.830749: Current learning rate: 0.00048 
2023-12-06 07:08:59.219043: train_loss 1.0206 
2023-12-06 07:08:59.219307: val_loss 1.1472 
2023-12-06 07:08:59.219376: Pseudo dice [0.8658] 
2023-12-06 07:08:59.219445: Epoch time: 51.39 s 
2023-12-06 07:09:00.708226:  
2023-12-06 07:09:00.708469: Epoch 967 
2023-12-06 07:09:00.708638: Current learning rate: 0.00046 
2023-12-06 07:09:52.510106: train_loss 1.0209 
2023-12-06 07:09:52.510381: val_loss 1.143 
2023-12-06 07:09:52.510459: Pseudo dice [0.8686] 
2023-12-06 07:09:52.510541: Epoch time: 51.8 s 
2023-12-06 07:09:54.165222:  
2023-12-06 07:09:54.165635: Epoch 968 
2023-12-06 07:09:54.165812: Current learning rate: 0.00045 
2023-12-06 07:10:45.733104: train_loss 1.0211 
2023-12-06 07:10:45.733394: val_loss 1.1457 
2023-12-06 07:10:45.733482: Pseudo dice [0.866] 
2023-12-06 07:10:45.733555: Epoch time: 51.57 s 
2023-12-06 07:10:47.020152:  
2023-12-06 07:10:47.020329: Epoch 969 
2023-12-06 07:10:47.020421: Current learning rate: 0.00044 
2023-12-06 07:11:38.464830: train_loss 1.0205 
2023-12-06 07:11:38.465059: val_loss 1.1483 
2023-12-06 07:11:38.465127: Pseudo dice [0.8639] 
2023-12-06 07:11:38.465194: Epoch time: 51.45 s 
2023-12-06 07:11:39.713544:  
2023-12-06 07:11:39.713699: Epoch 970 
2023-12-06 07:11:39.713786: Current learning rate: 0.00043 
2023-12-06 07:12:31.341901: train_loss 1.0207 
2023-12-06 07:12:31.342160: val_loss 1.151 
2023-12-06 07:12:31.342240: Pseudo dice [0.8618] 
2023-12-06 07:12:31.342325: Epoch time: 51.63 s 
2023-12-06 07:12:32.677682:  
2023-12-06 07:12:32.678116: Epoch 971 
2023-12-06 07:12:32.678212: Current learning rate: 0.00041 
2023-12-06 07:13:24.337952: train_loss 1.0206 
2023-12-06 07:13:24.338238: val_loss 1.1509 
2023-12-06 07:13:24.338319: Pseudo dice [0.8631] 
2023-12-06 07:13:24.338401: Epoch time: 51.66 s 
2023-12-06 07:13:25.616825:  
2023-12-06 07:13:25.616953: Epoch 972 
2023-12-06 07:13:25.617042: Current learning rate: 0.0004 
2023-12-06 07:14:17.203002: train_loss 1.0206 
2023-12-06 07:14:17.203280: val_loss 1.1458 
2023-12-06 07:14:17.203348: Pseudo dice [0.8664] 
2023-12-06 07:14:17.203434: Epoch time: 51.59 s 
2023-12-06 07:14:18.663476:  
2023-12-06 07:14:18.663685: Epoch 973 
2023-12-06 07:14:18.663952: Current learning rate: 0.00039 
2023-12-06 07:15:10.704160: train_loss 1.0204 
2023-12-06 07:15:10.704789: val_loss 1.1474 
2023-12-06 07:15:10.704904: Pseudo dice [0.8649] 
2023-12-06 07:15:10.705018: Epoch time: 52.04 s 
2023-12-06 07:15:12.025734:  
2023-12-06 07:15:12.025894: Epoch 974 
2023-12-06 07:15:12.025995: Current learning rate: 0.00037 
2023-12-06 07:16:03.851930: train_loss 1.0204 
2023-12-06 07:16:03.852194: val_loss 1.1468 
2023-12-06 07:16:03.852281: Pseudo dice [0.8646] 
2023-12-06 07:16:03.852366: Epoch time: 51.83 s 
2023-12-06 07:16:05.370220:  
2023-12-06 07:16:05.370466: Epoch 975 
2023-12-06 07:16:05.370565: Current learning rate: 0.00036 
2023-12-06 07:16:57.253773: train_loss 1.0206 
2023-12-06 07:16:57.253998: val_loss 1.1508 
2023-12-06 07:16:57.254064: Pseudo dice [0.8622] 
2023-12-06 07:16:57.254133: Epoch time: 51.89 s 
2023-12-06 07:16:58.493249:  
2023-12-06 07:16:58.493383: Epoch 976 
2023-12-06 07:16:58.493478: Current learning rate: 0.00035 
2023-12-06 07:17:50.353524: train_loss 1.0205 
2023-12-06 07:17:50.353815: val_loss 1.1415 
2023-12-06 07:17:50.353896: Pseudo dice [0.8692] 
2023-12-06 07:17:50.353983: Epoch time: 51.86 s 
2023-12-06 07:17:51.833480:  
2023-12-06 07:17:51.833625: Epoch 977 
2023-12-06 07:17:51.833719: Current learning rate: 0.00034 
2023-12-06 07:18:43.361709: train_loss 1.0198 
2023-12-06 07:18:43.361960: val_loss 1.1505 
2023-12-06 07:18:43.362029: Pseudo dice [0.8621] 
2023-12-06 07:18:43.362097: Epoch time: 51.53 s 
2023-12-06 07:18:44.944720:  
2023-12-06 07:18:44.945236: Epoch 978 
2023-12-06 07:18:44.945361: Current learning rate: 0.00032 
2023-12-06 07:19:36.492595: train_loss 1.0202 
2023-12-06 07:19:36.493255: val_loss 1.1481 
2023-12-06 07:19:36.493337: Pseudo dice [0.8653] 
2023-12-06 07:19:36.493426: Epoch time: 51.55 s 
2023-12-06 07:19:37.745000:  
2023-12-06 07:19:37.745429: Epoch 979 
2023-12-06 07:19:37.745529: Current learning rate: 0.00031 
2023-12-06 07:20:29.278063: train_loss 1.0206 
2023-12-06 07:20:29.278598: val_loss 1.1427 
2023-12-06 07:20:29.278788: Pseudo dice [0.8684] 
2023-12-06 07:20:29.278983: Epoch time: 51.53 s 
2023-12-06 07:20:31.120118:  
2023-12-06 07:20:31.120730: Epoch 980 
2023-12-06 07:20:31.120898: Current learning rate: 0.0003 
2023-12-06 07:21:22.694201: train_loss 1.0202 
2023-12-06 07:21:22.694451: val_loss 1.1413 
2023-12-06 07:21:22.694521: Pseudo dice [0.8706] 
2023-12-06 07:21:22.694590: Epoch time: 51.58 s 
2023-12-06 07:21:24.310462:  
2023-12-06 07:21:24.310963: Epoch 981 
2023-12-06 07:21:24.313119: Current learning rate: 0.00028 
2023-12-06 07:22:15.946513: train_loss 1.0198 
2023-12-06 07:22:15.946728: val_loss 1.1464 
2023-12-06 07:22:15.946790: Pseudo dice [0.8667] 
2023-12-06 07:22:15.946870: Epoch time: 51.64 s 
2023-12-06 07:22:17.160651:  
2023-12-06 07:22:17.160955: Epoch 982 
2023-12-06 07:22:17.161065: Current learning rate: 0.00027 
2023-12-06 07:23:09.170677: train_loss 1.02 
2023-12-06 07:23:09.171069: val_loss 1.1476 
2023-12-06 07:23:09.171173: Pseudo dice [0.8638] 
2023-12-06 07:23:09.171281: Epoch time: 52.01 s 
2023-12-06 07:23:10.405773:  
2023-12-06 07:23:10.405920: Epoch 983 
2023-12-06 07:23:10.406013: Current learning rate: 0.00026 
2023-12-06 07:24:02.038725: train_loss 1.0198 
2023-12-06 07:24:02.039524: val_loss 1.1475 
2023-12-06 07:24:02.039692: Pseudo dice [0.8643] 
2023-12-06 07:24:02.039827: Epoch time: 51.63 s 
2023-12-06 07:24:03.311099:  
2023-12-06 07:24:03.311301: Epoch 984 
2023-12-06 07:24:03.311405: Current learning rate: 0.00024 
2023-12-06 07:24:54.993366: train_loss 1.0201 
2023-12-06 07:24:54.993935: val_loss 1.1415 
2023-12-06 07:24:54.994030: Pseudo dice [0.8704] 
2023-12-06 07:24:54.994109: Epoch time: 51.68 s 
2023-12-06 07:24:56.231443:  
2023-12-06 07:24:56.231787: Epoch 985 
2023-12-06 07:24:56.232036: Current learning rate: 0.00023 
2023-12-06 07:25:47.724357: train_loss 1.0209 
2023-12-06 07:25:47.724714: val_loss 1.1507 
2023-12-06 07:25:47.724785: Pseudo dice [0.8618] 
2023-12-06 07:25:47.724873: Epoch time: 51.5 s 
2023-12-06 07:25:49.105759:  
2023-12-06 07:25:49.106195: Epoch 986 
2023-12-06 07:25:49.106306: Current learning rate: 0.00021 
2023-12-06 07:26:40.856936: train_loss 1.0201 
2023-12-06 07:26:40.857251: val_loss 1.1454 
2023-12-06 07:26:40.857482: Pseudo dice [0.8664] 
2023-12-06 07:26:40.857579: Epoch time: 51.75 s 
2023-12-06 07:26:42.446784:  
2023-12-06 07:26:42.447249: Epoch 987 
2023-12-06 07:26:42.447430: Current learning rate: 0.0002 
2023-12-06 07:27:34.296826: train_loss 1.02 
2023-12-06 07:27:34.297602: val_loss 1.1445 
2023-12-06 07:27:34.297718: Pseudo dice [0.8677] 
2023-12-06 07:27:34.297842: Epoch time: 51.85 s 
2023-12-06 07:27:35.962324:  
2023-12-06 07:27:35.962617: Epoch 988 
2023-12-06 07:27:35.962732: Current learning rate: 0.00019 
2023-12-06 07:28:27.744438: train_loss 1.0197 
2023-12-06 07:28:27.744715: val_loss 1.1462 
2023-12-06 07:28:27.744797: Pseudo dice [0.8657] 
2023-12-06 07:28:27.744879: Epoch time: 51.78 s 
2023-12-06 07:28:29.218299:  
2023-12-06 07:28:29.218478: Epoch 989 
2023-12-06 07:28:29.218593: Current learning rate: 0.00017 
2023-12-06 07:29:21.220376: train_loss 1.0197 
2023-12-06 07:29:21.220639: val_loss 1.1485 
2023-12-06 07:29:21.220720: Pseudo dice [0.864] 
2023-12-06 07:29:21.220801: Epoch time: 52.0 s 
2023-12-06 07:29:22.858088:  
2023-12-06 07:29:22.858258: Epoch 990 
2023-12-06 07:29:22.858381: Current learning rate: 0.00016 
2023-12-06 07:30:14.827690: train_loss 1.0201 
2023-12-06 07:30:14.827962: val_loss 1.1498 
2023-12-06 07:30:14.828043: Pseudo dice [0.8623] 
2023-12-06 07:30:14.828126: Epoch time: 51.97 s 
2023-12-06 07:30:16.498823:  
2023-12-06 07:30:16.499010: Epoch 991 
2023-12-06 07:30:16.499156: Current learning rate: 0.00014 
2023-12-06 07:31:08.564424: train_loss 1.0196 
2023-12-06 07:31:08.564814: val_loss 1.1452 
2023-12-06 07:31:08.564896: Pseudo dice [0.8678] 
2023-12-06 07:31:08.564978: Epoch time: 52.07 s 
2023-12-06 07:31:10.427521:  
2023-12-06 07:31:10.427987: Epoch 992 
2023-12-06 07:31:10.428169: Current learning rate: 0.00013 
2023-12-06 07:32:02.340331: train_loss 1.0201 
2023-12-06 07:32:02.340634: val_loss 1.1471 
2023-12-06 07:32:02.340736: Pseudo dice [0.8654] 
2023-12-06 07:32:02.340834: Epoch time: 51.91 s 
2023-12-06 07:32:03.906101:  
2023-12-06 07:32:03.906251: Epoch 993 
2023-12-06 07:32:03.906364: Current learning rate: 0.00011 
2023-12-06 07:32:55.526598: train_loss 1.0199 
2023-12-06 07:32:55.526856: val_loss 1.1478 
2023-12-06 07:32:55.526937: Pseudo dice [0.8661] 
2023-12-06 07:32:55.527030: Epoch time: 51.62 s 
2023-12-06 07:32:57.093286:  
2023-12-06 07:32:57.093554: Epoch 994 
2023-12-06 07:32:57.093679: Current learning rate: 0.0001 
2023-12-06 07:33:48.588693: train_loss 1.0198 
2023-12-06 07:33:48.588939: val_loss 1.147 
2023-12-06 07:33:48.589009: Pseudo dice [0.8669] 
2023-12-06 07:33:48.589081: Epoch time: 51.5 s 
2023-12-06 07:33:49.842343:  
2023-12-06 07:33:49.842581: Epoch 995 
2023-12-06 07:33:49.842775: Current learning rate: 8e-05 
2023-12-06 07:34:41.435614: train_loss 1.0196 
2023-12-06 07:34:41.436121: val_loss 1.1499 
2023-12-06 07:34:41.436212: Pseudo dice [0.8635] 
2023-12-06 07:34:41.436309: Epoch time: 51.6 s 
2023-12-06 07:34:42.661865:  
2023-12-06 07:34:42.662035: Epoch 996 
2023-12-06 07:34:42.662127: Current learning rate: 7e-05 
2023-12-06 07:35:34.170916: train_loss 1.0194 
2023-12-06 07:35:34.171175: val_loss 1.1456 
2023-12-06 07:35:34.171243: Pseudo dice [0.868] 
2023-12-06 07:35:34.171314: Epoch time: 51.51 s 
2023-12-06 07:35:35.382056:  
2023-12-06 07:35:35.382276: Epoch 997 
2023-12-06 07:35:35.382356: Current learning rate: 5e-05 
2023-12-06 07:36:27.162059: train_loss 1.0198 
2023-12-06 07:36:27.162282: val_loss 1.1459 
2023-12-06 07:36:27.162345: Pseudo dice [0.8668] 
2023-12-06 07:36:27.162414: Epoch time: 51.78 s 
2023-12-06 07:36:28.561232:  
2023-12-06 07:36:28.561440: Epoch 998 
2023-12-06 07:36:28.561521: Current learning rate: 4e-05 
2023-12-06 07:37:20.039097: train_loss 1.0199 
2023-12-06 07:37:20.039361: val_loss 1.1574 
2023-12-06 07:37:20.039444: Pseudo dice [0.8561] 
2023-12-06 07:37:20.039529: Epoch time: 51.48 s 
2023-12-06 07:37:21.589407:  
2023-12-06 07:37:21.589651: Epoch 999 
2023-12-06 07:37:21.589750: Current learning rate: 2e-05 
2023-12-06 07:38:13.064680: train_loss 1.0195 
2023-12-06 07:38:13.064898: val_loss 1.149 
2023-12-06 07:38:13.064964: Pseudo dice [0.8653] 
2023-12-06 07:38:13.065030: Epoch time: 51.48 s 
2023-12-06 07:38:15.552628: Using splits from existing split file: /data/chuan/nnUNet/nnUNet_preprocessed/Dataset040_DeepInfarct/splits_final.json 
2023-12-06 07:38:15.553281: The split file contains 5 splits. 
2023-12-06 07:38:15.553331: Desired fold for training: 0 
2023-12-06 07:38:15.553360: This split has 142 training and 36 validation cases. 
2023-12-06 07:38:15.553635: predicting DeepInfarct_00002 
2023-12-06 07:38:21.724882: predicting DeepInfarct_00010 
2023-12-06 07:38:22.687109: predicting DeepInfarct_00018 
2023-12-06 07:38:23.723132: predicting DeepInfarct_00021 
2023-12-06 07:38:24.753290: predicting DeepInfarct_00026 
2023-12-06 07:38:26.265850: predicting DeepInfarct_00028 
2023-12-06 07:38:27.909476: predicting DeepInfarct_00038 
2023-12-06 07:38:28.959661: predicting DeepInfarct_00047 
2023-12-06 07:38:29.994333: predicting DeepInfarct_00048 
2023-12-06 07:38:35.197623: predicting DeepInfarct_00055 
2023-12-06 07:38:36.236738: predicting DeepInfarct_00057 
2023-12-06 07:38:41.458903: predicting DeepInfarct_00059 
2023-12-06 07:38:42.508305: predicting DeepInfarct_00064 
2023-12-06 07:38:47.726638: predicting DeepInfarct_00071 
2023-12-06 07:38:48.775559: predicting DeepInfarct_00080 
2023-12-06 07:38:49.828163: predicting DeepInfarct_00094 
2023-12-06 07:38:51.225541: predicting DeepInfarct_00095 
2023-12-06 07:38:56.086980: predicting DeepInfarct_00106 
2023-12-06 07:38:57.690107: predicting DeepInfarct_00111 
2023-12-06 07:38:59.188265: predicting DeepInfarct_00128 
2023-12-06 07:39:00.684283: predicting DeepInfarct_00130 
2023-12-06 07:39:02.301030: predicting DeepInfarct_00131 
2023-12-06 07:39:04.394777: predicting DeepInfarct_00138 
2023-12-06 07:39:05.425015: predicting DeepInfarct_00139 
2023-12-06 07:39:06.454690: predicting DeepInfarct_00141 
2023-12-06 07:39:07.505952: predicting DeepInfarct_00151 
2023-12-06 07:39:12.186097: predicting DeepInfarct_00154 
2023-12-06 07:39:14.123108: predicting DeepInfarct_00157 
2023-12-06 07:39:14.861798: predicting DeepInfarct_00160 
2023-12-06 07:39:15.872570: predicting DeepInfarct_00163 
2023-12-06 07:39:16.913074: predicting DeepInfarct_00168 
2023-12-06 07:39:17.948150: predicting DeepInfarct_00171 
2023-12-06 07:39:23.164250: predicting DeepInfarct_00173 
2023-12-06 07:39:24.599106: predicting DeepInfarct_00176 
2023-12-06 07:39:29.428747: predicting DeepInfarct_00177 
2023-12-06 07:39:30.891535: predicting DeepInfarct_00178 
2023-12-06 07:39:38.466910: Validation complete 
2023-12-06 07:39:38.467111: Mean Validation Dice:  0.7364294846651781 
