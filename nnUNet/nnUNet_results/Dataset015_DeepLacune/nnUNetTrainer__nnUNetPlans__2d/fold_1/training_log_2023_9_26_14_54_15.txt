
This is the configuration used by this training:
Configuration name: 2d
 {'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 26, 'patch_size': [384, 320], 'median_image_size_in_voxels': [361.0, 308.0], 'spacing': [0.44920000433921814, 0.44920000433921814], 'normalization_schemes': ['ZScoreBrainNormalization'], 'use_mask_for_norm': [False], 'UNet_class_name': 'PlainConvUNet', 'UNet_base_num_features': 32, 'n_conv_per_stage_encoder': [2, 2, 2, 2, 2, 2, 2], 'n_conv_per_stage_decoder': [2, 2, 2, 2, 2, 2], 'num_pool_per_axis': [6, 6], 'pool_op_kernel_sizes': [[1, 1], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2], [2, 2]], 'conv_kernel_sizes': [[3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3], [3, 3]], 'unet_max_num_features': 512, 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'batch_dice': True} 
 
These are the global plan.json settings:
 {'dataset_name': 'Dataset015_DeepLacune', 'plans_name': 'nnUNetPlans', 'original_median_spacing_after_transp': [7.0, 0.44920000433921814, 0.44920000433921814], 'original_median_shape_after_transp': [21, 358, 307], 'image_reader_writer': 'SimpleITKIO', 'transpose_forward': [0, 1, 2], 'transpose_backward': [0, 1, 2], 'experiment_planner_used': 'ExperimentPlanner', 'label_manager': 'LabelManager', 'foreground_intensity_properties_per_channel': {'0': {'max': 2679.0, 'mean': 1094.3029018958514, 'median': 1072.0, 'min': 1.0, 'percentile_00_5': 266.0, 'percentile_99_5': 1868.0, 'std': 275.548242230399}}} 
 
2023-09-26 14:54:22.734922: unpacking dataset... 
2023-09-26 14:54:23.168861: unpacking done... 
2023-09-26 14:54:23.170946: do_dummy_2d_data_aug: False 
2023-09-26 14:54:23.172421: Using splits from existing split file: /data/chuan/nnUNet/nnUNet_preprocessed/Dataset015_DeepLacune/splits_final.json 
2023-09-26 14:54:23.172795: The split file contains 5 splits. 
2023-09-26 14:54:23.172852: Desired fold for training: 1 
2023-09-26 14:54:23.172893: This split has 76 training and 19 validation cases. 
2023-09-26 14:54:32.370398: Unable to plot network architecture: 
2023-09-26 14:54:32.371050: module 'torch.onnx' has no attribute '_optimize_trace' 
2023-09-26 14:54:32.542802:  
2023-09-26 14:54:32.542980: Epoch 0 
2023-09-26 14:54:32.543423: Current learning rate: 0.01 
2023-09-26 14:56:24.288981: train_loss 0.0347 
2023-09-26 14:56:24.289310: val_loss -0.1345 
2023-09-26 14:56:24.289416: Pseudo dice [0.6471, 0.0, 0.0] 
2023-09-26 14:56:24.289510: Epoch time: 111.75 s 
2023-09-26 14:56:24.289583: Yayy! New best EMA pseudo Dice: 0.2157 
2023-09-26 14:56:25.826851:  
2023-09-26 14:56:25.827063: Epoch 1 
2023-09-26 14:56:25.827167: Current learning rate: 0.00999 
2023-09-26 14:58:03.199382: train_loss -0.1934 
2023-09-26 14:58:03.199855: val_loss -0.2541 
2023-09-26 14:58:03.199960: Pseudo dice [0.8052, 0.0, 0.0] 
2023-09-26 14:58:03.200062: Epoch time: 97.37 s 
2023-09-26 14:58:03.200145: Yayy! New best EMA pseudo Dice: 0.221 
2023-09-26 14:58:06.739622:  
2023-09-26 14:58:06.739805: Epoch 2 
2023-09-26 14:58:06.739914: Current learning rate: 0.00998 
2023-09-26 14:59:45.272880: train_loss -0.3056 
2023-09-26 14:59:45.273259: val_loss -0.3243 
2023-09-26 14:59:45.273386: Pseudo dice [0.8092, 0.0, 0.4212] 
2023-09-26 14:59:45.273493: Epoch time: 98.53 s 
2023-09-26 14:59:45.273561: Yayy! New best EMA pseudo Dice: 0.2399 
2023-09-26 14:59:48.430804:  
2023-09-26 14:59:48.431160: Epoch 3 
2023-09-26 14:59:48.431283: Current learning rate: 0.00997 
2023-09-26 15:01:26.092679: train_loss -0.4148 
2023-09-26 15:01:26.092964: val_loss -0.3326 
2023-09-26 15:01:26.093059: Pseudo dice [0.8005, 0.0, 0.4069] 
2023-09-26 15:01:26.093144: Epoch time: 97.66 s 
2023-09-26 15:01:26.093224: Yayy! New best EMA pseudo Dice: 0.2561 
2023-09-26 15:01:29.047692:  
2023-09-26 15:01:29.047910: Epoch 4 
2023-09-26 15:01:29.048053: Current learning rate: 0.00996 
2023-09-26 15:03:07.079287: train_loss -0.431 
2023-09-26 15:03:07.079522: val_loss -0.3564 
2023-09-26 15:03:07.079600: Pseudo dice [0.8341, 0.0, 0.4402] 
2023-09-26 15:03:07.079674: Epoch time: 98.03 s 
2023-09-26 15:03:07.079727: Yayy! New best EMA pseudo Dice: 0.273 
2023-09-26 15:03:09.995718:  
2023-09-26 15:03:09.995858: Epoch 5 
2023-09-26 15:03:09.995945: Current learning rate: 0.00995 
2023-09-26 15:04:48.484503: train_loss -0.4496 
2023-09-26 15:04:48.484752: val_loss -0.3689 
2023-09-26 15:04:48.484827: Pseudo dice [0.8066, 0.0, 0.4727] 
2023-09-26 15:04:48.484897: Epoch time: 98.49 s 
2023-09-26 15:04:48.484949: Yayy! New best EMA pseudo Dice: 0.2883 
2023-09-26 15:04:51.553286:  
2023-09-26 15:04:51.553451: Epoch 6 
2023-09-26 15:04:51.553536: Current learning rate: 0.00995 
2023-09-26 15:06:29.920080: train_loss -0.4553 
2023-09-26 15:06:29.920317: val_loss -0.4121 
2023-09-26 15:06:29.920395: Pseudo dice [0.84, 0.0, 0.5872] 
2023-09-26 15:06:29.920467: Epoch time: 98.37 s 
2023-09-26 15:06:29.920521: Yayy! New best EMA pseudo Dice: 0.3071 
2023-09-26 15:06:32.861273:  
2023-09-26 15:06:32.861434: Epoch 7 
2023-09-26 15:06:32.861536: Current learning rate: 0.00994 
2023-09-26 15:08:11.549658: train_loss -0.4662 
2023-09-26 15:08:11.549905: val_loss -0.3099 
2023-09-26 15:08:11.549981: Pseudo dice [0.8216, 0.0, 0.2329] 
2023-09-26 15:08:11.550052: Epoch time: 98.69 s 
2023-09-26 15:08:11.550112: Yayy! New best EMA pseudo Dice: 0.3115 
2023-09-26 15:08:14.787662:  
2023-09-26 15:08:14.787960: Epoch 8 
2023-09-26 15:08:14.788074: Current learning rate: 0.00993 
2023-09-26 15:09:53.368283: train_loss -0.4821 
2023-09-26 15:09:53.368551: val_loss -0.4379 
2023-09-26 15:09:53.368639: Pseudo dice [0.8471, 0.0, 0.6038] 
2023-09-26 15:09:53.368714: Epoch time: 98.58 s 
2023-09-26 15:09:53.368770: Yayy! New best EMA pseudo Dice: 0.3287 
2023-09-26 15:09:56.184482:  
2023-09-26 15:09:56.184626: Epoch 9 
2023-09-26 15:09:56.184713: Current learning rate: 0.00992 
2023-09-26 15:11:34.274003: train_loss -0.5024 
2023-09-26 15:11:34.274286: val_loss -0.4303 
2023-09-26 15:11:34.274387: Pseudo dice [0.8473, 0.0, 0.5547] 
2023-09-26 15:11:34.274472: Epoch time: 98.09 s 
2023-09-26 15:11:34.274540: Yayy! New best EMA pseudo Dice: 0.3426 
2023-09-26 15:11:37.032578:  
2023-09-26 15:11:37.032851: Epoch 10 
2023-09-26 15:11:37.032946: Current learning rate: 0.00991 
2023-09-26 15:13:15.105981: train_loss -0.5443 
2023-09-26 15:13:15.106293: val_loss -0.4799 
2023-09-26 15:13:15.106393: Pseudo dice [0.8564, 0.0, 0.5564] 
2023-09-26 15:13:15.106480: Epoch time: 98.07 s 
2023-09-26 15:13:15.106548: Yayy! New best EMA pseudo Dice: 0.3554 
2023-09-26 15:13:18.034730:  
2023-09-26 15:13:18.035087: Epoch 11 
2023-09-26 15:13:18.035253: Current learning rate: 0.0099 
2023-09-26 15:14:56.873456: train_loss -0.5558 
2023-09-26 15:14:56.873707: val_loss -0.4491 
2023-09-26 15:14:56.873790: Pseudo dice [0.8274, 0.0, 0.5296] 
2023-09-26 15:14:56.873862: Epoch time: 98.84 s 
2023-09-26 15:14:56.873915: Yayy! New best EMA pseudo Dice: 0.3651 
2023-09-26 15:14:59.704887:  
2023-09-26 15:14:59.705059: Epoch 12 
2023-09-26 15:14:59.705150: Current learning rate: 0.00989 
2023-09-26 15:16:38.469257: train_loss -0.5938 
2023-09-26 15:16:38.469508: val_loss -0.5179 
2023-09-26 15:16:38.469588: Pseudo dice [0.8311, 0.484, 0.5913] 
2023-09-26 15:16:38.469659: Epoch time: 98.77 s 
2023-09-26 15:16:38.469712: Yayy! New best EMA pseudo Dice: 0.3922 
2023-09-26 15:16:41.177161:  
2023-09-26 15:16:41.177439: Epoch 13 
2023-09-26 15:16:41.177541: Current learning rate: 0.00988 
2023-09-26 15:18:19.651740: train_loss -0.6351 
2023-09-26 15:18:19.651999: val_loss -0.5499 
2023-09-26 15:18:19.652078: Pseudo dice [0.8582, 0.4478, 0.5644] 
2023-09-26 15:18:19.652151: Epoch time: 98.48 s 
2023-09-26 15:18:19.652204: Yayy! New best EMA pseudo Dice: 0.4153 
2023-09-26 15:18:22.487805:  
2023-09-26 15:18:22.488128: Epoch 14 
2023-09-26 15:18:22.488236: Current learning rate: 0.00987 
2023-09-26 15:20:00.580616: train_loss -0.6274 
2023-09-26 15:20:00.580910: val_loss -0.5154 
2023-09-26 15:20:00.580997: Pseudo dice [0.8553, 0.4982, 0.4988] 
2023-09-26 15:20:00.581079: Epoch time: 98.09 s 
2023-09-26 15:20:00.581253: Yayy! New best EMA pseudo Dice: 0.4355 
2023-09-26 15:20:03.451949:  
2023-09-26 15:20:03.452441: Epoch 15 
2023-09-26 15:20:03.452541: Current learning rate: 0.00986 
2023-09-26 15:21:41.825763: train_loss -0.6489 
2023-09-26 15:21:41.826064: val_loss -0.5122 
2023-09-26 15:21:41.826165: Pseudo dice [0.8361, 0.5085, 0.555] 
2023-09-26 15:21:41.826240: Epoch time: 98.38 s 
2023-09-26 15:21:41.826291: Yayy! New best EMA pseudo Dice: 0.4553 
2023-09-26 15:21:45.062685:  
2023-09-26 15:21:45.062999: Epoch 16 
2023-09-26 15:21:45.063119: Current learning rate: 0.00986 
2023-09-26 15:23:23.495650: train_loss -0.6657 
2023-09-26 15:23:23.495974: val_loss -0.5707 
2023-09-26 15:23:23.496059: Pseudo dice [0.8579, 0.5702, 0.638] 
2023-09-26 15:23:23.496139: Epoch time: 98.43 s 
2023-09-26 15:23:23.496193: Yayy! New best EMA pseudo Dice: 0.4786 
2023-09-26 15:23:26.572808:  
2023-09-26 15:23:26.573307: Epoch 17 
2023-09-26 15:23:26.573413: Current learning rate: 0.00985 
2023-09-26 15:25:05.424905: train_loss -0.6646 
2023-09-26 15:25:05.425500: val_loss -0.5336 
2023-09-26 15:25:05.425587: Pseudo dice [0.857, 0.4996, 0.504] 
2023-09-26 15:25:05.425694: Epoch time: 98.85 s 
2023-09-26 15:25:05.425758: Yayy! New best EMA pseudo Dice: 0.4928 
2023-09-26 15:25:08.544494:  
2023-09-26 15:25:08.544755: Epoch 18 
2023-09-26 15:25:08.544922: Current learning rate: 0.00984 
2023-09-26 15:26:47.211396: train_loss -0.6841 
2023-09-26 15:26:47.211712: val_loss -0.6065 
2023-09-26 15:26:47.211796: Pseudo dice [0.8665, 0.5816, 0.6302] 
2023-09-26 15:26:47.211869: Epoch time: 98.67 s 
2023-09-26 15:26:47.211923: Yayy! New best EMA pseudo Dice: 0.5128 
2023-09-26 15:26:50.120238:  
2023-09-26 15:26:50.120387: Epoch 19 
2023-09-26 15:26:50.120473: Current learning rate: 0.00983 
2023-09-26 15:28:28.793172: train_loss -0.6588 
2023-09-26 15:28:28.793417: val_loss -0.5718 
2023-09-26 15:28:28.793494: Pseudo dice [0.8373, 0.6081, 0.618] 
2023-09-26 15:28:28.793563: Epoch time: 98.67 s 
2023-09-26 15:28:28.793614: Yayy! New best EMA pseudo Dice: 0.5303 
2023-09-26 15:28:31.611101:  
2023-09-26 15:28:31.611345: Epoch 20 
2023-09-26 15:28:31.611443: Current learning rate: 0.00982 
2023-09-26 15:30:10.005565: train_loss -0.6591 
2023-09-26 15:30:10.005792: val_loss -0.5954 
2023-09-26 15:30:10.005871: Pseudo dice [0.8461, 0.6028, 0.6312] 
2023-09-26 15:30:10.005942: Epoch time: 98.4 s 
2023-09-26 15:30:10.005996: Yayy! New best EMA pseudo Dice: 0.5466 
2023-09-26 15:30:12.925924:  
2023-09-26 15:30:12.926076: Epoch 21 
2023-09-26 15:30:12.926192: Current learning rate: 0.00981 
2023-09-26 15:31:51.447158: train_loss -0.6817 
2023-09-26 15:31:51.447457: val_loss -0.5713 
2023-09-26 15:31:51.447556: Pseudo dice [0.8306, 0.5266, 0.5599] 
2023-09-26 15:31:51.447642: Epoch time: 98.52 s 
2023-09-26 15:31:51.447711: Yayy! New best EMA pseudo Dice: 0.5558 
2023-09-26 15:31:54.399751:  
2023-09-26 15:31:54.399962: Epoch 22 
2023-09-26 15:31:54.400057: Current learning rate: 0.0098 
2023-09-26 15:33:33.305780: train_loss -0.7079 
2023-09-26 15:33:33.306031: val_loss -0.5913 
2023-09-26 15:33:33.306119: Pseudo dice [0.8689, 0.566, 0.6198] 
2023-09-26 15:33:33.306193: Epoch time: 98.91 s 
2023-09-26 15:33:33.306245: Yayy! New best EMA pseudo Dice: 0.5687 
2023-09-26 15:33:36.443537:  
2023-09-26 15:33:36.443807: Epoch 23 
2023-09-26 15:33:36.443975: Current learning rate: 0.00979 
2023-09-26 15:35:14.362197: train_loss -0.7059 
2023-09-26 15:35:14.362506: val_loss -0.6022 
2023-09-26 15:35:14.362587: Pseudo dice [0.8528, 0.6005, 0.5966] 
2023-09-26 15:35:14.362660: Epoch time: 97.92 s 
2023-09-26 15:35:14.362714: Yayy! New best EMA pseudo Dice: 0.5802 
2023-09-26 15:35:17.268100:  
2023-09-26 15:35:17.268318: Epoch 24 
2023-09-26 15:35:17.268418: Current learning rate: 0.00978 
2023-09-26 15:36:55.548155: train_loss -0.6923 
2023-09-26 15:36:55.548426: val_loss -0.5625 
2023-09-26 15:36:55.548536: Pseudo dice [0.8686, 0.5155, 0.5648] 
2023-09-26 15:36:55.548622: Epoch time: 98.28 s 
2023-09-26 15:36:55.548690: Yayy! New best EMA pseudo Dice: 0.5871 
2023-09-26 15:36:58.318140:  
2023-09-26 15:36:58.318297: Epoch 25 
2023-09-26 15:36:58.318386: Current learning rate: 0.00977 
2023-09-26 15:38:36.591740: train_loss -0.6907 
2023-09-26 15:38:36.591996: val_loss -0.5799 
2023-09-26 15:38:36.592076: Pseudo dice [0.8626, 0.5176, 0.6067] 
2023-09-26 15:38:36.592145: Epoch time: 98.27 s 
2023-09-26 15:38:36.592197: Yayy! New best EMA pseudo Dice: 0.5947 
2023-09-26 15:38:39.381414:  
2023-09-26 15:38:39.381567: Epoch 26 
2023-09-26 15:38:39.381653: Current learning rate: 0.00977 
2023-09-26 15:40:17.459971: train_loss -0.6983 
2023-09-26 15:40:17.460210: val_loss -0.5854 
2023-09-26 15:40:17.460286: Pseudo dice [0.8643, 0.5681, 0.6504] 
2023-09-26 15:40:17.460353: Epoch time: 98.08 s 
2023-09-26 15:40:17.460403: Yayy! New best EMA pseudo Dice: 0.6046 
2023-09-26 15:40:20.214376:  
2023-09-26 15:40:20.214796: Epoch 27 
2023-09-26 15:40:20.214888: Current learning rate: 0.00976 
2023-09-26 15:41:58.629452: train_loss -0.6961 
2023-09-26 15:41:58.629699: val_loss -0.5605 
2023-09-26 15:41:58.629778: Pseudo dice [0.8465, 0.5996, 0.5285] 
2023-09-26 15:41:58.629848: Epoch time: 98.42 s 
2023-09-26 15:41:58.629900: Yayy! New best EMA pseudo Dice: 0.61 
2023-09-26 15:42:01.428874:  
2023-09-26 15:42:01.429194: Epoch 28 
2023-09-26 15:42:01.429333: Current learning rate: 0.00975 
2023-09-26 15:43:39.559769: train_loss -0.7206 
2023-09-26 15:43:39.560056: val_loss -0.6381 
2023-09-26 15:43:39.560153: Pseudo dice [0.8719, 0.6453, 0.6649] 
2023-09-26 15:43:39.560240: Epoch time: 98.13 s 
2023-09-26 15:43:39.560309: Yayy! New best EMA pseudo Dice: 0.6217 
2023-09-26 15:43:42.475978:  
2023-09-26 15:43:42.476175: Epoch 29 
2023-09-26 15:43:42.476315: Current learning rate: 0.00974 
2023-09-26 15:45:20.880898: train_loss -0.7341 
2023-09-26 15:45:20.881142: val_loss -0.6072 
2023-09-26 15:45:20.881220: Pseudo dice [0.8435, 0.6182, 0.6233] 
2023-09-26 15:45:20.881288: Epoch time: 98.41 s 
2023-09-26 15:45:20.881340: Yayy! New best EMA pseudo Dice: 0.629 
2023-09-26 15:45:23.701457:  
2023-09-26 15:45:23.701602: Epoch 30 
2023-09-26 15:45:23.701689: Current learning rate: 0.00973 
2023-09-26 15:47:01.833556: train_loss -0.7329 
2023-09-26 15:47:01.833813: val_loss -0.6169 
2023-09-26 15:47:01.833894: Pseudo dice [0.8718, 0.634, 0.5713] 
2023-09-26 15:47:01.833963: Epoch time: 98.13 s 
2023-09-26 15:47:01.834016: Yayy! New best EMA pseudo Dice: 0.6354 
2023-09-26 15:47:04.911878:  
2023-09-26 15:47:04.912043: Epoch 31 
2023-09-26 15:47:04.912151: Current learning rate: 0.00972 
2023-09-26 15:48:43.182239: train_loss -0.7382 
2023-09-26 15:48:43.182504: val_loss -0.6098 
2023-09-26 15:48:43.182583: Pseudo dice [0.8753, 0.616, 0.6179] 
2023-09-26 15:48:43.182654: Epoch time: 98.27 s 
2023-09-26 15:48:43.182709: Yayy! New best EMA pseudo Dice: 0.6421 
2023-09-26 15:48:45.953810:  
2023-09-26 15:48:45.954038: Epoch 32 
2023-09-26 15:48:45.954137: Current learning rate: 0.00971 
2023-09-26 15:50:24.260185: train_loss -0.7444 
2023-09-26 15:50:24.260433: val_loss -0.5604 
2023-09-26 15:50:24.260511: Pseudo dice [0.8643, 0.5348, 0.5369] 
2023-09-26 15:50:24.260582: Epoch time: 98.31 s 
2023-09-26 15:50:24.260634: Yayy! New best EMA pseudo Dice: 0.6425 
2023-09-26 15:50:27.256847:  
2023-09-26 15:50:27.257074: Epoch 33 
2023-09-26 15:50:27.257163: Current learning rate: 0.0097 
2023-09-26 15:52:05.600385: train_loss -0.7335 
2023-09-26 15:52:05.600630: val_loss -0.6021 
2023-09-26 15:52:05.600712: Pseudo dice [0.8814, 0.5864, 0.6802] 
2023-09-26 15:52:05.600787: Epoch time: 98.34 s 
2023-09-26 15:52:05.600841: Yayy! New best EMA pseudo Dice: 0.6498 
2023-09-26 15:52:08.738039:  
2023-09-26 15:52:08.738198: Epoch 34 
2023-09-26 15:52:08.738300: Current learning rate: 0.00969 
2023-09-26 15:53:46.839957: train_loss -0.7317 
2023-09-26 15:53:46.840235: val_loss -0.5868 
2023-09-26 15:53:46.840319: Pseudo dice [0.8682, 0.5514, 0.6675] 
2023-09-26 15:53:46.840394: Epoch time: 98.1 s 
2023-09-26 15:53:46.840451: Yayy! New best EMA pseudo Dice: 0.6544 
2023-09-26 15:53:49.620863:  
2023-09-26 15:53:49.621049: Epoch 35 
2023-09-26 15:53:49.621182: Current learning rate: 0.00968 
2023-09-26 15:55:27.633735: train_loss -0.7487 
2023-09-26 15:55:27.633987: val_loss -0.5729 
2023-09-26 15:55:27.634066: Pseudo dice [0.8656, 0.5613, 0.6046] 
2023-09-26 15:55:27.634146: Epoch time: 98.01 s 
2023-09-26 15:55:27.634201: Yayy! New best EMA pseudo Dice: 0.6567 
2023-09-26 15:55:30.471805:  
2023-09-26 15:55:30.471952: Epoch 36 
2023-09-26 15:55:30.472041: Current learning rate: 0.00968 
2023-09-26 15:57:08.712295: train_loss -0.7599 
2023-09-26 15:57:08.712532: val_loss -0.5886 
2023-09-26 15:57:08.712609: Pseudo dice [0.8625, 0.5198, 0.6311] 
2023-09-26 15:57:08.712678: Epoch time: 98.24 s 
2023-09-26 15:57:08.712729: Yayy! New best EMA pseudo Dice: 0.6581 
2023-09-26 15:57:11.647329:  
2023-09-26 15:57:11.647594: Epoch 37 
2023-09-26 15:57:11.647689: Current learning rate: 0.00967 
2023-09-26 15:58:51.175333: train_loss -0.7445 
2023-09-26 15:58:51.175583: val_loss -0.4743 
2023-09-26 15:58:51.175664: Pseudo dice [0.8443, 0.5965, 0.1943] 
2023-09-26 15:58:51.175735: Epoch time: 99.53 s 
2023-09-26 15:58:52.641046:  
2023-09-26 15:58:52.641185: Epoch 38 
2023-09-26 15:58:52.641273: Current learning rate: 0.00966 
2023-09-26 16:00:32.496516: train_loss -0.6973 
2023-09-26 16:00:32.496764: val_loss -0.6092 
2023-09-26 16:00:32.496848: Pseudo dice [0.861, 0.6363, 0.6078] 
2023-09-26 16:00:32.496918: Epoch time: 99.86 s 
2023-09-26 16:00:33.786483:  
2023-09-26 16:00:33.786631: Epoch 39 
2023-09-26 16:00:33.786718: Current learning rate: 0.00965 
2023-09-26 16:02:13.619193: train_loss -0.6905 
2023-09-26 16:02:13.619448: val_loss -0.5922 
2023-09-26 16:02:13.619528: Pseudo dice [0.86, 0.5617, 0.6203] 
2023-09-26 16:02:13.619598: Epoch time: 99.83 s 
2023-09-26 16:02:14.965666:  
2023-09-26 16:02:14.966019: Epoch 40 
2023-09-26 16:02:14.966139: Current learning rate: 0.00964 
2023-09-26 16:03:54.831292: train_loss -0.7147 
2023-09-26 16:03:54.831537: val_loss -0.5862 
2023-09-26 16:03:54.831613: Pseudo dice [0.8476, 0.5878, 0.6277] 
2023-09-26 16:03:54.831683: Epoch time: 99.87 s 
2023-09-26 16:03:54.831738: Yayy! New best EMA pseudo Dice: 0.6584 
2023-09-26 16:03:57.763807:  
2023-09-26 16:03:57.764037: Epoch 41 
2023-09-26 16:03:57.764130: Current learning rate: 0.00963 
2023-09-26 16:05:37.756851: train_loss -0.7294 
2023-09-26 16:05:37.757100: val_loss -0.6383 
2023-09-26 16:05:37.757179: Pseudo dice [0.8706, 0.6269, 0.7087] 
2023-09-26 16:05:37.757248: Epoch time: 99.99 s 
2023-09-26 16:05:37.757301: Yayy! New best EMA pseudo Dice: 0.6661 
2023-09-26 16:05:40.637719:  
2023-09-26 16:05:40.637974: Epoch 42 
2023-09-26 16:05:40.638082: Current learning rate: 0.00962 
2023-09-26 16:07:20.898738: train_loss -0.7503 
2023-09-26 16:07:20.899088: val_loss -0.6286 
2023-09-26 16:07:20.899205: Pseudo dice [0.8559, 0.6262, 0.6943] 
2023-09-26 16:07:20.899297: Epoch time: 100.26 s 
2023-09-26 16:07:20.899365: Yayy! New best EMA pseudo Dice: 0.672 
2023-09-26 16:07:23.696514:  
2023-09-26 16:07:23.696757: Epoch 43 
2023-09-26 16:07:23.696858: Current learning rate: 0.00961 
2023-09-26 16:09:03.616997: train_loss -0.7679 
2023-09-26 16:09:03.617234: val_loss -0.6179 
2023-09-26 16:09:03.617313: Pseudo dice [0.8694, 0.5857, 0.654] 
2023-09-26 16:09:03.617383: Epoch time: 99.92 s 
2023-09-26 16:09:03.617435: Yayy! New best EMA pseudo Dice: 0.6751 
2023-09-26 16:09:06.555995:  
2023-09-26 16:09:06.556142: Epoch 44 
2023-09-26 16:09:06.556230: Current learning rate: 0.0096 
2023-09-26 16:10:46.559490: train_loss -0.7661 
2023-09-26 16:10:46.559749: val_loss -0.6213 
2023-09-26 16:10:46.559831: Pseudo dice [0.8763, 0.6233, 0.6131] 
2023-09-26 16:10:46.559904: Epoch time: 100.0 s 
2023-09-26 16:10:46.559958: Yayy! New best EMA pseudo Dice: 0.678 
2023-09-26 16:10:49.652139:  
2023-09-26 16:10:49.652474: Epoch 45 
2023-09-26 16:10:49.652585: Current learning rate: 0.00959 
2023-09-26 16:12:29.742438: train_loss -0.7644 
2023-09-26 16:12:29.742688: val_loss -0.6013 
2023-09-26 16:12:29.742764: Pseudo dice [0.8804, 0.5363, 0.6618] 
2023-09-26 16:12:29.742837: Epoch time: 100.09 s 
2023-09-26 16:12:29.742889: Yayy! New best EMA pseudo Dice: 0.6795 
2023-09-26 16:12:32.609520:  
2023-09-26 16:12:32.609675: Epoch 46 
2023-09-26 16:12:32.609765: Current learning rate: 0.00959 
2023-09-26 16:14:12.425825: train_loss -0.7589 
2023-09-26 16:14:12.426087: val_loss -0.6288 
2023-09-26 16:14:12.426188: Pseudo dice [0.8687, 0.5867, 0.6164] 
2023-09-26 16:14:12.426261: Epoch time: 99.82 s 
2023-09-26 16:14:12.426314: Yayy! New best EMA pseudo Dice: 0.6806 
2023-09-26 16:14:15.438512:  
2023-09-26 16:14:15.438998: Epoch 47 
2023-09-26 16:14:15.439161: Current learning rate: 0.00958 
2023-09-26 16:15:55.325628: train_loss -0.7688 
2023-09-26 16:15:55.325879: val_loss -0.657 
2023-09-26 16:15:55.325956: Pseudo dice [0.8752, 0.6254, 0.6579] 
2023-09-26 16:15:55.326025: Epoch time: 99.89 s 
2023-09-26 16:15:55.326076: Yayy! New best EMA pseudo Dice: 0.6845 
2023-09-26 16:15:58.261224:  
2023-09-26 16:15:58.261462: Epoch 48 
2023-09-26 16:15:58.261554: Current learning rate: 0.00957 
2023-09-26 16:17:38.602425: train_loss -0.7687 
2023-09-26 16:17:38.602712: val_loss -0.5918 
2023-09-26 16:17:38.602810: Pseudo dice [0.8841, 0.5768, 0.6003] 
2023-09-26 16:17:38.602899: Epoch time: 100.34 s 
2023-09-26 16:17:38.602966: Yayy! New best EMA pseudo Dice: 0.6848 
2023-09-26 16:17:41.523487:  
2023-09-26 16:17:41.523630: Epoch 49 
2023-09-26 16:17:41.523717: Current learning rate: 0.00956 
2023-09-26 16:19:20.818175: train_loss -0.7782 
2023-09-26 16:19:20.818424: val_loss -0.6488 
2023-09-26 16:19:20.818501: Pseudo dice [0.8752, 0.6191, 0.7023] 
2023-09-26 16:19:20.818569: Epoch time: 99.3 s 
2023-09-26 16:19:21.145236: Yayy! New best EMA pseudo Dice: 0.6895 
2023-09-26 16:19:24.090698:  
2023-09-26 16:19:24.091057: Epoch 50 
2023-09-26 16:19:24.091153: Current learning rate: 0.00955 
2023-09-26 16:21:02.679270: train_loss -0.7814 
2023-09-26 16:21:02.679538: val_loss -0.6249 
2023-09-26 16:21:02.679622: Pseudo dice [0.8817, 0.5573, 0.6861] 
2023-09-26 16:21:02.679695: Epoch time: 98.59 s 
2023-09-26 16:21:02.679750: Yayy! New best EMA pseudo Dice: 0.6914 
2023-09-26 16:21:05.413919:  
2023-09-26 16:21:05.414134: Epoch 51 
2023-09-26 16:21:05.414231: Current learning rate: 0.00954 
2023-09-26 16:22:43.239608: train_loss -0.7741 
2023-09-26 16:22:43.239876: val_loss -0.6354 
2023-09-26 16:22:43.239957: Pseudo dice [0.875, 0.6221, 0.6287] 
2023-09-26 16:22:43.240030: Epoch time: 97.83 s 
2023-09-26 16:22:43.240084: Yayy! New best EMA pseudo Dice: 0.6931 
2023-09-26 16:22:46.081319:  
2023-09-26 16:22:46.081562: Epoch 52 
2023-09-26 16:22:46.081648: Current learning rate: 0.00953 
2023-09-26 16:24:24.453326: train_loss -0.7793 
2023-09-26 16:24:24.453579: val_loss -0.6275 
2023-09-26 16:24:24.453660: Pseudo dice [0.8837, 0.6356, 0.6501] 
2023-09-26 16:24:24.453732: Epoch time: 98.37 s 
2023-09-26 16:24:24.453785: Yayy! New best EMA pseudo Dice: 0.6961 
2023-09-26 16:24:27.320361:  
2023-09-26 16:24:27.320528: Epoch 53 
2023-09-26 16:24:27.320617: Current learning rate: 0.00952 
2023-09-26 16:26:05.105119: train_loss -0.7691 
2023-09-26 16:26:05.105377: val_loss -0.5585 
2023-09-26 16:26:05.105465: Pseudo dice [0.8504, 0.6254, 0.4905] 
2023-09-26 16:26:05.105547: Epoch time: 97.79 s 
2023-09-26 16:26:06.345599:  
2023-09-26 16:26:06.345756: Epoch 54 
2023-09-26 16:26:06.345860: Current learning rate: 0.00951 
2023-09-26 16:27:44.119569: train_loss -0.7531 
2023-09-26 16:27:44.119807: val_loss -0.6019 
2023-09-26 16:27:44.119886: Pseudo dice [0.8541, 0.5915, 0.6421] 
2023-09-26 16:27:44.119958: Epoch time: 97.78 s 
2023-09-26 16:27:45.797410:  
2023-09-26 16:27:45.797563: Epoch 55 
2023-09-26 16:27:45.797667: Current learning rate: 0.0095 
2023-09-26 16:29:25.707086: train_loss -0.7627 
2023-09-26 16:29:25.707346: val_loss -0.5762 
2023-09-26 16:29:25.707430: Pseudo dice [0.8597, 0.5978, 0.5605] 
2023-09-26 16:29:25.707506: Epoch time: 99.91 s 
2023-09-26 16:29:26.918525:  
2023-09-26 16:29:26.918760: Epoch 56 
2023-09-26 16:29:26.918860: Current learning rate: 0.00949 
2023-09-26 16:31:05.253291: train_loss -0.7697 
2023-09-26 16:31:05.253559: val_loss -0.5939 
2023-09-26 16:31:05.253646: Pseudo dice [0.8786, 0.5778, 0.5851] 
2023-09-26 16:31:05.253723: Epoch time: 98.34 s 
2023-09-26 16:31:06.480865:  
2023-09-26 16:31:06.481149: Epoch 57 
2023-09-26 16:31:06.481259: Current learning rate: 0.00949 
2023-09-26 16:32:44.798662: train_loss -0.7821 
2023-09-26 16:32:44.798918: val_loss -0.6184 
2023-09-26 16:32:44.798999: Pseudo dice [0.8767, 0.5747, 0.6153] 
2023-09-26 16:32:44.799074: Epoch time: 98.32 s 
2023-09-26 16:32:46.044974:  
2023-09-26 16:32:46.045158: Epoch 58 
2023-09-26 16:32:46.045273: Current learning rate: 0.00948 
2023-09-26 16:34:23.873562: train_loss -0.7931 
2023-09-26 16:34:23.873835: val_loss -0.6276 
2023-09-26 16:34:23.873918: Pseudo dice [0.8775, 0.6351, 0.6519] 
2023-09-26 16:34:23.873989: Epoch time: 97.83 s 
2023-09-26 16:34:25.113337:  
2023-09-26 16:34:25.113480: Epoch 59 
2023-09-26 16:34:25.113569: Current learning rate: 0.00947 
2023-09-26 16:36:05.286895: train_loss -0.7757 
2023-09-26 16:36:05.287154: val_loss -0.5592 
2023-09-26 16:36:05.287245: Pseudo dice [0.8616, 0.4989, 0.5646] 
2023-09-26 16:36:05.287327: Epoch time: 100.17 s 
2023-09-26 16:36:06.602581:  
2023-09-26 16:36:06.602734: Epoch 60 
2023-09-26 16:36:06.602823: Current learning rate: 0.00946 
2023-09-26 16:37:46.536026: train_loss -0.7799 
2023-09-26 16:37:46.536285: val_loss -0.6413 
2023-09-26 16:37:46.536365: Pseudo dice [0.8871, 0.6155, 0.668] 
2023-09-26 16:37:46.536435: Epoch time: 99.93 s 
2023-09-26 16:37:47.970508:  
2023-09-26 16:37:47.970697: Epoch 61 
2023-09-26 16:37:47.970791: Current learning rate: 0.00945 
2023-09-26 16:39:26.139244: train_loss -0.7827 
2023-09-26 16:39:26.139503: val_loss -0.6077 
2023-09-26 16:39:26.139586: Pseudo dice [0.861, 0.5637, 0.648] 
2023-09-26 16:39:26.139661: Epoch time: 98.17 s 
2023-09-26 16:39:27.390783:  
2023-09-26 16:39:27.391279: Epoch 62 
2023-09-26 16:39:27.391382: Current learning rate: 0.00944 
2023-09-26 16:41:06.004913: train_loss -0.7631 
2023-09-26 16:41:06.005180: val_loss -0.6286 
2023-09-26 16:41:06.005265: Pseudo dice [0.8809, 0.688, 0.6209] 
2023-09-26 16:41:06.005338: Epoch time: 98.62 s 
2023-09-26 16:41:07.272927:  
2023-09-26 16:41:07.273244: Epoch 63 
2023-09-26 16:41:07.273341: Current learning rate: 0.00943 
2023-09-26 16:42:47.123831: train_loss -0.763 
2023-09-26 16:42:47.124077: val_loss -0.6274 
2023-09-26 16:42:47.124157: Pseudo dice [0.8574, 0.6905, 0.65] 
2023-09-26 16:42:47.124231: Epoch time: 99.85 s 
2023-09-26 16:42:47.124282: Yayy! New best EMA pseudo Dice: 0.6988 
2023-09-26 16:42:49.871136:  
2023-09-26 16:42:49.871442: Epoch 64 
2023-09-26 16:42:49.871553: Current learning rate: 0.00942 
2023-09-26 16:44:29.750191: train_loss -0.7669 
2023-09-26 16:44:29.750427: val_loss -0.6062 
2023-09-26 16:44:29.750503: Pseudo dice [0.8513, 0.6085, 0.5961] 
2023-09-26 16:44:29.750573: Epoch time: 99.88 s 
2023-09-26 16:44:31.060750:  
2023-09-26 16:44:31.060899: Epoch 65 
2023-09-26 16:44:31.060990: Current learning rate: 0.00941 
2023-09-26 16:46:11.065049: train_loss -0.7791 
2023-09-26 16:46:11.065315: val_loss -0.6233 
2023-09-26 16:46:11.065394: Pseudo dice [0.8861, 0.607, 0.6246] 
2023-09-26 16:46:11.065470: Epoch time: 100.01 s 
2023-09-26 16:46:12.311303:  
2023-09-26 16:46:12.311453: Epoch 66 
2023-09-26 16:46:12.311539: Current learning rate: 0.0094 
2023-09-26 16:47:51.856090: train_loss -0.7709 
2023-09-26 16:47:51.856340: val_loss -0.6067 
2023-09-26 16:47:51.856414: Pseudo dice [0.8789, 0.6181, 0.6639] 
2023-09-26 16:47:51.856486: Epoch time: 99.55 s 
2023-09-26 16:47:51.856538: Yayy! New best EMA pseudo Dice: 0.7005 
2023-09-26 16:47:54.842281:  
2023-09-26 16:47:54.842420: Epoch 67 
2023-09-26 16:47:54.842511: Current learning rate: 0.00939 
2023-09-26 16:49:34.878226: train_loss -0.7757 
2023-09-26 16:49:34.878477: val_loss -0.626 
2023-09-26 16:49:34.878553: Pseudo dice [0.8691, 0.6101, 0.6628] 
2023-09-26 16:49:34.878621: Epoch time: 100.04 s 
2023-09-26 16:49:34.878674: Yayy! New best EMA pseudo Dice: 0.7018 
2023-09-26 16:49:38.098993:  
2023-09-26 16:49:38.099454: Epoch 68 
2023-09-26 16:49:38.099619: Current learning rate: 0.00939 
2023-09-26 16:51:18.066060: train_loss -0.7908 
2023-09-26 16:51:18.066709: val_loss -0.5909 
2023-09-26 16:51:18.066801: Pseudo dice [0.8847, 0.6294, 0.6041] 
2023-09-26 16:51:18.066883: Epoch time: 99.97 s 
2023-09-26 16:51:18.066947: Yayy! New best EMA pseudo Dice: 0.7022 
2023-09-26 16:51:21.306013:  
2023-09-26 16:51:21.306587: Epoch 69 
2023-09-26 16:51:21.306721: Current learning rate: 0.00938 
2023-09-26 16:52:59.648851: train_loss -0.7854 
2023-09-26 16:52:59.649399: val_loss -0.6015 
2023-09-26 16:52:59.649488: Pseudo dice [0.8773, 0.5746, 0.6238] 
2023-09-26 16:52:59.649581: Epoch time: 98.34 s 
2023-09-26 16:53:01.080436:  
2023-09-26 16:53:01.080826: Epoch 70 
2023-09-26 16:53:01.080940: Current learning rate: 0.00937 
2023-09-26 16:54:39.099026: train_loss -0.7635 
2023-09-26 16:54:39.099304: val_loss -0.5769 
2023-09-26 16:54:39.099389: Pseudo dice [0.8644, 0.5637, 0.5882] 
2023-09-26 16:54:39.099467: Epoch time: 98.02 s 
2023-09-26 16:54:40.392510:  
2023-09-26 16:54:40.392800: Epoch 71 
2023-09-26 16:54:40.392900: Current learning rate: 0.00936 
2023-09-26 16:56:20.862143: train_loss -0.7767 
2023-09-26 16:56:20.862398: val_loss -0.6015 
2023-09-26 16:56:20.862478: Pseudo dice [0.8554, 0.5311, 0.6569] 
2023-09-26 16:56:20.862551: Epoch time: 100.47 s 
2023-09-26 16:56:22.138789:  
2023-09-26 16:56:22.138962: Epoch 72 
2023-09-26 16:56:22.139062: Current learning rate: 0.00935 
2023-09-26 16:58:01.576714: train_loss -0.781 
2023-09-26 16:58:01.576974: val_loss -0.6337 
2023-09-26 16:58:01.577055: Pseudo dice [0.8849, 0.6193, 0.6603] 
2023-09-26 16:58:01.577128: Epoch time: 99.44 s 
2023-09-26 16:58:03.025021:  
2023-09-26 16:58:03.025277: Epoch 73 
2023-09-26 16:58:03.025419: Current learning rate: 0.00934 
2023-09-26 16:59:42.765178: train_loss -0.7902 
2023-09-26 16:59:42.765452: val_loss -0.5869 
2023-09-26 16:59:42.765547: Pseudo dice [0.8662, 0.6405, 0.5942] 
2023-09-26 16:59:42.765634: Epoch time: 99.74 s 
2023-09-26 16:59:44.408684:  
2023-09-26 16:59:44.408867: Epoch 74 
2023-09-26 16:59:44.408973: Current learning rate: 0.00933 
2023-09-26 17:01:23.897749: train_loss -0.7877 
2023-09-26 17:01:23.898027: val_loss -0.5603 
2023-09-26 17:01:23.898142: Pseudo dice [0.8611, 0.5789, 0.56] 
2023-09-26 17:01:23.898236: Epoch time: 99.49 s 
2023-09-26 17:01:25.509285:  
2023-09-26 17:01:25.509534: Epoch 75 
2023-09-26 17:01:25.509639: Current learning rate: 0.00932 
2023-09-26 17:03:05.298750: train_loss -0.7962 
2023-09-26 17:03:05.299002: val_loss -0.549 
2023-09-26 17:03:05.299078: Pseudo dice [0.8745, 0.5533, 0.4914] 
2023-09-26 17:03:05.299154: Epoch time: 99.79 s 
2023-09-26 17:03:06.558424:  
2023-09-26 17:03:06.558693: Epoch 76 
2023-09-26 17:03:06.558794: Current learning rate: 0.00931 
2023-09-26 17:04:46.859828: train_loss -0.7998 
2023-09-26 17:04:46.860173: val_loss -0.6214 
2023-09-26 17:04:46.860261: Pseudo dice [0.8797, 0.5769, 0.6231] 
2023-09-26 17:04:46.860351: Epoch time: 100.3 s 
2023-09-26 17:04:48.194162:  
2023-09-26 17:04:48.194328: Epoch 77 
2023-09-26 17:04:48.194419: Current learning rate: 0.0093 
2023-09-26 17:06:28.089001: train_loss -0.8043 
2023-09-26 17:06:28.089285: val_loss -0.6469 
2023-09-26 17:06:28.089365: Pseudo dice [0.8959, 0.6313, 0.6536] 
2023-09-26 17:06:28.089438: Epoch time: 99.9 s 
2023-09-26 17:06:29.408542:  
2023-09-26 17:06:29.408775: Epoch 78 
2023-09-26 17:06:29.408876: Current learning rate: 0.0093 
2023-09-26 17:08:09.475534: train_loss -0.7975 
2023-09-26 17:08:09.476190: val_loss -0.6281 
2023-09-26 17:08:09.476592: Pseudo dice [0.8904, 0.6212, 0.6232] 
2023-09-26 17:08:09.476694: Epoch time: 100.07 s 
2023-09-26 17:08:11.094167:  
2023-09-26 17:08:11.094324: Epoch 79 
2023-09-26 17:08:11.094412: Current learning rate: 0.00929 
2023-09-26 17:09:51.275030: train_loss -0.8021 
2023-09-26 17:09:51.275410: val_loss -0.5746 
2023-09-26 17:09:51.275512: Pseudo dice [0.8745, 0.5785, 0.4961] 
2023-09-26 17:09:51.275603: Epoch time: 100.18 s 
2023-09-26 17:09:52.653074:  
2023-09-26 17:09:52.653356: Epoch 80 
2023-09-26 17:09:52.653450: Current learning rate: 0.00928 
2023-09-26 17:11:32.910068: train_loss -0.8062 
2023-09-26 17:11:32.910383: val_loss -0.641 
2023-09-26 17:11:32.910483: Pseudo dice [0.8768, 0.6292, 0.641] 
2023-09-26 17:11:32.910576: Epoch time: 100.26 s 
2023-09-26 17:11:34.583775:  
2023-09-26 17:11:34.584237: Epoch 81 
2023-09-26 17:11:34.584600: Current learning rate: 0.00927 
2023-09-26 17:13:14.543550: train_loss -0.8005 
2023-09-26 17:13:14.543850: val_loss -0.6262 
2023-09-26 17:13:14.543935: Pseudo dice [0.8818, 0.6117, 0.6747] 
2023-09-26 17:13:14.544014: Epoch time: 99.96 s 
2023-09-26 17:13:15.869439:  
2023-09-26 17:13:15.869614: Epoch 82 
2023-09-26 17:13:15.869703: Current learning rate: 0.00926 
2023-09-26 17:14:55.723233: train_loss -0.8024 
2023-09-26 17:14:55.723879: val_loss -0.5765 
2023-09-26 17:14:55.723969: Pseudo dice [0.8802, 0.5396, 0.5751] 
2023-09-26 17:14:55.724068: Epoch time: 99.85 s 
2023-09-26 17:14:56.951076:  
2023-09-26 17:14:56.951280: Epoch 83 
2023-09-26 17:14:56.951402: Current learning rate: 0.00925 
2023-09-26 17:16:37.616437: train_loss -0.7901 
2023-09-26 17:16:37.616730: val_loss -0.5942 
2023-09-26 17:16:37.616827: Pseudo dice [0.8817, 0.582, 0.6207] 
2023-09-26 17:16:37.616913: Epoch time: 100.67 s 
2023-09-26 17:16:38.839702:  
2023-09-26 17:16:38.839959: Epoch 84 
2023-09-26 17:16:38.840067: Current learning rate: 0.00924 
2023-09-26 17:18:20.130785: train_loss -0.7931 
2023-09-26 17:18:20.131597: val_loss -0.5559 
2023-09-26 17:18:20.131716: Pseudo dice [0.885, 0.6082, 0.5411] 
2023-09-26 17:18:20.131856: Epoch time: 101.29 s 
2023-09-26 17:18:21.369645:  
2023-09-26 17:18:21.369922: Epoch 85 
2023-09-26 17:18:21.370025: Current learning rate: 0.00923 
2023-09-26 17:20:02.880080: train_loss -0.8067 
2023-09-26 17:20:02.880373: val_loss -0.6646 
2023-09-26 17:20:02.880459: Pseudo dice [0.8764, 0.6606, 0.7124] 
2023-09-26 17:20:02.880549: Epoch time: 101.51 s 
2023-09-26 17:20:04.392285:  
2023-09-26 17:20:04.392820: Epoch 86 
2023-09-26 17:20:04.392941: Current learning rate: 0.00922 
2023-09-26 17:21:45.902554: train_loss -0.804 
2023-09-26 17:21:45.902822: val_loss -0.6169 
2023-09-26 17:21:45.902903: Pseudo dice [0.8783, 0.5553, 0.6482] 
2023-09-26 17:21:45.902974: Epoch time: 101.51 s 
2023-09-26 17:21:47.147736:  
2023-09-26 17:21:47.147908: Epoch 87 
2023-09-26 17:21:47.148004: Current learning rate: 0.00921 
2023-09-26 17:23:28.280320: train_loss -0.8127 
2023-09-26 17:23:28.280602: val_loss -0.6364 
2023-09-26 17:23:28.280685: Pseudo dice [0.8942, 0.6074, 0.6719] 
2023-09-26 17:23:28.280759: Epoch time: 101.13 s 
2023-09-26 17:23:29.636828:  
2023-09-26 17:23:29.637142: Epoch 88 
2023-09-26 17:23:29.637239: Current learning rate: 0.0092 
2023-09-26 17:25:10.680956: train_loss -0.8165 
2023-09-26 17:25:10.681247: val_loss -0.6195 
2023-09-26 17:25:10.681341: Pseudo dice [0.8854, 0.5774, 0.6352] 
2023-09-26 17:25:10.681418: Epoch time: 101.05 s 
2023-09-26 17:25:12.046798:  
2023-09-26 17:25:12.047058: Epoch 89 
2023-09-26 17:25:12.047220: Current learning rate: 0.0092 
2023-09-26 17:26:52.462556: train_loss -0.8225 
2023-09-26 17:26:52.462862: val_loss -0.6118 
2023-09-26 17:26:52.462939: Pseudo dice [0.8903, 0.602, 0.5933] 
2023-09-26 17:26:52.463011: Epoch time: 100.42 s 
2023-09-26 17:26:53.718862:  
2023-09-26 17:26:53.719177: Epoch 90 
2023-09-26 17:26:53.719315: Current learning rate: 0.00919 
2023-09-26 17:28:33.693000: train_loss -0.8228 
2023-09-26 17:28:33.693360: val_loss -0.5761 
2023-09-26 17:28:33.693476: Pseudo dice [0.8954, 0.5084, 0.5694] 
2023-09-26 17:28:33.693575: Epoch time: 99.98 s 
2023-09-26 17:28:35.320720:  
2023-09-26 17:28:35.320910: Epoch 91 
2023-09-26 17:28:35.321029: Current learning rate: 0.00918 
2023-09-26 17:30:13.993444: train_loss -0.8233 
2023-09-26 17:30:13.994087: val_loss -0.6097 
2023-09-26 17:30:13.994195: Pseudo dice [0.8806, 0.5895, 0.6308] 
2023-09-26 17:30:13.994309: Epoch time: 98.67 s 
2023-09-26 17:30:15.299103:  
2023-09-26 17:30:15.299381: Epoch 92 
2023-09-26 17:30:15.299480: Current learning rate: 0.00917 
2023-09-26 17:31:53.789190: train_loss -0.8209 
2023-09-26 17:31:53.789491: val_loss -0.5702 
2023-09-26 17:31:53.789587: Pseudo dice [0.8853, 0.6893, 0.4127] 
2023-09-26 17:31:53.789681: Epoch time: 98.49 s 
2023-09-26 17:31:55.041083:  
2023-09-26 17:31:55.041305: Epoch 93 
2023-09-26 17:31:55.041423: Current learning rate: 0.00916 
2023-09-26 17:33:33.605179: train_loss -0.8261 
2023-09-26 17:33:33.605435: val_loss -0.6242 
2023-09-26 17:33:33.605515: Pseudo dice [0.8845, 0.5367, 0.6682] 
2023-09-26 17:33:33.605588: Epoch time: 98.57 s 
2023-09-26 17:33:34.821834:  
2023-09-26 17:33:34.822008: Epoch 94 
2023-09-26 17:33:34.822114: Current learning rate: 0.00915 
2023-09-26 17:35:13.117386: train_loss -0.8266 
2023-09-26 17:35:13.117649: val_loss -0.6014 
2023-09-26 17:35:13.117731: Pseudo dice [0.8849, 0.6369, 0.5766] 
2023-09-26 17:35:13.117904: Epoch time: 98.3 s 
2023-09-26 17:35:14.334857:  
2023-09-26 17:35:14.335092: Epoch 95 
2023-09-26 17:35:14.335183: Current learning rate: 0.00914 
2023-09-26 17:36:52.904433: train_loss -0.8166 
2023-09-26 17:36:52.904665: val_loss -0.6232 
2023-09-26 17:36:52.904744: Pseudo dice [0.897, 0.632, 0.5924] 
2023-09-26 17:36:52.904813: Epoch time: 98.57 s 
2023-09-26 17:36:54.201102:  
2023-09-26 17:36:54.201255: Epoch 96 
2023-09-26 17:36:54.201346: Current learning rate: 0.00913 
2023-09-26 17:38:34.192086: train_loss -0.8205 
2023-09-26 17:38:34.192340: val_loss -0.6291 
2023-09-26 17:38:34.192421: Pseudo dice [0.8842, 0.5817, 0.6692] 
2023-09-26 17:38:34.192496: Epoch time: 99.99 s 
2023-09-26 17:38:35.633570:  
2023-09-26 17:38:35.633721: Epoch 97 
2023-09-26 17:38:35.633808: Current learning rate: 0.00912 
2023-09-26 17:40:15.642873: train_loss -0.833 
2023-09-26 17:40:15.643130: val_loss -0.6232 
2023-09-26 17:40:15.643209: Pseudo dice [0.885, 0.6296, 0.6329] 
2023-09-26 17:40:15.643282: Epoch time: 100.01 s 
2023-09-26 17:40:16.849495:  
2023-09-26 17:40:16.849656: Epoch 98 
2023-09-26 17:40:16.849741: Current learning rate: 0.00911 
2023-09-26 17:41:57.016041: train_loss -0.8086 
2023-09-26 17:41:57.016463: val_loss -0.6049 
2023-09-26 17:41:57.016569: Pseudo dice [0.8807, 0.6334, 0.5238] 
2023-09-26 17:41:57.016655: Epoch time: 100.17 s 
2023-09-26 17:41:58.296443:  
2023-09-26 17:41:58.296611: Epoch 99 
2023-09-26 17:41:58.296721: Current learning rate: 0.0091 
2023-09-26 17:43:38.507800: train_loss -0.8199 
2023-09-26 17:43:38.508070: val_loss -0.6092 
2023-09-26 17:43:38.508154: Pseudo dice [0.8927, 0.5517, 0.5412] 
2023-09-26 17:43:38.508230: Epoch time: 100.21 s 
2023-09-26 17:43:41.265441:  
2023-09-26 17:43:41.265575: Epoch 100 
2023-09-26 17:43:41.265661: Current learning rate: 0.0091 
2023-09-26 17:45:19.396132: train_loss -0.8015 
2023-09-26 17:45:19.396778: val_loss -0.5991 
2023-09-26 17:45:19.396873: Pseudo dice [0.8838, 0.5812, 0.5867] 
2023-09-26 17:45:19.396959: Epoch time: 98.13 s 
2023-09-26 17:45:20.610950:  
2023-09-26 17:45:20.611231: Epoch 101 
2023-09-26 17:45:20.611364: Current learning rate: 0.00909 
2023-09-26 17:47:00.605034: train_loss -0.7754 
2023-09-26 17:47:00.605308: val_loss -0.547 
2023-09-26 17:47:00.605386: Pseudo dice [0.8492, 0.6103, 0.4478] 
2023-09-26 17:47:00.605458: Epoch time: 100.0 s 
2023-09-26 17:47:01.860128:  
2023-09-26 17:47:01.860359: Epoch 102 
2023-09-26 17:47:01.860501: Current learning rate: 0.00908 
2023-09-26 17:48:41.418526: train_loss -0.7755 
2023-09-26 17:48:41.419250: val_loss -0.5626 
2023-09-26 17:48:41.419358: Pseudo dice [0.8816, 0.6228, 0.4658] 
2023-09-26 17:48:41.419488: Epoch time: 99.56 s 
2023-09-26 17:48:43.288499:  
2023-09-26 17:48:43.289294: Epoch 103 
2023-09-26 17:48:43.289767: Current learning rate: 0.00907 
2023-09-26 17:50:21.743790: train_loss -0.7863 
2023-09-26 17:50:21.744343: val_loss -0.5717 
2023-09-26 17:50:21.744433: Pseudo dice [0.8692, 0.616, 0.568] 
2023-09-26 17:50:21.744528: Epoch time: 98.46 s 
2023-09-26 17:50:22.958536:  
2023-09-26 17:50:22.958686: Epoch 104 
2023-09-26 17:50:22.958773: Current learning rate: 0.00906 
2023-09-26 17:52:01.667502: train_loss -0.7912 
2023-09-26 17:52:01.667819: val_loss -0.591 
2023-09-26 17:52:01.667924: Pseudo dice [0.8883, 0.5636, 0.5848] 
2023-09-26 17:52:01.668018: Epoch time: 98.71 s 
2023-09-26 17:52:02.945361:  
2023-09-26 17:52:02.945534: Epoch 105 
2023-09-26 17:52:02.945623: Current learning rate: 0.00905 
2023-09-26 17:53:41.272732: train_loss -0.8018 
2023-09-26 17:53:41.273003: val_loss -0.6236 
2023-09-26 17:53:41.273084: Pseudo dice [0.8866, 0.6173, 0.6453] 
2023-09-26 17:53:41.273157: Epoch time: 98.33 s 
2023-09-26 17:53:42.509396:  
2023-09-26 17:53:42.509558: Epoch 106 
2023-09-26 17:53:42.509644: Current learning rate: 0.00904 
2023-09-26 17:55:22.419959: train_loss -0.7943 
2023-09-26 17:55:22.420216: val_loss -0.6166 
2023-09-26 17:55:22.420296: Pseudo dice [0.8827, 0.5317, 0.6863] 
2023-09-26 17:55:22.420369: Epoch time: 99.91 s 
2023-09-26 17:55:23.668075:  
2023-09-26 17:55:23.668223: Epoch 107 
2023-09-26 17:55:23.668312: Current learning rate: 0.00903 
2023-09-26 17:57:03.775608: train_loss -0.7878 
2023-09-26 17:57:03.775873: val_loss -0.5565 
2023-09-26 17:57:03.775954: Pseudo dice [0.8683, 0.5946, 0.5194] 
2023-09-26 17:57:03.776025: Epoch time: 100.11 s 
2023-09-26 17:57:05.025013:  
2023-09-26 17:57:05.025273: Epoch 108 
2023-09-26 17:57:05.025363: Current learning rate: 0.00902 
2023-09-26 17:58:44.711622: train_loss -0.8016 
2023-09-26 17:58:44.711975: val_loss -0.6259 
2023-09-26 17:58:44.712058: Pseudo dice [0.8839, 0.6154, 0.6458] 
2023-09-26 17:58:44.712129: Epoch time: 99.69 s 
2023-09-26 17:58:46.094020:  
2023-09-26 17:58:46.094343: Epoch 109 
2023-09-26 17:58:46.094443: Current learning rate: 0.00901 
2023-09-26 18:00:26.353252: train_loss -0.7986 
2023-09-26 18:00:26.353511: val_loss -0.5954 
2023-09-26 18:00:26.353593: Pseudo dice [0.8927, 0.4843, 0.6713] 
2023-09-26 18:00:26.353669: Epoch time: 100.26 s 
2023-09-26 18:00:27.623050:  
2023-09-26 18:00:27.623264: Epoch 110 
2023-09-26 18:00:27.623356: Current learning rate: 0.009 
2023-09-26 18:02:07.737598: train_loss -0.7941 
2023-09-26 18:02:07.737859: val_loss -0.6167 
2023-09-26 18:02:07.737941: Pseudo dice [0.8829, 0.6216, 0.5887] 
2023-09-26 18:02:07.738014: Epoch time: 100.12 s 
2023-09-26 18:02:09.054929:  
2023-09-26 18:02:09.055073: Epoch 111 
2023-09-26 18:02:09.055180: Current learning rate: 0.009 
2023-09-26 18:03:48.932890: train_loss -0.7967 
2023-09-26 18:03:48.933136: val_loss -0.6427 
2023-09-26 18:03:48.933215: Pseudo dice [0.89, 0.5664, 0.6755] 
2023-09-26 18:03:48.933285: Epoch time: 99.88 s 
2023-09-26 18:03:50.195334:  
2023-09-26 18:03:50.195525: Epoch 112 
2023-09-26 18:03:50.195668: Current learning rate: 0.00899 
2023-09-26 18:05:30.264167: train_loss -0.7762 
2023-09-26 18:05:30.264741: val_loss -0.6355 
2023-09-26 18:05:30.264984: Pseudo dice [0.8766, 0.6219, 0.679] 
2023-09-26 18:05:30.265196: Epoch time: 100.07 s 
2023-09-26 18:05:31.548951:  
2023-09-26 18:05:31.549114: Epoch 113 
2023-09-26 18:05:31.549209: Current learning rate: 0.00898 
2023-09-26 18:07:11.556154: train_loss -0.7905 
2023-09-26 18:07:11.556445: val_loss -0.6555 
2023-09-26 18:07:11.556541: Pseudo dice [0.8808, 0.6201, 0.6918] 
2023-09-26 18:07:11.556627: Epoch time: 100.01 s 
2023-09-26 18:07:12.801226:  
2023-09-26 18:07:12.801374: Epoch 114 
2023-09-26 18:07:12.801462: Current learning rate: 0.00897 
2023-09-26 18:08:52.641495: train_loss -0.8103 
2023-09-26 18:08:52.641807: val_loss -0.6038 
2023-09-26 18:08:52.641885: Pseudo dice [0.8757, 0.5656, 0.6355] 
2023-09-26 18:08:52.641960: Epoch time: 99.84 s 
2023-09-26 18:08:53.934999:  
2023-09-26 18:08:53.935429: Epoch 115 
2023-09-26 18:08:53.935531: Current learning rate: 0.00896 
2023-09-26 18:10:33.918296: train_loss -0.8119 
2023-09-26 18:10:33.918595: val_loss -0.5883 
2023-09-26 18:10:33.918695: Pseudo dice [0.8748, 0.5572, 0.6223] 
2023-09-26 18:10:33.918783: Epoch time: 99.98 s 
2023-09-26 18:10:35.644470:  
2023-09-26 18:10:35.644711: Epoch 116 
2023-09-26 18:10:35.644821: Current learning rate: 0.00895 
2023-09-26 18:12:15.950063: train_loss -0.8209 
2023-09-26 18:12:15.950331: val_loss -0.621 
2023-09-26 18:12:15.950409: Pseudo dice [0.8932, 0.641, 0.6206] 
2023-09-26 18:12:15.950485: Epoch time: 100.31 s 
2023-09-26 18:12:17.199955:  
2023-09-26 18:12:17.200224: Epoch 117 
2023-09-26 18:12:17.200314: Current learning rate: 0.00894 
2023-09-26 18:13:57.267306: train_loss -0.8108 
2023-09-26 18:13:57.267560: val_loss -0.6002 
2023-09-26 18:13:57.267639: Pseudo dice [0.8902, 0.5881, 0.6355] 
2023-09-26 18:13:57.267709: Epoch time: 100.07 s 
2023-09-26 18:13:58.525714:  
2023-09-26 18:13:58.525974: Epoch 118 
2023-09-26 18:13:58.526140: Current learning rate: 0.00893 
2023-09-26 18:15:38.674826: train_loss -0.8043 
2023-09-26 18:15:38.675088: val_loss -0.607 
2023-09-26 18:15:38.675164: Pseudo dice [0.8584, 0.6039, 0.5989] 
2023-09-26 18:15:38.675238: Epoch time: 100.15 s 
2023-09-26 18:15:39.913153:  
2023-09-26 18:15:39.913435: Epoch 119 
2023-09-26 18:15:39.913529: Current learning rate: 0.00892 
2023-09-26 18:17:20.144612: train_loss -0.7954 
2023-09-26 18:17:20.144859: val_loss -0.5879 
2023-09-26 18:17:20.144938: Pseudo dice [0.868, 0.5546, 0.5952] 
2023-09-26 18:17:20.145012: Epoch time: 100.23 s 
2023-09-26 18:17:21.480685:  
2023-09-26 18:17:21.480930: Epoch 120 
2023-09-26 18:17:21.481025: Current learning rate: 0.00891 
2023-09-26 18:19:01.388341: train_loss -0.8047 
2023-09-26 18:19:01.388626: val_loss -0.6199 
2023-09-26 18:19:01.388726: Pseudo dice [0.8852, 0.5502, 0.6596] 
2023-09-26 18:19:01.388814: Epoch time: 99.91 s 
2023-09-26 18:19:03.020046:  
2023-09-26 18:19:03.020512: Epoch 121 
2023-09-26 18:19:03.020622: Current learning rate: 0.0089 
2023-09-26 18:20:43.123893: train_loss -0.8154 
2023-09-26 18:20:43.124148: val_loss -0.6344 
2023-09-26 18:20:43.124228: Pseudo dice [0.8872, 0.621, 0.6291] 
2023-09-26 18:20:43.124300: Epoch time: 100.11 s 
2023-09-26 18:20:44.576955:  
2023-09-26 18:20:44.577167: Epoch 122 
2023-09-26 18:20:44.577304: Current learning rate: 0.00889 
2023-09-26 18:22:24.685731: train_loss -0.8263 
2023-09-26 18:22:24.686021: val_loss -0.654 
2023-09-26 18:22:24.686145: Pseudo dice [0.8998, 0.6162, 0.6905] 
2023-09-26 18:22:24.686242: Epoch time: 100.11 s 
2023-09-26 18:22:26.172714:  
2023-09-26 18:22:26.172977: Epoch 123 
2023-09-26 18:22:26.173185: Current learning rate: 0.00889 
2023-09-26 18:24:06.215025: train_loss -0.8212 
2023-09-26 18:24:06.215312: val_loss -0.634 
2023-09-26 18:24:06.215422: Pseudo dice [0.8967, 0.6234, 0.6361] 
2023-09-26 18:24:06.215515: Epoch time: 100.04 s 
2023-09-26 18:24:06.215587: Yayy! New best EMA pseudo Dice: 0.7028 
2023-09-26 18:24:09.181579:  
2023-09-26 18:24:09.181931: Epoch 124 
2023-09-26 18:24:09.182125: Current learning rate: 0.00888 
2023-09-26 18:25:48.913191: train_loss -0.8272 
2023-09-26 18:25:48.913452: val_loss -0.678 
2023-09-26 18:25:48.913536: Pseudo dice [0.8864, 0.6526, 0.7222] 
2023-09-26 18:25:48.913612: Epoch time: 99.73 s 
2023-09-26 18:25:48.913667: Yayy! New best EMA pseudo Dice: 0.7079 
2023-09-26 18:25:51.814829:  
2023-09-26 18:25:51.815307: Epoch 125 
2023-09-26 18:25:51.815408: Current learning rate: 0.00887 
2023-09-26 18:27:31.900685: train_loss -0.8215 
2023-09-26 18:27:31.900943: val_loss -0.6187 
2023-09-26 18:27:31.901020: Pseudo dice [0.8799, 0.5886, 0.6863] 
2023-09-26 18:27:31.901091: Epoch time: 100.09 s 
2023-09-26 18:27:31.901144: Yayy! New best EMA pseudo Dice: 0.709 
2023-09-26 18:27:34.844675:  
2023-09-26 18:27:34.844820: Epoch 126 
2023-09-26 18:27:34.844907: Current learning rate: 0.00886 
2023-09-26 18:29:14.681941: train_loss -0.8219 
2023-09-26 18:29:14.682210: val_loss -0.6121 
2023-09-26 18:29:14.682294: Pseudo dice [0.88, 0.5938, 0.6347] 
2023-09-26 18:29:14.682368: Epoch time: 99.84 s 
2023-09-26 18:29:16.117210:  
2023-09-26 18:29:16.117349: Epoch 127 
2023-09-26 18:29:16.117441: Current learning rate: 0.00885 
2023-09-26 18:30:55.982517: train_loss -0.8279 
2023-09-26 18:30:55.982793: val_loss -0.5704 
2023-09-26 18:30:55.982872: Pseudo dice [0.8858, 0.5821, 0.5927] 
2023-09-26 18:30:55.982944: Epoch time: 99.87 s 
2023-09-26 18:30:57.249996:  
2023-09-26 18:30:57.250249: Epoch 128 
2023-09-26 18:30:57.250344: Current learning rate: 0.00884 
2023-09-26 18:32:36.999784: train_loss -0.8367 
2023-09-26 18:32:37.000131: val_loss -0.596 
2023-09-26 18:32:37.000217: Pseudo dice [0.8869, 0.5873, 0.5505] 
2023-09-26 18:32:37.000291: Epoch time: 99.75 s 
2023-09-26 18:32:38.241806:  
2023-09-26 18:32:38.241952: Epoch 129 
2023-09-26 18:32:38.242040: Current learning rate: 0.00883 
2023-09-26 18:34:18.189882: train_loss -0.8322 
2023-09-26 18:34:18.190145: val_loss -0.5972 
2023-09-26 18:34:18.190226: Pseudo dice [0.8958, 0.601, 0.6223] 
2023-09-26 18:34:18.190299: Epoch time: 99.95 s 
2023-09-26 18:34:19.428795:  
2023-09-26 18:34:19.428937: Epoch 130 
2023-09-26 18:34:19.429026: Current learning rate: 0.00882 
2023-09-26 18:35:59.100924: train_loss -0.833 
2023-09-26 18:35:59.101191: val_loss -0.5863 
2023-09-26 18:35:59.101270: Pseudo dice [0.8844, 0.5747, 0.5742] 
2023-09-26 18:35:59.101344: Epoch time: 99.67 s 
2023-09-26 18:36:00.342363:  
2023-09-26 18:36:00.342513: Epoch 131 
2023-09-26 18:36:00.342602: Current learning rate: 0.00881 
2023-09-26 18:37:40.331477: train_loss -0.838 
2023-09-26 18:37:40.331723: val_loss -0.5865 
2023-09-26 18:37:40.331814: Pseudo dice [0.8839, 0.5483, 0.5605] 
2023-09-26 18:37:40.331894: Epoch time: 99.99 s 
2023-09-26 18:37:41.824818:  
2023-09-26 18:37:41.825024: Epoch 132 
2023-09-26 18:37:41.825109: Current learning rate: 0.0088 
2023-09-26 18:39:21.134825: train_loss -0.8204 
2023-09-26 18:39:21.135098: val_loss -0.6175 
2023-09-26 18:39:21.135180: Pseudo dice [0.8774, 0.6325, 0.5531] 
2023-09-26 18:39:21.135252: Epoch time: 99.31 s 
2023-09-26 18:39:22.531611:  
2023-09-26 18:39:22.531770: Epoch 133 
2023-09-26 18:39:22.531859: Current learning rate: 0.00879 
2023-09-26 18:41:02.579847: train_loss -0.8108 
2023-09-26 18:41:02.580230: val_loss -0.6064 
2023-09-26 18:41:02.580318: Pseudo dice [0.8865, 0.6108, 0.5759] 
2023-09-26 18:41:02.580392: Epoch time: 100.05 s 
2023-09-26 18:41:03.899950:  
2023-09-26 18:41:03.900366: Epoch 134 
2023-09-26 18:41:03.900475: Current learning rate: 0.00879 
2023-09-26 18:42:43.932989: train_loss -0.8197 
2023-09-26 18:42:43.933289: val_loss -0.5953 
2023-09-26 18:42:43.933385: Pseudo dice [0.8899, 0.5864, 0.548] 
2023-09-26 18:42:43.933474: Epoch time: 100.03 s 
2023-09-26 18:42:45.538810:  
2023-09-26 18:42:45.539093: Epoch 135 
2023-09-26 18:42:45.539209: Current learning rate: 0.00878 
2023-09-26 18:44:25.196763: train_loss -0.8189 
2023-09-26 18:44:25.197013: val_loss -0.619 
2023-09-26 18:44:25.197092: Pseudo dice [0.883, 0.6191, 0.6272] 
2023-09-26 18:44:25.197164: Epoch time: 99.66 s 
2023-09-26 18:44:26.451407:  
2023-09-26 18:44:26.451559: Epoch 136 
2023-09-26 18:44:26.451649: Current learning rate: 0.00877 
2023-09-26 18:46:06.531170: train_loss -0.8257 
2023-09-26 18:46:06.531456: val_loss -0.6178 
2023-09-26 18:46:06.531553: Pseudo dice [0.8901, 0.5739, 0.6711] 
2023-09-26 18:46:06.531644: Epoch time: 100.08 s 
2023-09-26 18:46:07.947258:  
2023-09-26 18:46:07.947407: Epoch 137 
2023-09-26 18:46:07.947495: Current learning rate: 0.00876 
2023-09-26 18:47:47.985174: train_loss -0.8397 
2023-09-26 18:47:47.985433: val_loss -0.6274 
2023-09-26 18:47:47.985513: Pseudo dice [0.8891, 0.593, 0.6135] 
2023-09-26 18:47:47.985585: Epoch time: 100.04 s 
2023-09-26 18:47:49.237678:  
2023-09-26 18:47:49.237835: Epoch 138 
2023-09-26 18:47:49.237921: Current learning rate: 0.00875 
2023-09-26 18:49:29.246773: train_loss -0.8176 
2023-09-26 18:49:29.247038: val_loss -0.6309 
2023-09-26 18:49:29.247146: Pseudo dice [0.8529, 0.6347, 0.6301] 
2023-09-26 18:49:29.247238: Epoch time: 100.01 s 
2023-09-26 18:49:30.739420:  
2023-09-26 18:49:30.739608: Epoch 139 
2023-09-26 18:49:30.739700: Current learning rate: 0.00874 
2023-09-26 18:51:10.300462: train_loss -0.8305 
2023-09-26 18:51:10.300724: val_loss -0.5937 
2023-09-26 18:51:10.300805: Pseudo dice [0.8855, 0.5942, 0.6137] 
2023-09-26 18:51:10.300877: Epoch time: 99.56 s 
2023-09-26 18:51:11.580275:  
2023-09-26 18:51:11.580426: Epoch 140 
2023-09-26 18:51:11.580516: Current learning rate: 0.00873 
2023-09-26 18:52:51.602467: train_loss -0.8339 
2023-09-26 18:52:51.602723: val_loss -0.6536 
2023-09-26 18:52:51.602801: Pseudo dice [0.8864, 0.5891, 0.7035] 
2023-09-26 18:52:51.602874: Epoch time: 100.02 s 
2023-09-26 18:52:52.848565:  
2023-09-26 18:52:52.848820: Epoch 141 
2023-09-26 18:52:52.848914: Current learning rate: 0.00872 
2023-09-26 18:54:32.315911: train_loss -0.8234 
2023-09-26 18:54:32.316149: val_loss -0.5775 
2023-09-26 18:54:32.316227: Pseudo dice [0.8888, 0.5368, 0.4851] 
2023-09-26 18:54:32.316337: Epoch time: 99.47 s 
2023-09-26 18:54:33.584624:  
2023-09-26 18:54:33.584760: Epoch 142 
2023-09-26 18:54:33.584846: Current learning rate: 0.00871 
2023-09-26 18:56:13.260457: train_loss -0.8392 
2023-09-26 18:56:13.260760: val_loss -0.6325 
2023-09-26 18:56:13.260857: Pseudo dice [0.8936, 0.5761, 0.641] 
2023-09-26 18:56:13.260945: Epoch time: 99.68 s 
2023-09-26 18:56:14.634567:  
2023-09-26 18:56:14.635024: Epoch 143 
2023-09-26 18:56:14.635142: Current learning rate: 0.0087 
2023-09-26 18:57:54.484719: train_loss -0.839 
2023-09-26 18:57:54.484975: val_loss -0.5739 
2023-09-26 18:57:54.485054: Pseudo dice [0.8945, 0.5279, 0.5772] 
2023-09-26 18:57:54.485128: Epoch time: 99.85 s 
2023-09-26 18:57:55.783169:  
2023-09-26 18:57:55.783349: Epoch 144 
2023-09-26 18:57:55.783440: Current learning rate: 0.00869 
2023-09-26 18:59:35.562076: train_loss -0.8365 
2023-09-26 18:59:35.562364: val_loss -0.6352 
2023-09-26 18:59:35.562456: Pseudo dice [0.8846, 0.5889, 0.6873] 
2023-09-26 18:59:35.562541: Epoch time: 99.78 s 
2023-09-26 18:59:37.295802:  
2023-09-26 18:59:37.296174: Epoch 145 
2023-09-26 18:59:37.296266: Current learning rate: 0.00868 
2023-09-26 19:01:17.266580: train_loss -0.8245 
2023-09-26 19:01:17.266871: val_loss -0.5574 
2023-09-26 19:01:17.266967: Pseudo dice [0.8813, 0.6142, 0.4738] 
2023-09-26 19:01:17.267057: Epoch time: 99.97 s 
2023-09-26 19:01:18.610475:  
2023-09-26 19:01:18.610636: Epoch 146 
2023-09-26 19:01:18.610723: Current learning rate: 0.00868 
2023-09-26 19:02:58.240856: train_loss -0.8453 
2023-09-26 19:02:58.241156: val_loss -0.6081 
2023-09-26 19:02:58.241250: Pseudo dice [0.8908, 0.5543, 0.5902] 
2023-09-26 19:02:58.241340: Epoch time: 99.63 s 
2023-09-26 19:02:59.886762:  
2023-09-26 19:02:59.886937: Epoch 147 
2023-09-26 19:02:59.887061: Current learning rate: 0.00867 
2023-09-26 19:04:39.919206: train_loss -0.8375 
2023-09-26 19:04:39.919454: val_loss -0.5626 
2023-09-26 19:04:39.919534: Pseudo dice [0.8851, 0.4266, 0.6138] 
2023-09-26 19:04:39.919610: Epoch time: 100.03 s 
2023-09-26 19:04:41.170907:  
2023-09-26 19:04:41.171031: Epoch 148 
2023-09-26 19:04:41.171120: Current learning rate: 0.00866 
2023-09-26 19:06:21.037893: train_loss -0.8256 
2023-09-26 19:06:21.038313: val_loss -0.6326 
2023-09-26 19:06:21.038407: Pseudo dice [0.8926, 0.6258, 0.6053] 
2023-09-26 19:06:21.038486: Epoch time: 99.87 s 
2023-09-26 19:06:22.358077:  
2023-09-26 19:06:22.358294: Epoch 149 
2023-09-26 19:06:22.358390: Current learning rate: 0.00865 
2023-09-26 19:08:02.397388: train_loss -0.8351 
2023-09-26 19:08:02.397666: val_loss -0.5614 
2023-09-26 19:08:02.397747: Pseudo dice [0.8719, 0.5535, 0.4319] 
2023-09-26 19:08:02.397823: Epoch time: 100.04 s 
2023-09-26 19:08:05.358220:  
2023-09-26 19:08:05.358908: Epoch 150 
2023-09-26 19:08:05.359080: Current learning rate: 0.00864 
2023-09-26 19:09:43.810983: train_loss -0.8267 
2023-09-26 19:09:43.811259: val_loss -0.571 
2023-09-26 19:09:43.811354: Pseudo dice [0.8882, 0.5868, 0.5687] 
2023-09-26 19:09:43.811440: Epoch time: 98.45 s 
2023-09-26 19:09:45.168191:  
2023-09-26 19:09:45.168455: Epoch 151 
2023-09-26 19:09:45.168563: Current learning rate: 0.00863 
2023-09-26 19:11:25.144513: train_loss -0.8446 
2023-09-26 19:11:25.144750: val_loss -0.6142 
2023-09-26 19:11:25.144830: Pseudo dice [0.8904, 0.5978, 0.6643] 
2023-09-26 19:11:25.144900: Epoch time: 99.98 s 
2023-09-26 19:11:26.463894:  
2023-09-26 19:11:26.464127: Epoch 152 
2023-09-26 19:11:26.464268: Current learning rate: 0.00862 
2023-09-26 19:13:06.347950: train_loss -0.8363 
2023-09-26 19:13:06.348202: val_loss -0.5663 
2023-09-26 19:13:06.348283: Pseudo dice [0.8912, 0.5206, 0.6062] 
2023-09-26 19:13:06.348353: Epoch time: 99.89 s 
2023-09-26 19:13:07.630632:  
2023-09-26 19:13:07.630777: Epoch 153 
2023-09-26 19:13:07.630865: Current learning rate: 0.00861 
2023-09-26 19:14:47.831805: train_loss -0.8411 
2023-09-26 19:14:47.832081: val_loss -0.6205 
2023-09-26 19:14:47.832415: Pseudo dice [0.877, 0.5663, 0.6087] 
2023-09-26 19:14:47.832493: Epoch time: 100.2 s 
2023-09-26 19:14:49.390399:  
2023-09-26 19:14:49.390702: Epoch 154 
2023-09-26 19:14:49.390851: Current learning rate: 0.0086 
2023-09-26 19:16:29.478785: train_loss -0.8438 
2023-09-26 19:16:29.479068: val_loss -0.5637 
2023-09-26 19:16:29.479169: Pseudo dice [0.8815, 0.5241, 0.5215] 
2023-09-26 19:16:29.479263: Epoch time: 100.09 s 
2023-09-26 19:16:31.016439:  
2023-09-26 19:16:31.016591: Epoch 155 
2023-09-26 19:16:31.016679: Current learning rate: 0.00859 
2023-09-26 19:18:10.939811: train_loss -0.8436 
2023-09-26 19:18:10.940063: val_loss -0.6228 
2023-09-26 19:18:10.940139: Pseudo dice [0.8823, 0.5992, 0.6416] 
2023-09-26 19:18:10.940208: Epoch time: 99.92 s 
2023-09-26 19:18:12.386152:  
2023-09-26 19:18:12.386291: Epoch 156 
2023-09-26 19:18:12.386378: Current learning rate: 0.00858 
2023-09-26 19:19:52.376795: train_loss -0.8502 
2023-09-26 19:19:52.377125: val_loss -0.6085 
2023-09-26 19:19:52.377207: Pseudo dice [0.9002, 0.6082, 0.5302] 
2023-09-26 19:19:52.377278: Epoch time: 99.99 s 
2023-09-26 19:19:54.076655:  
2023-09-26 19:19:54.076923: Epoch 157 
2023-09-26 19:19:54.077032: Current learning rate: 0.00858 
2023-09-26 19:21:34.083083: train_loss -0.8285 
2023-09-26 19:21:34.083323: val_loss -0.6248 
2023-09-26 19:21:34.083400: Pseudo dice [0.8923, 0.639, 0.6688] 
2023-09-26 19:21:34.083470: Epoch time: 100.01 s 
2023-09-26 19:21:35.382756:  
2023-09-26 19:21:35.383208: Epoch 158 
2023-09-26 19:21:35.383311: Current learning rate: 0.00857 
2023-09-26 19:23:15.526648: train_loss -0.8345 
2023-09-26 19:23:15.526950: val_loss -0.5978 
2023-09-26 19:23:15.527046: Pseudo dice [0.8863, 0.5172, 0.582] 
2023-09-26 19:23:15.527132: Epoch time: 100.14 s 
2023-09-26 19:23:17.154085:  
2023-09-26 19:23:17.154431: Epoch 159 
2023-09-26 19:23:17.154573: Current learning rate: 0.00856 
2023-09-26 19:24:57.815842: train_loss -0.8201 
2023-09-26 19:24:57.816094: val_loss -0.6025 
2023-09-26 19:24:57.816172: Pseudo dice [0.8697, 0.6171, 0.6046] 
2023-09-26 19:24:57.816243: Epoch time: 100.66 s 
2023-09-26 19:24:59.118329:  
2023-09-26 19:24:59.118563: Epoch 160 
2023-09-26 19:24:59.118765: Current learning rate: 0.00855 
2023-09-26 19:26:40.504434: train_loss -0.7881 
2023-09-26 19:26:40.504698: val_loss -0.5735 
2023-09-26 19:26:40.504776: Pseudo dice [0.8358, 0.6387, 0.5565] 
2023-09-26 19:26:40.504845: Epoch time: 101.39 s 
2023-09-26 19:26:42.127101:  
2023-09-26 19:26:42.127421: Epoch 161 
2023-09-26 19:26:42.127566: Current learning rate: 0.00854 
2023-09-26 19:28:23.526057: train_loss -0.796 
2023-09-26 19:28:23.526316: val_loss -0.6006 
2023-09-26 19:28:23.526398: Pseudo dice [0.8715, 0.6141, 0.5776] 
2023-09-26 19:28:23.526469: Epoch time: 101.4 s 
2023-09-26 19:28:24.979385:  
2023-09-26 19:28:24.979541: Epoch 162 
2023-09-26 19:28:24.979626: Current learning rate: 0.00853 
2023-09-26 19:30:06.450805: train_loss -0.7988 
2023-09-26 19:30:06.451068: val_loss -0.5674 
2023-09-26 19:30:06.451150: Pseudo dice [0.8809, 0.5596, 0.5083] 
2023-09-26 19:30:06.451225: Epoch time: 101.47 s 
2023-09-26 19:30:07.735835:  
2023-09-26 19:30:07.735977: Epoch 163 
2023-09-26 19:30:07.736076: Current learning rate: 0.00852 
2023-09-26 19:31:49.326639: train_loss -0.822 
2023-09-26 19:31:49.326937: val_loss -0.6416 
2023-09-26 19:31:49.327051: Pseudo dice [0.8909, 0.6195, 0.6374] 
2023-09-26 19:31:49.327148: Epoch time: 101.59 s 
2023-09-26 19:31:50.716685:  
2023-09-26 19:31:50.717095: Epoch 164 
2023-09-26 19:31:50.717186: Current learning rate: 0.00851 
2023-09-26 19:33:31.813951: train_loss -0.8231 
2023-09-26 19:33:31.814214: val_loss -0.6179 
2023-09-26 19:33:31.814293: Pseudo dice [0.8875, 0.5624, 0.652] 
2023-09-26 19:33:31.814361: Epoch time: 101.1 s 
2023-09-26 19:33:33.101085:  
2023-09-26 19:33:33.101499: Epoch 165 
2023-09-26 19:33:33.101601: Current learning rate: 0.0085 
2023-09-26 19:35:13.372463: train_loss -0.7812 
2023-09-26 19:35:13.372717: val_loss -0.6132 
2023-09-26 19:35:13.372795: Pseudo dice [0.868, 0.5391, 0.629] 
2023-09-26 19:35:13.372867: Epoch time: 100.27 s 
2023-09-26 19:35:14.672096:  
2023-09-26 19:35:14.672372: Epoch 166 
2023-09-26 19:35:14.672466: Current learning rate: 0.00849 
2023-09-26 19:36:54.823174: train_loss -0.7934 
2023-09-26 19:36:54.823432: val_loss -0.5663 
2023-09-26 19:36:54.823511: Pseudo dice [0.8744, 0.5702, 0.522] 
2023-09-26 19:36:54.823582: Epoch time: 100.15 s 
2023-09-26 19:36:56.073455:  
2023-09-26 19:36:56.073597: Epoch 167 
2023-09-26 19:36:56.073684: Current learning rate: 0.00848 
2023-09-26 19:38:36.114761: train_loss -0.7961 
2023-09-26 19:38:36.115025: val_loss -0.6352 
2023-09-26 19:38:36.115101: Pseudo dice [0.8773, 0.6071, 0.6687] 
2023-09-26 19:38:36.115169: Epoch time: 100.04 s 
2023-09-26 19:38:37.591261:  
2023-09-26 19:38:37.591594: Epoch 168 
2023-09-26 19:38:37.591771: Current learning rate: 0.00847 
2023-09-26 19:40:17.829389: train_loss -0.818 
2023-09-26 19:40:17.829684: val_loss -0.5858 
2023-09-26 19:40:17.829785: Pseudo dice [0.8792, 0.5199, 0.6081] 
2023-09-26 19:40:17.829878: Epoch time: 100.24 s 
2023-09-26 19:40:19.254760:  
2023-09-26 19:40:19.255611: Epoch 169 
2023-09-26 19:40:19.255800: Current learning rate: 0.00847 
2023-09-26 19:41:59.349849: train_loss -0.8168 
2023-09-26 19:41:59.350179: val_loss -0.5818 
2023-09-26 19:41:59.350284: Pseudo dice [0.884, 0.5182, 0.5958] 
2023-09-26 19:41:59.350375: Epoch time: 100.1 s 
2023-09-26 19:42:00.696306:  
2023-09-26 19:42:00.696473: Epoch 170 
2023-09-26 19:42:00.696585: Current learning rate: 0.00846 
2023-09-26 19:43:40.766500: train_loss -0.82 
2023-09-26 19:43:40.767020: val_loss -0.6034 
2023-09-26 19:43:40.767107: Pseudo dice [0.8784, 0.5059, 0.6045] 
2023-09-26 19:43:40.767224: Epoch time: 100.07 s 
2023-09-26 19:43:42.048369:  
2023-09-26 19:43:42.048528: Epoch 171 
2023-09-26 19:43:42.048616: Current learning rate: 0.00845 
2023-09-26 19:45:21.948155: train_loss -0.7909 
2023-09-26 19:45:21.948407: val_loss -0.5792 
2023-09-26 19:45:21.948488: Pseudo dice [0.8715, 0.6148, 0.5075] 
2023-09-26 19:45:21.948562: Epoch time: 99.9 s 
2023-09-26 19:45:23.247686:  
2023-09-26 19:45:23.248018: Epoch 172 
2023-09-26 19:45:23.248139: Current learning rate: 0.00844 
2023-09-26 19:47:03.321908: train_loss -0.7878 
2023-09-26 19:47:03.322294: val_loss -0.5643 
2023-09-26 19:47:03.322416: Pseudo dice [0.8632, 0.6148, 0.5036] 
2023-09-26 19:47:03.322563: Epoch time: 100.08 s 
2023-09-26 19:47:04.705665:  
2023-09-26 19:47:04.705977: Epoch 173 
2023-09-26 19:47:04.706226: Current learning rate: 0.00843 
2023-09-26 19:48:44.264523: train_loss -0.8123 
2023-09-26 19:48:44.264912: val_loss -0.6331 
2023-09-26 19:48:44.265070: Pseudo dice [0.8858, 0.6116, 0.6455] 
2023-09-26 19:48:44.265208: Epoch time: 99.56 s 
2023-09-26 19:48:45.946321:  
2023-09-26 19:48:45.946779: Epoch 174 
2023-09-26 19:48:45.946967: Current learning rate: 0.00842 
2023-09-26 19:50:25.691512: train_loss -0.8334 
2023-09-26 19:50:25.691787: val_loss -0.5899 
2023-09-26 19:50:25.691886: Pseudo dice [0.8874, 0.527, 0.5845] 
2023-09-26 19:50:25.691969: Epoch time: 99.75 s 
2023-09-26 19:50:27.009310:  
2023-09-26 19:50:27.009658: Epoch 175 
2023-09-26 19:50:27.009779: Current learning rate: 0.00841 
2023-09-26 19:52:06.989383: train_loss -0.8403 
2023-09-26 19:52:06.989689: val_loss -0.6169 
2023-09-26 19:52:06.989787: Pseudo dice [0.8842, 0.5892, 0.58] 
2023-09-26 19:52:06.989877: Epoch time: 99.98 s 
2023-09-26 19:52:08.613752:  
2023-09-26 19:52:08.613926: Epoch 176 
2023-09-26 19:52:08.614029: Current learning rate: 0.0084 
2023-09-26 19:53:48.467592: train_loss -0.8227 
2023-09-26 19:53:48.467833: val_loss -0.6305 
2023-09-26 19:53:48.467913: Pseudo dice [0.8905, 0.5811, 0.5785] 
2023-09-26 19:53:48.467985: Epoch time: 99.86 s 
2023-09-26 19:53:49.765970:  
2023-09-26 19:53:49.766406: Epoch 177 
2023-09-26 19:53:49.766512: Current learning rate: 0.00839 
2023-09-26 19:55:29.489948: train_loss -0.8331 
2023-09-26 19:55:29.490196: val_loss -0.6365 
2023-09-26 19:55:29.490279: Pseudo dice [0.8891, 0.6243, 0.6582] 
2023-09-26 19:55:29.490354: Epoch time: 99.73 s 
2023-09-26 19:55:30.833848:  
2023-09-26 19:55:30.834049: Epoch 178 
2023-09-26 19:55:30.834192: Current learning rate: 0.00838 
2023-09-26 19:57:10.587695: train_loss -0.8401 
2023-09-26 19:57:10.587952: val_loss -0.5721 
2023-09-26 19:57:10.588027: Pseudo dice [0.8806, 0.5772, 0.5254] 
2023-09-26 19:57:10.588100: Epoch time: 99.76 s 
2023-09-26 19:57:12.015650:  
2023-09-26 19:57:12.015788: Epoch 179 
2023-09-26 19:57:12.015877: Current learning rate: 0.00837 
2023-09-26 19:58:51.618797: train_loss -0.8452 
2023-09-26 19:58:51.619056: val_loss -0.6187 
2023-09-26 19:58:51.619135: Pseudo dice [0.8834, 0.5498, 0.63] 
2023-09-26 19:58:51.619206: Epoch time: 99.6 s 
2023-09-26 19:58:52.879095:  
2023-09-26 19:58:52.879340: Epoch 180 
2023-09-26 19:58:52.879432: Current learning rate: 0.00836 
2023-09-26 20:00:32.307710: train_loss -0.8477 
2023-09-26 20:00:32.307994: val_loss -0.5909 
2023-09-26 20:00:32.308092: Pseudo dice [0.8933, 0.5702, 0.5875] 
2023-09-26 20:00:32.308182: Epoch time: 99.43 s 
2023-09-26 20:00:33.583666:  
2023-09-26 20:00:33.583841: Epoch 181 
2023-09-26 20:00:33.583938: Current learning rate: 0.00836 
2023-09-26 20:02:13.226377: train_loss -0.8258 
2023-09-26 20:02:13.226666: val_loss -0.5828 
2023-09-26 20:02:13.226828: Pseudo dice [0.8832, 0.6585, 0.5422] 
2023-09-26 20:02:13.226994: Epoch time: 99.64 s 
2023-09-26 20:02:14.793416:  
2023-09-26 20:02:14.793563: Epoch 182 
2023-09-26 20:02:14.793651: Current learning rate: 0.00835 
2023-09-26 20:03:54.653613: train_loss -0.8398 
2023-09-26 20:03:54.653867: val_loss -0.6034 
2023-09-26 20:03:54.653946: Pseudo dice [0.8832, 0.5709, 0.6216] 
2023-09-26 20:03:54.654019: Epoch time: 99.86 s 
2023-09-26 20:03:55.910313:  
2023-09-26 20:03:55.910484: Epoch 183 
2023-09-26 20:03:55.910579: Current learning rate: 0.00834 
2023-09-26 20:05:35.669146: train_loss -0.8388 
2023-09-26 20:05:35.669409: val_loss -0.6419 
2023-09-26 20:05:35.669487: Pseudo dice [0.8937, 0.5946, 0.6727] 
2023-09-26 20:05:35.669560: Epoch time: 99.76 s 
2023-09-26 20:05:36.966861:  
2023-09-26 20:05:36.967036: Epoch 184 
2023-09-26 20:05:36.967141: Current learning rate: 0.00833 
2023-09-26 20:07:16.978534: train_loss -0.8381 
2023-09-26 20:07:16.978849: val_loss -0.6318 
2023-09-26 20:07:16.978951: Pseudo dice [0.8873, 0.6147, 0.6678] 
2023-09-26 20:07:16.979045: Epoch time: 100.01 s 
2023-09-26 20:07:18.568532:  
2023-09-26 20:07:18.568713: Epoch 185 
2023-09-26 20:07:18.568813: Current learning rate: 0.00832 
2023-09-26 20:08:58.194165: train_loss -0.848 
2023-09-26 20:08:58.194418: val_loss -0.6239 
2023-09-26 20:08:58.194497: Pseudo dice [0.8897, 0.6301, 0.6386] 
2023-09-26 20:08:58.194568: Epoch time: 99.63 s 
2023-09-26 20:08:59.454447:  
2023-09-26 20:08:59.454615: Epoch 186 
2023-09-26 20:08:59.454706: Current learning rate: 0.00831 
2023-09-26 20:10:39.253466: train_loss -0.8443 
2023-09-26 20:10:39.253715: val_loss -0.5619 
2023-09-26 20:10:39.253793: Pseudo dice [0.8918, 0.5406, 0.6092] 
2023-09-26 20:10:39.253866: Epoch time: 99.8 s 
2023-09-26 20:10:40.513988:  
2023-09-26 20:10:40.514152: Epoch 187 
2023-09-26 20:10:40.514240: Current learning rate: 0.0083 
2023-09-26 20:12:20.383160: train_loss -0.8499 
2023-09-26 20:12:20.383421: val_loss -0.6321 
2023-09-26 20:12:20.383511: Pseudo dice [0.888, 0.6194, 0.5998] 
2023-09-26 20:12:20.383584: Epoch time: 99.87 s 
2023-09-26 20:12:21.673096:  
2023-09-26 20:12:21.673358: Epoch 188 
2023-09-26 20:12:21.673446: Current learning rate: 0.00829 
2023-09-26 20:14:01.660020: train_loss -0.8297 
2023-09-26 20:14:01.660314: val_loss -0.6009 
2023-09-26 20:14:01.660410: Pseudo dice [0.8742, 0.5694, 0.5626] 
2023-09-26 20:14:01.660498: Epoch time: 99.99 s 
2023-09-26 20:14:03.273673:  
2023-09-26 20:14:03.273840: Epoch 189 
2023-09-26 20:14:03.273946: Current learning rate: 0.00828 
2023-09-26 20:15:43.174658: train_loss -0.8408 
2023-09-26 20:15:43.174942: val_loss -0.5996 
2023-09-26 20:15:43.175038: Pseudo dice [0.8837, 0.6187, 0.5536] 
2023-09-26 20:15:43.175123: Epoch time: 99.9 s 
2023-09-26 20:15:44.831745:  
2023-09-26 20:15:44.831914: Epoch 190 
2023-09-26 20:15:44.832018: Current learning rate: 0.00827 
2023-09-26 20:17:24.594650: train_loss -0.8432 
2023-09-26 20:17:24.594916: val_loss -0.6075 
2023-09-26 20:17:24.594998: Pseudo dice [0.8864, 0.5592, 0.639] 
2023-09-26 20:17:24.595073: Epoch time: 99.76 s 
2023-09-26 20:17:26.045620:  
2023-09-26 20:17:26.045872: Epoch 191 
2023-09-26 20:17:26.045969: Current learning rate: 0.00826 
2023-09-26 20:19:05.860179: train_loss -0.8478 
2023-09-26 20:19:05.860516: val_loss -0.5825 
2023-09-26 20:19:05.860606: Pseudo dice [0.8695, 0.562, 0.5404] 
2023-09-26 20:19:05.860709: Epoch time: 99.82 s 
2023-09-26 20:19:07.222570:  
2023-09-26 20:19:07.223398: Epoch 192 
2023-09-26 20:19:07.223629: Current learning rate: 0.00825 
2023-09-26 20:20:47.373618: train_loss -0.8452 
2023-09-26 20:20:47.373993: val_loss -0.6252 
2023-09-26 20:20:47.374081: Pseudo dice [0.8811, 0.5916, 0.6734] 
2023-09-26 20:20:47.374179: Epoch time: 100.15 s 
2023-09-26 20:20:48.721779:  
2023-09-26 20:20:48.722216: Epoch 193 
2023-09-26 20:20:48.722434: Current learning rate: 0.00824 
2023-09-26 20:22:29.094858: train_loss -0.8528 
2023-09-26 20:22:29.095111: val_loss -0.6207 
2023-09-26 20:22:29.095188: Pseudo dice [0.8919, 0.5936, 0.6187] 
2023-09-26 20:22:29.095261: Epoch time: 100.38 s 
2023-09-26 20:22:30.397667:  
2023-09-26 20:22:30.397920: Epoch 194 
2023-09-26 20:22:30.398057: Current learning rate: 0.00824 
2023-09-26 20:24:10.416447: train_loss -0.8446 
2023-09-26 20:24:10.416738: val_loss -0.5929 
2023-09-26 20:24:10.416833: Pseudo dice [0.8884, 0.5857, 0.5498] 
2023-09-26 20:24:10.416929: Epoch time: 100.02 s 
2023-09-26 20:24:11.739907:  
2023-09-26 20:24:11.740207: Epoch 195 
2023-09-26 20:24:11.740350: Current learning rate: 0.00823 
2023-09-26 20:25:51.933892: train_loss -0.8524 
2023-09-26 20:25:51.934214: val_loss -0.5929 
2023-09-26 20:25:51.934301: Pseudo dice [0.8787, 0.6111, 0.5263] 
2023-09-26 20:25:51.934378: Epoch time: 100.2 s 
2023-09-26 20:25:53.244103:  
2023-09-26 20:25:53.244249: Epoch 196 
2023-09-26 20:25:53.244338: Current learning rate: 0.00822 
2023-09-26 20:27:33.404781: train_loss -0.8433 
2023-09-26 20:27:33.405105: val_loss -0.5998 
2023-09-26 20:27:33.405197: Pseudo dice [0.888, 0.5657, 0.5791] 
2023-09-26 20:27:33.405310: Epoch time: 100.16 s 
2023-09-26 20:27:34.710340:  
2023-09-26 20:27:34.710512: Epoch 197 
2023-09-26 20:27:34.710605: Current learning rate: 0.00821 
2023-09-26 20:29:14.482563: train_loss -0.8415 
2023-09-26 20:29:14.483870: val_loss -0.6011 
2023-09-26 20:29:14.483959: Pseudo dice [0.8906, 0.5525, 0.6256] 
2023-09-26 20:29:14.484060: Epoch time: 99.77 s 
2023-09-26 20:29:15.768825:  
2023-09-26 20:29:15.769068: Epoch 198 
2023-09-26 20:29:15.769159: Current learning rate: 0.0082 
2023-09-26 20:30:55.478982: train_loss -0.8504 
2023-09-26 20:30:55.479324: val_loss -0.6293 
2023-09-26 20:30:55.479406: Pseudo dice [0.8871, 0.5793, 0.6524] 
2023-09-26 20:30:55.479481: Epoch time: 99.71 s 
2023-09-26 20:30:56.764033:  
2023-09-26 20:30:56.764310: Epoch 199 
2023-09-26 20:30:56.764418: Current learning rate: 0.00819 
2023-09-26 20:32:36.902139: train_loss -0.8403 
2023-09-26 20:32:36.902409: val_loss -0.6 
2023-09-26 20:32:36.902487: Pseudo dice [0.8853, 0.6072, 0.5791] 
2023-09-26 20:32:36.902574: Epoch time: 100.14 s 
2023-09-26 20:32:39.894638:  
2023-09-26 20:32:39.894853: Epoch 200 
2023-09-26 20:32:39.894953: Current learning rate: 0.00818 
2023-09-26 20:34:20.009844: train_loss -0.8458 
2023-09-26 20:34:20.010221: val_loss -0.5952 
2023-09-26 20:34:20.010329: Pseudo dice [0.8907, 0.6065, 0.5854] 
2023-09-26 20:34:20.010428: Epoch time: 100.12 s 
2023-09-26 20:34:21.398853:  
2023-09-26 20:34:21.400111: Epoch 201 
2023-09-26 20:34:21.400772: Current learning rate: 0.00817 
2023-09-26 20:35:59.712441: train_loss -0.8465 
2023-09-26 20:35:59.712873: val_loss -0.5855 
2023-09-26 20:35:59.712980: Pseudo dice [0.8926, 0.5884, 0.4599] 
2023-09-26 20:35:59.713078: Epoch time: 98.32 s 
2023-09-26 20:36:01.563165:  
2023-09-26 20:36:01.563350: Epoch 202 
2023-09-26 20:36:01.563454: Current learning rate: 0.00816 
2023-09-26 20:37:41.626988: train_loss -0.8463 
2023-09-26 20:37:41.627319: val_loss -0.5974 
2023-09-26 20:37:41.627437: Pseudo dice [0.8909, 0.5705, 0.619] 
2023-09-26 20:37:41.627531: Epoch time: 100.07 s 
2023-09-26 20:37:42.971634:  
2023-09-26 20:37:42.972278: Epoch 203 
2023-09-26 20:37:42.972628: Current learning rate: 0.00815 
2023-09-26 20:39:22.504606: train_loss -0.8558 
2023-09-26 20:39:22.504953: val_loss -0.605 
2023-09-26 20:39:22.505056: Pseudo dice [0.8996, 0.5041, 0.5838] 
2023-09-26 20:39:22.505148: Epoch time: 99.54 s 
2023-09-26 20:39:23.988068:  
2023-09-26 20:39:23.988635: Epoch 204 
2023-09-26 20:39:23.988985: Current learning rate: 0.00814 
2023-09-26 20:41:03.664169: train_loss -0.8348 
2023-09-26 20:41:03.664562: val_loss -0.6021 
2023-09-26 20:41:03.664652: Pseudo dice [0.8808, 0.488, 0.6561] 
2023-09-26 20:41:03.664739: Epoch time: 99.68 s 
2023-09-26 20:41:05.054573:  
2023-09-26 20:41:05.054976: Epoch 205 
2023-09-26 20:41:05.055103: Current learning rate: 0.00813 
2023-09-26 20:42:45.347927: train_loss -0.7922 
2023-09-26 20:42:45.348228: val_loss -0.6286 
2023-09-26 20:42:45.348314: Pseudo dice [0.8709, 0.5964, 0.6478] 
2023-09-26 20:42:45.348420: Epoch time: 100.3 s 
2023-09-26 20:42:46.630386:  
2023-09-26 20:42:46.630649: Epoch 206 
2023-09-26 20:42:46.630742: Current learning rate: 0.00813 
2023-09-26 20:44:26.818931: train_loss -0.816 
2023-09-26 20:44:26.819432: val_loss -0.6088 
2023-09-26 20:44:26.819539: Pseudo dice [0.8737, 0.5118, 0.6083] 
2023-09-26 20:44:26.819637: Epoch time: 100.19 s 
2023-09-26 20:44:28.156456:  
2023-09-26 20:44:28.156861: Epoch 207 
2023-09-26 20:44:28.156974: Current learning rate: 0.00812 
2023-09-26 20:46:08.236504: train_loss -0.835 
2023-09-26 20:46:08.236887: val_loss -0.5953 
2023-09-26 20:46:08.237011: Pseudo dice [0.8954, 0.5656, 0.5544] 
2023-09-26 20:46:08.237118: Epoch time: 100.08 s 
2023-09-26 20:46:09.874284:  
2023-09-26 20:46:09.874563: Epoch 208 
2023-09-26 20:46:09.874660: Current learning rate: 0.00811 
2023-09-26 20:47:49.779766: train_loss -0.8161 
2023-09-26 20:47:49.780523: val_loss -0.5576 
2023-09-26 20:47:49.780635: Pseudo dice [0.8689, 0.5576, 0.5832] 
2023-09-26 20:47:49.780752: Epoch time: 99.91 s 
2023-09-26 20:47:51.058000:  
2023-09-26 20:47:51.058450: Epoch 209 
2023-09-26 20:47:51.058722: Current learning rate: 0.0081 
2023-09-26 20:49:31.042308: train_loss -0.8352 
2023-09-26 20:49:31.042620: val_loss -0.6658 
2023-09-26 20:49:31.042717: Pseudo dice [0.8936, 0.5996, 0.6733] 
2023-09-26 20:49:31.042800: Epoch time: 99.99 s 
2023-09-26 20:49:32.341644:  
2023-09-26 20:49:32.341863: Epoch 210 
2023-09-26 20:49:32.341982: Current learning rate: 0.00809 
2023-09-26 20:51:12.345498: train_loss -0.8308 
2023-09-26 20:51:12.346008: val_loss -0.5652 
2023-09-26 20:51:12.346122: Pseudo dice [0.8739, 0.454, 0.6475] 
2023-09-26 20:51:12.346244: Epoch time: 100.01 s 
2023-09-26 20:51:14.000858:  
2023-09-26 20:51:14.001462: Epoch 211 
2023-09-26 20:51:14.001603: Current learning rate: 0.00808 
2023-09-26 20:52:53.739795: train_loss -0.8382 
2023-09-26 20:52:53.740121: val_loss -0.5531 
2023-09-26 20:52:53.740218: Pseudo dice [0.8707, 0.5499, 0.5217] 
2023-09-26 20:52:53.740323: Epoch time: 99.74 s 
2023-09-26 20:52:55.038902:  
2023-09-26 20:52:55.039335: Epoch 212 
2023-09-26 20:52:55.039565: Current learning rate: 0.00807 
2023-09-26 20:54:34.813755: train_loss -0.8251 
2023-09-26 20:54:34.814390: val_loss -0.5801 
2023-09-26 20:54:34.814480: Pseudo dice [0.8846, 0.5508, 0.6206] 
2023-09-26 20:54:34.814584: Epoch time: 99.78 s 
2023-09-26 20:54:36.147468:  
2023-09-26 20:54:36.147716: Epoch 213 
2023-09-26 20:54:36.147837: Current learning rate: 0.00806 
2023-09-26 20:56:16.314415: train_loss -0.8411 
2023-09-26 20:56:16.314700: val_loss -0.6133 
2023-09-26 20:56:16.314782: Pseudo dice [0.8902, 0.622, 0.5837] 
2023-09-26 20:56:16.314861: Epoch time: 100.17 s 
2023-09-26 20:56:17.804188:  
2023-09-26 20:56:17.804335: Epoch 214 
2023-09-26 20:56:17.804425: Current learning rate: 0.00805 
2023-09-26 20:57:58.258059: train_loss -0.8518 
2023-09-26 20:57:58.258383: val_loss -0.6319 
2023-09-26 20:57:58.258475: Pseudo dice [0.8852, 0.5784, 0.6754] 
2023-09-26 20:57:58.258551: Epoch time: 100.46 s 
2023-09-26 20:57:59.566036:  
2023-09-26 20:57:59.566258: Epoch 215 
2023-09-26 20:57:59.566361: Current learning rate: 0.00804 
2023-09-26 20:59:39.242513: train_loss -0.8464 
2023-09-26 20:59:39.242796: val_loss -0.5969 
2023-09-26 20:59:39.242878: Pseudo dice [0.8946, 0.5969, 0.5465] 
2023-09-26 20:59:39.242954: Epoch time: 99.68 s 
2023-09-26 20:59:40.515108:  
2023-09-26 20:59:40.515501: Epoch 216 
2023-09-26 20:59:40.515728: Current learning rate: 0.00803 
2023-09-26 21:01:20.652489: train_loss -0.8524 
2023-09-26 21:01:20.652761: val_loss -0.611 
2023-09-26 21:01:20.652863: Pseudo dice [0.8918, 0.6218, 0.5707] 
2023-09-26 21:01:20.653008: Epoch time: 100.14 s 
2023-09-26 21:01:21.911410:  
2023-09-26 21:01:21.911597: Epoch 217 
2023-09-26 21:01:21.911703: Current learning rate: 0.00802 
2023-09-26 21:03:02.011841: train_loss -0.8483 
2023-09-26 21:03:02.012124: val_loss -0.5837 
2023-09-26 21:03:02.012204: Pseudo dice [0.8792, 0.5301, 0.5786] 
2023-09-26 21:03:02.012281: Epoch time: 100.1 s 
2023-09-26 21:03:03.287408:  
2023-09-26 21:03:03.287592: Epoch 218 
2023-09-26 21:03:03.287686: Current learning rate: 0.00801 
2023-09-26 21:04:43.365988: train_loss -0.8523 
2023-09-26 21:04:43.366267: val_loss -0.6334 
2023-09-26 21:04:43.366349: Pseudo dice [0.8981, 0.6486, 0.6584] 
2023-09-26 21:04:43.366425: Epoch time: 100.08 s 
2023-09-26 21:04:44.604718:  
2023-09-26 21:04:44.604863: Epoch 219 
2023-09-26 21:04:44.604950: Current learning rate: 0.00801 
2023-09-26 21:06:24.763185: train_loss -0.8448 
2023-09-26 21:06:24.763444: val_loss -0.5962 
2023-09-26 21:06:24.763524: Pseudo dice [0.8816, 0.5889, 0.5561] 
2023-09-26 21:06:24.763599: Epoch time: 100.16 s 
2023-09-26 21:06:26.232374:  
2023-09-26 21:06:26.232513: Epoch 220 
2023-09-26 21:06:26.232619: Current learning rate: 0.008 
2023-09-26 21:08:06.415615: train_loss -0.8371 
2023-09-26 21:08:06.415877: val_loss -0.6103 
2023-09-26 21:08:06.415959: Pseudo dice [0.8819, 0.5815, 0.6304] 
2023-09-26 21:08:06.416034: Epoch time: 100.18 s 
2023-09-26 21:08:07.656080:  
2023-09-26 21:08:07.656236: Epoch 221 
2023-09-26 21:08:07.656327: Current learning rate: 0.00799 
2023-09-26 21:09:47.743652: train_loss -0.8325 
2023-09-26 21:09:47.743975: val_loss -0.5654 
2023-09-26 21:09:47.744076: Pseudo dice [0.8753, 0.5476, 0.5191] 
2023-09-26 21:09:47.744171: Epoch time: 100.09 s 
2023-09-26 21:09:49.313221:  
2023-09-26 21:09:49.313410: Epoch 222 
2023-09-26 21:09:49.313521: Current learning rate: 0.00798 
2023-09-26 21:11:29.397252: train_loss -0.8354 
2023-09-26 21:11:29.397510: val_loss -0.5632 
2023-09-26 21:11:29.397591: Pseudo dice [0.8484, 0.5675, 0.5447] 
2023-09-26 21:11:29.397663: Epoch time: 100.09 s 
2023-09-26 21:11:30.644916:  
2023-09-26 21:11:30.645089: Epoch 223 
2023-09-26 21:11:30.645181: Current learning rate: 0.00797 
2023-09-26 21:13:10.645932: train_loss -0.8011 
2023-09-26 21:13:10.646218: val_loss -0.5588 
2023-09-26 21:13:10.646304: Pseudo dice [0.8788, 0.5463, 0.5007] 
2023-09-26 21:13:10.646381: Epoch time: 100.0 s 
2023-09-26 21:13:11.964768:  
2023-09-26 21:13:11.964937: Epoch 224 
2023-09-26 21:13:11.965037: Current learning rate: 0.00796 
2023-09-26 21:14:51.866507: train_loss -0.8165 
2023-09-26 21:14:51.867244: val_loss -0.5142 
2023-09-26 21:14:51.867355: Pseudo dice [0.8844, 0.5452, 0.2903] 
2023-09-26 21:14:51.867493: Epoch time: 99.9 s 
2023-09-26 21:14:53.515611:  
2023-09-26 21:14:53.515937: Epoch 225 
2023-09-26 21:14:53.516359: Current learning rate: 0.00795 
2023-09-26 21:16:33.732410: train_loss -0.8412 
2023-09-26 21:16:33.732662: val_loss -0.5725 
2023-09-26 21:16:33.732741: Pseudo dice [0.8914, 0.5629, 0.5532] 
2023-09-26 21:16:33.732814: Epoch time: 100.22 s 
2023-09-26 21:16:34.957658:  
2023-09-26 21:16:34.957797: Epoch 226 
2023-09-26 21:16:34.957887: Current learning rate: 0.00794 
2023-09-26 21:18:14.823669: train_loss -0.8142 
2023-09-26 21:18:14.824026: val_loss -0.6485 
2023-09-26 21:18:14.824157: Pseudo dice [0.8871, 0.672, 0.6141] 
2023-09-26 21:18:14.824277: Epoch time: 99.87 s 
2023-09-26 21:18:16.396132:  
2023-09-26 21:18:16.396292: Epoch 227 
2023-09-26 21:18:16.396381: Current learning rate: 0.00793 
2023-09-26 21:19:56.120565: train_loss -0.8172 
2023-09-26 21:19:56.120870: val_loss -0.5515 
2023-09-26 21:19:56.120973: Pseudo dice [0.861, 0.5496, 0.5275] 
2023-09-26 21:19:56.121066: Epoch time: 99.73 s 
2023-09-26 21:19:57.616562:  
2023-09-26 21:19:57.616800: Epoch 228 
2023-09-26 21:19:57.616917: Current learning rate: 0.00792 
2023-09-26 21:21:37.413312: train_loss -0.8184 
2023-09-26 21:21:37.413627: val_loss -0.6332 
2023-09-26 21:21:37.413743: Pseudo dice [0.8843, 0.5236, 0.6243] 
2023-09-26 21:21:37.413846: Epoch time: 99.8 s 
2023-09-26 21:21:38.680778:  
2023-09-26 21:21:38.681151: Epoch 229 
2023-09-26 21:21:38.681257: Current learning rate: 0.00791 
2023-09-26 21:23:18.807994: train_loss -0.8286 
2023-09-26 21:23:18.808238: val_loss -0.6259 
2023-09-26 21:23:18.808314: Pseudo dice [0.8835, 0.5946, 0.6608] 
2023-09-26 21:23:18.808384: Epoch time: 100.13 s 
2023-09-26 21:23:20.023021:  
2023-09-26 21:23:20.023332: Epoch 230 
2023-09-26 21:23:20.023426: Current learning rate: 0.0079 
2023-09-26 21:24:59.446802: train_loss -0.8443 
2023-09-26 21:24:59.447053: val_loss -0.6271 
2023-09-26 21:24:59.447130: Pseudo dice [0.8901, 0.6006, 0.64] 
2023-09-26 21:24:59.447202: Epoch time: 99.42 s 
2023-09-26 21:25:00.674825:  
2023-09-26 21:25:00.674979: Epoch 231 
2023-09-26 21:25:00.675066: Current learning rate: 0.00789 
2023-09-26 21:26:40.508162: train_loss -0.842 
2023-09-26 21:26:40.508471: val_loss -0.6014 
2023-09-26 21:26:40.508574: Pseudo dice [0.8926, 0.5465, 0.6102] 
2023-09-26 21:26:40.508671: Epoch time: 99.83 s 
2023-09-26 21:26:42.082748:  
2023-09-26 21:26:42.083426: Epoch 232 
2023-09-26 21:26:42.083558: Current learning rate: 0.00789 
2023-09-26 21:28:22.016016: train_loss -0.8485 
2023-09-26 21:28:22.016304: val_loss -0.6165 
2023-09-26 21:28:22.016401: Pseudo dice [0.8899, 0.5984, 0.5498] 
2023-09-26 21:28:22.016493: Epoch time: 99.93 s 
2023-09-26 21:28:23.785328:  
2023-09-26 21:28:23.785872: Epoch 233 
2023-09-26 21:28:23.785985: Current learning rate: 0.00788 
2023-09-26 21:30:03.550409: train_loss -0.8524 
2023-09-26 21:30:03.550892: val_loss -0.6359 
2023-09-26 21:30:03.550981: Pseudo dice [0.8955, 0.6219, 0.6805] 
2023-09-26 21:30:03.551063: Epoch time: 99.77 s 
2023-09-26 21:30:04.785103:  
2023-09-26 21:30:04.785257: Epoch 234 
2023-09-26 21:30:04.785344: Current learning rate: 0.00787 
2023-09-26 21:31:44.281775: train_loss -0.8419 
2023-09-26 21:31:44.282049: val_loss -0.6219 
2023-09-26 21:31:44.282156: Pseudo dice [0.8668, 0.6617, 0.6374] 
2023-09-26 21:31:44.282245: Epoch time: 99.5 s 
2023-09-26 21:31:45.928813:  
2023-09-26 21:31:45.928992: Epoch 235 
2023-09-26 21:31:45.929100: Current learning rate: 0.00786 
2023-09-26 21:33:25.830756: train_loss -0.8262 
2023-09-26 21:33:25.831043: val_loss -0.6188 
2023-09-26 21:33:25.831139: Pseudo dice [0.879, 0.5708, 0.6765] 
2023-09-26 21:33:25.831227: Epoch time: 99.9 s 
2023-09-26 21:33:27.419107:  
2023-09-26 21:33:27.419444: Epoch 236 
2023-09-26 21:33:27.419591: Current learning rate: 0.00785 
2023-09-26 21:35:07.321317: train_loss -0.8429 
2023-09-26 21:35:07.321613: val_loss -0.5914 
2023-09-26 21:35:07.321705: Pseudo dice [0.8878, 0.6031, 0.5987] 
2023-09-26 21:35:07.321787: Epoch time: 99.9 s 
2023-09-26 21:35:08.877057:  
2023-09-26 21:35:08.877743: Epoch 237 
2023-09-26 21:35:08.877977: Current learning rate: 0.00784 
2023-09-26 21:36:48.644584: train_loss -0.8437 
2023-09-26 21:36:48.645126: val_loss -0.6216 
2023-09-26 21:36:48.645217: Pseudo dice [0.8888, 0.5879, 0.6176] 
2023-09-26 21:36:48.645321: Epoch time: 99.77 s 
2023-09-26 21:36:49.917936:  
2023-09-26 21:36:49.918123: Epoch 238 
2023-09-26 21:36:49.918221: Current learning rate: 0.00783 
2023-09-26 21:38:30.156510: train_loss -0.8472 
2023-09-26 21:38:30.156880: val_loss -0.6433 
2023-09-26 21:38:30.156965: Pseudo dice [0.8962, 0.6642, 0.6278] 
2023-09-26 21:38:30.157051: Epoch time: 100.24 s 
2023-09-26 21:38:31.668830:  
2023-09-26 21:38:31.669207: Epoch 239 
2023-09-26 21:38:31.669303: Current learning rate: 0.00782 
2023-09-26 21:40:11.765160: train_loss -0.8538 
2023-09-26 21:40:11.765432: val_loss -0.6101 
2023-09-26 21:40:11.765514: Pseudo dice [0.8894, 0.5759, 0.6227] 
2023-09-26 21:40:11.765588: Epoch time: 100.1 s 
2023-09-26 21:40:13.022889:  
2023-09-26 21:40:13.023397: Epoch 240 
2023-09-26 21:40:13.023500: Current learning rate: 0.00781 
2023-09-26 21:41:53.070514: train_loss -0.8549 
2023-09-26 21:41:53.070814: val_loss -0.6132 
2023-09-26 21:41:53.070898: Pseudo dice [0.8801, 0.6198, 0.5929] 
2023-09-26 21:41:53.070976: Epoch time: 100.05 s 
2023-09-26 21:41:54.336691:  
2023-09-26 21:41:54.336872: Epoch 241 
2023-09-26 21:41:54.336962: Current learning rate: 0.0078 
2023-09-26 21:43:34.155330: train_loss -0.859 
2023-09-26 21:43:34.155600: val_loss -0.6266 
2023-09-26 21:43:34.155680: Pseudo dice [0.8844, 0.5672, 0.6404] 
2023-09-26 21:43:34.155755: Epoch time: 99.82 s 
2023-09-26 21:43:35.495876:  
2023-09-26 21:43:35.496157: Epoch 242 
2023-09-26 21:43:35.496312: Current learning rate: 0.00779 
2023-09-26 21:45:15.762254: train_loss -0.8454 
2023-09-26 21:45:15.762536: val_loss -0.6211 
2023-09-26 21:45:15.762630: Pseudo dice [0.894, 0.5709, 0.6616] 
2023-09-26 21:45:15.762725: Epoch time: 100.27 s 
2023-09-26 21:45:17.315720:  
2023-09-26 21:45:17.316061: Epoch 243 
2023-09-26 21:45:17.316253: Current learning rate: 0.00778 
2023-09-26 21:46:57.530909: train_loss -0.8375 
2023-09-26 21:46:57.531164: val_loss -0.6083 
2023-09-26 21:46:57.531241: Pseudo dice [0.8873, 0.495, 0.6353] 
2023-09-26 21:46:57.531359: Epoch time: 100.22 s 
2023-09-26 21:46:58.895553:  
2023-09-26 21:46:58.896189: Epoch 244 
2023-09-26 21:46:58.896421: Current learning rate: 0.00777 
2023-09-26 21:48:38.945236: train_loss -0.8473 
2023-09-26 21:48:38.945601: val_loss -0.5838 
2023-09-26 21:48:38.945704: Pseudo dice [0.8857, 0.5811, 0.5581] 
2023-09-26 21:48:38.945797: Epoch time: 100.05 s 
2023-09-26 21:48:40.435777:  
2023-09-26 21:48:40.435934: Epoch 245 
2023-09-26 21:48:40.436026: Current learning rate: 0.00777 
2023-09-26 21:50:20.459766: train_loss -0.8534 
2023-09-26 21:50:20.460063: val_loss -0.6156 
2023-09-26 21:50:20.460147: Pseudo dice [0.898, 0.5919, 0.617] 
2023-09-26 21:50:20.460228: Epoch time: 100.03 s 
2023-09-26 21:50:21.959589:  
2023-09-26 21:50:21.959802: Epoch 246 
2023-09-26 21:50:21.959896: Current learning rate: 0.00776 
2023-09-26 21:52:02.094236: train_loss -0.8591 
2023-09-26 21:52:02.094524: val_loss -0.626 
2023-09-26 21:52:02.094624: Pseudo dice [0.8926, 0.5278, 0.6365] 
2023-09-26 21:52:02.094716: Epoch time: 100.14 s 
2023-09-26 21:52:03.685584:  
2023-09-26 21:52:03.685967: Epoch 247 
2023-09-26 21:52:03.686077: Current learning rate: 0.00775 
2023-09-26 21:53:43.676606: train_loss -0.8636 
2023-09-26 21:53:43.677009: val_loss -0.6073 
2023-09-26 21:53:43.677127: Pseudo dice [0.8908, 0.5543, 0.7] 
2023-09-26 21:53:43.677220: Epoch time: 99.99 s 
2023-09-26 21:53:44.936986:  
2023-09-26 21:53:44.937140: Epoch 248 
2023-09-26 21:53:44.937228: Current learning rate: 0.00774 
2023-09-26 21:55:24.828448: train_loss -0.8513 
2023-09-26 21:55:24.829228: val_loss -0.5948 
2023-09-26 21:55:24.829318: Pseudo dice [0.8837, 0.5931, 0.607] 
2023-09-26 21:55:24.829427: Epoch time: 99.89 s 
2023-09-26 21:55:26.090194:  
2023-09-26 21:55:26.090372: Epoch 249 
2023-09-26 21:55:26.090468: Current learning rate: 0.00773 
2023-09-26 21:57:06.449359: train_loss -0.8522 
2023-09-26 21:57:06.449672: val_loss -0.6826 
2023-09-26 21:57:06.449760: Pseudo dice [0.8922, 0.6592, 0.7023] 
2023-09-26 21:57:06.449839: Epoch time: 100.36 s 
2023-09-26 21:57:09.280761:  
2023-09-26 21:57:09.281225: Epoch 250 
2023-09-26 21:57:09.281338: Current learning rate: 0.00772 
2023-09-26 21:58:49.054857: train_loss -0.8567 
2023-09-26 21:58:49.055190: val_loss -0.6171 
2023-09-26 21:58:49.055336: Pseudo dice [0.8821, 0.603, 0.6425] 
2023-09-26 21:58:49.055451: Epoch time: 99.78 s 
2023-09-26 21:58:50.690775:  
2023-09-26 21:58:50.691080: Epoch 251 
2023-09-26 21:58:50.691207: Current learning rate: 0.00771 
2023-09-26 22:00:28.889107: train_loss -0.8486 
2023-09-26 22:00:28.889368: val_loss -0.6119 
2023-09-26 22:00:28.890411: Pseudo dice [0.8903, 0.5861, 0.6121] 
2023-09-26 22:00:28.890729: Epoch time: 98.2 s 
2023-09-26 22:00:30.902543:  
2023-09-26 22:00:30.902805: Epoch 252 
2023-09-26 22:00:30.902953: Current learning rate: 0.0077 
2023-09-26 22:02:10.690981: train_loss -0.8549 
2023-09-26 22:02:10.691830: val_loss -0.5986 
2023-09-26 22:02:10.691943: Pseudo dice [0.8818, 0.5636, 0.5578] 
2023-09-26 22:02:10.692077: Epoch time: 99.79 s 
2023-09-26 22:02:12.348124:  
2023-09-26 22:02:12.348313: Epoch 253 
2023-09-26 22:02:12.348426: Current learning rate: 0.00769 
2023-09-26 22:03:52.016992: train_loss -0.8377 
2023-09-26 22:03:52.017319: val_loss -0.5909 
2023-09-26 22:03:52.017431: Pseudo dice [0.8947, 0.564, 0.6055] 
2023-09-26 22:03:52.017523: Epoch time: 99.67 s 
2023-09-26 22:03:53.633759:  
2023-09-26 22:03:53.633994: Epoch 254 
2023-09-26 22:03:53.634124: Current learning rate: 0.00768 
2023-09-26 22:05:34.172204: train_loss -0.8574 
2023-09-26 22:05:34.172451: val_loss -0.637 
2023-09-26 22:05:34.172534: Pseudo dice [0.8924, 0.6275, 0.6513] 
2023-09-26 22:05:34.172607: Epoch time: 100.54 s 
2023-09-26 22:05:35.446522:  
2023-09-26 22:05:35.446835: Epoch 255 
2023-09-26 22:05:35.446937: Current learning rate: 0.00767 
2023-09-26 22:07:16.540020: train_loss -0.8468 
2023-09-26 22:07:16.540270: val_loss -0.6011 
2023-09-26 22:07:16.540346: Pseudo dice [0.8816, 0.6233, 0.5936] 
2023-09-26 22:07:16.540416: Epoch time: 101.09 s 
2023-09-26 22:07:17.809127:  
2023-09-26 22:07:17.809498: Epoch 256 
2023-09-26 22:07:17.809681: Current learning rate: 0.00766 
2023-09-26 22:08:59.230277: train_loss -0.8455 
2023-09-26 22:08:59.230896: val_loss -0.5967 
2023-09-26 22:08:59.230987: Pseudo dice [0.8796, 0.6223, 0.5244] 
2023-09-26 22:08:59.231097: Epoch time: 101.42 s 
2023-09-26 22:09:00.529599:  
2023-09-26 22:09:00.529896: Epoch 257 
2023-09-26 22:09:00.529997: Current learning rate: 0.00765 
2023-09-26 22:10:41.583487: train_loss -0.8588 
2023-09-26 22:10:41.583750: val_loss -0.6166 
2023-09-26 22:10:41.583832: Pseudo dice [0.8856, 0.5844, 0.6289] 
2023-09-26 22:10:41.583912: Epoch time: 101.06 s 
2023-09-26 22:10:43.052504:  
2023-09-26 22:10:43.052672: Epoch 258 
2023-09-26 22:10:43.052767: Current learning rate: 0.00764 
2023-09-26 22:12:23.764287: train_loss -0.8543 
2023-09-26 22:12:23.764614: val_loss -0.6024 
2023-09-26 22:12:23.764731: Pseudo dice [0.8948, 0.5666, 0.6284] 
2023-09-26 22:12:23.764827: Epoch time: 100.71 s 
2023-09-26 22:12:25.425092:  
2023-09-26 22:12:25.425411: Epoch 259 
2023-09-26 22:12:25.425527: Current learning rate: 0.00764 
2023-09-26 22:14:06.204419: train_loss -0.8627 
2023-09-26 22:14:06.204956: val_loss -0.5719 
2023-09-26 22:14:06.205039: Pseudo dice [0.8844, 0.6121, 0.5074] 
2023-09-26 22:14:06.205137: Epoch time: 100.78 s 
2023-09-26 22:14:07.597089:  
2023-09-26 22:14:07.597318: Epoch 260 
2023-09-26 22:14:07.597528: Current learning rate: 0.00763 
2023-09-26 22:15:47.612960: train_loss -0.8536 
2023-09-26 22:15:47.613206: val_loss -0.5914 
2023-09-26 22:15:47.613286: Pseudo dice [0.8978, 0.5219, 0.6025] 
2023-09-26 22:15:47.613358: Epoch time: 100.02 s 
2023-09-26 22:15:49.095757:  
2023-09-26 22:15:49.096020: Epoch 261 
2023-09-26 22:15:49.096132: Current learning rate: 0.00762 
2023-09-26 22:17:29.254177: train_loss -0.8595 
2023-09-26 22:17:29.254470: val_loss -0.5947 
2023-09-26 22:17:29.254567: Pseudo dice [0.8929, 0.6143, 0.5479] 
2023-09-26 22:17:29.254655: Epoch time: 100.16 s 
2023-09-26 22:17:30.821488:  
2023-09-26 22:17:30.821656: Epoch 262 
2023-09-26 22:17:30.821761: Current learning rate: 0.00761 
2023-09-26 22:19:10.863314: train_loss -0.869 
2023-09-26 22:19:10.863567: val_loss -0.601 
2023-09-26 22:19:10.863646: Pseudo dice [0.8961, 0.5791, 0.5454] 
2023-09-26 22:19:10.863721: Epoch time: 100.04 s 
2023-09-26 22:19:12.164582:  
2023-09-26 22:19:12.164800: Epoch 263 
2023-09-26 22:19:12.164897: Current learning rate: 0.0076 
2023-09-26 22:20:52.034719: train_loss -0.8669 
2023-09-26 22:20:52.034979: val_loss -0.6298 
2023-09-26 22:20:52.035059: Pseudo dice [0.8901, 0.6139, 0.5935] 
2023-09-26 22:20:52.035130: Epoch time: 99.87 s 
2023-09-26 22:20:53.509521:  
2023-09-26 22:20:53.509668: Epoch 264 
2023-09-26 22:20:53.509772: Current learning rate: 0.00759 
2023-09-26 22:22:33.513148: train_loss -0.8623 
2023-09-26 22:22:33.513461: val_loss -0.637 
2023-09-26 22:22:33.513561: Pseudo dice [0.8981, 0.6476, 0.6413] 
2023-09-26 22:22:33.513648: Epoch time: 100.0 s 
2023-09-26 22:22:35.079951:  
2023-09-26 22:22:35.080307: Epoch 265 
2023-09-26 22:22:35.080432: Current learning rate: 0.00758 
2023-09-26 22:24:14.905706: train_loss -0.8704 
2023-09-26 22:24:14.905954: val_loss -0.6046 
2023-09-26 22:24:14.906028: Pseudo dice [0.8911, 0.6367, 0.5861] 
2023-09-26 22:24:14.906104: Epoch time: 99.83 s 
2023-09-26 22:24:16.158683:  
2023-09-26 22:24:16.159155: Epoch 266 
2023-09-26 22:24:16.159269: Current learning rate: 0.00757 
2023-09-26 22:25:55.931580: train_loss -0.8712 
2023-09-26 22:25:55.931839: val_loss -0.6192 
2023-09-26 22:25:55.931920: Pseudo dice [0.8931, 0.5865, 0.6407] 
2023-09-26 22:25:55.931993: Epoch time: 99.77 s 
2023-09-26 22:25:57.496207:  
2023-09-26 22:25:57.496543: Epoch 267 
2023-09-26 22:25:57.496657: Current learning rate: 0.00756 
2023-09-26 22:27:37.237402: train_loss -0.8658 
2023-09-26 22:27:37.237658: val_loss -0.5576 
2023-09-26 22:27:37.237737: Pseudo dice [0.8863, 0.5833, 0.5019] 
2023-09-26 22:27:37.237810: Epoch time: 99.74 s 
2023-09-26 22:27:38.483412:  
2023-09-26 22:27:38.483547: Epoch 268 
2023-09-26 22:27:38.483633: Current learning rate: 0.00755 
2023-09-26 22:29:18.283319: train_loss -0.8641 
2023-09-26 22:29:18.283602: val_loss -0.5882 
2023-09-26 22:29:18.283701: Pseudo dice [0.8839, 0.581, 0.5437] 
2023-09-26 22:29:18.283871: Epoch time: 99.8 s 
2023-09-26 22:29:19.877509:  
2023-09-26 22:29:19.877745: Epoch 269 
2023-09-26 22:29:19.877860: Current learning rate: 0.00754 
2023-09-26 22:30:59.726879: train_loss -0.8608 
2023-09-26 22:30:59.727149: val_loss -0.6061 
2023-09-26 22:30:59.727230: Pseudo dice [0.9006, 0.6403, 0.516] 
2023-09-26 22:30:59.727304: Epoch time: 99.85 s 
2023-09-26 22:31:01.247831:  
2023-09-26 22:31:01.247977: Epoch 270 
2023-09-26 22:31:01.248065: Current learning rate: 0.00753 
2023-09-26 22:32:41.097373: train_loss -0.8606 
2023-09-26 22:32:41.097698: val_loss -0.5822 
2023-09-26 22:32:41.097838: Pseudo dice [0.8906, 0.5586, 0.5095] 
2023-09-26 22:32:41.097914: Epoch time: 99.85 s 
2023-09-26 22:32:42.371503:  
2023-09-26 22:32:42.371650: Epoch 271 
2023-09-26 22:32:42.371738: Current learning rate: 0.00752 
2023-09-26 22:34:22.346036: train_loss -0.8447 
2023-09-26 22:34:22.346289: val_loss -0.6398 
2023-09-26 22:34:22.346367: Pseudo dice [0.8695, 0.6155, 0.6509] 
2023-09-26 22:34:22.346437: Epoch time: 99.98 s 
2023-09-26 22:34:23.591497:  
2023-09-26 22:34:23.591651: Epoch 272 
2023-09-26 22:34:23.591748: Current learning rate: 0.00751 
2023-09-26 22:36:03.692749: train_loss -0.8486 
2023-09-26 22:36:03.693040: val_loss -0.5949 
2023-09-26 22:36:03.693136: Pseudo dice [0.8947, 0.5348, 0.5769] 
2023-09-26 22:36:03.693227: Epoch time: 100.1 s 
2023-09-26 22:36:05.046013:  
2023-09-26 22:36:05.046220: Epoch 273 
2023-09-26 22:36:05.046321: Current learning rate: 0.00751 
2023-09-26 22:37:44.549417: train_loss -0.866 
2023-09-26 22:37:44.549697: val_loss -0.6033 
2023-09-26 22:37:44.549776: Pseudo dice [0.8923, 0.5389, 0.6568] 
2023-09-26 22:37:44.549846: Epoch time: 99.5 s 
2023-09-26 22:37:45.790957:  
2023-09-26 22:37:45.791125: Epoch 274 
2023-09-26 22:37:45.791213: Current learning rate: 0.0075 
2023-09-26 22:39:25.804429: train_loss -0.8511 
2023-09-26 22:39:25.804725: val_loss -0.5867 
2023-09-26 22:39:25.804825: Pseudo dice [0.8848, 0.5405, 0.5894] 
2023-09-26 22:39:25.804914: Epoch time: 100.01 s 
2023-09-26 22:39:27.131084:  
2023-09-26 22:39:27.131216: Epoch 275 
2023-09-26 22:39:27.131306: Current learning rate: 0.00749 
2023-09-26 22:41:07.243256: train_loss -0.8604 
2023-09-26 22:41:07.243492: val_loss -0.6044 
2023-09-26 22:41:07.243569: Pseudo dice [0.8925, 0.5633, 0.6878] 
2023-09-26 22:41:07.243639: Epoch time: 100.11 s 
2023-09-26 22:41:08.643692:  
2023-09-26 22:41:08.643845: Epoch 276 
2023-09-26 22:41:08.643997: Current learning rate: 0.00748 
2023-09-26 22:42:48.700811: train_loss -0.8602 
2023-09-26 22:42:48.701079: val_loss -0.5841 
2023-09-26 22:42:48.701160: Pseudo dice [0.8754, 0.5396, 0.5947] 
2023-09-26 22:42:48.701232: Epoch time: 100.06 s 
2023-09-26 22:42:49.913754:  
2023-09-26 22:42:49.913879: Epoch 277 
2023-09-26 22:42:49.913965: Current learning rate: 0.00747 
2023-09-26 22:44:29.921775: train_loss -0.8421 
2023-09-26 22:44:29.922031: val_loss -0.5963 
2023-09-26 22:44:29.922154: Pseudo dice [0.8799, 0.5675, 0.5484] 
2023-09-26 22:44:29.922255: Epoch time: 100.01 s 
2023-09-26 22:44:31.170897:  
2023-09-26 22:44:31.171361: Epoch 278 
2023-09-26 22:44:31.171494: Current learning rate: 0.00746 
2023-09-26 22:46:11.299743: train_loss -0.848 
2023-09-26 22:46:11.299989: val_loss -0.5902 
2023-09-26 22:46:11.300066: Pseudo dice [0.8765, 0.534, 0.6003] 
2023-09-26 22:46:11.300138: Epoch time: 100.13 s 
2023-09-26 22:46:12.554510:  
2023-09-26 22:46:12.554869: Epoch 279 
2023-09-26 22:46:12.554974: Current learning rate: 0.00745 
2023-09-26 22:47:52.159726: train_loss -0.8639 
2023-09-26 22:47:52.159968: val_loss -0.6426 
2023-09-26 22:47:52.160048: Pseudo dice [0.8977, 0.5983, 0.6819] 
2023-09-26 22:47:52.160122: Epoch time: 99.61 s 
2023-09-26 22:47:53.652409:  
2023-09-26 22:47:53.652595: Epoch 280 
2023-09-26 22:47:53.652693: Current learning rate: 0.00744 
2023-09-26 22:49:33.804106: train_loss -0.8679 
2023-09-26 22:49:33.804359: val_loss -0.67 
2023-09-26 22:49:33.804440: Pseudo dice [0.8962, 0.6354, 0.6977] 
2023-09-26 22:49:33.804518: Epoch time: 100.15 s 
2023-09-26 22:49:35.107267:  
2023-09-26 22:49:35.107731: Epoch 281 
2023-09-26 22:49:35.107835: Current learning rate: 0.00743 
2023-09-26 22:51:14.982146: train_loss -0.8566 
2023-09-26 22:51:14.982421: val_loss -0.5962 
2023-09-26 22:51:14.982500: Pseudo dice [0.8919, 0.5665, 0.5385] 
2023-09-26 22:51:14.982573: Epoch time: 99.88 s 
2023-09-26 22:51:16.238943:  
2023-09-26 22:51:16.239087: Epoch 282 
2023-09-26 22:51:16.239177: Current learning rate: 0.00742 
2023-09-26 22:52:56.280333: train_loss -0.8615 
2023-09-26 22:52:56.280589: val_loss -0.5736 
2023-09-26 22:52:56.280663: Pseudo dice [0.8915, 0.518, 0.542] 
2023-09-26 22:52:56.280733: Epoch time: 100.04 s 
2023-09-26 22:52:57.727897:  
2023-09-26 22:52:57.728244: Epoch 283 
2023-09-26 22:52:57.728337: Current learning rate: 0.00741 
2023-09-26 22:54:37.898952: train_loss -0.8346 
2023-09-26 22:54:37.899214: val_loss -0.6081 
2023-09-26 22:54:37.899293: Pseudo dice [0.8812, 0.6255, 0.5614] 
2023-09-26 22:54:37.899365: Epoch time: 100.17 s 
2023-09-26 22:54:39.341720:  
2023-09-26 22:54:39.342208: Epoch 284 
2023-09-26 22:54:39.342321: Current learning rate: 0.0074 
2023-09-26 22:56:19.535105: train_loss -0.8403 
2023-09-26 22:56:19.535400: val_loss -0.5866 
2023-09-26 22:56:19.535494: Pseudo dice [0.8727, 0.6025, 0.5705] 
2023-09-26 22:56:19.535581: Epoch time: 100.19 s 
2023-09-26 22:56:20.804988:  
2023-09-26 22:56:20.805782: Epoch 285 
2023-09-26 22:56:20.806281: Current learning rate: 0.00739 
2023-09-26 22:58:00.953829: train_loss -0.8466 
2023-09-26 22:58:00.954532: val_loss -0.6096 
2023-09-26 22:58:00.954626: Pseudo dice [0.8912, 0.5681, 0.6223] 
2023-09-26 22:58:00.954706: Epoch time: 100.15 s 
2023-09-26 22:58:02.240068:  
2023-09-26 22:58:02.240420: Epoch 286 
2023-09-26 22:58:02.240570: Current learning rate: 0.00738 
2023-09-26 22:59:42.511658: train_loss -0.8618 
2023-09-26 22:59:42.512089: val_loss -0.599 
2023-09-26 22:59:42.512209: Pseudo dice [0.8942, 0.5349, 0.659] 
2023-09-26 22:59:42.512291: Epoch time: 100.27 s 
2023-09-26 22:59:43.819144:  
2023-09-26 22:59:43.819384: Epoch 287 
2023-09-26 22:59:43.819475: Current learning rate: 0.00738 
2023-09-26 23:01:23.458995: train_loss -0.8693 
2023-09-26 23:01:23.459292: val_loss -0.5649 
2023-09-26 23:01:23.459384: Pseudo dice [0.898, 0.5151, 0.454] 
2023-09-26 23:01:23.459474: Epoch time: 99.64 s 
2023-09-26 23:01:24.824568:  
2023-09-26 23:01:24.824707: Epoch 288 
2023-09-26 23:01:24.824800: Current learning rate: 0.00737 
2023-09-26 23:03:05.195675: train_loss -0.8449 
2023-09-26 23:03:05.196374: val_loss -0.5597 
2023-09-26 23:03:05.196481: Pseudo dice [0.8868, 0.4843, 0.5607] 
2023-09-26 23:03:05.196611: Epoch time: 100.37 s 
2023-09-26 23:03:07.111536:  
2023-09-26 23:03:07.111723: Epoch 289 
2023-09-26 23:03:07.111831: Current learning rate: 0.00736 
2023-09-26 23:04:47.172992: train_loss -0.8585 
2023-09-26 23:04:47.173254: val_loss -0.6118 
2023-09-26 23:04:47.173332: Pseudo dice [0.893, 0.5659, 0.6387] 
2023-09-26 23:04:47.173406: Epoch time: 100.06 s 
2023-09-26 23:04:48.448223:  
2023-09-26 23:04:48.448851: Epoch 290 
2023-09-26 23:04:48.449067: Current learning rate: 0.00735 
2023-09-26 23:06:28.548103: train_loss -0.8692 
2023-09-26 23:06:28.548362: val_loss -0.5762 
2023-09-26 23:06:28.548448: Pseudo dice [0.8947, 0.5396, 0.5639] 
2023-09-26 23:06:28.548524: Epoch time: 100.1 s 
2023-09-26 23:06:29.820318:  
2023-09-26 23:06:29.820461: Epoch 291 
2023-09-26 23:06:29.820554: Current learning rate: 0.00734 
2023-09-26 23:08:09.505618: train_loss -0.8719 
2023-09-26 23:08:09.505896: val_loss -0.5942 
2023-09-26 23:08:09.505975: Pseudo dice [0.8987, 0.5769, 0.5997] 
2023-09-26 23:08:09.506052: Epoch time: 99.69 s 
2023-09-26 23:08:10.827682:  
2023-09-26 23:08:10.827900: Epoch 292 
2023-09-26 23:08:10.827991: Current learning rate: 0.00733 
2023-09-26 23:09:50.445267: train_loss -0.8764 
2023-09-26 23:09:50.445559: val_loss -0.5871 
2023-09-26 23:09:50.445641: Pseudo dice [0.8997, 0.4578, 0.6348] 
2023-09-26 23:09:50.445717: Epoch time: 99.62 s 
2023-09-26 23:09:51.777268:  
2023-09-26 23:09:51.777732: Epoch 293 
2023-09-26 23:09:51.777933: Current learning rate: 0.00732 
2023-09-26 23:11:31.833142: train_loss -0.8744 
2023-09-26 23:11:31.833438: val_loss -0.6286 
2023-09-26 23:11:31.833532: Pseudo dice [0.8964, 0.5112, 0.6644] 
2023-09-26 23:11:31.833614: Epoch time: 100.06 s 
2023-09-26 23:11:33.273883:  
2023-09-26 23:11:33.275020: Epoch 294 
2023-09-26 23:11:33.275370: Current learning rate: 0.00731 
2023-09-26 23:13:13.547520: train_loss -0.8735 
2023-09-26 23:13:13.547931: val_loss -0.5625 
2023-09-26 23:13:13.548087: Pseudo dice [0.8945, 0.5813, 0.4784] 
2023-09-26 23:13:13.548273: Epoch time: 100.28 s 
2023-09-26 23:13:15.148916:  
2023-09-26 23:13:15.149342: Epoch 295 
2023-09-26 23:13:15.149502: Current learning rate: 0.0073 
2023-09-26 23:14:55.510406: train_loss -0.8612 
2023-09-26 23:14:55.510682: val_loss -0.6194 
2023-09-26 23:14:55.510776: Pseudo dice [0.8959, 0.5463, 0.6464] 
2023-09-26 23:14:55.510857: Epoch time: 100.36 s 
2023-09-26 23:14:57.145648:  
2023-09-26 23:14:57.146018: Epoch 296 
2023-09-26 23:14:57.146224: Current learning rate: 0.00729 
2023-09-26 23:16:37.466141: train_loss -0.8701 
2023-09-26 23:16:37.466645: val_loss -0.5563 
2023-09-26 23:16:37.466731: Pseudo dice [0.8755, 0.5628, 0.5189] 
2023-09-26 23:16:37.466857: Epoch time: 100.32 s 
2023-09-26 23:16:38.771458:  
2023-09-26 23:16:38.771606: Epoch 297 
2023-09-26 23:16:38.771695: Current learning rate: 0.00728 
2023-09-26 23:18:18.858322: train_loss -0.8684 
2023-09-26 23:18:18.858600: val_loss -0.5964 
2023-09-26 23:18:18.858690: Pseudo dice [0.8714, 0.5641, 0.6205] 
2023-09-26 23:18:18.858770: Epoch time: 100.09 s 
2023-09-26 23:18:20.430783:  
2023-09-26 23:18:20.431051: Epoch 298 
2023-09-26 23:18:20.431175: Current learning rate: 0.00727 
2023-09-26 23:20:00.675999: train_loss -0.8421 
2023-09-26 23:20:00.676554: val_loss -0.5924 
2023-09-26 23:20:00.676645: Pseudo dice [0.8836, 0.5323, 0.5459] 
2023-09-26 23:20:00.676754: Epoch time: 100.25 s 
2023-09-26 23:20:02.011372:  
2023-09-26 23:20:02.011556: Epoch 299 
2023-09-26 23:20:02.011649: Current learning rate: 0.00726 
2023-09-26 23:21:41.666180: train_loss -0.8599 
2023-09-26 23:21:41.666813: val_loss -0.6138 
2023-09-26 23:21:41.666940: Pseudo dice [0.8833, 0.59, 0.6297] 
2023-09-26 23:21:41.667067: Epoch time: 99.66 s 
2023-09-26 23:21:44.823961:  
2023-09-26 23:21:44.824345: Epoch 300 
2023-09-26 23:21:44.824446: Current learning rate: 0.00725 
2023-09-26 23:23:24.690422: train_loss -0.8543 
2023-09-26 23:23:24.690739: val_loss -0.5953 
2023-09-26 23:23:24.690838: Pseudo dice [0.893, 0.5001, 0.6255] 
2023-09-26 23:23:24.690913: Epoch time: 99.87 s 
2023-09-26 23:23:26.034491:  
2023-09-26 23:23:26.035386: Epoch 301 
2023-09-26 23:23:26.035767: Current learning rate: 0.00724 
2023-09-26 23:25:05.943309: train_loss -0.8577 
2023-09-26 23:25:05.943713: val_loss -0.5982 
2023-09-26 23:25:05.943805: Pseudo dice [0.8833, 0.5287, 0.6316] 
2023-09-26 23:25:05.943889: Epoch time: 99.91 s 
2023-09-26 23:25:07.230339:  
2023-09-26 23:25:07.230642: Epoch 302 
2023-09-26 23:25:07.230736: Current learning rate: 0.00724 
2023-09-26 23:26:45.461283: train_loss -0.8409 
2023-09-26 23:26:45.461523: val_loss -0.5974 
2023-09-26 23:26:45.461601: Pseudo dice [0.877, 0.546, 0.6158] 
2023-09-26 23:26:45.461674: Epoch time: 98.23 s 
2023-09-26 23:26:46.740083:  
2023-09-26 23:26:46.740395: Epoch 303 
2023-09-26 23:26:46.740497: Current learning rate: 0.00723 
2023-09-26 23:28:26.598038: train_loss -0.8692 
2023-09-26 23:28:26.598349: val_loss -0.5934 
2023-09-26 23:28:26.598437: Pseudo dice [0.8833, 0.4758, 0.634] 
2023-09-26 23:28:26.598572: Epoch time: 99.86 s 
2023-09-26 23:28:27.984583:  
2023-09-26 23:28:27.985113: Epoch 304 
2023-09-26 23:28:27.985247: Current learning rate: 0.00722 
2023-09-26 23:30:06.649531: train_loss -0.8671 
2023-09-26 23:30:06.649815: val_loss -0.6184 
2023-09-26 23:30:06.649904: Pseudo dice [0.8686, 0.5446, 0.6718] 
2023-09-26 23:30:06.649979: Epoch time: 98.67 s 
2023-09-26 23:30:07.915768:  
2023-09-26 23:30:07.916011: Epoch 305 
2023-09-26 23:30:07.916106: Current learning rate: 0.00721 
2023-09-26 23:31:46.410390: train_loss -0.8297 
2023-09-26 23:31:46.410658: val_loss -0.5419 
2023-09-26 23:31:46.410750: Pseudo dice [0.8787, 0.56, 0.4083] 
2023-09-26 23:31:46.410829: Epoch time: 98.5 s 
2023-09-26 23:31:47.911847:  
2023-09-26 23:31:47.912048: Epoch 306 
2023-09-26 23:31:47.912144: Current learning rate: 0.0072 
2023-09-26 23:33:26.499072: train_loss -0.8171 
2023-09-26 23:33:26.499397: val_loss -0.6146 
2023-09-26 23:33:26.499504: Pseudo dice [0.8944, 0.5227, 0.6276] 
2023-09-26 23:33:26.499621: Epoch time: 98.59 s 
2023-09-26 23:33:28.199682:  
2023-09-26 23:33:28.200373: Epoch 307 
2023-09-26 23:33:28.200652: Current learning rate: 0.00719 
2023-09-26 23:35:08.378596: train_loss -0.813 
2023-09-26 23:35:08.379014: val_loss -0.5511 
2023-09-26 23:35:08.379106: Pseudo dice [0.8715, 0.6096, 0.3546] 
2023-09-26 23:35:08.379184: Epoch time: 100.18 s 
2023-09-26 23:35:09.661736:  
2023-09-26 23:35:09.661885: Epoch 308 
2023-09-26 23:35:09.661972: Current learning rate: 0.00718 
2023-09-26 23:36:49.514764: train_loss -0.8086 
2023-09-26 23:36:49.515065: val_loss -0.5583 
2023-09-26 23:36:49.515155: Pseudo dice [0.8689, 0.6069, 0.4788] 
2023-09-26 23:36:49.515247: Epoch time: 99.85 s 
2023-09-26 23:36:50.802052:  
2023-09-26 23:36:50.802562: Epoch 309 
2023-09-26 23:36:50.802706: Current learning rate: 0.00717 
2023-09-26 23:38:30.499622: train_loss -0.8253 
2023-09-26 23:38:30.499879: val_loss -0.5646 
2023-09-26 23:38:30.499957: Pseudo dice [0.8622, 0.5262, 0.5414] 
2023-09-26 23:38:30.500029: Epoch time: 99.7 s 
2023-09-26 23:38:32.006976:  
2023-09-26 23:38:32.007141: Epoch 310 
2023-09-26 23:38:32.007230: Current learning rate: 0.00716 
2023-09-26 23:40:12.118951: train_loss -0.8028 
2023-09-26 23:40:12.119234: val_loss -0.5827 
2023-09-26 23:40:12.119328: Pseudo dice [0.8697, 0.5239, 0.6141] 
2023-09-26 23:40:12.119418: Epoch time: 100.11 s 
2023-09-26 23:40:13.742280:  
2023-09-26 23:40:13.742454: Epoch 311 
2023-09-26 23:40:13.742558: Current learning rate: 0.00715 
2023-09-26 23:41:53.891972: train_loss -0.7904 
2023-09-26 23:41:53.892247: val_loss -0.5757 
2023-09-26 23:41:53.892344: Pseudo dice [0.8698, 0.5809, 0.4941] 
2023-09-26 23:41:53.892481: Epoch time: 100.15 s 
2023-09-26 23:41:55.240155:  
2023-09-26 23:41:55.240446: Epoch 312 
2023-09-26 23:41:55.240551: Current learning rate: 0.00714 
2023-09-26 23:43:34.977418: train_loss -0.7982 
2023-09-26 23:43:34.977676: val_loss -0.5752 
2023-09-26 23:43:34.977753: Pseudo dice [0.8762, 0.5407, 0.5671] 
2023-09-26 23:43:34.977826: Epoch time: 99.74 s 
2023-09-26 23:43:36.502405:  
2023-09-26 23:43:36.502579: Epoch 313 
2023-09-26 23:43:36.502671: Current learning rate: 0.00713 
2023-09-26 23:45:16.435583: train_loss -0.8319 
2023-09-26 23:45:16.435843: val_loss -0.6351 
2023-09-26 23:45:16.435921: Pseudo dice [0.8978, 0.6041, 0.6937] 
2023-09-26 23:45:16.435993: Epoch time: 99.93 s 
2023-09-26 23:45:17.679681:  
2023-09-26 23:45:17.679832: Epoch 314 
2023-09-26 23:45:17.679922: Current learning rate: 0.00712 
2023-09-26 23:46:57.442974: train_loss -0.8434 
2023-09-26 23:46:57.443230: val_loss -0.5645 
2023-09-26 23:46:57.443309: Pseudo dice [0.8827, 0.5209, 0.6171] 
2023-09-26 23:46:57.443377: Epoch time: 99.76 s 
2023-09-26 23:46:58.762155:  
2023-09-26 23:46:58.762395: Epoch 315 
2023-09-26 23:46:58.762486: Current learning rate: 0.00711 
2023-09-26 23:48:38.670095: train_loss -0.8491 
2023-09-26 23:48:38.670357: val_loss -0.6056 
2023-09-26 23:48:38.670427: Pseudo dice [0.8867, 0.577, 0.5907] 
2023-09-26 23:48:38.670490: Epoch time: 99.91 s 
2023-09-26 23:48:39.924641:  
2023-09-26 23:48:39.924819: Epoch 316 
2023-09-26 23:48:39.924920: Current learning rate: 0.0071 
2023-09-26 23:50:19.971175: train_loss -0.8506 
2023-09-26 23:50:19.971447: val_loss -0.6535 
2023-09-26 23:50:19.971527: Pseudo dice [0.8922, 0.6253, 0.6589] 
2023-09-26 23:50:19.971598: Epoch time: 100.05 s 
2023-09-26 23:50:21.264320:  
2023-09-26 23:50:21.264457: Epoch 317 
2023-09-26 23:50:21.264545: Current learning rate: 0.0071 
2023-09-26 23:52:01.260202: train_loss -0.8452 
2023-09-26 23:52:01.260465: val_loss -0.5836 
2023-09-26 23:52:01.260559: Pseudo dice [0.871, 0.5774, 0.6127] 
2023-09-26 23:52:01.260643: Epoch time: 100.0 s 
2023-09-26 23:52:02.543538:  
2023-09-26 23:52:02.543687: Epoch 318 
2023-09-26 23:52:02.543774: Current learning rate: 0.00709 
2023-09-26 23:53:42.586679: train_loss -0.838 
2023-09-26 23:53:42.587025: val_loss -0.5963 
2023-09-26 23:53:42.587118: Pseudo dice [0.881, 0.5114, 0.6425] 
2023-09-26 23:53:42.587200: Epoch time: 100.04 s 
2023-09-26 23:53:44.023953:  
2023-09-26 23:53:44.024109: Epoch 319 
2023-09-26 23:53:44.024198: Current learning rate: 0.00708 
2023-09-26 23:55:23.703904: train_loss -0.8244 
2023-09-26 23:55:23.704220: val_loss -0.5207 
2023-09-26 23:55:23.704315: Pseudo dice [0.8571, 0.4187, 0.5474] 
2023-09-26 23:55:23.704407: Epoch time: 99.68 s 
2023-09-26 23:55:25.120376:  
2023-09-26 23:55:25.120539: Epoch 320 
2023-09-26 23:55:25.120629: Current learning rate: 0.00707 
2023-09-26 23:57:04.707959: train_loss -0.8326 
2023-09-26 23:57:04.708216: val_loss -0.6249 
2023-09-26 23:57:04.708294: Pseudo dice [0.8889, 0.5692, 0.6395] 
2023-09-26 23:57:04.708366: Epoch time: 99.59 s 
2023-09-26 23:57:06.306058:  
2023-09-26 23:57:06.306246: Epoch 321 
2023-09-26 23:57:06.306353: Current learning rate: 0.00706 
2023-09-26 23:58:46.480528: train_loss -0.852 
2023-09-26 23:58:46.480811: val_loss -0.57 
2023-09-26 23:58:46.480905: Pseudo dice [0.887, 0.4823, 0.6187] 
2023-09-26 23:58:46.480995: Epoch time: 100.18 s 
2023-09-26 23:58:47.796952:  
2023-09-26 23:58:47.797204: Epoch 322 
2023-09-26 23:58:47.797299: Current learning rate: 0.00705 
2023-09-27 00:00:27.757472: train_loss -0.849 
2023-09-27 00:00:27.758333: val_loss -0.5933 
2023-09-27 00:00:27.758445: Pseudo dice [0.8879, 0.5689, 0.6043] 
2023-09-27 00:00:27.758570: Epoch time: 99.96 s 
2023-09-27 00:00:29.069110:  
2023-09-27 00:00:29.069280: Epoch 323 
2023-09-27 00:00:29.069374: Current learning rate: 0.00704 
2023-09-27 00:02:09.256298: train_loss -0.8525 
2023-09-27 00:02:09.256580: val_loss -0.588 
2023-09-27 00:02:09.256661: Pseudo dice [0.8894, 0.6198, 0.5517] 
2023-09-27 00:02:09.256753: Epoch time: 100.19 s 
2023-09-27 00:02:10.597005:  
2023-09-27 00:02:10.597157: Epoch 324 
2023-09-27 00:02:10.597253: Current learning rate: 0.00703 
2023-09-27 00:03:50.957086: train_loss -0.8623 
2023-09-27 00:03:50.957342: val_loss -0.6132 
2023-09-27 00:03:50.957423: Pseudo dice [0.8791, 0.5747, 0.6229] 
2023-09-27 00:03:50.957496: Epoch time: 100.36 s 
2023-09-27 00:03:52.508835:  
2023-09-27 00:03:52.509115: Epoch 325 
2023-09-27 00:03:52.509211: Current learning rate: 0.00702 
2023-09-27 00:05:32.766664: train_loss -0.8675 
2023-09-27 00:05:32.767230: val_loss -0.6267 
2023-09-27 00:05:32.767318: Pseudo dice [0.8949, 0.6245, 0.6008] 
2023-09-27 00:05:32.767422: Epoch time: 100.26 s 
2023-09-27 00:05:34.038137:  
2023-09-27 00:05:34.038619: Epoch 326 
2023-09-27 00:05:34.038721: Current learning rate: 0.00701 
2023-09-27 00:07:13.414814: train_loss -0.8616 
2023-09-27 00:07:13.415124: val_loss -0.6312 
2023-09-27 00:07:13.415283: Pseudo dice [0.8906, 0.5857, 0.6745] 
2023-09-27 00:07:13.415416: Epoch time: 99.38 s 
2023-09-27 00:07:14.803555:  
2023-09-27 00:07:14.803687: Epoch 327 
2023-09-27 00:07:14.803775: Current learning rate: 0.007 
2023-09-27 00:08:54.298549: train_loss -0.8724 
2023-09-27 00:08:54.298837: val_loss -0.6509 
2023-09-27 00:08:54.298914: Pseudo dice [0.8914, 0.5587, 0.6598] 
2023-09-27 00:08:54.298989: Epoch time: 99.5 s 
2023-09-27 00:08:55.630493:  
2023-09-27 00:08:55.630638: Epoch 328 
2023-09-27 00:08:55.630726: Current learning rate: 0.00699 
2023-09-27 00:10:35.630822: train_loss -0.8775 
2023-09-27 00:10:35.631071: val_loss -0.6284 
2023-09-27 00:10:35.631151: Pseudo dice [0.8983, 0.5297, 0.6635] 
2023-09-27 00:10:35.631222: Epoch time: 100.0 s 
2023-09-27 00:10:37.225166:  
2023-09-27 00:10:37.225398: Epoch 329 
2023-09-27 00:10:37.225508: Current learning rate: 0.00698 
2023-09-27 00:12:17.050629: train_loss -0.8704 
2023-09-27 00:12:17.050880: val_loss -0.6211 
2023-09-27 00:12:17.050958: Pseudo dice [0.8909, 0.58, 0.6592] 
2023-09-27 00:12:17.051032: Epoch time: 99.83 s 
2023-09-27 00:12:18.353565:  
2023-09-27 00:12:18.353819: Epoch 330 
2023-09-27 00:12:18.353916: Current learning rate: 0.00697 
2023-09-27 00:13:58.357559: train_loss -0.8708 
2023-09-27 00:13:58.357795: val_loss -0.6014 
2023-09-27 00:13:58.357875: Pseudo dice [0.8911, 0.5632, 0.5964] 
2023-09-27 00:13:58.357948: Epoch time: 100.01 s 
2023-09-27 00:13:59.789789:  
2023-09-27 00:13:59.789926: Epoch 331 
2023-09-27 00:13:59.790014: Current learning rate: 0.00696 
2023-09-27 00:15:39.825108: train_loss -0.8668 
2023-09-27 00:15:39.825366: val_loss -0.5846 
2023-09-27 00:15:39.825445: Pseudo dice [0.8967, 0.5734, 0.5509] 
2023-09-27 00:15:39.825517: Epoch time: 100.04 s 
2023-09-27 00:15:41.188276:  
2023-09-27 00:15:41.188486: Epoch 332 
2023-09-27 00:15:41.188577: Current learning rate: 0.00696 
2023-09-27 00:17:20.815633: train_loss -0.8724 
2023-09-27 00:17:20.815897: val_loss -0.58 
2023-09-27 00:17:20.815991: Pseudo dice [0.8985, 0.5507, 0.5473] 
2023-09-27 00:17:20.816075: Epoch time: 99.63 s 
2023-09-27 00:17:22.402819:  
2023-09-27 00:17:22.403061: Epoch 333 
2023-09-27 00:17:22.403182: Current learning rate: 0.00695 
2023-09-27 00:19:01.932897: train_loss -0.8733 
2023-09-27 00:19:01.933148: val_loss -0.6113 
2023-09-27 00:19:01.933228: Pseudo dice [0.8956, 0.5543, 0.5981] 
2023-09-27 00:19:01.933297: Epoch time: 99.53 s 
2023-09-27 00:19:03.270545:  
2023-09-27 00:19:03.270683: Epoch 334 
2023-09-27 00:19:03.270771: Current learning rate: 0.00694 
2023-09-27 00:20:43.123842: train_loss -0.8644 
2023-09-27 00:20:43.124197: val_loss -0.5758 
2023-09-27 00:20:43.124300: Pseudo dice [0.8896, 0.4734, 0.5927] 
2023-09-27 00:20:43.124396: Epoch time: 99.85 s 
2023-09-27 00:20:44.452270:  
2023-09-27 00:20:44.452600: Epoch 335 
2023-09-27 00:20:44.452712: Current learning rate: 0.00693 
2023-09-27 00:22:24.347691: train_loss -0.8708 
2023-09-27 00:22:24.347942: val_loss -0.6274 
2023-09-27 00:22:24.348023: Pseudo dice [0.8907, 0.5735, 0.6336] 
2023-09-27 00:22:24.348098: Epoch time: 99.9 s 
2023-09-27 00:22:25.776364:  
2023-09-27 00:22:25.776498: Epoch 336 
2023-09-27 00:22:25.776596: Current learning rate: 0.00692 
2023-09-27 00:24:05.830211: train_loss -0.8726 
2023-09-27 00:24:05.830475: val_loss -0.5625 
2023-09-27 00:24:05.830556: Pseudo dice [0.891, 0.4991, 0.5537] 
2023-09-27 00:24:05.830629: Epoch time: 100.05 s 
2023-09-27 00:24:07.364710:  
2023-09-27 00:24:07.364909: Epoch 337 
2023-09-27 00:24:07.365018: Current learning rate: 0.00691 
2023-09-27 00:25:47.163257: train_loss -0.8629 
2023-09-27 00:25:47.163539: val_loss -0.5792 
2023-09-27 00:25:47.163635: Pseudo dice [0.8829, 0.565, 0.6024] 
2023-09-27 00:25:47.163726: Epoch time: 99.8 s 
2023-09-27 00:25:48.548136:  
2023-09-27 00:25:48.548282: Epoch 338 
2023-09-27 00:25:48.548368: Current learning rate: 0.0069 
2023-09-27 00:27:28.762603: train_loss -0.8665 
2023-09-27 00:27:28.762831: val_loss -0.5841 
2023-09-27 00:27:28.762913: Pseudo dice [0.8846, 0.4512, 0.6546] 
2023-09-27 00:27:28.762986: Epoch time: 100.22 s 
2023-09-27 00:27:30.036919:  
2023-09-27 00:27:30.037056: Epoch 339 
2023-09-27 00:27:30.037143: Current learning rate: 0.00689 
2023-09-27 00:29:11.322516: train_loss -0.8602 
2023-09-27 00:29:11.322768: val_loss -0.5885 
2023-09-27 00:29:11.322848: Pseudo dice [0.8816, 0.5518, 0.5407] 
2023-09-27 00:29:11.322919: Epoch time: 101.29 s 
2023-09-27 00:29:12.604666:  
2023-09-27 00:29:12.604841: Epoch 340 
2023-09-27 00:29:12.604932: Current learning rate: 0.00688 
2023-09-27 00:30:54.100071: train_loss -0.8423 
2023-09-27 00:30:54.100342: val_loss -0.5895 
2023-09-27 00:30:54.100424: Pseudo dice [0.8922, 0.5353, 0.655] 
2023-09-27 00:30:54.100503: Epoch time: 101.5 s 
2023-09-27 00:30:55.433141:  
2023-09-27 00:30:55.433441: Epoch 341 
2023-09-27 00:30:55.433531: Current learning rate: 0.00687 
2023-09-27 00:32:36.069476: train_loss -0.8576 
2023-09-27 00:32:36.069732: val_loss -0.613 
2023-09-27 00:32:36.069810: Pseudo dice [0.8951, 0.5123, 0.6206] 
2023-09-27 00:32:36.069882: Epoch time: 100.64 s 
2023-09-27 00:32:37.591703:  
2023-09-27 00:32:37.591878: Epoch 342 
2023-09-27 00:32:37.591974: Current learning rate: 0.00686 
2023-09-27 00:34:17.958847: train_loss -0.8738 
2023-09-27 00:34:17.959172: val_loss -0.6175 
2023-09-27 00:34:17.959270: Pseudo dice [0.8869, 0.5542, 0.5896] 
2023-09-27 00:34:17.959361: Epoch time: 100.37 s 
2023-09-27 00:34:19.282317:  
2023-09-27 00:34:19.282572: Epoch 343 
2023-09-27 00:34:19.282683: Current learning rate: 0.00685 
2023-09-27 00:35:59.403925: train_loss -0.8401 
2023-09-27 00:35:59.404404: val_loss -0.5735 
2023-09-27 00:35:59.404698: Pseudo dice [0.8865, 0.5505, 0.5342] 
2023-09-27 00:35:59.405017: Epoch time: 100.12 s 
2023-09-27 00:36:00.822808:  
2023-09-27 00:36:00.823084: Epoch 344 
2023-09-27 00:36:00.823177: Current learning rate: 0.00684 
2023-09-27 00:37:41.121642: train_loss -0.8549 
2023-09-27 00:37:41.121905: val_loss -0.6003 
2023-09-27 00:37:41.121984: Pseudo dice [0.8725, 0.6011, 0.5773] 
2023-09-27 00:37:41.122056: Epoch time: 100.3 s 
2023-09-27 00:37:42.442394:  
2023-09-27 00:37:42.442647: Epoch 345 
2023-09-27 00:37:42.442741: Current learning rate: 0.00683 
2023-09-27 00:39:22.396811: train_loss -0.8628 
2023-09-27 00:39:22.397059: val_loss -0.5966 
2023-09-27 00:39:22.397139: Pseudo dice [0.8745, 0.5982, 0.5114] 
2023-09-27 00:39:22.397215: Epoch time: 99.96 s 
2023-09-27 00:39:24.008384:  
2023-09-27 00:39:24.008541: Epoch 346 
2023-09-27 00:39:24.008646: Current learning rate: 0.00682 
2023-09-27 00:41:03.965471: train_loss -0.8559 
2023-09-27 00:41:03.965715: val_loss -0.5931 
2023-09-27 00:41:03.965792: Pseudo dice [0.8942, 0.4755, 0.5615] 
2023-09-27 00:41:03.965864: Epoch time: 99.96 s 
2023-09-27 00:41:05.293751:  
2023-09-27 00:41:05.293885: Epoch 347 
2023-09-27 00:41:05.293987: Current learning rate: 0.00681 
2023-09-27 00:42:45.152558: train_loss -0.8631 
2023-09-27 00:42:45.152807: val_loss -0.6189 
2023-09-27 00:42:45.152886: Pseudo dice [0.8944, 0.6269, 0.5634] 
2023-09-27 00:42:45.152957: Epoch time: 99.86 s 
2023-09-27 00:42:46.618863:  
2023-09-27 00:42:46.619009: Epoch 348 
2023-09-27 00:42:46.619102: Current learning rate: 0.0068 
2023-09-27 00:44:26.531866: train_loss -0.8644 
2023-09-27 00:44:26.532132: val_loss -0.6119 
2023-09-27 00:44:26.532222: Pseudo dice [0.9006, 0.5551, 0.5805] 
2023-09-27 00:44:26.532302: Epoch time: 99.91 s 
2023-09-27 00:44:27.825608:  
2023-09-27 00:44:27.825747: Epoch 349 
2023-09-27 00:44:27.825833: Current learning rate: 0.0068 
2023-09-27 00:46:07.637545: train_loss -0.8768 
2023-09-27 00:46:07.637790: val_loss -0.5714 
2023-09-27 00:46:07.637869: Pseudo dice [0.8912, 0.5456, 0.5126] 
2023-09-27 00:46:07.637941: Epoch time: 99.81 s 
2023-09-27 00:46:10.542458:  
2023-09-27 00:46:10.542588: Epoch 350 
2023-09-27 00:46:10.542675: Current learning rate: 0.00679 
2023-09-27 00:47:50.394670: train_loss -0.8842 
2023-09-27 00:47:50.394920: val_loss -0.6016 
2023-09-27 00:47:50.395000: Pseudo dice [0.8992, 0.5864, 0.5684] 
2023-09-27 00:47:50.395075: Epoch time: 99.85 s 
2023-09-27 00:47:51.746358:  
2023-09-27 00:47:51.746583: Epoch 351 
2023-09-27 00:47:51.746679: Current learning rate: 0.00678 
2023-09-27 00:49:31.524526: train_loss -0.8786 
2023-09-27 00:49:31.524770: val_loss -0.5955 
2023-09-27 00:49:31.524851: Pseudo dice [0.8874, 0.5417, 0.5662] 
2023-09-27 00:49:31.524922: Epoch time: 99.78 s 
2023-09-27 00:49:32.805467:  
2023-09-27 00:49:32.805619: Epoch 352 
2023-09-27 00:49:32.805707: Current learning rate: 0.00677 
2023-09-27 00:51:12.501735: train_loss -0.8678 
2023-09-27 00:51:12.501979: val_loss -0.5994 
2023-09-27 00:51:12.502056: Pseudo dice [0.8865, 0.5241, 0.5831] 
2023-09-27 00:51:12.502137: Epoch time: 99.7 s 
2023-09-27 00:51:13.798430:  
2023-09-27 00:51:13.798579: Epoch 353 
2023-09-27 00:51:13.798664: Current learning rate: 0.00676 
2023-09-27 00:52:52.270753: train_loss -0.8653 
2023-09-27 00:52:52.271005: val_loss -0.6129 
2023-09-27 00:52:52.271084: Pseudo dice [0.8959, 0.4933, 0.6554] 
2023-09-27 00:52:52.271159: Epoch time: 98.47 s 
2023-09-27 00:52:53.696654:  
2023-09-27 00:52:53.696800: Epoch 354 
2023-09-27 00:52:53.696888: Current learning rate: 0.00675 
2023-09-27 00:54:33.823467: train_loss -0.8741 
2023-09-27 00:54:33.823842: val_loss -0.5785 
2023-09-27 00:54:33.823943: Pseudo dice [0.8893, 0.5675, 0.56] 
2023-09-27 00:54:33.824034: Epoch time: 100.13 s 
2023-09-27 00:54:35.179374:  
2023-09-27 00:54:35.179645: Epoch 355 
2023-09-27 00:54:35.179733: Current learning rate: 0.00674 
2023-09-27 00:56:15.330076: train_loss -0.8712 
2023-09-27 00:56:15.330391: val_loss -0.6206 
2023-09-27 00:56:15.330484: Pseudo dice [0.8969, 0.5385, 0.6814] 
2023-09-27 00:56:15.330559: Epoch time: 100.15 s 
2023-09-27 00:56:16.611201:  
2023-09-27 00:56:16.611472: Epoch 356 
2023-09-27 00:56:16.611565: Current learning rate: 0.00673 
2023-09-27 00:57:56.602676: train_loss -0.8649 
2023-09-27 00:57:56.602910: val_loss -0.6147 
2023-09-27 00:57:56.602988: Pseudo dice [0.8899, 0.5578, 0.6359] 
2023-09-27 00:57:56.603057: Epoch time: 99.99 s 
2023-09-27 00:57:57.881388:  
2023-09-27 00:57:57.881784: Epoch 357 
2023-09-27 00:57:57.881877: Current learning rate: 0.00672 
2023-09-27 00:59:37.926414: train_loss -0.8713 
2023-09-27 00:59:37.926729: val_loss -0.6076 
2023-09-27 00:59:37.926927: Pseudo dice [0.8998, 0.6107, 0.6043] 
2023-09-27 00:59:37.927025: Epoch time: 100.05 s 
2023-09-27 00:59:39.560549:  
2023-09-27 00:59:39.560704: Epoch 358 
2023-09-27 00:59:39.560809: Current learning rate: 0.00671 
2023-09-27 01:01:18.965128: train_loss -0.8732 
2023-09-27 01:01:18.965388: val_loss -0.5771 
2023-09-27 01:01:18.965469: Pseudo dice [0.8774, 0.5301, 0.5567] 
2023-09-27 01:01:18.965540: Epoch time: 99.41 s 
2023-09-27 01:01:20.245069:  
2023-09-27 01:01:20.245334: Epoch 359 
2023-09-27 01:01:20.245423: Current learning rate: 0.0067 
2023-09-27 01:02:59.805268: train_loss -0.8735 
2023-09-27 01:02:59.805549: val_loss -0.5485 
2023-09-27 01:02:59.805644: Pseudo dice [0.8904, 0.464, 0.511] 
2023-09-27 01:02:59.805727: Epoch time: 99.56 s 
2023-09-27 01:03:01.466087:  
2023-09-27 01:03:01.466305: Epoch 360 
2023-09-27 01:03:01.466410: Current learning rate: 0.00669 
2023-09-27 01:04:41.502922: train_loss -0.8732 
2023-09-27 01:04:41.503209: val_loss -0.5864 
2023-09-27 01:04:41.503307: Pseudo dice [0.8841, 0.5253, 0.5929] 
2023-09-27 01:04:41.503396: Epoch time: 100.04 s 
2023-09-27 01:04:42.785287:  
2023-09-27 01:04:42.785502: Epoch 361 
2023-09-27 01:04:42.785594: Current learning rate: 0.00668 
2023-09-27 01:06:22.798988: train_loss -0.875 
2023-09-27 01:06:22.799237: val_loss -0.5544 
2023-09-27 01:06:22.799318: Pseudo dice [0.8888, 0.5407, 0.4864] 
2023-09-27 01:06:22.799392: Epoch time: 100.01 s 
2023-09-27 01:06:24.133978:  
2023-09-27 01:06:24.134301: Epoch 362 
2023-09-27 01:06:24.134396: Current learning rate: 0.00667 
2023-09-27 01:08:04.016972: train_loss -0.8771 
2023-09-27 01:08:04.017227: val_loss -0.5747 
2023-09-27 01:08:04.017309: Pseudo dice [0.8985, 0.5435, 0.5508] 
2023-09-27 01:08:04.017382: Epoch time: 99.88 s 
2023-09-27 01:08:05.582661:  
2023-09-27 01:08:05.582832: Epoch 363 
2023-09-27 01:08:05.582934: Current learning rate: 0.00666 
2023-09-27 01:09:45.396411: train_loss -0.8719 
2023-09-27 01:09:45.396659: val_loss -0.4944 
2023-09-27 01:09:45.396740: Pseudo dice [0.884, 0.5718, 0.2148] 
2023-09-27 01:09:45.396814: Epoch time: 99.82 s 
2023-09-27 01:09:46.676257:  
2023-09-27 01:09:46.676410: Epoch 364 
2023-09-27 01:09:46.676509: Current learning rate: 0.00665 
2023-09-27 01:11:26.812339: train_loss -0.8605 
2023-09-27 01:11:26.812580: val_loss -0.5901 
2023-09-27 01:11:26.812659: Pseudo dice [0.8874, 0.5019, 0.6039] 
2023-09-27 01:11:26.812730: Epoch time: 100.14 s 
2023-09-27 01:11:28.089257:  
2023-09-27 01:11:28.089513: Epoch 365 
2023-09-27 01:11:28.089614: Current learning rate: 0.00665 
2023-09-27 01:13:08.264897: train_loss -0.8536 
2023-09-27 01:13:08.265125: val_loss -0.577 
2023-09-27 01:13:08.265212: Pseudo dice [0.8867, 0.52, 0.5408] 
2023-09-27 01:13:08.265284: Epoch time: 100.18 s 
2023-09-27 01:13:09.572016:  
2023-09-27 01:13:09.572159: Epoch 366 
2023-09-27 01:13:09.572247: Current learning rate: 0.00664 
2023-09-27 01:14:49.803587: train_loss -0.8714 
2023-09-27 01:14:49.803851: val_loss -0.5905 
2023-09-27 01:14:49.803931: Pseudo dice [0.8848, 0.5736, 0.556] 
2023-09-27 01:14:49.804010: Epoch time: 100.23 s 
2023-09-27 01:14:51.085216:  
2023-09-27 01:14:51.085474: Epoch 367 
2023-09-27 01:14:51.085574: Current learning rate: 0.00663 
2023-09-27 01:16:30.957458: train_loss -0.8617 
2023-09-27 01:16:30.957716: val_loss -0.5718 
2023-09-27 01:16:30.957798: Pseudo dice [0.8914, 0.577, 0.4738] 
2023-09-27 01:16:30.957870: Epoch time: 99.87 s 
2023-09-27 01:16:32.244063:  
2023-09-27 01:16:32.244247: Epoch 368 
2023-09-27 01:16:32.244355: Current learning rate: 0.00662 
2023-09-27 01:18:11.805683: train_loss -0.8627 
2023-09-27 01:18:11.805934: val_loss -0.543 
2023-09-27 01:18:11.806014: Pseudo dice [0.8774, 0.5511, 0.3757] 
2023-09-27 01:18:11.806089: Epoch time: 99.56 s 
2023-09-27 01:18:13.082585:  
2023-09-27 01:18:13.082885: Epoch 369 
2023-09-27 01:18:13.082975: Current learning rate: 0.00661 
2023-09-27 01:19:52.699229: train_loss -0.8583 
2023-09-27 01:19:52.699533: val_loss -0.5284 
2023-09-27 01:19:52.699622: Pseudo dice [0.8873, 0.5381, 0.3679] 
2023-09-27 01:19:52.699701: Epoch time: 99.62 s 
2023-09-27 01:19:54.006950:  
2023-09-27 01:19:54.007081: Epoch 370 
2023-09-27 01:19:54.007165: Current learning rate: 0.0066 
2023-09-27 01:21:34.170626: train_loss -0.864 
2023-09-27 01:21:34.170977: val_loss -0.5515 
2023-09-27 01:21:34.171059: Pseudo dice [0.8897, 0.4996, 0.5652] 
2023-09-27 01:21:34.171135: Epoch time: 100.16 s 
2023-09-27 01:21:35.651920:  
2023-09-27 01:21:35.652060: Epoch 371 
2023-09-27 01:21:35.652147: Current learning rate: 0.00659 
2023-09-27 01:23:15.639746: train_loss -0.8727 
2023-09-27 01:23:15.640042: val_loss -0.6029 
2023-09-27 01:23:15.640141: Pseudo dice [0.8927, 0.5846, 0.6109] 
2023-09-27 01:23:15.640230: Epoch time: 99.99 s 
2023-09-27 01:23:16.986043:  
2023-09-27 01:23:16.986259: Epoch 372 
2023-09-27 01:23:16.986426: Current learning rate: 0.00658 
2023-09-27 01:24:56.962770: train_loss -0.8775 
2023-09-27 01:24:56.963031: val_loss -0.6122 
2023-09-27 01:24:56.963111: Pseudo dice [0.8878, 0.5541, 0.6237] 
2023-09-27 01:24:56.963184: Epoch time: 99.98 s 
2023-09-27 01:24:58.301853:  
2023-09-27 01:24:58.302105: Epoch 373 
2023-09-27 01:24:58.302205: Current learning rate: 0.00657 
2023-09-27 01:26:38.437033: train_loss -0.8546 
2023-09-27 01:26:38.437277: val_loss -0.5786 
2023-09-27 01:26:38.437355: Pseudo dice [0.8782, 0.5697, 0.5321] 
2023-09-27 01:26:38.437429: Epoch time: 100.14 s 
2023-09-27 01:26:39.713992:  
2023-09-27 01:26:39.714148: Epoch 374 
2023-09-27 01:26:39.714239: Current learning rate: 0.00656 
2023-09-27 01:28:19.447215: train_loss -0.8494 
2023-09-27 01:28:19.447604: val_loss -0.5765 
2023-09-27 01:28:19.447686: Pseudo dice [0.8758, 0.5899, 0.499] 
2023-09-27 01:28:19.447760: Epoch time: 99.73 s 
2023-09-27 01:28:20.733459:  
2023-09-27 01:28:20.733616: Epoch 375 
2023-09-27 01:28:20.733706: Current learning rate: 0.00655 
2023-09-27 01:30:00.521763: train_loss -0.8566 
2023-09-27 01:30:00.522024: val_loss -0.5751 
2023-09-27 01:30:00.522117: Pseudo dice [0.899, 0.5107, 0.5631] 
2023-09-27 01:30:00.522196: Epoch time: 99.79 s 
2023-09-27 01:30:01.899543:  
2023-09-27 01:30:01.900009: Epoch 376 
2023-09-27 01:30:01.900109: Current learning rate: 0.00654 
2023-09-27 01:31:41.739805: train_loss -0.864 
2023-09-27 01:31:41.740166: val_loss -0.6068 
2023-09-27 01:31:41.740243: Pseudo dice [0.8927, 0.5284, 0.6286] 
2023-09-27 01:31:41.740315: Epoch time: 99.84 s 
2023-09-27 01:31:43.219131:  
2023-09-27 01:31:43.219280: Epoch 377 
2023-09-27 01:31:43.219369: Current learning rate: 0.00653 
2023-09-27 01:33:22.758618: train_loss -0.8734 
2023-09-27 01:33:22.758875: val_loss -0.603 
2023-09-27 01:33:22.758952: Pseudo dice [0.896, 0.6109, 0.5271] 
2023-09-27 01:33:22.759022: Epoch time: 99.54 s 
2023-09-27 01:33:24.109911:  
2023-09-27 01:33:24.110049: Epoch 378 
2023-09-27 01:33:24.110156: Current learning rate: 0.00652 
2023-09-27 01:35:03.710617: train_loss -0.8836 
2023-09-27 01:35:03.710875: val_loss -0.6278 
2023-09-27 01:35:03.710956: Pseudo dice [0.9031, 0.5894, 0.6289] 
2023-09-27 01:35:03.711030: Epoch time: 99.6 s 
2023-09-27 01:35:04.982323:  
2023-09-27 01:35:04.982496: Epoch 379 
2023-09-27 01:35:04.982596: Current learning rate: 0.00651 
2023-09-27 01:36:44.883105: train_loss -0.8775 
2023-09-27 01:36:44.883362: val_loss -0.6078 
2023-09-27 01:36:44.883444: Pseudo dice [0.8762, 0.589, 0.6148] 
2023-09-27 01:36:44.883516: Epoch time: 99.9 s 
2023-09-27 01:36:46.204285:  
2023-09-27 01:36:46.204606: Epoch 380 
2023-09-27 01:36:46.204847: Current learning rate: 0.0065 
2023-09-27 01:38:26.064032: train_loss -0.8703 
2023-09-27 01:38:26.064299: val_loss -0.5645 
2023-09-27 01:38:26.064379: Pseudo dice [0.8953, 0.5258, 0.5507] 
2023-09-27 01:38:26.064454: Epoch time: 99.86 s 
2023-09-27 01:38:27.614483:  
2023-09-27 01:38:27.614722: Epoch 381 
2023-09-27 01:38:27.614830: Current learning rate: 0.00649 
2023-09-27 01:40:07.315377: train_loss -0.8724 
2023-09-27 01:40:07.315715: val_loss -0.5806 
2023-09-27 01:40:07.315872: Pseudo dice [0.8844, 0.6025, 0.4769] 
2023-09-27 01:40:07.315999: Epoch time: 99.7 s 
2023-09-27 01:40:09.034438:  
2023-09-27 01:40:09.034627: Epoch 382 
2023-09-27 01:40:09.034736: Current learning rate: 0.00648 
2023-09-27 01:41:49.058687: train_loss -0.879 
2023-09-27 01:41:49.058918: val_loss -0.5876 
2023-09-27 01:41:49.058996: Pseudo dice [0.8995, 0.5774, 0.6222] 
2023-09-27 01:41:49.059067: Epoch time: 100.03 s 
2023-09-27 01:41:50.586992:  
2023-09-27 01:41:50.587155: Epoch 383 
2023-09-27 01:41:50.587253: Current learning rate: 0.00648 
2023-09-27 01:43:30.454565: train_loss -0.8813 
2023-09-27 01:43:30.454860: val_loss -0.6405 
2023-09-27 01:43:30.454957: Pseudo dice [0.8956, 0.6499, 0.6667] 
2023-09-27 01:43:30.455044: Epoch time: 99.87 s 
2023-09-27 01:43:31.783188:  
2023-09-27 01:43:31.783449: Epoch 384 
2023-09-27 01:43:31.783628: Current learning rate: 0.00647 
2023-09-27 01:45:11.671329: train_loss -0.8775 
2023-09-27 01:45:11.671578: val_loss -0.6272 
2023-09-27 01:45:11.671653: Pseudo dice [0.8979, 0.6025, 0.6308] 
2023-09-27 01:45:11.671722: Epoch time: 99.89 s 
2023-09-27 01:45:12.977925:  
2023-09-27 01:45:12.978056: Epoch 385 
2023-09-27 01:45:12.978158: Current learning rate: 0.00646 
2023-09-27 01:46:52.647660: train_loss -0.8795 
2023-09-27 01:46:52.647912: val_loss -0.5891 
2023-09-27 01:46:52.647990: Pseudo dice [0.902, 0.528, 0.5349] 
2023-09-27 01:46:52.648061: Epoch time: 99.67 s 
2023-09-27 01:46:54.251263:  
2023-09-27 01:46:54.251464: Epoch 386 
2023-09-27 01:46:54.251574: Current learning rate: 0.00645 
2023-09-27 01:48:33.977087: train_loss -0.8814 
2023-09-27 01:48:33.977318: val_loss -0.6247 
2023-09-27 01:48:33.977395: Pseudo dice [0.8969, 0.5917, 0.6503] 
2023-09-27 01:48:33.977467: Epoch time: 99.73 s 
2023-09-27 01:48:35.275983:  
2023-09-27 01:48:35.276217: Epoch 387 
2023-09-27 01:48:35.276306: Current learning rate: 0.00644 
2023-09-27 01:50:15.315185: train_loss -0.8711 
2023-09-27 01:50:15.315468: val_loss -0.5377 
2023-09-27 01:50:15.315580: Pseudo dice [0.8708, 0.5643, 0.4078] 
2023-09-27 01:50:15.315685: Epoch time: 100.04 s 
2023-09-27 01:50:16.982909:  
2023-09-27 01:50:16.983054: Epoch 388 
2023-09-27 01:50:16.983161: Current learning rate: 0.00643 
2023-09-27 01:51:57.213939: train_loss -0.8703 
2023-09-27 01:51:57.214209: val_loss -0.6346 
2023-09-27 01:51:57.214291: Pseudo dice [0.9032, 0.5883, 0.6717] 
2023-09-27 01:51:57.214364: Epoch time: 100.23 s 
2023-09-27 01:51:58.949591:  
2023-09-27 01:51:58.949824: Epoch 389 
2023-09-27 01:51:58.949936: Current learning rate: 0.00642 
2023-09-27 01:53:38.713939: train_loss -0.8767 
2023-09-27 01:53:38.714226: val_loss -0.5937 
2023-09-27 01:53:38.714320: Pseudo dice [0.8928, 0.5279, 0.5984] 
2023-09-27 01:53:38.714402: Epoch time: 99.77 s 
2023-09-27 01:53:39.988008:  
2023-09-27 01:53:39.988284: Epoch 390 
2023-09-27 01:53:39.988377: Current learning rate: 0.00641 
2023-09-27 01:55:20.057967: train_loss -0.8676 
2023-09-27 01:55:20.058330: val_loss -0.5475 
2023-09-27 01:55:20.058415: Pseudo dice [0.8813, 0.4699, 0.5091] 
2023-09-27 01:55:20.058492: Epoch time: 100.07 s 
2023-09-27 01:55:21.364275:  
2023-09-27 01:55:21.364779: Epoch 391 
2023-09-27 01:55:21.364881: Current learning rate: 0.0064 
2023-09-27 01:57:01.110654: train_loss -0.8624 
2023-09-27 01:57:01.110918: val_loss -0.574 
2023-09-27 01:57:01.111000: Pseudo dice [0.8755, 0.491, 0.5709] 
2023-09-27 01:57:01.111073: Epoch time: 99.75 s 
2023-09-27 01:57:02.442596:  
2023-09-27 01:57:02.442986: Epoch 392 
2023-09-27 01:57:02.443095: Current learning rate: 0.00639 
2023-09-27 01:58:42.229725: train_loss -0.8569 
2023-09-27 01:58:42.229970: val_loss -0.629 
2023-09-27 01:58:42.230049: Pseudo dice [0.8963, 0.6242, 0.6092] 
2023-09-27 01:58:42.230162: Epoch time: 99.79 s 
2023-09-27 01:58:43.526502:  
2023-09-27 01:58:43.526632: Epoch 393 
2023-09-27 01:58:43.526720: Current learning rate: 0.00638 
2023-09-27 02:00:23.698536: train_loss -0.8714 
2023-09-27 02:00:23.698792: val_loss -0.6445 
2023-09-27 02:00:23.698868: Pseudo dice [0.8918, 0.5883, 0.6915] 
2023-09-27 02:00:23.698950: Epoch time: 100.17 s 
2023-09-27 02:00:25.164368:  
2023-09-27 02:00:25.164519: Epoch 394 
2023-09-27 02:00:25.164603: Current learning rate: 0.00637 
2023-09-27 02:02:05.184264: train_loss -0.8775 
2023-09-27 02:02:05.184541: val_loss -0.6148 
2023-09-27 02:02:05.184638: Pseudo dice [0.8957, 0.6276, 0.5895] 
2023-09-27 02:02:05.184723: Epoch time: 100.02 s 
2023-09-27 02:02:06.802025:  
2023-09-27 02:02:06.802186: Epoch 395 
2023-09-27 02:02:06.802293: Current learning rate: 0.00636 
2023-09-27 02:03:46.720639: train_loss -0.8801 
2023-09-27 02:03:46.720895: val_loss -0.5944 
2023-09-27 02:03:46.720976: Pseudo dice [0.896, 0.5125, 0.6015] 
2023-09-27 02:03:46.721049: Epoch time: 99.92 s 
2023-09-27 02:03:48.002707:  
2023-09-27 02:03:48.002847: Epoch 396 
2023-09-27 02:03:48.002938: Current learning rate: 0.00635 
2023-09-27 02:05:27.770993: train_loss -0.8792 
2023-09-27 02:05:27.771258: val_loss -0.6003 
2023-09-27 02:05:27.771337: Pseudo dice [0.8957, 0.5444, 0.6456] 
2023-09-27 02:05:27.771408: Epoch time: 99.77 s 
2023-09-27 02:05:29.053713:  
2023-09-27 02:05:29.053861: Epoch 397 
2023-09-27 02:05:29.053950: Current learning rate: 0.00634 
2023-09-27 02:07:08.873007: train_loss -0.8881 
2023-09-27 02:07:08.873254: val_loss -0.6505 
2023-09-27 02:07:08.873333: Pseudo dice [0.9019, 0.5988, 0.6505] 
2023-09-27 02:07:08.873407: Epoch time: 99.82 s 
2023-09-27 02:07:10.171740:  
2023-09-27 02:07:10.171892: Epoch 398 
2023-09-27 02:07:10.171980: Current learning rate: 0.00633 
2023-09-27 02:08:50.175815: train_loss -0.8947 
2023-09-27 02:08:50.176090: val_loss -0.5722 
2023-09-27 02:08:50.176184: Pseudo dice [0.8962, 0.5587, 0.4634] 
2023-09-27 02:08:50.176272: Epoch time: 100.01 s 
2023-09-27 02:08:51.567325:  
2023-09-27 02:08:51.567469: Epoch 399 
2023-09-27 02:08:51.567556: Current learning rate: 0.00632 
2023-09-27 02:10:31.616669: train_loss -0.8824 
2023-09-27 02:10:31.616912: val_loss -0.5822 
2023-09-27 02:10:31.616995: Pseudo dice [0.8944, 0.5423, 0.5562] 
2023-09-27 02:10:31.617072: Epoch time: 100.05 s 
2023-09-27 02:10:34.954352:  
2023-09-27 02:10:34.954514: Epoch 400 
2023-09-27 02:10:34.954630: Current learning rate: 0.00631 
2023-09-27 02:12:15.219677: train_loss -0.8914 
2023-09-27 02:12:15.219922: val_loss -0.5834 
2023-09-27 02:12:15.219998: Pseudo dice [0.8734, 0.5683, 0.543] 
2023-09-27 02:12:15.220069: Epoch time: 100.27 s 
2023-09-27 02:12:16.493713:  
2023-09-27 02:12:16.493876: Epoch 401 
2023-09-27 02:12:16.493962: Current learning rate: 0.0063 
2023-09-27 02:13:56.717789: train_loss -0.8805 
2023-09-27 02:13:56.718062: val_loss -0.5288 
2023-09-27 02:13:56.718153: Pseudo dice [0.8941, 0.5363, 0.4279] 
2023-09-27 02:13:56.718235: Epoch time: 100.23 s 
2023-09-27 02:13:58.055224:  
2023-09-27 02:13:58.055380: Epoch 402 
2023-09-27 02:13:58.055475: Current learning rate: 0.0063 
2023-09-27 02:15:38.269938: train_loss -0.8817 
2023-09-27 02:15:38.270208: val_loss -0.5955 
2023-09-27 02:15:38.270286: Pseudo dice [0.9049, 0.5382, 0.6108] 
2023-09-27 02:15:38.270357: Epoch time: 100.22 s 
2023-09-27 02:15:39.664952:  
2023-09-27 02:15:39.665531: Epoch 403 
2023-09-27 02:15:39.665848: Current learning rate: 0.00629 
2023-09-27 02:17:18.336303: train_loss -0.8867 
2023-09-27 02:17:18.336962: val_loss -0.5956 
2023-09-27 02:17:18.337048: Pseudo dice [0.8944, 0.5227, 0.6356] 
2023-09-27 02:17:18.337148: Epoch time: 98.67 s 
2023-09-27 02:17:19.694930:  
2023-09-27 02:17:19.695132: Epoch 404 
2023-09-27 02:17:19.695239: Current learning rate: 0.00628 
2023-09-27 02:18:59.671025: train_loss -0.8895 
2023-09-27 02:18:59.671288: val_loss -0.6026 
2023-09-27 02:18:59.671371: Pseudo dice [0.8977, 0.5331, 0.5705] 
2023-09-27 02:18:59.671447: Epoch time: 99.98 s 
2023-09-27 02:19:00.989980:  
2023-09-27 02:19:00.990241: Epoch 405 
2023-09-27 02:19:00.990335: Current learning rate: 0.00627 
2023-09-27 02:20:41.341235: train_loss -0.8922 
2023-09-27 02:20:41.341614: val_loss -0.6295 
2023-09-27 02:20:41.341706: Pseudo dice [0.912, 0.6014, 0.673] 
2023-09-27 02:20:41.341818: Epoch time: 100.35 s 
2023-09-27 02:20:42.996397:  
2023-09-27 02:20:42.996592: Epoch 406 
2023-09-27 02:20:42.996717: Current learning rate: 0.00626 
2023-09-27 02:22:23.324676: train_loss -0.8816 
2023-09-27 02:22:23.324937: val_loss -0.5852 
2023-09-27 02:22:23.325016: Pseudo dice [0.8907, 0.5068, 0.6095] 
2023-09-27 02:22:23.325090: Epoch time: 100.33 s 
2023-09-27 02:22:24.626315:  
2023-09-27 02:22:24.626480: Epoch 407 
2023-09-27 02:22:24.626574: Current learning rate: 0.00625 
2023-09-27 02:24:04.458695: train_loss -0.8732 
2023-09-27 02:24:04.459094: val_loss -0.5501 
2023-09-27 02:24:04.459178: Pseudo dice [0.8913, 0.5107, 0.5475] 
2023-09-27 02:24:04.459256: Epoch time: 99.83 s 
2023-09-27 02:24:05.818844:  
2023-09-27 02:24:05.819229: Epoch 408 
2023-09-27 02:24:05.819359: Current learning rate: 0.00624 
2023-09-27 02:25:46.136921: train_loss -0.8805 
2023-09-27 02:25:46.137180: val_loss -0.5842 
2023-09-27 02:25:46.137261: Pseudo dice [0.8994, 0.5375, 0.6236] 
2023-09-27 02:25:46.137338: Epoch time: 100.32 s 
2023-09-27 02:25:47.494607:  
2023-09-27 02:25:47.494879: Epoch 409 
2023-09-27 02:25:47.494973: Current learning rate: 0.00623 
2023-09-27 02:27:27.659178: train_loss -0.8829 
2023-09-27 02:27:27.659458: val_loss -0.6008 
2023-09-27 02:27:27.659539: Pseudo dice [0.9015, 0.6014, 0.6127] 
2023-09-27 02:27:27.659610: Epoch time: 100.17 s 
2023-09-27 02:27:28.991157:  
2023-09-27 02:27:28.991609: Epoch 410 
2023-09-27 02:27:28.991708: Current learning rate: 0.00622 
2023-09-27 02:29:09.309102: train_loss -0.8869 
2023-09-27 02:29:09.309645: val_loss -0.5819 
2023-09-27 02:29:09.309728: Pseudo dice [0.9043, 0.5464, 0.5947] 
2023-09-27 02:29:09.309850: Epoch time: 100.32 s 
2023-09-27 02:29:10.815097:  
2023-09-27 02:29:10.815258: Epoch 411 
2023-09-27 02:29:10.815349: Current learning rate: 0.00621 
2023-09-27 02:30:50.768723: train_loss -0.8797 
2023-09-27 02:30:50.768984: val_loss -0.6266 
2023-09-27 02:30:50.769067: Pseudo dice [0.8993, 0.6386, 0.5941] 
2023-09-27 02:30:50.769143: Epoch time: 99.95 s 
2023-09-27 02:30:52.047628:  
2023-09-27 02:30:52.047969: Epoch 412 
2023-09-27 02:30:52.048206: Current learning rate: 0.0062 
2023-09-27 02:32:31.619885: train_loss -0.8725 
2023-09-27 02:32:31.620431: val_loss -0.5488 
2023-09-27 02:32:31.620522: Pseudo dice [0.8876, 0.5366, 0.4718] 
2023-09-27 02:32:31.620628: Epoch time: 99.58 s 
2023-09-27 02:32:32.947752:  
2023-09-27 02:32:32.948177: Epoch 413 
2023-09-27 02:32:32.948309: Current learning rate: 0.00619 
2023-09-27 02:34:12.680100: train_loss -0.8792 
2023-09-27 02:34:12.680417: val_loss -0.6115 
2023-09-27 02:34:12.680502: Pseudo dice [0.8838, 0.5396, 0.6309] 
2023-09-27 02:34:12.680577: Epoch time: 99.73 s 
2023-09-27 02:34:14.010046:  
2023-09-27 02:34:14.010571: Epoch 414 
2023-09-27 02:34:14.010881: Current learning rate: 0.00618 
2023-09-27 02:35:53.968013: train_loss -0.8555 
2023-09-27 02:35:53.968330: val_loss -0.57 
2023-09-27 02:35:53.968428: Pseudo dice [0.8866, 0.4794, 0.6148] 
2023-09-27 02:35:53.968544: Epoch time: 99.96 s 
2023-09-27 02:35:55.329973:  
2023-09-27 02:35:55.330186: Epoch 415 
2023-09-27 02:35:55.330286: Current learning rate: 0.00617 
2023-09-27 02:37:35.420857: train_loss -0.8646 
2023-09-27 02:37:35.421173: val_loss -0.6226 
2023-09-27 02:37:35.421261: Pseudo dice [0.8865, 0.5698, 0.7041] 
2023-09-27 02:37:35.421345: Epoch time: 100.09 s 
2023-09-27 02:37:36.723820:  
2023-09-27 02:37:36.723970: Epoch 416 
2023-09-27 02:37:36.724059: Current learning rate: 0.00616 
2023-09-27 02:39:16.051049: train_loss -0.8576 
2023-09-27 02:39:16.051306: val_loss -0.605 
2023-09-27 02:39:16.051383: Pseudo dice [0.8792, 0.6127, 0.5497] 
2023-09-27 02:39:16.051453: Epoch time: 99.33 s 
2023-09-27 02:39:17.294446:  
2023-09-27 02:39:17.294598: Epoch 417 
2023-09-27 02:39:17.294685: Current learning rate: 0.00615 
2023-09-27 02:40:56.967780: train_loss -0.866 
2023-09-27 02:40:56.968057: val_loss -0.6086 
2023-09-27 02:40:56.968149: Pseudo dice [0.8865, 0.5583, 0.6455] 
2023-09-27 02:40:56.968233: Epoch time: 99.67 s 
2023-09-27 02:40:58.476610:  
2023-09-27 02:40:58.476765: Epoch 418 
2023-09-27 02:40:58.476865: Current learning rate: 0.00614 
2023-09-27 02:42:38.295973: train_loss -0.8809 
2023-09-27 02:42:38.296239: val_loss -0.573 
2023-09-27 02:42:38.296321: Pseudo dice [0.8893, 0.4754, 0.614] 
2023-09-27 02:42:38.296407: Epoch time: 99.82 s 
2023-09-27 02:42:39.923808:  
2023-09-27 02:42:39.924154: Epoch 419 
2023-09-27 02:42:39.924329: Current learning rate: 0.00613 
2023-09-27 02:44:19.977434: train_loss -0.8777 
2023-09-27 02:44:19.977855: val_loss -0.5678 
2023-09-27 02:44:19.977942: Pseudo dice [0.8812, 0.5815, 0.5377] 
2023-09-27 02:44:19.978022: Epoch time: 100.06 s 
2023-09-27 02:44:21.228662:  
2023-09-27 02:44:21.228821: Epoch 420 
2023-09-27 02:44:21.228915: Current learning rate: 0.00612 
2023-09-27 02:46:01.139929: train_loss -0.8687 
2023-09-27 02:46:01.140180: val_loss -0.5453 
2023-09-27 02:46:01.140257: Pseudo dice [0.8775, 0.5025, 0.6065] 
2023-09-27 02:46:01.140332: Epoch time: 99.91 s 
2023-09-27 02:46:02.535806:  
2023-09-27 02:46:02.536393: Epoch 421 
2023-09-27 02:46:02.536683: Current learning rate: 0.00612 
2023-09-27 02:47:41.873374: train_loss -0.8583 
2023-09-27 02:47:41.873644: val_loss -0.5953 
2023-09-27 02:47:41.873724: Pseudo dice [0.8955, 0.4925, 0.6145] 
2023-09-27 02:47:41.873802: Epoch time: 99.34 s 
2023-09-27 02:47:43.149963:  
2023-09-27 02:47:43.150210: Epoch 422 
2023-09-27 02:47:43.150302: Current learning rate: 0.00611 
2023-09-27 02:49:23.212754: train_loss -0.8718 
2023-09-27 02:49:23.213168: val_loss -0.5923 
2023-09-27 02:49:23.213257: Pseudo dice [0.8961, 0.5041, 0.6557] 
2023-09-27 02:49:23.213341: Epoch time: 100.06 s 
2023-09-27 02:49:24.470404:  
2023-09-27 02:49:24.470589: Epoch 423 
2023-09-27 02:49:24.470686: Current learning rate: 0.0061 
2023-09-27 02:51:04.617010: train_loss -0.8842 
2023-09-27 02:51:04.617269: val_loss -0.5859 
2023-09-27 02:51:04.617348: Pseudo dice [0.8797, 0.5501, 0.6054] 
2023-09-27 02:51:04.617424: Epoch time: 100.15 s 
2023-09-27 02:51:06.044079:  
2023-09-27 02:51:06.044247: Epoch 424 
2023-09-27 02:51:06.044335: Current learning rate: 0.00609 
2023-09-27 02:52:46.934834: train_loss -0.8733 
2023-09-27 02:52:46.935140: val_loss -0.5709 
2023-09-27 02:52:46.935241: Pseudo dice [0.8967, 0.5875, 0.5024] 
2023-09-27 02:52:46.935333: Epoch time: 100.89 s 
2023-09-27 02:52:48.260491:  
2023-09-27 02:52:48.260656: Epoch 425 
2023-09-27 02:52:48.260747: Current learning rate: 0.00608 
2023-09-27 02:54:29.542977: train_loss -0.8793 
2023-09-27 02:54:29.543241: val_loss -0.6299 
2023-09-27 02:54:29.543325: Pseudo dice [0.8934, 0.5839, 0.5927] 
2023-09-27 02:54:29.543402: Epoch time: 101.28 s 
2023-09-27 02:54:30.837399:  
2023-09-27 02:54:30.837627: Epoch 426 
2023-09-27 02:54:30.837716: Current learning rate: 0.00607 
2023-09-27 02:56:12.447912: train_loss -0.877 
2023-09-27 02:56:12.448191: val_loss -0.5935 
2023-09-27 02:56:12.448277: Pseudo dice [0.8951, 0.6792, 0.5183] 
2023-09-27 02:56:12.448369: Epoch time: 101.61 s 
2023-09-27 02:56:13.761952:  
2023-09-27 02:56:13.762186: Epoch 427 
2023-09-27 02:56:13.762334: Current learning rate: 0.00606 
2023-09-27 02:57:54.356516: train_loss -0.8617 
2023-09-27 02:57:54.356772: val_loss -0.6101 
2023-09-27 02:57:54.356851: Pseudo dice [0.8854, 0.5973, 0.5894] 
2023-09-27 02:57:54.356923: Epoch time: 100.6 s 
2023-09-27 02:57:55.638637:  
2023-09-27 02:57:55.638792: Epoch 428 
2023-09-27 02:57:55.638878: Current learning rate: 0.00605 
2023-09-27 02:59:35.293605: train_loss -0.8762 
2023-09-27 02:59:35.293926: val_loss -0.5937 
2023-09-27 02:59:35.294012: Pseudo dice [0.8865, 0.5708, 0.6297] 
2023-09-27 02:59:35.294114: Epoch time: 99.66 s 
2023-09-27 02:59:36.555574:  
2023-09-27 02:59:36.555729: Epoch 429 
2023-09-27 02:59:36.555817: Current learning rate: 0.00604 
2023-09-27 03:01:16.539740: train_loss -0.8635 
2023-09-27 03:01:16.540037: val_loss -0.5883 
2023-09-27 03:01:16.540118: Pseudo dice [0.8733, 0.5066, 0.6548] 
2023-09-27 03:01:16.540204: Epoch time: 99.99 s 
2023-09-27 03:01:17.994689:  
2023-09-27 03:01:17.994836: Epoch 430 
2023-09-27 03:01:17.994932: Current learning rate: 0.00603 
2023-09-27 03:02:57.996208: train_loss -0.8534 
2023-09-27 03:02:57.996501: val_loss -0.6303 
2023-09-27 03:02:57.996584: Pseudo dice [0.8848, 0.5963, 0.6676] 
2023-09-27 03:02:57.996668: Epoch time: 100.0 s 
2023-09-27 03:02:59.355414:  
2023-09-27 03:02:59.355597: Epoch 431 
2023-09-27 03:02:59.355697: Current learning rate: 0.00602 
2023-09-27 03:04:39.335792: train_loss -0.8602 
2023-09-27 03:04:39.336635: val_loss -0.5918 
2023-09-27 03:04:39.336802: Pseudo dice [0.8827, 0.5604, 0.6131] 
2023-09-27 03:04:39.337024: Epoch time: 99.98 s 
2023-09-27 03:04:40.748760:  
2023-09-27 03:04:40.749268: Epoch 432 
2023-09-27 03:04:40.749405: Current learning rate: 0.00601 
2023-09-27 03:06:21.003206: train_loss -0.8596 
2023-09-27 03:06:21.003523: val_loss -0.6058 
2023-09-27 03:06:21.003639: Pseudo dice [0.8913, 0.4721, 0.6597] 
2023-09-27 03:06:21.003737: Epoch time: 100.26 s 
2023-09-27 03:06:22.321125:  
2023-09-27 03:06:22.321262: Epoch 433 
2023-09-27 03:06:22.321353: Current learning rate: 0.006 
2023-09-27 03:08:02.705130: train_loss -0.8691 
2023-09-27 03:08:02.705663: val_loss -0.5803 
2023-09-27 03:08:02.705749: Pseudo dice [0.893, 0.4546, 0.6282] 
2023-09-27 03:08:02.705868: Epoch time: 100.39 s 
2023-09-27 03:08:03.973597:  
2023-09-27 03:08:03.973765: Epoch 434 
2023-09-27 03:08:03.973852: Current learning rate: 0.00599 
2023-09-27 03:09:43.771863: train_loss -0.8786 
2023-09-27 03:09:43.772121: val_loss -0.6162 
2023-09-27 03:09:43.772202: Pseudo dice [0.9017, 0.5612, 0.6292] 
2023-09-27 03:09:43.772279: Epoch time: 99.8 s 
2023-09-27 03:09:45.074459:  
2023-09-27 03:09:45.074863: Epoch 435 
2023-09-27 03:09:45.075046: Current learning rate: 0.00598 
2023-09-27 03:11:24.773420: train_loss -0.8899 
2023-09-27 03:11:24.773741: val_loss -0.6423 
2023-09-27 03:11:24.773825: Pseudo dice [0.8995, 0.5595, 0.6723] 
2023-09-27 03:11:24.773903: Epoch time: 99.7 s 
2023-09-27 03:11:26.344487:  
2023-09-27 03:11:26.344658: Epoch 436 
2023-09-27 03:11:26.344763: Current learning rate: 0.00597 
2023-09-27 03:13:06.387376: train_loss -0.8898 
2023-09-27 03:13:06.387665: val_loss -0.6254 
2023-09-27 03:13:06.387748: Pseudo dice [0.9001, 0.6022, 0.6621] 
2023-09-27 03:13:06.387828: Epoch time: 100.04 s 
2023-09-27 03:13:07.662855:  
2023-09-27 03:13:07.663031: Epoch 437 
2023-09-27 03:13:07.663146: Current learning rate: 0.00596 
2023-09-27 03:14:47.357139: train_loss -0.8964 
2023-09-27 03:14:47.357558: val_loss -0.5928 
2023-09-27 03:14:47.357647: Pseudo dice [0.9063, 0.4641, 0.6594] 
2023-09-27 03:14:47.357736: Epoch time: 99.7 s 
2023-09-27 03:14:48.851667:  
2023-09-27 03:14:48.851897: Epoch 438 
2023-09-27 03:14:48.852027: Current learning rate: 0.00595 
2023-09-27 03:16:28.798253: train_loss -0.89 
2023-09-27 03:16:28.798717: val_loss -0.5979 
2023-09-27 03:16:28.798830: Pseudo dice [0.8969, 0.6065, 0.5507] 
2023-09-27 03:16:28.798917: Epoch time: 99.95 s 
2023-09-27 03:16:30.454624:  
2023-09-27 03:16:30.455026: Epoch 439 
2023-09-27 03:16:30.455196: Current learning rate: 0.00594 
2023-09-27 03:18:10.323352: train_loss -0.8889 
2023-09-27 03:18:10.323698: val_loss -0.6229 
2023-09-27 03:18:10.323778: Pseudo dice [0.8962, 0.5537, 0.6591] 
2023-09-27 03:18:10.323864: Epoch time: 99.87 s 
2023-09-27 03:18:11.600540:  
2023-09-27 03:18:11.600811: Epoch 440 
2023-09-27 03:18:11.600905: Current learning rate: 0.00593 
2023-09-27 03:19:51.312581: train_loss -0.8883 
2023-09-27 03:19:51.312892: val_loss -0.6108 
2023-09-27 03:19:51.312987: Pseudo dice [0.8977, 0.5486, 0.5928] 
2023-09-27 03:19:51.313070: Epoch time: 99.71 s 
2023-09-27 03:19:52.651873:  
2023-09-27 03:19:52.652459: Epoch 441 
2023-09-27 03:19:52.652884: Current learning rate: 0.00592 
2023-09-27 03:21:32.165941: train_loss -0.8845 
2023-09-27 03:21:32.166246: val_loss -0.6306 
2023-09-27 03:21:32.166333: Pseudo dice [0.8994, 0.5643, 0.6777] 
2023-09-27 03:21:32.166412: Epoch time: 99.52 s 
2023-09-27 03:21:33.694314:  
2023-09-27 03:21:33.694748: Epoch 442 
2023-09-27 03:21:33.694985: Current learning rate: 0.00592 
2023-09-27 03:23:13.553933: train_loss -0.853 
2023-09-27 03:23:13.554699: val_loss -0.5987 
2023-09-27 03:23:13.554809: Pseudo dice [0.8899, 0.5841, 0.5909] 
2023-09-27 03:23:13.554956: Epoch time: 99.86 s 
2023-09-27 03:23:15.306785:  
2023-09-27 03:23:15.306940: Epoch 443 
2023-09-27 03:23:15.307051: Current learning rate: 0.00591 
2023-09-27 03:24:55.315358: train_loss -0.8623 
2023-09-27 03:24:55.315675: val_loss -0.5749 
2023-09-27 03:24:55.315771: Pseudo dice [0.8868, 0.5443, 0.6161] 
2023-09-27 03:24:55.315851: Epoch time: 100.01 s 
2023-09-27 03:24:56.566191:  
2023-09-27 03:24:56.566340: Epoch 444 
2023-09-27 03:24:56.566431: Current learning rate: 0.0059 
2023-09-27 03:26:36.498571: train_loss -0.8611 
2023-09-27 03:26:36.498883: val_loss -0.6611 
2023-09-27 03:26:36.498985: Pseudo dice [0.898, 0.6532, 0.7106] 
2023-09-27 03:26:36.499085: Epoch time: 99.93 s 
2023-09-27 03:26:38.086127:  
2023-09-27 03:26:38.086523: Epoch 445 
2023-09-27 03:26:38.086658: Current learning rate: 0.00589 
2023-09-27 03:28:17.844433: train_loss -0.8894 
2023-09-27 03:28:17.844776: val_loss -0.6282 
2023-09-27 03:28:17.844886: Pseudo dice [0.8979, 0.5793, 0.6838] 
2023-09-27 03:28:17.844984: Epoch time: 99.76 s 
2023-09-27 03:28:19.087119:  
2023-09-27 03:28:19.087260: Epoch 446 
2023-09-27 03:28:19.087351: Current learning rate: 0.00588 
2023-09-27 03:29:58.563501: train_loss -0.8907 
2023-09-27 03:29:58.563777: val_loss -0.6477 
2023-09-27 03:29:58.563855: Pseudo dice [0.8981, 0.5907, 0.6602] 
2023-09-27 03:29:58.563930: Epoch time: 99.48 s 
2023-09-27 03:29:59.929607:  
2023-09-27 03:29:59.929761: Epoch 447 
2023-09-27 03:29:59.929867: Current learning rate: 0.00587 
2023-09-27 03:31:39.318088: train_loss -0.8891 
2023-09-27 03:31:39.318362: val_loss -0.5478 
2023-09-27 03:31:39.318541: Pseudo dice [0.8923, 0.5645, 0.4509] 
2023-09-27 03:31:39.318666: Epoch time: 99.39 s 
2023-09-27 03:31:40.564612:  
2023-09-27 03:31:40.564760: Epoch 448 
2023-09-27 03:31:40.564849: Current learning rate: 0.00586 
2023-09-27 03:33:20.276226: train_loss -0.8521 
2023-09-27 03:33:20.276479: val_loss -0.6251 
2023-09-27 03:33:20.276558: Pseudo dice [0.8942, 0.5964, 0.6217] 
2023-09-27 03:33:20.276630: Epoch time: 99.71 s 
2023-09-27 03:33:21.757618:  
2023-09-27 03:33:21.757877: Epoch 449 
2023-09-27 03:33:21.757969: Current learning rate: 0.00585 
2023-09-27 03:35:01.602726: train_loss -0.8615 
2023-09-27 03:35:01.603091: val_loss -0.5865 
2023-09-27 03:35:01.603223: Pseudo dice [0.8913, 0.5736, 0.6165] 
2023-09-27 03:35:01.603343: Epoch time: 99.85 s 
2023-09-27 03:35:04.526059:  
2023-09-27 03:35:04.526252: Epoch 450 
2023-09-27 03:35:04.526353: Current learning rate: 0.00584 
2023-09-27 03:36:44.415093: train_loss -0.8719 
2023-09-27 03:36:44.415352: val_loss -0.5478 
2023-09-27 03:36:44.415430: Pseudo dice [0.8792, 0.5852, 0.4254] 
2023-09-27 03:36:44.415504: Epoch time: 99.89 s 
2023-09-27 03:36:45.651310:  
2023-09-27 03:36:45.651474: Epoch 451 
2023-09-27 03:36:45.651561: Current learning rate: 0.00583 
2023-09-27 03:38:25.159547: train_loss -0.8797 
2023-09-27 03:38:25.159828: val_loss -0.5873 
2023-09-27 03:38:25.159908: Pseudo dice [0.8965, 0.5034, 0.6336] 
2023-09-27 03:38:25.159987: Epoch time: 99.51 s 
2023-09-27 03:38:26.370489:  
2023-09-27 03:38:26.370631: Epoch 452 
2023-09-27 03:38:26.370725: Current learning rate: 0.00582 
2023-09-27 03:40:06.112327: train_loss -0.8867 
2023-09-27 03:40:06.112628: val_loss -0.5694 
2023-09-27 03:40:06.112707: Pseudo dice [0.8991, 0.5652, 0.5351] 
2023-09-27 03:40:06.112785: Epoch time: 99.74 s 
2023-09-27 03:40:07.446065:  
2023-09-27 03:40:07.446362: Epoch 453 
2023-09-27 03:40:07.446479: Current learning rate: 0.00581 
2023-09-27 03:41:47.132266: train_loss -0.886 
2023-09-27 03:41:47.132570: val_loss -0.6189 
2023-09-27 03:41:47.132671: Pseudo dice [0.9, 0.5993, 0.5626] 
2023-09-27 03:41:47.132763: Epoch time: 99.69 s 
2023-09-27 03:41:48.698578:  
2023-09-27 03:41:48.698864: Epoch 454 
2023-09-27 03:41:48.698983: Current learning rate: 0.0058 
2023-09-27 03:43:26.866483: train_loss -0.8852 
2023-09-27 03:43:26.866750: val_loss -0.634 
2023-09-27 03:43:26.866831: Pseudo dice [0.8963, 0.5027, 0.701] 
2023-09-27 03:43:26.866905: Epoch time: 98.17 s 
2023-09-27 03:43:28.286897:  
2023-09-27 03:43:28.287062: Epoch 455 
2023-09-27 03:43:28.287155: Current learning rate: 0.00579 
2023-09-27 03:45:08.294948: train_loss -0.877 
2023-09-27 03:45:08.295731: val_loss -0.5949 
2023-09-27 03:45:08.295830: Pseudo dice [0.8908, 0.5013, 0.6374] 
2023-09-27 03:45:08.295952: Epoch time: 100.01 s 
2023-09-27 03:45:09.633298:  
2023-09-27 03:45:09.633693: Epoch 456 
2023-09-27 03:45:09.633811: Current learning rate: 0.00578 
2023-09-27 03:46:49.642994: train_loss -0.8793 
2023-09-27 03:46:49.643255: val_loss -0.5965 
2023-09-27 03:46:49.643339: Pseudo dice [0.8964, 0.5031, 0.6605] 
2023-09-27 03:46:49.643414: Epoch time: 100.01 s 
2023-09-27 03:46:50.869534:  
2023-09-27 03:46:50.869681: Epoch 457 
2023-09-27 03:46:50.869774: Current learning rate: 0.00577 
2023-09-27 03:48:30.902392: train_loss -0.8862 
2023-09-27 03:48:30.903022: val_loss -0.6231 
2023-09-27 03:48:30.903107: Pseudo dice [0.8981, 0.5394, 0.6714] 
2023-09-27 03:48:30.903210: Epoch time: 100.03 s 
2023-09-27 03:48:32.186103:  
2023-09-27 03:48:32.186407: Epoch 458 
2023-09-27 03:48:32.186510: Current learning rate: 0.00576 
2023-09-27 03:50:11.942973: train_loss -0.8836 
2023-09-27 03:50:11.943233: val_loss -0.6252 
2023-09-27 03:50:11.943314: Pseudo dice [0.9003, 0.5828, 0.6822] 
2023-09-27 03:50:11.943389: Epoch time: 99.76 s 
2023-09-27 03:50:13.185190:  
2023-09-27 03:50:13.185406: Epoch 459 
2023-09-27 03:50:13.185556: Current learning rate: 0.00575 
2023-09-27 03:51:52.956553: train_loss -0.8911 
2023-09-27 03:51:52.956812: val_loss -0.6132 
2023-09-27 03:51:52.956890: Pseudo dice [0.8955, 0.4976, 0.6822] 
2023-09-27 03:51:52.956963: Epoch time: 99.77 s 
2023-09-27 03:51:54.157073:  
2023-09-27 03:51:54.157306: Epoch 460 
2023-09-27 03:51:54.157405: Current learning rate: 0.00574 
2023-09-27 03:53:34.082852: train_loss -0.8955 
2023-09-27 03:53:34.083126: val_loss -0.6124 
2023-09-27 03:53:34.083206: Pseudo dice [0.9029, 0.4907, 0.6607] 
2023-09-27 03:53:34.083280: Epoch time: 99.93 s 
2023-09-27 03:53:35.532092:  
2023-09-27 03:53:35.532233: Epoch 461 
2023-09-27 03:53:35.532320: Current learning rate: 0.00573 
2023-09-27 03:55:15.398143: train_loss -0.9023 
2023-09-27 03:55:15.398482: val_loss -0.6238 
2023-09-27 03:55:15.398564: Pseudo dice [0.8983, 0.622, 0.6315] 
2023-09-27 03:55:15.398638: Epoch time: 99.87 s 
2023-09-27 03:55:16.617246:  
2023-09-27 03:55:16.617536: Epoch 462 
2023-09-27 03:55:16.617627: Current learning rate: 0.00572 
2023-09-27 03:56:56.268808: train_loss -0.8973 
2023-09-27 03:56:56.269060: val_loss -0.6482 
2023-09-27 03:56:56.269136: Pseudo dice [0.8944, 0.5857, 0.6825] 
2023-09-27 03:56:56.269208: Epoch time: 99.65 s 
2023-09-27 03:56:57.524725:  
2023-09-27 03:56:57.524866: Epoch 463 
2023-09-27 03:56:57.524953: Current learning rate: 0.00571 
2023-09-27 03:58:37.856385: train_loss -0.9004 
2023-09-27 03:58:37.856670: val_loss -0.6245 
2023-09-27 03:58:37.856752: Pseudo dice [0.9036, 0.5793, 0.6811] 
2023-09-27 03:58:37.856832: Epoch time: 100.33 s 
2023-09-27 03:58:39.177396:  
2023-09-27 03:58:39.177900: Epoch 464 
2023-09-27 03:58:39.178080: Current learning rate: 0.0057 
2023-09-27 04:00:19.085994: train_loss -0.8959 
2023-09-27 04:00:19.086272: val_loss -0.6163 
2023-09-27 04:00:19.086350: Pseudo dice [0.8988, 0.5232, 0.6569] 
2023-09-27 04:00:19.086425: Epoch time: 99.91 s 
2023-09-27 04:00:20.326870:  
2023-09-27 04:00:20.327013: Epoch 465 
2023-09-27 04:00:20.327101: Current learning rate: 0.0057 
2023-09-27 04:02:00.357542: train_loss -0.8947 
2023-09-27 04:02:00.357846: val_loss -0.6021 
2023-09-27 04:02:00.357927: Pseudo dice [0.9013, 0.5683, 0.5512] 
2023-09-27 04:02:00.358012: Epoch time: 100.03 s 
2023-09-27 04:02:01.584652:  
2023-09-27 04:02:01.584787: Epoch 466 
2023-09-27 04:02:01.584874: Current learning rate: 0.00569 
2023-09-27 04:03:41.133653: train_loss -0.8917 
2023-09-27 04:03:41.134288: val_loss -0.5667 
2023-09-27 04:03:41.134376: Pseudo dice [0.8828, 0.6169, 0.4709] 
2023-09-27 04:03:41.134489: Epoch time: 99.55 s 
2023-09-27 04:03:42.398385:  
2023-09-27 04:03:42.398559: Epoch 467 
2023-09-27 04:03:42.398655: Current learning rate: 0.00568 
2023-09-27 04:05:22.421274: train_loss -0.8772 
2023-09-27 04:05:22.421543: val_loss -0.6258 
2023-09-27 04:05:22.421623: Pseudo dice [0.9007, 0.5684, 0.6477] 
2023-09-27 04:05:22.421697: Epoch time: 100.02 s 
2023-09-27 04:05:23.660704:  
2023-09-27 04:05:23.660976: Epoch 468 
2023-09-27 04:05:23.661107: Current learning rate: 0.00567 
2023-09-27 04:07:03.658263: train_loss -0.8701 
2023-09-27 04:07:03.658564: val_loss -0.5779 
2023-09-27 04:07:03.658654: Pseudo dice [0.8856, 0.5599, 0.5992] 
2023-09-27 04:07:03.658729: Epoch time: 100.0 s 
2023-09-27 04:07:04.954137:  
2023-09-27 04:07:04.954369: Epoch 469 
2023-09-27 04:07:04.954479: Current learning rate: 0.00566 
2023-09-27 04:08:45.363251: train_loss -0.8704 
2023-09-27 04:08:45.363760: val_loss -0.6006 
2023-09-27 04:08:45.363852: Pseudo dice [0.9036, 0.5711, 0.6006] 
2023-09-27 04:08:45.363959: Epoch time: 100.41 s 
2023-09-27 04:08:46.639587:  
2023-09-27 04:08:46.639762: Epoch 470 
2023-09-27 04:08:46.639857: Current learning rate: 0.00565 
2023-09-27 04:10:26.285009: train_loss -0.8917 
2023-09-27 04:10:26.285396: val_loss -0.6393 
2023-09-27 04:10:26.285491: Pseudo dice [0.9106, 0.5811, 0.6624] 
2023-09-27 04:10:26.285584: Epoch time: 99.65 s 
2023-09-27 04:10:27.609256:  
2023-09-27 04:10:27.609515: Epoch 471 
2023-09-27 04:10:27.609611: Current learning rate: 0.00564 
2023-09-27 04:12:07.141289: train_loss -0.8935 
2023-09-27 04:12:07.141807: val_loss -0.5886 
2023-09-27 04:12:07.141898: Pseudo dice [0.8944, 0.4914, 0.5625] 
2023-09-27 04:12:07.142011: Epoch time: 99.53 s 
2023-09-27 04:12:08.444058:  
2023-09-27 04:12:08.444313: Epoch 472 
2023-09-27 04:12:08.444442: Current learning rate: 0.00563 
2023-09-27 04:13:48.060765: train_loss -0.8929 
2023-09-27 04:13:48.061029: val_loss -0.6068 
2023-09-27 04:13:48.061105: Pseudo dice [0.898, 0.5562, 0.5935] 
2023-09-27 04:13:48.061175: Epoch time: 99.62 s 
2023-09-27 04:13:49.311301:  
2023-09-27 04:13:49.311578: Epoch 473 
2023-09-27 04:13:49.311668: Current learning rate: 0.00562 
2023-09-27 04:15:29.434757: train_loss -0.8972 
2023-09-27 04:15:29.435020: val_loss -0.6207 
2023-09-27 04:15:29.435185: Pseudo dice [0.9067, 0.4996, 0.6497] 
2023-09-27 04:15:29.435267: Epoch time: 100.12 s 
2023-09-27 04:15:31.212742:  
2023-09-27 04:15:31.212963: Epoch 474 
2023-09-27 04:15:31.213086: Current learning rate: 0.00561 
2023-09-27 04:17:11.211097: train_loss -0.8981 
2023-09-27 04:17:11.211413: val_loss -0.6482 
2023-09-27 04:17:11.211501: Pseudo dice [0.8942, 0.5817, 0.6793] 
2023-09-27 04:17:11.211586: Epoch time: 100.0 s 
2023-09-27 04:17:12.547360:  
2023-09-27 04:17:12.547511: Epoch 475 
2023-09-27 04:17:12.547603: Current learning rate: 0.0056 
2023-09-27 04:18:52.673458: train_loss -0.895 
2023-09-27 04:18:52.673724: val_loss -0.6213 
2023-09-27 04:18:52.673960: Pseudo dice [0.8973, 0.5255, 0.6802] 
2023-09-27 04:18:52.674639: Epoch time: 100.13 s 
2023-09-27 04:18:53.946807:  
2023-09-27 04:18:53.946990: Epoch 476 
2023-09-27 04:18:53.947089: Current learning rate: 0.00559 
2023-09-27 04:20:34.035874: train_loss -0.8829 
2023-09-27 04:20:34.036134: val_loss -0.6027 
2023-09-27 04:20:34.036213: Pseudo dice [0.9077, 0.5381, 0.5702] 
2023-09-27 04:20:34.036285: Epoch time: 100.09 s 
2023-09-27 04:20:35.303239:  
2023-09-27 04:20:35.303644: Epoch 477 
2023-09-27 04:20:35.303741: Current learning rate: 0.00558 
2023-09-27 04:22:15.474381: train_loss -0.8832 
2023-09-27 04:22:15.474661: val_loss -0.6119 
2023-09-27 04:22:15.474743: Pseudo dice [0.902, 0.5728, 0.6409] 
2023-09-27 04:22:15.474817: Epoch time: 100.17 s 
2023-09-27 04:22:16.906373:  
2023-09-27 04:22:16.906555: Epoch 478 
2023-09-27 04:22:16.906653: Current learning rate: 0.00557 
2023-09-27 04:23:56.400253: train_loss -0.8916 
2023-09-27 04:23:56.400522: val_loss -0.5988 
2023-09-27 04:23:56.400615: Pseudo dice [0.8921, 0.5527, 0.627] 
2023-09-27 04:23:56.400688: Epoch time: 99.5 s 
2023-09-27 04:23:57.668069:  
2023-09-27 04:23:57.668215: Epoch 479 
2023-09-27 04:23:57.668304: Current learning rate: 0.00556 
2023-09-27 04:25:37.496160: train_loss -0.8757 
2023-09-27 04:25:37.496857: val_loss -0.6123 
2023-09-27 04:25:37.496963: Pseudo dice [0.8968, 0.5785, 0.6368] 
2023-09-27 04:25:37.497083: Epoch time: 99.83 s 
2023-09-27 04:25:39.350246:  
2023-09-27 04:25:39.350514: Epoch 480 
2023-09-27 04:25:39.350700: Current learning rate: 0.00555 
2023-09-27 04:27:19.082215: train_loss -0.8828 
2023-09-27 04:27:19.082501: val_loss -0.6205 
2023-09-27 04:27:19.082598: Pseudo dice [0.8918, 0.6251, 0.5428] 
2023-09-27 04:27:19.082921: Epoch time: 99.73 s 
2023-09-27 04:27:20.446303:  
2023-09-27 04:27:20.446639: Epoch 481 
2023-09-27 04:27:20.446885: Current learning rate: 0.00554 
2023-09-27 04:29:00.474425: train_loss -0.8797 
2023-09-27 04:29:00.474691: val_loss -0.5907 
2023-09-27 04:29:00.474773: Pseudo dice [0.889, 0.5474, 0.5422] 
2023-09-27 04:29:00.474844: Epoch time: 100.03 s 
2023-09-27 04:29:01.764158:  
2023-09-27 04:29:01.764484: Epoch 482 
2023-09-27 04:29:01.764585: Current learning rate: 0.00553 
2023-09-27 04:30:41.765280: train_loss -0.889 
2023-09-27 04:30:41.765552: val_loss -0.5659 
2023-09-27 04:30:41.765643: Pseudo dice [0.8836, 0.4845, 0.5485] 
2023-09-27 04:30:41.765717: Epoch time: 100.0 s 
2023-09-27 04:30:43.023698:  
2023-09-27 04:30:43.024191: Epoch 483 
2023-09-27 04:30:43.024332: Current learning rate: 0.00552 
2023-09-27 04:32:22.981196: train_loss -0.8896 
2023-09-27 04:32:22.981459: val_loss -0.526 
2023-09-27 04:32:22.981540: Pseudo dice [0.8867, 0.5113, 0.4112] 
2023-09-27 04:32:22.981678: Epoch time: 99.96 s 
2023-09-27 04:32:24.290382:  
2023-09-27 04:32:24.290545: Epoch 484 
2023-09-27 04:32:24.290636: Current learning rate: 0.00551 
2023-09-27 04:34:03.917343: train_loss -0.8903 
2023-09-27 04:34:03.917604: val_loss -0.6311 
2023-09-27 04:34:03.917713: Pseudo dice [0.8939, 0.6145, 0.6394] 
2023-09-27 04:34:03.917825: Epoch time: 99.63 s 
2023-09-27 04:34:05.206726:  
2023-09-27 04:34:05.206870: Epoch 485 
2023-09-27 04:34:05.206956: Current learning rate: 0.0055 
2023-09-27 04:35:45.132081: train_loss -0.8919 
2023-09-27 04:35:45.132334: val_loss -0.6126 
2023-09-27 04:35:45.132413: Pseudo dice [0.8933, 0.547, 0.5945] 
2023-09-27 04:35:45.132555: Epoch time: 99.93 s 
2023-09-27 04:35:46.388215:  
2023-09-27 04:35:46.388422: Epoch 486 
2023-09-27 04:35:46.388517: Current learning rate: 0.00549 
2023-09-27 04:37:26.621086: train_loss -0.8975 
2023-09-27 04:37:26.621369: val_loss -0.6011 
2023-09-27 04:37:26.621463: Pseudo dice [0.888, 0.5851, 0.5426] 
2023-09-27 04:37:26.621550: Epoch time: 100.23 s 
2023-09-27 04:37:28.425324:  
2023-09-27 04:37:28.425480: Epoch 487 
2023-09-27 04:37:28.425569: Current learning rate: 0.00548 
2023-09-27 04:39:08.871537: train_loss -0.9007 
2023-09-27 04:39:08.871790: val_loss -0.5737 
2023-09-27 04:39:08.871869: Pseudo dice [0.8994, 0.5298, 0.5923] 
2023-09-27 04:39:08.871940: Epoch time: 100.45 s 
2023-09-27 04:39:10.404086:  
2023-09-27 04:39:10.404356: Epoch 488 
2023-09-27 04:39:10.404461: Current learning rate: 0.00547 
2023-09-27 04:40:49.955215: train_loss -0.9009 
2023-09-27 04:40:49.955539: val_loss -0.6204 
2023-09-27 04:40:49.955636: Pseudo dice [0.8982, 0.5522, 0.6256] 
2023-09-27 04:40:49.955723: Epoch time: 99.55 s 
2023-09-27 04:40:51.281985:  
2023-09-27 04:40:51.282162: Epoch 489 
2023-09-27 04:40:51.282255: Current learning rate: 0.00546 
2023-09-27 04:42:31.194313: train_loss -0.8991 
2023-09-27 04:42:31.194567: val_loss -0.6043 
2023-09-27 04:42:31.194645: Pseudo dice [0.9013, 0.5617, 0.6179] 
2023-09-27 04:42:31.194717: Epoch time: 99.91 s 
2023-09-27 04:42:32.798359:  
2023-09-27 04:42:32.798516: Epoch 490 
2023-09-27 04:42:32.798620: Current learning rate: 0.00546 
2023-09-27 04:44:12.143240: train_loss -0.8935 
2023-09-27 04:44:12.143488: val_loss -0.5978 
2023-09-27 04:44:12.143566: Pseudo dice [0.8932, 0.4598, 0.6243] 
2023-09-27 04:44:12.143686: Epoch time: 99.35 s 
2023-09-27 04:44:13.407868:  
2023-09-27 04:44:13.408030: Epoch 491 
2023-09-27 04:44:13.408121: Current learning rate: 0.00545 
2023-09-27 04:45:53.402963: train_loss -0.8931 
2023-09-27 04:45:53.403259: val_loss -0.629 
2023-09-27 04:45:53.403356: Pseudo dice [0.8903, 0.5981, 0.6751] 
2023-09-27 04:45:53.403442: Epoch time: 100.0 s 
2023-09-27 04:45:54.834076:  
2023-09-27 04:45:54.834229: Epoch 492 
2023-09-27 04:45:54.834323: Current learning rate: 0.00544 
2023-09-27 04:47:34.335333: train_loss -0.8881 
2023-09-27 04:47:34.335592: val_loss -0.6232 
2023-09-27 04:47:34.335680: Pseudo dice [0.8994, 0.57, 0.659] 
2023-09-27 04:47:34.335760: Epoch time: 99.5 s 
2023-09-27 04:47:36.077830:  
2023-09-27 04:47:36.077992: Epoch 493 
2023-09-27 04:47:36.078137: Current learning rate: 0.00543 
2023-09-27 04:49:15.676169: train_loss -0.8999 
2023-09-27 04:49:15.676451: val_loss -0.592 
2023-09-27 04:49:15.676535: Pseudo dice [0.8945, 0.5222, 0.6355] 
2023-09-27 04:49:15.676609: Epoch time: 99.6 s 
2023-09-27 04:49:17.279944:  
2023-09-27 04:49:17.280112: Epoch 494 
2023-09-27 04:49:17.280216: Current learning rate: 0.00542 
2023-09-27 04:50:57.231626: train_loss -0.8999 
2023-09-27 04:50:57.232265: val_loss -0.6211 
2023-09-27 04:50:57.232356: Pseudo dice [0.9024, 0.5939, 0.5953] 
2023-09-27 04:50:57.232439: Epoch time: 99.95 s 
2023-09-27 04:50:58.543520:  
2023-09-27 04:50:58.543895: Epoch 495 
2023-09-27 04:50:58.544059: Current learning rate: 0.00541 
2023-09-27 04:52:38.830982: train_loss -0.9035 
2023-09-27 04:52:38.831520: val_loss -0.621 
2023-09-27 04:52:38.831610: Pseudo dice [0.8984, 0.5422, 0.6332] 
2023-09-27 04:52:38.831694: Epoch time: 100.29 s 
2023-09-27 04:52:40.164403:  
2023-09-27 04:52:40.165005: Epoch 496 
2023-09-27 04:52:40.165120: Current learning rate: 0.0054 
2023-09-27 04:54:20.238154: train_loss -0.8831 
2023-09-27 04:54:20.238485: val_loss -0.5994 
2023-09-27 04:54:20.238587: Pseudo dice [0.8882, 0.5683, 0.5882] 
2023-09-27 04:54:20.238679: Epoch time: 100.07 s 
2023-09-27 04:54:21.853681:  
2023-09-27 04:54:21.853991: Epoch 497 
2023-09-27 04:54:21.854106: Current learning rate: 0.00539 
2023-09-27 04:56:01.687367: train_loss -0.8956 
2023-09-27 04:56:01.687643: val_loss -0.5789 
2023-09-27 04:56:01.687732: Pseudo dice [0.8964, 0.5227, 0.5796] 
2023-09-27 04:56:01.687812: Epoch time: 99.84 s 
2023-09-27 04:56:02.943194:  
2023-09-27 04:56:02.943645: Epoch 498 
2023-09-27 04:56:02.943748: Current learning rate: 0.00538 
2023-09-27 04:57:43.031970: train_loss -0.8962 
2023-09-27 04:57:43.032355: val_loss -0.5987 
2023-09-27 04:57:43.032875: Pseudo dice [0.9025, 0.5082, 0.5982] 
2023-09-27 04:57:43.033148: Epoch time: 100.09 s 
2023-09-27 04:57:44.455296:  
2023-09-27 04:57:44.455456: Epoch 499 
2023-09-27 04:57:44.455545: Current learning rate: 0.00537 
2023-09-27 04:59:24.998755: train_loss -0.9019 
2023-09-27 04:59:24.998991: val_loss -0.6073 
2023-09-27 04:59:24.999072: Pseudo dice [0.9046, 0.5886, 0.5325] 
2023-09-27 04:59:24.999143: Epoch time: 100.54 s 
2023-09-27 04:59:27.828737:  
2023-09-27 04:59:27.828882: Epoch 500 
2023-09-27 04:59:27.828975: Current learning rate: 0.00536 
2023-09-27 05:01:07.940849: train_loss -0.9006 
2023-09-27 05:01:07.941094: val_loss -0.6346 
2023-09-27 05:01:07.941173: Pseudo dice [0.9038, 0.5498, 0.6728] 
2023-09-27 05:01:07.941243: Epoch time: 100.11 s 
2023-09-27 05:01:09.192971:  
2023-09-27 05:01:09.193117: Epoch 501 
2023-09-27 05:01:09.193203: Current learning rate: 0.00535 
2023-09-27 05:02:49.542990: train_loss -0.8968 
2023-09-27 05:02:49.543273: val_loss -0.5289 
2023-09-27 05:02:49.543369: Pseudo dice [0.8641, 0.4838, 0.4699] 
2023-09-27 05:02:49.543458: Epoch time: 100.35 s 
2023-09-27 05:02:50.960802:  
2023-09-27 05:02:50.961079: Epoch 502 
2023-09-27 05:02:50.961171: Current learning rate: 0.00534 
2023-09-27 05:04:31.021311: train_loss -0.8591 
2023-09-27 05:04:31.021580: val_loss -0.616 
2023-09-27 05:04:31.021974: Pseudo dice [0.8929, 0.557, 0.6135] 
2023-09-27 05:04:31.022057: Epoch time: 100.06 s 
2023-09-27 05:04:32.291132:  
2023-09-27 05:04:32.291281: Epoch 503 
2023-09-27 05:04:32.291371: Current learning rate: 0.00533 
2023-09-27 05:06:12.339204: train_loss -0.8709 
2023-09-27 05:06:12.339466: val_loss -0.5846 
2023-09-27 05:06:12.339545: Pseudo dice [0.8854, 0.509, 0.5872] 
2023-09-27 05:06:12.339618: Epoch time: 100.05 s 
2023-09-27 05:06:13.598656:  
2023-09-27 05:06:13.598802: Epoch 504 
2023-09-27 05:06:13.598907: Current learning rate: 0.00532 
2023-09-27 05:07:53.035833: train_loss -0.8727 
2023-09-27 05:07:53.036095: val_loss -0.6298 
2023-09-27 05:07:53.036180: Pseudo dice [0.9011, 0.5777, 0.6348] 
2023-09-27 05:07:53.036256: Epoch time: 99.44 s 
2023-09-27 05:07:54.485917:  
2023-09-27 05:07:54.486072: Epoch 505 
2023-09-27 05:07:54.486173: Current learning rate: 0.00531 
2023-09-27 05:09:36.019329: train_loss -0.8668 
2023-09-27 05:09:36.019582: val_loss -0.6016 
2023-09-27 05:09:36.019663: Pseudo dice [0.8823, 0.5517, 0.5971] 
2023-09-27 05:09:36.019735: Epoch time: 101.53 s 
2023-09-27 05:09:37.561759:  
2023-09-27 05:09:37.562037: Epoch 506 
2023-09-27 05:09:37.562152: Current learning rate: 0.0053 
2023-09-27 05:11:18.988241: train_loss -0.8726 
2023-09-27 05:11:18.988601: val_loss -0.5911 
2023-09-27 05:11:18.988678: Pseudo dice [0.8891, 0.4919, 0.6396] 
2023-09-27 05:11:18.988753: Epoch time: 101.43 s 
2023-09-27 05:11:20.253459:  
2023-09-27 05:11:20.253605: Epoch 507 
2023-09-27 05:11:20.253699: Current learning rate: 0.00529 
2023-09-27 05:13:01.905577: train_loss -0.8692 
2023-09-27 05:13:01.905827: val_loss -0.5913 
2023-09-27 05:13:01.905909: Pseudo dice [0.8953, 0.5026, 0.6012] 
2023-09-27 05:13:01.906167: Epoch time: 101.65 s 
2023-09-27 05:13:03.161647:  
2023-09-27 05:13:03.161813: Epoch 508 
2023-09-27 05:13:03.161905: Current learning rate: 0.00528 
2023-09-27 05:14:45.151564: train_loss -0.882 
2023-09-27 05:14:45.151808: val_loss -0.6055 
2023-09-27 05:14:45.151881: Pseudo dice [0.8892, 0.534, 0.5934] 
2023-09-27 05:14:45.151948: Epoch time: 101.99 s 
2023-09-27 05:14:46.396739:  
2023-09-27 05:14:46.396993: Epoch 509 
2023-09-27 05:14:46.397087: Current learning rate: 0.00527 
2023-09-27 05:16:28.057811: train_loss -0.8803 
2023-09-27 05:16:28.058053: val_loss -0.5752 
2023-09-27 05:16:28.058153: Pseudo dice [0.8895, 0.4893, 0.6139] 
2023-09-27 05:16:28.058230: Epoch time: 101.66 s 
2023-09-27 05:16:29.363790:  
2023-09-27 05:16:29.363915: Epoch 510 
2023-09-27 05:16:29.364001: Current learning rate: 0.00526 
2023-09-27 05:18:10.675637: train_loss -0.879 
2023-09-27 05:18:10.675886: val_loss -0.635 
2023-09-27 05:18:10.675964: Pseudo dice [0.8891, 0.577, 0.6054] 
2023-09-27 05:18:10.676034: Epoch time: 101.31 s 
2023-09-27 05:18:11.932044:  
2023-09-27 05:18:11.932287: Epoch 511 
2023-09-27 05:18:11.932378: Current learning rate: 0.00525 
2023-09-27 05:19:52.949385: train_loss -0.8793 
2023-09-27 05:19:52.949642: val_loss -0.5902 
2023-09-27 05:19:52.949724: Pseudo dice [0.8919, 0.5804, 0.5236] 
2023-09-27 05:19:52.949795: Epoch time: 101.02 s 
2023-09-27 05:19:54.425871:  
2023-09-27 05:19:54.426014: Epoch 512 
2023-09-27 05:19:54.426117: Current learning rate: 0.00524 
2023-09-27 05:21:35.509857: train_loss -0.886 
2023-09-27 05:21:35.510291: val_loss -0.5416 
2023-09-27 05:21:35.510446: Pseudo dice [0.8813, 0.4955, 0.4972] 
2023-09-27 05:21:35.510540: Epoch time: 101.09 s 
2023-09-27 05:21:37.140053:  
2023-09-27 05:21:37.140210: Epoch 513 
2023-09-27 05:21:37.140314: Current learning rate: 0.00523 
2023-09-27 05:23:18.492303: train_loss -0.8891 
2023-09-27 05:23:18.492594: val_loss -0.5549 
2023-09-27 05:23:18.492688: Pseudo dice [0.8931, 0.5762, 0.4099] 
2023-09-27 05:23:18.492777: Epoch time: 101.35 s 
2023-09-27 05:23:19.847215:  
2023-09-27 05:23:19.847363: Epoch 514 
2023-09-27 05:23:19.847449: Current learning rate: 0.00522 
2023-09-27 05:25:00.855982: train_loss -0.89 
2023-09-27 05:25:00.856318: val_loss -0.6023 
2023-09-27 05:25:00.856400: Pseudo dice [0.8938, 0.6411, 0.5559] 
2023-09-27 05:25:00.856470: Epoch time: 101.01 s 
2023-09-27 05:25:02.115304:  
2023-09-27 05:25:02.115444: Epoch 515 
2023-09-27 05:25:02.115531: Current learning rate: 0.00521 
2023-09-27 05:26:42.468767: train_loss -0.8626 
2023-09-27 05:26:42.469106: val_loss -0.5943 
2023-09-27 05:26:42.469189: Pseudo dice [0.8959, 0.6226, 0.4936] 
2023-09-27 05:26:42.469260: Epoch time: 100.35 s 
2023-09-27 05:26:43.739401:  
2023-09-27 05:26:43.739633: Epoch 516 
2023-09-27 05:26:43.739730: Current learning rate: 0.0052 
2023-09-27 05:28:23.711323: train_loss -0.8707 
2023-09-27 05:28:23.711574: val_loss -0.5845 
2023-09-27 05:28:23.711651: Pseudo dice [0.889, 0.5908, 0.5499] 
2023-09-27 05:28:23.711720: Epoch time: 99.97 s 
2023-09-27 05:28:24.970346:  
2023-09-27 05:28:24.970497: Epoch 517 
2023-09-27 05:28:24.970588: Current learning rate: 0.00519 
2023-09-27 05:30:05.168605: train_loss -0.8836 
2023-09-27 05:30:05.168874: val_loss -0.6142 
2023-09-27 05:30:05.168954: Pseudo dice [0.8979, 0.5791, 0.6312] 
2023-09-27 05:30:05.169026: Epoch time: 100.2 s 
2023-09-27 05:30:06.812025:  
2023-09-27 05:30:06.812171: Epoch 518 
2023-09-27 05:30:06.812264: Current learning rate: 0.00518 
2023-09-27 05:31:46.788021: train_loss -0.8815 
2023-09-27 05:31:46.788254: val_loss -0.6095 
2023-09-27 05:31:46.788332: Pseudo dice [0.8889, 0.58, 0.6049] 
2023-09-27 05:31:46.788404: Epoch time: 99.98 s 
2023-09-27 05:31:48.114959:  
2023-09-27 05:31:48.115117: Epoch 519 
2023-09-27 05:31:48.115212: Current learning rate: 0.00518 
2023-09-27 05:33:26.423549: train_loss -0.8874 
2023-09-27 05:33:26.423789: val_loss -0.6293 
2023-09-27 05:33:26.423868: Pseudo dice [0.8976, 0.5738, 0.6082] 
2023-09-27 05:33:26.423938: Epoch time: 98.31 s 
2023-09-27 05:33:27.673209:  
2023-09-27 05:33:27.673347: Epoch 520 
2023-09-27 05:33:27.673438: Current learning rate: 0.00517 
2023-09-27 05:35:07.497204: train_loss -0.8927 
2023-09-27 05:35:07.497438: val_loss -0.5879 
2023-09-27 05:35:07.497516: Pseudo dice [0.8916, 0.5579, 0.5522] 
2023-09-27 05:35:07.497587: Epoch time: 99.83 s 
2023-09-27 05:35:08.783070:  
2023-09-27 05:35:08.783212: Epoch 521 
2023-09-27 05:35:08.783314: Current learning rate: 0.00516 
2023-09-27 05:36:48.444480: train_loss -0.8812 
2023-09-27 05:36:48.444768: val_loss -0.6155 
2023-09-27 05:36:48.444861: Pseudo dice [0.8945, 0.5955, 0.58] 
2023-09-27 05:36:48.444947: Epoch time: 99.66 s 
2023-09-27 05:36:49.823759:  
2023-09-27 05:36:49.823926: Epoch 522 
2023-09-27 05:36:49.824015: Current learning rate: 0.00515 
2023-09-27 05:38:29.515624: train_loss -0.8646 
2023-09-27 05:38:29.515908: val_loss -0.6386 
2023-09-27 05:38:29.515987: Pseudo dice [0.891, 0.6013, 0.6388] 
2023-09-27 05:38:29.516058: Epoch time: 99.69 s 
2023-09-27 05:38:30.828708:  
2023-09-27 05:38:30.828883: Epoch 523 
2023-09-27 05:38:30.828970: Current learning rate: 0.00514 
2023-09-27 05:40:10.668403: train_loss -0.882 
2023-09-27 05:40:10.668676: val_loss -0.5673 
2023-09-27 05:40:10.668755: Pseudo dice [0.8907, 0.456, 0.5489] 
2023-09-27 05:40:10.668828: Epoch time: 99.84 s 
2023-09-27 05:40:12.113118:  
2023-09-27 05:40:12.113259: Epoch 524 
2023-09-27 05:40:12.113344: Current learning rate: 0.00513 
2023-09-27 05:41:51.722199: train_loss -0.8898 
2023-09-27 05:41:51.722462: val_loss -0.5879 
2023-09-27 05:41:51.722536: Pseudo dice [0.8965, 0.4795, 0.6396] 
2023-09-27 05:41:51.722614: Epoch time: 99.61 s 
2023-09-27 05:41:53.292068:  
2023-09-27 05:41:53.292252: Epoch 525 
2023-09-27 05:41:53.292358: Current learning rate: 0.00512 
2023-09-27 05:43:32.726482: train_loss -0.887 
2023-09-27 05:43:32.726720: val_loss -0.5932 
2023-09-27 05:43:32.726798: Pseudo dice [0.8964, 0.5146, 0.579] 
2023-09-27 05:43:32.726868: Epoch time: 99.44 s 
2023-09-27 05:43:33.984720:  
2023-09-27 05:43:33.984866: Epoch 526 
2023-09-27 05:43:33.984954: Current learning rate: 0.00511 
2023-09-27 05:45:13.827488: train_loss -0.9001 
2023-09-27 05:45:13.827772: val_loss -0.5872 
2023-09-27 05:45:13.827869: Pseudo dice [0.9022, 0.5611, 0.5283] 
2023-09-27 05:45:13.827955: Epoch time: 99.84 s 
2023-09-27 05:45:15.133208:  
2023-09-27 05:45:15.133358: Epoch 527 
2023-09-27 05:45:15.133456: Current learning rate: 0.0051 
2023-09-27 05:46:55.127683: train_loss -0.8909 
2023-09-27 05:46:55.127969: val_loss -0.6056 
2023-09-27 05:46:55.128070: Pseudo dice [0.8973, 0.5639, 0.5655] 
2023-09-27 05:46:55.128142: Epoch time: 100.0 s 
2023-09-27 05:46:56.421713:  
2023-09-27 05:46:56.421856: Epoch 528 
2023-09-27 05:46:56.421941: Current learning rate: 0.00509 
2023-09-27 05:48:36.168423: train_loss -0.8941 
2023-09-27 05:48:36.168689: val_loss -0.6129 
2023-09-27 05:48:36.168784: Pseudo dice [0.9, 0.5865, 0.6175] 
2023-09-27 05:48:36.168874: Epoch time: 99.75 s 
2023-09-27 05:48:37.485153:  
2023-09-27 05:48:37.485403: Epoch 529 
2023-09-27 05:48:37.485568: Current learning rate: 0.00508 
2023-09-27 05:50:17.415779: train_loss -0.8954 
2023-09-27 05:50:17.416032: val_loss -0.5761 
2023-09-27 05:50:17.416113: Pseudo dice [0.9004, 0.5321, 0.5336] 
2023-09-27 05:50:17.416188: Epoch time: 99.93 s 
2023-09-27 05:50:18.894525:  
2023-09-27 05:50:18.894696: Epoch 530 
2023-09-27 05:50:18.894813: Current learning rate: 0.00507 
2023-09-27 05:51:58.678212: train_loss -0.8998 
2023-09-27 05:51:58.678484: val_loss -0.6324 
2023-09-27 05:51:58.678563: Pseudo dice [0.9009, 0.6199, 0.5748] 
2023-09-27 05:51:58.678638: Epoch time: 99.78 s 
2023-09-27 05:51:59.985790:  
2023-09-27 05:51:59.986040: Epoch 531 
2023-09-27 05:51:59.986155: Current learning rate: 0.00506 
2023-09-27 05:53:39.749399: train_loss -0.8988 
2023-09-27 05:53:39.749655: val_loss -0.6106 
2023-09-27 05:53:39.749732: Pseudo dice [0.8954, 0.5541, 0.6202] 
2023-09-27 05:53:39.749804: Epoch time: 99.76 s 
2023-09-27 05:53:41.294248:  
2023-09-27 05:53:41.294403: Epoch 532 
2023-09-27 05:53:41.294509: Current learning rate: 0.00505 
2023-09-27 05:55:20.927377: train_loss -0.8982 
2023-09-27 05:55:20.927962: val_loss -0.6612 
2023-09-27 05:55:20.928214: Pseudo dice [0.8995, 0.5915, 0.7111] 
2023-09-27 05:55:20.928424: Epoch time: 99.63 s 
2023-09-27 05:55:22.532709:  
2023-09-27 05:55:22.533011: Epoch 533 
2023-09-27 05:55:22.533147: Current learning rate: 0.00504 
2023-09-27 05:57:02.354459: train_loss -0.9028 
2023-09-27 05:57:02.354715: val_loss -0.6046 
2023-09-27 05:57:02.354792: Pseudo dice [0.8978, 0.6056, 0.531] 
2023-09-27 05:57:02.354865: Epoch time: 99.82 s 
2023-09-27 05:57:03.648040:  
2023-09-27 05:57:03.648277: Epoch 534 
2023-09-27 05:57:03.648365: Current learning rate: 0.00503 
2023-09-27 05:58:43.233809: train_loss -0.8972 
2023-09-27 05:58:43.234090: val_loss -0.6377 
2023-09-27 05:58:43.234200: Pseudo dice [0.9088, 0.6117, 0.5886] 
2023-09-27 05:58:43.234287: Epoch time: 99.59 s 
2023-09-27 05:58:44.752831:  
2023-09-27 05:58:44.753104: Epoch 535 
2023-09-27 05:58:44.753211: Current learning rate: 0.00502 
2023-09-27 06:00:24.499045: train_loss -0.9029 
2023-09-27 06:00:24.499306: val_loss -0.6263 
2023-09-27 06:00:24.499384: Pseudo dice [0.9128, 0.5699, 0.6048] 
2023-09-27 06:00:24.499456: Epoch time: 99.75 s 
2023-09-27 06:00:25.915289:  
2023-09-27 06:00:25.915470: Epoch 536 
2023-09-27 06:00:25.915575: Current learning rate: 0.00501 
2023-09-27 06:02:05.974480: train_loss -0.8968 
2023-09-27 06:02:05.974901: val_loss -0.5918 
2023-09-27 06:02:05.974991: Pseudo dice [0.9043, 0.6189, 0.5888] 
2023-09-27 06:02:05.975060: Epoch time: 100.06 s 
2023-09-27 06:02:07.225350:  
2023-09-27 06:02:07.225502: Epoch 537 
2023-09-27 06:02:07.225599: Current learning rate: 0.005 
2023-09-27 06:03:47.332955: train_loss -0.9065 
2023-09-27 06:03:47.333232: val_loss -0.6433 
2023-09-27 06:03:47.333328: Pseudo dice [0.9068, 0.5869, 0.6325] 
2023-09-27 06:03:47.333415: Epoch time: 100.11 s 
2023-09-27 06:03:48.673165:  
2023-09-27 06:03:48.673519: Epoch 538 
2023-09-27 06:03:48.673620: Current learning rate: 0.00499 
2023-09-27 06:05:28.684458: train_loss -0.9021 
2023-09-27 06:05:28.684716: val_loss -0.5831 
2023-09-27 06:05:28.684794: Pseudo dice [0.8882, 0.6073, 0.5097] 
2023-09-27 06:05:28.684863: Epoch time: 100.01 s 
2023-09-27 06:05:29.934923:  
2023-09-27 06:05:29.935054: Epoch 539 
2023-09-27 06:05:29.935139: Current learning rate: 0.00498 
2023-09-27 06:07:09.919241: train_loss -0.8971 
2023-09-27 06:07:09.919493: val_loss -0.5971 
2023-09-27 06:07:09.919573: Pseudo dice [0.8997, 0.5653, 0.6391] 
2023-09-27 06:07:09.919642: Epoch time: 99.99 s 
2023-09-27 06:07:11.189410:  
2023-09-27 06:07:11.189788: Epoch 540 
2023-09-27 06:07:11.189884: Current learning rate: 0.00497 
2023-09-27 06:08:51.171932: train_loss -0.8747 
2023-09-27 06:08:51.172197: val_loss -0.5688 
2023-09-27 06:08:51.172276: Pseudo dice [0.8815, 0.4984, 0.5079] 
2023-09-27 06:08:51.172347: Epoch time: 99.98 s 
2023-09-27 06:08:52.442205:  
2023-09-27 06:08:52.442678: Epoch 541 
2023-09-27 06:08:52.442771: Current learning rate: 0.00496 
2023-09-27 06:10:32.519201: train_loss -0.8802 
2023-09-27 06:10:32.519445: val_loss -0.641 
2023-09-27 06:10:32.519522: Pseudo dice [0.8998, 0.5677, 0.6477] 
2023-09-27 06:10:32.519590: Epoch time: 100.08 s 
2023-09-27 06:10:33.792670:  
2023-09-27 06:10:33.792822: Epoch 542 
2023-09-27 06:10:33.792918: Current learning rate: 0.00495 
2023-09-27 06:12:13.660907: train_loss -0.8958 
2023-09-27 06:12:13.661182: val_loss -0.5786 
2023-09-27 06:12:13.661262: Pseudo dice [0.9034, 0.5056, 0.5489] 
2023-09-27 06:12:13.661332: Epoch time: 99.87 s 
2023-09-27 06:12:15.152333:  
2023-09-27 06:12:15.152500: Epoch 543 
2023-09-27 06:12:15.152590: Current learning rate: 0.00494 
2023-09-27 06:13:55.304465: train_loss -0.8926 
2023-09-27 06:13:55.304721: val_loss -0.6288 
2023-09-27 06:13:55.304800: Pseudo dice [0.8995, 0.5375, 0.659] 
2023-09-27 06:13:55.304871: Epoch time: 100.15 s 
2023-09-27 06:13:56.552610:  
2023-09-27 06:13:56.552749: Epoch 544 
2023-09-27 06:13:56.552839: Current learning rate: 0.00493 
2023-09-27 06:15:36.521871: train_loss -0.8878 
2023-09-27 06:15:36.522193: val_loss -0.5891 
2023-09-27 06:15:36.522290: Pseudo dice [0.8953, 0.5056, 0.5998] 
2023-09-27 06:15:36.522381: Epoch time: 99.97 s 
2023-09-27 06:15:37.987412:  
2023-09-27 06:15:37.987565: Epoch 545 
2023-09-27 06:15:37.987660: Current learning rate: 0.00492 
2023-09-27 06:17:18.130219: train_loss -0.9044 
2023-09-27 06:17:18.130474: val_loss -0.6326 
2023-09-27 06:17:18.130553: Pseudo dice [0.9048, 0.6358, 0.6114] 
2023-09-27 06:17:18.130627: Epoch time: 100.14 s 
2023-09-27 06:17:19.377371:  
2023-09-27 06:17:19.377639: Epoch 546 
2023-09-27 06:17:19.377725: Current learning rate: 0.00491 
2023-09-27 06:18:59.602648: train_loss -0.9026 
2023-09-27 06:18:59.602939: val_loss -0.6184 
2023-09-27 06:18:59.603021: Pseudo dice [0.9014, 0.5568, 0.6062] 
2023-09-27 06:18:59.603204: Epoch time: 100.23 s 
2023-09-27 06:19:00.885872:  
2023-09-27 06:19:00.886037: Epoch 547 
2023-09-27 06:19:00.886158: Current learning rate: 0.0049 
2023-09-27 06:20:40.658820: train_loss -0.8934 
2023-09-27 06:20:40.659084: val_loss -0.6119 
2023-09-27 06:20:40.659163: Pseudo dice [0.9, 0.5428, 0.6193] 
2023-09-27 06:20:40.659236: Epoch time: 99.77 s 
2023-09-27 06:20:41.941975:  
2023-09-27 06:20:41.942168: Epoch 548 
2023-09-27 06:20:41.942269: Current learning rate: 0.00489 
2023-09-27 06:22:22.128385: train_loss -0.8932 
2023-09-27 06:22:22.128672: val_loss -0.647 
2023-09-27 06:22:22.128768: Pseudo dice [0.9009, 0.6183, 0.651] 
2023-09-27 06:22:22.128945: Epoch time: 100.19 s 
2023-09-27 06:22:23.713696:  
2023-09-27 06:22:23.713838: Epoch 549 
2023-09-27 06:22:23.713928: Current learning rate: 0.00488 
2023-09-27 06:24:03.880903: train_loss -0.9021 
2023-09-27 06:24:03.881261: val_loss -0.5694 
2023-09-27 06:24:03.881341: Pseudo dice [0.8974, 0.5717, 0.5312] 
2023-09-27 06:24:03.881415: Epoch time: 100.17 s 
2023-09-27 06:24:06.755177:  
2023-09-27 06:24:06.755494: Epoch 550 
2023-09-27 06:24:06.755594: Current learning rate: 0.00487 
2023-09-27 06:25:47.007807: train_loss -0.9026 
2023-09-27 06:25:47.008080: val_loss -0.5623 
2023-09-27 06:25:47.008157: Pseudo dice [0.9059, 0.5471, 0.4695] 
2023-09-27 06:25:47.008231: Epoch time: 100.25 s 
2023-09-27 06:25:48.292006:  
2023-09-27 06:25:48.292191: Epoch 551 
2023-09-27 06:25:48.292281: Current learning rate: 0.00486 
2023-09-27 06:27:28.506921: train_loss -0.8947 
2023-09-27 06:27:28.507183: val_loss -0.641 
2023-09-27 06:27:28.507262: Pseudo dice [0.8994, 0.6029, 0.6697] 
2023-09-27 06:27:28.507334: Epoch time: 100.22 s 
2023-09-27 06:27:29.762933:  
2023-09-27 06:27:29.763088: Epoch 552 
2023-09-27 06:27:29.763175: Current learning rate: 0.00485 
2023-09-27 06:29:09.622430: train_loss -0.9074 
2023-09-27 06:29:09.622723: val_loss -0.5959 
2023-09-27 06:29:09.622803: Pseudo dice [0.8906, 0.5971, 0.5259] 
2023-09-27 06:29:09.622874: Epoch time: 99.86 s 
2023-09-27 06:29:10.995867:  
2023-09-27 06:29:10.996061: Epoch 553 
2023-09-27 06:29:10.996154: Current learning rate: 0.00484 
2023-09-27 06:30:50.865921: train_loss -0.9088 
2023-09-27 06:30:50.866231: val_loss -0.5867 
2023-09-27 06:30:50.866328: Pseudo dice [0.8865, 0.551, 0.6221] 
2023-09-27 06:30:50.866416: Epoch time: 99.87 s 
2023-09-27 06:30:52.155436:  
2023-09-27 06:30:52.155603: Epoch 554 
2023-09-27 06:30:52.155694: Current learning rate: 0.00484 
2023-09-27 06:32:32.338095: train_loss -0.8962 
2023-09-27 06:32:32.338367: val_loss -0.6136 
2023-09-27 06:32:32.338442: Pseudo dice [0.899, 0.5653, 0.6525] 
2023-09-27 06:32:32.338513: Epoch time: 100.18 s 
2023-09-27 06:32:33.755289:  
2023-09-27 06:32:33.755500: Epoch 555 
2023-09-27 06:32:33.755598: Current learning rate: 0.00483 
2023-09-27 06:34:12.285860: train_loss -0.8888 
2023-09-27 06:34:12.286135: val_loss -0.5689 
2023-09-27 06:34:12.286544: Pseudo dice [0.8962, 0.5945, 0.495] 
2023-09-27 06:34:12.286624: Epoch time: 98.53 s 
2023-09-27 06:34:13.519928:  
2023-09-27 06:34:13.520414: Epoch 556 
2023-09-27 06:34:13.520511: Current learning rate: 0.00482 
2023-09-27 06:35:53.342928: train_loss -0.8843 
2023-09-27 06:35:53.343181: val_loss -0.5991 
2023-09-27 06:35:53.343256: Pseudo dice [0.9009, 0.564, 0.6505] 
2023-09-27 06:35:53.343327: Epoch time: 99.82 s 
2023-09-27 06:35:54.699304:  
2023-09-27 06:35:54.699647: Epoch 557 
2023-09-27 06:35:54.699738: Current learning rate: 0.00481 
2023-09-27 06:37:34.676871: train_loss -0.9024 
2023-09-27 06:37:34.677160: val_loss -0.6071 
2023-09-27 06:37:34.677256: Pseudo dice [0.9008, 0.5952, 0.574] 
2023-09-27 06:37:34.677343: Epoch time: 99.98 s 
2023-09-27 06:37:35.943504:  
2023-09-27 06:37:35.943646: Epoch 558 
2023-09-27 06:37:35.943733: Current learning rate: 0.0048 
2023-09-27 06:39:15.967969: train_loss -0.8966 
2023-09-27 06:39:15.968229: val_loss -0.6275 
2023-09-27 06:39:15.968307: Pseudo dice [0.9009, 0.5951, 0.5966] 
2023-09-27 06:39:15.968380: Epoch time: 100.03 s 
2023-09-27 06:39:17.336408:  
2023-09-27 06:39:17.336554: Epoch 559 
2023-09-27 06:39:17.336643: Current learning rate: 0.00479 
2023-09-27 06:40:57.398848: train_loss -0.892 
2023-09-27 06:40:57.399110: val_loss -0.5283 
2023-09-27 06:40:57.399197: Pseudo dice [0.8824, 0.4755, 0.5544] 
2023-09-27 06:40:57.399280: Epoch time: 100.06 s 
2023-09-27 06:40:58.660718:  
2023-09-27 06:40:58.660872: Epoch 560 
2023-09-27 06:40:58.660958: Current learning rate: 0.00478 
2023-09-27 06:42:38.389242: train_loss -0.8857 
2023-09-27 06:42:38.389517: val_loss -0.5881 
2023-09-27 06:42:38.389596: Pseudo dice [0.9029, 0.5286, 0.5597] 
2023-09-27 06:42:38.389666: Epoch time: 99.73 s 
2023-09-27 06:42:39.846797:  
2023-09-27 06:42:39.846932: Epoch 561 
2023-09-27 06:42:39.847025: Current learning rate: 0.00477 
2023-09-27 06:44:20.322910: train_loss -0.8973 
2023-09-27 06:44:20.323175: val_loss -0.6338 
2023-09-27 06:44:20.323254: Pseudo dice [0.8988, 0.6017, 0.654] 
2023-09-27 06:44:20.323325: Epoch time: 100.48 s 
2023-09-27 06:44:21.801099:  
2023-09-27 06:44:21.801576: Epoch 562 
2023-09-27 06:44:21.801687: Current learning rate: 0.00476 
2023-09-27 06:46:02.155735: train_loss -0.9019 
2023-09-27 06:46:02.156110: val_loss -0.6396 
2023-09-27 06:46:02.156195: Pseudo dice [0.9091, 0.5934, 0.6275] 
2023-09-27 06:46:02.156271: Epoch time: 100.36 s 
2023-09-27 06:46:03.502575:  
2023-09-27 06:46:03.502739: Epoch 563 
2023-09-27 06:46:03.502830: Current learning rate: 0.00475 
2023-09-27 06:47:43.582448: train_loss -0.9091 
2023-09-27 06:47:43.583035: val_loss -0.616 
2023-09-27 06:47:43.583145: Pseudo dice [0.9028, 0.6028, 0.6177] 
2023-09-27 06:47:43.583247: Epoch time: 100.08 s 
2023-09-27 06:47:44.893403:  
2023-09-27 06:47:44.893576: Epoch 564 
2023-09-27 06:47:44.893668: Current learning rate: 0.00474 
2023-09-27 06:49:24.925665: train_loss -0.9084 
2023-09-27 06:49:24.926147: val_loss -0.5986 
2023-09-27 06:49:24.926244: Pseudo dice [0.9032, 0.5497, 0.6323] 
2023-09-27 06:49:24.926324: Epoch time: 100.03 s 
2023-09-27 06:49:26.202467:  
2023-09-27 06:49:26.202671: Epoch 565 
2023-09-27 06:49:26.202765: Current learning rate: 0.00473 
2023-09-27 06:51:06.371516: train_loss -0.9093 
2023-09-27 06:51:06.372103: val_loss -0.59 
2023-09-27 06:51:06.372208: Pseudo dice [0.903, 0.5268, 0.6073] 
2023-09-27 06:51:06.372322: Epoch time: 100.17 s 
2023-09-27 06:51:07.964346:  
2023-09-27 06:51:07.964527: Epoch 566 
2023-09-27 06:51:07.964631: Current learning rate: 0.00472 
2023-09-27 06:52:48.212546: train_loss -0.9115 
2023-09-27 06:52:48.212796: val_loss -0.6404 
2023-09-27 06:52:48.212873: Pseudo dice [0.8972, 0.5969, 0.6725] 
2023-09-27 06:52:48.212943: Epoch time: 100.25 s 
2023-09-27 06:52:49.649051:  
2023-09-27 06:52:49.649194: Epoch 567 
2023-09-27 06:52:49.649281: Current learning rate: 0.00471 
2023-09-27 06:54:29.781996: train_loss -0.9123 
2023-09-27 06:54:29.782262: val_loss -0.6006 
2023-09-27 06:54:29.782342: Pseudo dice [0.8978, 0.5344, 0.5856] 
2023-09-27 06:54:29.782416: Epoch time: 100.13 s 
2023-09-27 06:54:31.126248:  
2023-09-27 06:54:31.126412: Epoch 568 
2023-09-27 06:54:31.126505: Current learning rate: 0.0047 
2023-09-27 06:56:11.479407: train_loss -0.9101 
2023-09-27 06:56:11.479668: val_loss -0.6358 
2023-09-27 06:56:11.479750: Pseudo dice [0.903, 0.5496, 0.6212] 
2023-09-27 06:56:11.479820: Epoch time: 100.35 s 
2023-09-27 06:56:12.794408:  
2023-09-27 06:56:12.794557: Epoch 569 
2023-09-27 06:56:12.794649: Current learning rate: 0.00469 
2023-09-27 06:57:53.038122: train_loss -0.9067 
2023-09-27 06:57:53.038374: val_loss -0.6051 
2023-09-27 06:57:53.038454: Pseudo dice [0.9011, 0.542, 0.6378] 
2023-09-27 06:57:53.038526: Epoch time: 100.24 s 
2023-09-27 06:57:54.339921:  
2023-09-27 06:57:54.340072: Epoch 570 
2023-09-27 06:57:54.340161: Current learning rate: 0.00468 
2023-09-27 06:59:34.630511: train_loss -0.9035 
2023-09-27 06:59:34.630763: val_loss -0.6364 
2023-09-27 06:59:34.630840: Pseudo dice [0.8986, 0.5592, 0.6559] 
2023-09-27 06:59:34.630911: Epoch time: 100.29 s 
2023-09-27 06:59:35.980866:  
2023-09-27 06:59:35.981007: Epoch 571 
2023-09-27 06:59:35.981094: Current learning rate: 0.00467 
2023-09-27 07:01:15.993810: train_loss -0.9085 
2023-09-27 07:01:15.994069: val_loss -0.6407 
2023-09-27 07:01:15.994164: Pseudo dice [0.9072, 0.5891, 0.6203] 
2023-09-27 07:01:15.994238: Epoch time: 100.01 s 
2023-09-27 07:01:17.295844:  
2023-09-27 07:01:17.296144: Epoch 572 
2023-09-27 07:01:17.296243: Current learning rate: 0.00466 
2023-09-27 07:02:57.559083: train_loss -0.907 
2023-09-27 07:02:57.559419: val_loss -0.585 
2023-09-27 07:02:57.559500: Pseudo dice [0.9097, 0.5143, 0.5395] 
2023-09-27 07:02:57.559571: Epoch time: 100.26 s 
2023-09-27 07:02:58.977721:  
2023-09-27 07:02:58.977869: Epoch 573 
2023-09-27 07:02:58.977954: Current learning rate: 0.00465 
2023-09-27 07:04:39.207510: train_loss -0.9033 
2023-09-27 07:04:39.207796: val_loss -0.6111 
2023-09-27 07:04:39.207878: Pseudo dice [0.9083, 0.6375, 0.4912] 
2023-09-27 07:04:39.207956: Epoch time: 100.23 s 
2023-09-27 07:04:40.474431:  
2023-09-27 07:04:40.474597: Epoch 574 
2023-09-27 07:04:40.474696: Current learning rate: 0.00464 
2023-09-27 07:06:20.563717: train_loss -0.9049 
2023-09-27 07:06:20.563998: val_loss -0.6538 
2023-09-27 07:06:20.564094: Pseudo dice [0.9039, 0.5842, 0.6832] 
2023-09-27 07:06:20.564180: Epoch time: 100.09 s 
2023-09-27 07:06:22.150001:  
2023-09-27 07:06:22.150156: Epoch 575 
2023-09-27 07:06:22.150249: Current learning rate: 0.00463 
2023-09-27 07:08:02.520197: train_loss -0.904 
2023-09-27 07:08:02.520455: val_loss -0.6579 
2023-09-27 07:08:02.520548: Pseudo dice [0.9022, 0.5785, 0.7015] 
2023-09-27 07:08:02.520622: Epoch time: 100.37 s 
2023-09-27 07:08:03.804686:  
2023-09-27 07:08:03.805213: Epoch 576 
2023-09-27 07:08:03.805324: Current learning rate: 0.00462 
2023-09-27 07:09:44.026227: train_loss -0.9017 
2023-09-27 07:09:44.026580: val_loss -0.6181 
2023-09-27 07:09:44.026663: Pseudo dice [0.8947, 0.6536, 0.5189] 
2023-09-27 07:09:44.026738: Epoch time: 100.22 s 
2023-09-27 07:09:45.296148:  
2023-09-27 07:09:45.296287: Epoch 577 
2023-09-27 07:09:45.296373: Current learning rate: 0.00461 
2023-09-27 07:11:25.481130: train_loss -0.9034 
2023-09-27 07:11:25.481376: val_loss -0.6116 
2023-09-27 07:11:25.481456: Pseudo dice [0.9022, 0.5474, 0.6177] 
2023-09-27 07:11:25.481528: Epoch time: 100.19 s 
2023-09-27 07:11:26.791332:  
2023-09-27 07:11:26.791459: Epoch 578 
2023-09-27 07:11:26.791546: Current learning rate: 0.0046 
2023-09-27 07:13:06.634029: train_loss -0.9098 
2023-09-27 07:13:06.634297: val_loss -0.6289 
2023-09-27 07:13:06.634378: Pseudo dice [0.9082, 0.587, 0.625] 
2023-09-27 07:13:06.634452: Epoch time: 99.84 s 
2023-09-27 07:13:08.057746:  
2023-09-27 07:13:08.057882: Epoch 579 
2023-09-27 07:13:08.057977: Current learning rate: 0.00459 
2023-09-27 07:14:48.264373: train_loss -0.913 
2023-09-27 07:14:48.264637: val_loss -0.6333 
2023-09-27 07:14:48.264715: Pseudo dice [0.9029, 0.5124, 0.6894] 
2023-09-27 07:14:48.264787: Epoch time: 100.21 s 
2023-09-27 07:14:49.563299:  
2023-09-27 07:14:49.563469: Epoch 580 
2023-09-27 07:14:49.563601: Current learning rate: 0.00458 
2023-09-27 07:16:29.886919: train_loss -0.9061 
2023-09-27 07:16:29.887184: val_loss -0.6278 
2023-09-27 07:16:29.887267: Pseudo dice [0.8988, 0.5756, 0.6702] 
2023-09-27 07:16:29.887337: Epoch time: 100.33 s 
2023-09-27 07:16:31.221892:  
2023-09-27 07:16:31.222055: Epoch 581 
2023-09-27 07:16:31.222157: Current learning rate: 0.00457 
2023-09-27 07:18:11.341485: train_loss -0.8963 
2023-09-27 07:18:11.341814: val_loss -0.5828 
2023-09-27 07:18:11.341946: Pseudo dice [0.8909, 0.5394, 0.6301] 
2023-09-27 07:18:11.342056: Epoch time: 100.12 s 
2023-09-27 07:18:12.998698:  
2023-09-27 07:18:12.999053: Epoch 582 
2023-09-27 07:18:12.999161: Current learning rate: 0.00456 
2023-09-27 07:19:53.148024: train_loss -0.8941 
2023-09-27 07:19:53.148265: val_loss -0.5975 
2023-09-27 07:19:53.148343: Pseudo dice [0.8899, 0.516, 0.6403] 
2023-09-27 07:19:53.148414: Epoch time: 100.15 s 
2023-09-27 07:19:54.765040:  
2023-09-27 07:19:54.765261: Epoch 583 
2023-09-27 07:19:54.765373: Current learning rate: 0.00455 
2023-09-27 07:21:35.029026: train_loss -0.8981 
2023-09-27 07:21:35.029305: val_loss -0.6165 
2023-09-27 07:21:35.029404: Pseudo dice [0.8921, 0.5687, 0.6251] 
2023-09-27 07:21:35.029492: Epoch time: 100.27 s 
2023-09-27 07:21:36.404150:  
2023-09-27 07:21:36.404289: Epoch 584 
2023-09-27 07:21:36.404375: Current learning rate: 0.00454 
2023-09-27 07:23:16.425260: train_loss -0.8892 
2023-09-27 07:23:16.425539: val_loss -0.5718 
2023-09-27 07:23:16.425634: Pseudo dice [0.8902, 0.5562, 0.5048] 
2023-09-27 07:23:16.425719: Epoch time: 100.02 s 
2023-09-27 07:23:18.250654:  
2023-09-27 07:23:18.250810: Epoch 585 
2023-09-27 07:23:18.250918: Current learning rate: 0.00453 
2023-09-27 07:24:58.574168: train_loss -0.903 
2023-09-27 07:24:58.574445: val_loss -0.5567 
2023-09-27 07:24:58.574525: Pseudo dice [0.8987, 0.5817, 0.4731] 
2023-09-27 07:24:58.574602: Epoch time: 100.32 s 
2023-09-27 07:24:59.839294:  
2023-09-27 07:24:59.839442: Epoch 586 
2023-09-27 07:24:59.839527: Current learning rate: 0.00452 
2023-09-27 07:26:39.963810: train_loss -0.899 
2023-09-27 07:26:39.964162: val_loss -0.5497 
2023-09-27 07:26:39.964245: Pseudo dice [0.8899, 0.4598, 0.5318] 
2023-09-27 07:26:39.964321: Epoch time: 100.13 s 
2023-09-27 07:26:41.232186:  
2023-09-27 07:26:41.232574: Epoch 587 
2023-09-27 07:26:41.232729: Current learning rate: 0.00451 
2023-09-27 07:28:21.412078: train_loss -0.8907 
2023-09-27 07:28:21.412328: val_loss -0.608 
2023-09-27 07:28:21.412407: Pseudo dice [0.8934, 0.571, 0.6302] 
2023-09-27 07:28:21.412493: Epoch time: 100.18 s 
2023-09-27 07:28:22.710763:  
2023-09-27 07:28:22.710908: Epoch 588 
2023-09-27 07:28:22.710998: Current learning rate: 0.0045 
2023-09-27 07:30:02.816046: train_loss -0.8996 
2023-09-27 07:30:02.816326: val_loss -0.6101 
2023-09-27 07:30:02.816422: Pseudo dice [0.8948, 0.5069, 0.6378] 
2023-09-27 07:30:02.816509: Epoch time: 100.11 s 
2023-09-27 07:30:04.428231:  
2023-09-27 07:30:04.428385: Epoch 589 
2023-09-27 07:30:04.428491: Current learning rate: 0.00449 
2023-09-27 07:31:44.598216: train_loss -0.884 
2023-09-27 07:31:44.598478: val_loss -0.5654 
2023-09-27 07:31:44.598557: Pseudo dice [0.8723, 0.4985, 0.5962] 
2023-09-27 07:31:44.598632: Epoch time: 100.17 s 
2023-09-27 07:31:45.895222:  
2023-09-27 07:31:45.895429: Epoch 590 
2023-09-27 07:31:45.895567: Current learning rate: 0.00448 
2023-09-27 07:33:26.101450: train_loss -0.882 
2023-09-27 07:33:26.101782: val_loss -0.5624 
2023-09-27 07:33:26.101898: Pseudo dice [0.9, 0.4949, 0.5045] 
2023-09-27 07:33:26.101995: Epoch time: 100.21 s 
2023-09-27 07:33:27.542870:  
2023-09-27 07:33:27.543071: Epoch 591 
2023-09-27 07:33:27.543232: Current learning rate: 0.00447 
2023-09-27 07:35:07.928583: train_loss -0.8956 
2023-09-27 07:35:07.928944: val_loss -0.6064 
2023-09-27 07:35:07.929024: Pseudo dice [0.901, 0.4837, 0.6765] 
2023-09-27 07:35:07.929101: Epoch time: 100.39 s 
2023-09-27 07:35:09.660276:  
2023-09-27 07:35:09.660424: Epoch 592 
2023-09-27 07:35:09.660544: Current learning rate: 0.00446 
2023-09-27 07:36:50.010438: train_loss -0.9041 
2023-09-27 07:36:50.010679: val_loss -0.598 
2023-09-27 07:36:50.010790: Pseudo dice [0.88, 0.6417, 0.5405] 
2023-09-27 07:36:50.010882: Epoch time: 100.35 s 
2023-09-27 07:36:51.286881:  
2023-09-27 07:36:51.287027: Epoch 593 
2023-09-27 07:36:51.287124: Current learning rate: 0.00445 
2023-09-27 07:38:31.759254: train_loss -0.8916 
2023-09-27 07:38:31.759572: val_loss -0.6066 
2023-09-27 07:38:31.759701: Pseudo dice [0.9033, 0.5124, 0.6368] 
2023-09-27 07:38:31.759824: Epoch time: 100.47 s 
2023-09-27 07:38:33.346752:  
2023-09-27 07:38:33.346881: Epoch 594 
2023-09-27 07:38:33.346967: Current learning rate: 0.00444 
2023-09-27 07:40:13.511914: train_loss -0.8784 
2023-09-27 07:40:13.512161: val_loss -0.5384 
2023-09-27 07:40:13.512241: Pseudo dice [0.879, 0.4925, 0.4976] 
2023-09-27 07:40:13.512316: Epoch time: 100.17 s 
2023-09-27 07:40:15.107720:  
2023-09-27 07:40:15.107925: Epoch 595 
2023-09-27 07:40:15.108040: Current learning rate: 0.00443 
2023-09-27 07:41:55.409575: train_loss -0.8519 
2023-09-27 07:41:55.409832: val_loss -0.5624 
2023-09-27 07:41:55.409910: Pseudo dice [0.8646, 0.5162, 0.5359] 
2023-09-27 07:41:55.409996: Epoch time: 100.3 s 
2023-09-27 07:41:56.688777:  
2023-09-27 07:41:56.688958: Epoch 596 
2023-09-27 07:41:56.689051: Current learning rate: 0.00442 
2023-09-27 07:43:36.474150: train_loss -0.857 
2023-09-27 07:43:36.474407: val_loss -0.6345 
2023-09-27 07:43:36.474486: Pseudo dice [0.8944, 0.5512, 0.6496] 
2023-09-27 07:43:36.474562: Epoch time: 99.79 s 
2023-09-27 07:43:37.765090:  
2023-09-27 07:43:37.765237: Epoch 597 
2023-09-27 07:43:37.765323: Current learning rate: 0.00441 
2023-09-27 07:45:18.152822: train_loss -0.8762 
2023-09-27 07:45:18.153075: val_loss -0.5791 
2023-09-27 07:45:18.153155: Pseudo dice [0.8885, 0.5758, 0.5235] 
2023-09-27 07:45:18.153226: Epoch time: 100.39 s 
2023-09-27 07:45:19.682798:  
2023-09-27 07:45:19.682992: Epoch 598 
2023-09-27 07:45:19.683087: Current learning rate: 0.0044 
2023-09-27 07:46:59.907110: train_loss -0.8777 
2023-09-27 07:46:59.907355: val_loss -0.5923 
2023-09-27 07:46:59.907434: Pseudo dice [0.8989, 0.6141, 0.4945] 
2023-09-27 07:46:59.907507: Epoch time: 100.23 s 
2023-09-27 07:47:01.160628:  
2023-09-27 07:47:01.160779: Epoch 599 
2023-09-27 07:47:01.160870: Current learning rate: 0.00439 
2023-09-27 07:48:40.943347: train_loss -0.8702 
2023-09-27 07:48:40.943585: val_loss -0.5633 
2023-09-27 07:48:40.943663: Pseudo dice [0.8757, 0.5346, 0.5255] 
2023-09-27 07:48:40.943735: Epoch time: 99.78 s 
2023-09-27 07:48:43.551957:  
2023-09-27 07:48:43.552105: Epoch 600 
2023-09-27 07:48:43.552188: Current learning rate: 0.00438 
2023-09-27 07:50:23.697198: train_loss -0.8788 
2023-09-27 07:50:23.697487: val_loss -0.6146 
2023-09-27 07:50:23.697583: Pseudo dice [0.8915, 0.5413, 0.6869] 
2023-09-27 07:50:23.697670: Epoch time: 100.15 s 
2023-09-27 07:50:25.118969:  
2023-09-27 07:50:25.119257: Epoch 601 
2023-09-27 07:50:25.119440: Current learning rate: 0.00437 
2023-09-27 07:52:05.435746: train_loss -0.8456 
2023-09-27 07:52:05.436000: val_loss -0.5772 
2023-09-27 07:52:05.436077: Pseudo dice [0.8822, 0.5918, 0.5667] 
2023-09-27 07:52:05.436147: Epoch time: 100.32 s 
2023-09-27 07:52:06.705048:  
2023-09-27 07:52:06.705180: Epoch 602 
2023-09-27 07:52:06.705268: Current learning rate: 0.00436 
2023-09-27 07:53:46.971635: train_loss -0.8564 
2023-09-27 07:53:46.971875: val_loss -0.5785 
2023-09-27 07:53:46.971948: Pseudo dice [0.8871, 0.505, 0.5196] 
2023-09-27 07:53:46.972018: Epoch time: 100.27 s 
2023-09-27 07:53:48.391007:  
2023-09-27 07:53:48.391153: Epoch 603 
2023-09-27 07:53:48.391240: Current learning rate: 0.00435 
2023-09-27 07:55:28.824284: train_loss -0.8835 
2023-09-27 07:55:28.824534: val_loss -0.6154 
2023-09-27 07:55:28.824612: Pseudo dice [0.9058, 0.5798, 0.6334] 
2023-09-27 07:55:28.824685: Epoch time: 100.43 s 
2023-09-27 07:55:30.348396:  
2023-09-27 07:55:30.348562: Epoch 604 
2023-09-27 07:55:30.348667: Current learning rate: 0.00434 
2023-09-27 07:57:10.312463: train_loss -0.8981 
2023-09-27 07:57:10.312712: val_loss -0.5682 
2023-09-27 07:57:10.312790: Pseudo dice [0.8901, 0.5474, 0.538] 
2023-09-27 07:57:10.312862: Epoch time: 99.97 s 
2023-09-27 07:57:11.832955:  
2023-09-27 07:57:11.833121: Epoch 605 
2023-09-27 07:57:11.833210: Current learning rate: 0.00433 
2023-09-27 07:58:50.332777: train_loss -0.8978 
2023-09-27 07:58:50.333032: val_loss -0.5983 
2023-09-27 07:58:50.333112: Pseudo dice [0.8896, 0.5234, 0.6237] 
2023-09-27 07:58:50.333187: Epoch time: 98.5 s 
2023-09-27 07:58:51.671299:  
2023-09-27 07:58:51.671603: Epoch 606 
2023-09-27 07:58:51.671708: Current learning rate: 0.00432 
2023-09-27 08:00:31.391801: train_loss -0.8758 
2023-09-27 08:00:31.392060: val_loss -0.6101 
2023-09-27 08:00:31.392139: Pseudo dice [0.8808, 0.5956, 0.5719] 
2023-09-27 08:00:31.392212: Epoch time: 99.72 s 
2023-09-27 08:00:32.975249:  
2023-09-27 08:00:32.975538: Epoch 607 
2023-09-27 08:00:32.975647: Current learning rate: 0.00431 
2023-09-27 08:02:12.901766: train_loss -0.8852 
2023-09-27 08:02:12.902022: val_loss -0.5596 
2023-09-27 08:02:12.902120: Pseudo dice [0.8794, 0.493, 0.5194] 
2023-09-27 08:02:12.902200: Epoch time: 99.93 s 
2023-09-27 08:02:14.191812:  
2023-09-27 08:02:14.192062: Epoch 608 
2023-09-27 08:02:14.192160: Current learning rate: 0.0043 
2023-09-27 08:03:53.862227: train_loss -0.8823 
2023-09-27 08:03:53.862489: val_loss -0.5952 
2023-09-27 08:03:53.862567: Pseudo dice [0.8881, 0.5223, 0.619] 
2023-09-27 08:03:53.862640: Epoch time: 99.67 s 
2023-09-27 08:03:55.358771:  
2023-09-27 08:03:55.358925: Epoch 609 
2023-09-27 08:03:55.359018: Current learning rate: 0.00429 
2023-09-27 08:05:35.195276: train_loss -0.8972 
2023-09-27 08:05:35.195518: val_loss -0.6541 
2023-09-27 08:05:35.195600: Pseudo dice [0.8909, 0.5998, 0.6638] 
2023-09-27 08:05:35.195673: Epoch time: 99.84 s 
2023-09-27 08:05:36.459510:  
2023-09-27 08:05:36.459652: Epoch 610 
2023-09-27 08:05:36.459737: Current learning rate: 0.00429 
2023-09-27 08:07:16.380233: train_loss -0.9004 
2023-09-27 08:07:16.380482: val_loss -0.5971 
2023-09-27 08:07:16.380843: Pseudo dice [0.8977, 0.5208, 0.6002] 
2023-09-27 08:07:16.380920: Epoch time: 99.92 s 
2023-09-27 08:07:17.676135:  
2023-09-27 08:07:17.676388: Epoch 611 
2023-09-27 08:07:17.676477: Current learning rate: 0.00428 
2023-09-27 08:08:56.471925: train_loss -0.8999 
2023-09-27 08:08:56.472157: val_loss -0.589 
2023-09-27 08:08:56.472235: Pseudo dice [0.8997, 0.5163, 0.5772] 
2023-09-27 08:08:56.472307: Epoch time: 98.8 s 
2023-09-27 08:08:57.930944:  
2023-09-27 08:08:57.931099: Epoch 612 
2023-09-27 08:08:57.931205: Current learning rate: 0.00427 
2023-09-27 08:10:38.960645: train_loss -0.8982 
2023-09-27 08:10:38.960905: val_loss -0.5956 
2023-09-27 08:10:38.960985: Pseudo dice [0.8941, 0.5504, 0.6385] 
2023-09-27 08:10:38.961060: Epoch time: 101.03 s 
2023-09-27 08:10:40.270289:  
2023-09-27 08:10:40.270555: Epoch 613 
2023-09-27 08:10:40.270655: Current learning rate: 0.00426 
2023-09-27 08:12:21.439898: train_loss -0.9017 
2023-09-27 08:12:21.440149: val_loss -0.5549 
2023-09-27 08:12:21.440226: Pseudo dice [0.8902, 0.5324, 0.5576] 
2023-09-27 08:12:21.440299: Epoch time: 101.17 s 
2023-09-27 08:12:22.758591:  
2023-09-27 08:12:22.758879: Epoch 614 
2023-09-27 08:12:22.758981: Current learning rate: 0.00425 
2023-09-27 08:14:02.955977: train_loss -0.904 
2023-09-27 08:14:02.956308: val_loss -0.6255 
2023-09-27 08:14:02.956387: Pseudo dice [0.901, 0.5867, 0.6507] 
2023-09-27 08:14:02.956460: Epoch time: 100.2 s 
2023-09-27 08:14:04.424305:  
2023-09-27 08:14:04.424444: Epoch 615 
2023-09-27 08:14:04.424539: Current learning rate: 0.00424 
2023-09-27 08:15:43.039093: train_loss -0.9076 
2023-09-27 08:15:43.039352: val_loss -0.5992 
2023-09-27 08:15:43.039433: Pseudo dice [0.9063, 0.4763, 0.6142] 
2023-09-27 08:15:43.039509: Epoch time: 98.62 s 
2023-09-27 08:15:44.333652:  
2023-09-27 08:15:44.333786: Epoch 616 
2023-09-27 08:15:44.333875: Current learning rate: 0.00423 
2023-09-27 08:17:24.315652: train_loss -0.8993 
2023-09-27 08:17:24.315925: val_loss -0.6272 
2023-09-27 08:17:24.316010: Pseudo dice [0.9012, 0.5858, 0.62] 
2023-09-27 08:17:24.316090: Epoch time: 99.98 s 
2023-09-27 08:17:25.606462:  
2023-09-27 08:17:25.606620: Epoch 617 
2023-09-27 08:17:25.606722: Current learning rate: 0.00422 
2023-09-27 08:19:03.891318: train_loss -0.9047 
2023-09-27 08:19:03.891597: val_loss -0.6337 
2023-09-27 08:19:03.891691: Pseudo dice [0.9007, 0.5501, 0.6603] 
2023-09-27 08:19:03.891781: Epoch time: 98.29 s 
2023-09-27 08:19:05.359828:  
2023-09-27 08:19:05.359980: Epoch 618 
2023-09-27 08:19:05.360069: Current learning rate: 0.00421 
2023-09-27 08:20:43.931340: train_loss -0.904 
2023-09-27 08:20:43.931640: val_loss -0.6407 
2023-09-27 08:20:43.931739: Pseudo dice [0.898, 0.5927, 0.6604] 
2023-09-27 08:20:43.931831: Epoch time: 98.57 s 
2023-09-27 08:20:45.314908:  
2023-09-27 08:20:45.315047: Epoch 619 
2023-09-27 08:20:45.315138: Current learning rate: 0.0042 
2023-09-27 08:22:25.413360: train_loss -0.9086 
2023-09-27 08:22:25.413611: val_loss -0.6167 
2023-09-27 08:22:25.413689: Pseudo dice [0.9044, 0.5343, 0.6441] 
2023-09-27 08:22:25.413763: Epoch time: 100.1 s 
2023-09-27 08:22:26.705090:  
2023-09-27 08:22:26.705226: Epoch 620 
2023-09-27 08:22:26.705313: Current learning rate: 0.00419 
2023-09-27 08:24:06.736384: train_loss -0.9079 
2023-09-27 08:24:06.736645: val_loss -0.5916 
2023-09-27 08:24:06.736752: Pseudo dice [0.8957, 0.539, 0.6007] 
2023-09-27 08:24:06.736851: Epoch time: 100.03 s 
2023-09-27 08:24:08.183228:  
2023-09-27 08:24:08.183450: Epoch 621 
2023-09-27 08:24:08.183543: Current learning rate: 0.00418 
2023-09-27 08:25:46.872339: train_loss -0.8976 
2023-09-27 08:25:46.872592: val_loss -0.5997 
2023-09-27 08:25:46.872672: Pseudo dice [0.8953, 0.5534, 0.6111] 
2023-09-27 08:25:46.872747: Epoch time: 98.69 s 
2023-09-27 08:25:48.142415:  
2023-09-27 08:25:48.142559: Epoch 622 
2023-09-27 08:25:48.142651: Current learning rate: 0.00417 
2023-09-27 08:27:26.749219: train_loss -0.9041 
2023-09-27 08:27:26.749513: val_loss -0.6019 
2023-09-27 08:27:26.749609: Pseudo dice [0.8985, 0.4743, 0.6739] 
2023-09-27 08:27:26.749697: Epoch time: 98.61 s 
2023-09-27 08:27:28.175182:  
2023-09-27 08:27:28.175331: Epoch 623 
2023-09-27 08:27:28.175598: Current learning rate: 0.00416 
2023-09-27 08:29:06.356960: train_loss -0.914 
2023-09-27 08:29:06.357200: val_loss -0.66 
2023-09-27 08:29:06.357279: Pseudo dice [0.9094, 0.5649, 0.674] 
2023-09-27 08:29:06.357353: Epoch time: 98.18 s 
2023-09-27 08:29:07.647173:  
2023-09-27 08:29:07.647335: Epoch 624 
2023-09-27 08:29:07.647439: Current learning rate: 0.00415 
2023-09-27 08:30:46.132936: train_loss -0.9079 
2023-09-27 08:30:46.133191: val_loss -0.622 
2023-09-27 08:30:46.133394: Pseudo dice [0.9094, 0.5932, 0.569] 
2023-09-27 08:30:46.133533: Epoch time: 98.49 s 
2023-09-27 08:30:47.452625:  
2023-09-27 08:30:47.452849: Epoch 625 
2023-09-27 08:30:47.452994: Current learning rate: 0.00414 
2023-09-27 08:32:27.262644: train_loss -0.9004 
2023-09-27 08:32:27.262898: val_loss -0.6241 
2023-09-27 08:32:27.262978: Pseudo dice [0.8977, 0.499, 0.6548] 
2023-09-27 08:32:27.263052: Epoch time: 99.81 s 
2023-09-27 08:32:28.555540:  
2023-09-27 08:32:28.556023: Epoch 626 
2023-09-27 08:32:28.556126: Current learning rate: 0.00413 
2023-09-27 08:34:07.179895: train_loss -0.8883 
2023-09-27 08:34:07.180163: val_loss -0.6007 
2023-09-27 08:34:07.180255: Pseudo dice [0.8599, 0.5657, 0.5644] 
2023-09-27 08:34:07.180337: Epoch time: 98.63 s 
2023-09-27 08:34:08.659174:  
2023-09-27 08:34:08.659317: Epoch 627 
2023-09-27 08:34:08.659419: Current learning rate: 0.00412 
2023-09-27 08:35:47.261734: train_loss -0.8769 
2023-09-27 08:35:47.261981: val_loss -0.6197 
2023-09-27 08:35:47.262060: Pseudo dice [0.8989, 0.5699, 0.6677] 
2023-09-27 08:35:47.262154: Epoch time: 98.6 s 
2023-09-27 08:35:48.517775:  
2023-09-27 08:35:48.517917: Epoch 628 
2023-09-27 08:35:48.518003: Current learning rate: 0.00411 
2023-09-27 08:37:27.315813: train_loss -0.9024 
2023-09-27 08:37:27.316054: val_loss -0.6309 
2023-09-27 08:37:27.316132: Pseudo dice [0.8992, 0.5516, 0.6669] 
2023-09-27 08:37:27.316208: Epoch time: 98.8 s 
2023-09-27 08:37:28.595352:  
2023-09-27 08:37:28.595502: Epoch 629 
2023-09-27 08:37:28.595592: Current learning rate: 0.0041 
2023-09-27 08:39:07.009132: train_loss -0.9047 
2023-09-27 08:39:07.009424: val_loss -0.6397 
2023-09-27 08:39:07.009509: Pseudo dice [0.9038, 0.5515, 0.6662] 
2023-09-27 08:39:07.009626: Epoch time: 98.41 s 
2023-09-27 08:39:08.351166:  
2023-09-27 08:39:08.351343: Epoch 630 
2023-09-27 08:39:08.351445: Current learning rate: 0.00409 
2023-09-27 08:40:48.334227: train_loss -0.9068 
2023-09-27 08:40:48.335018: val_loss -0.6249 
2023-09-27 08:40:48.335118: Pseudo dice [0.9006, 0.5642, 0.6146] 
2023-09-27 08:40:48.335211: Epoch time: 99.98 s 
2023-09-27 08:40:49.666763:  
2023-09-27 08:40:49.666943: Epoch 631 
2023-09-27 08:40:49.667034: Current learning rate: 0.00408 
2023-09-27 08:42:30.000735: train_loss -0.9074 
2023-09-27 08:42:30.001009: val_loss -0.6388 
2023-09-27 08:42:30.001089: Pseudo dice [0.9076, 0.5408, 0.6405] 
2023-09-27 08:42:30.001163: Epoch time: 100.34 s 
2023-09-27 08:42:31.288080:  
2023-09-27 08:42:31.288335: Epoch 632 
2023-09-27 08:42:31.288424: Current learning rate: 0.00407 
2023-09-27 08:44:10.112864: train_loss -0.9077 
2023-09-27 08:44:10.113134: val_loss -0.5672 
2023-09-27 08:44:10.113213: Pseudo dice [0.8892, 0.5353, 0.5913] 
2023-09-27 08:44:10.113290: Epoch time: 98.83 s 
2023-09-27 08:44:12.002137:  
2023-09-27 08:44:12.002663: Epoch 633 
2023-09-27 08:44:12.002788: Current learning rate: 0.00406 
2023-09-27 08:45:50.865535: train_loss -0.8917 
2023-09-27 08:45:50.865869: val_loss -0.6268 
2023-09-27 08:45:50.865967: Pseudo dice [0.8958, 0.6054, 0.6281] 
2023-09-27 08:45:50.866049: Epoch time: 98.87 s 
2023-09-27 08:45:52.262630:  
2023-09-27 08:45:52.263017: Epoch 634 
2023-09-27 08:45:52.263130: Current learning rate: 0.00405 
2023-09-27 08:47:32.444008: train_loss -0.89 
2023-09-27 08:47:32.444464: val_loss -0.6579 
2023-09-27 08:47:32.444572: Pseudo dice [0.8916, 0.6442, 0.6877] 
2023-09-27 08:47:32.444690: Epoch time: 100.18 s 
2023-09-27 08:47:34.000076:  
2023-09-27 08:47:34.000613: Epoch 635 
2023-09-27 08:47:34.000724: Current learning rate: 0.00404 
2023-09-27 08:49:14.269032: train_loss -0.8935 
2023-09-27 08:49:14.269683: val_loss -0.6062 
2023-09-27 08:49:14.269790: Pseudo dice [0.8967, 0.5984, 0.5859] 
2023-09-27 08:49:14.269919: Epoch time: 100.27 s 
2023-09-27 08:49:15.694364:  
2023-09-27 08:49:15.694631: Epoch 636 
2023-09-27 08:49:15.694727: Current learning rate: 0.00403 
2023-09-27 08:50:55.232837: train_loss -0.9069 
2023-09-27 08:50:55.233128: val_loss -0.6165 
2023-09-27 08:50:55.233210: Pseudo dice [0.9012, 0.5304, 0.6532] 
2023-09-27 08:50:55.233290: Epoch time: 99.54 s 
2023-09-27 08:50:56.549805:  
2023-09-27 08:50:56.549966: Epoch 637 
2023-09-27 08:50:56.550064: Current learning rate: 0.00402 
2023-09-27 08:52:36.874891: train_loss -0.9108 
2023-09-27 08:52:36.875526: val_loss -0.6241 
2023-09-27 08:52:36.875615: Pseudo dice [0.8995, 0.5336, 0.6492] 
2023-09-27 08:52:36.875739: Epoch time: 100.33 s 
2023-09-27 08:52:38.213806:  
2023-09-27 08:52:38.214004: Epoch 638 
2023-09-27 08:52:38.214121: Current learning rate: 0.00401 
2023-09-27 08:54:18.700639: train_loss -0.9045 
2023-09-27 08:54:18.700892: val_loss -0.5607 
2023-09-27 08:54:18.700973: Pseudo dice [0.8892, 0.5304, 0.5515] 
2023-09-27 08:54:18.701045: Epoch time: 100.49 s 
2023-09-27 08:54:20.338786:  
2023-09-27 08:54:20.338965: Epoch 639 
2023-09-27 08:54:20.339076: Current learning rate: 0.004 
2023-09-27 08:56:00.766487: train_loss -0.9028 
2023-09-27 08:56:00.766782: val_loss -0.6416 
2023-09-27 08:56:00.766873: Pseudo dice [0.9063, 0.5731, 0.7182] 
2023-09-27 08:56:00.766954: Epoch time: 100.43 s 
2023-09-27 08:56:02.207248:  
2023-09-27 08:56:02.207458: Epoch 640 
2023-09-27 08:56:02.207577: Current learning rate: 0.00399 
2023-09-27 08:57:42.205930: train_loss -0.8905 
2023-09-27 08:57:42.206257: val_loss -0.5751 
2023-09-27 08:57:42.206429: Pseudo dice [0.8985, 0.4447, 0.6096] 
2023-09-27 08:57:42.206621: Epoch time: 100.0 s 
2023-09-27 08:57:43.522569:  
2023-09-27 08:57:43.522731: Epoch 641 
2023-09-27 08:57:43.522821: Current learning rate: 0.00398 
2023-09-27 08:59:23.840750: train_loss -0.8952 
2023-09-27 08:59:23.841022: val_loss -0.5974 
2023-09-27 08:59:23.841104: Pseudo dice [0.8961, 0.528, 0.6312] 
2023-09-27 08:59:23.841180: Epoch time: 100.32 s 
2023-09-27 08:59:25.475324:  
2023-09-27 08:59:25.475647: Epoch 642 
2023-09-27 08:59:25.475776: Current learning rate: 0.00397 
2023-09-27 09:01:05.625291: train_loss -0.8987 
2023-09-27 09:01:05.625624: val_loss -0.589 
2023-09-27 09:01:05.625731: Pseudo dice [0.8992, 0.5285, 0.5835] 
2023-09-27 09:01:05.625832: Epoch time: 100.15 s 
2023-09-27 09:01:07.012356:  
2023-09-27 09:01:07.012813: Epoch 643 
2023-09-27 09:01:07.013057: Current learning rate: 0.00396 
2023-09-27 09:02:47.211771: train_loss -0.9078 
2023-09-27 09:02:47.212103: val_loss -0.6126 
2023-09-27 09:02:47.212231: Pseudo dice [0.9052, 0.5735, 0.6462] 
2023-09-27 09:02:47.212367: Epoch time: 100.2 s 
2023-09-27 09:02:48.751458:  
2023-09-27 09:02:48.751905: Epoch 644 
2023-09-27 09:02:48.752006: Current learning rate: 0.00395 
2023-09-27 09:04:28.790952: train_loss -0.9097 
2023-09-27 09:04:28.791407: val_loss -0.6128 
2023-09-27 09:04:28.791511: Pseudo dice [0.9044, 0.4568, 0.7004] 
2023-09-27 09:04:28.791616: Epoch time: 100.04 s 
2023-09-27 09:04:30.700850:  
2023-09-27 09:04:30.701049: Epoch 645 
2023-09-27 09:04:30.701154: Current learning rate: 0.00394 
2023-09-27 09:06:10.703436: train_loss -0.9125 
2023-09-27 09:06:10.703693: val_loss -0.6014 
2023-09-27 09:06:10.703775: Pseudo dice [0.9053, 0.5307, 0.588] 
2023-09-27 09:06:10.703848: Epoch time: 100.0 s 
2023-09-27 09:06:12.040779:  
2023-09-27 09:06:12.040946: Epoch 646 
2023-09-27 09:06:12.041041: Current learning rate: 0.00393 
2023-09-27 09:07:52.377229: train_loss -0.8996 
2023-09-27 09:07:52.377478: val_loss -0.6411 
2023-09-27 09:07:52.377556: Pseudo dice [0.8728, 0.5541, 0.6802] 
2023-09-27 09:07:52.377630: Epoch time: 100.34 s 
2023-09-27 09:07:53.685846:  
2023-09-27 09:07:53.685984: Epoch 647 
2023-09-27 09:07:53.686074: Current learning rate: 0.00392 
2023-09-27 09:09:33.972248: train_loss -0.8831 
2023-09-27 09:09:33.972512: val_loss -0.5758 
2023-09-27 09:09:33.972593: Pseudo dice [0.8862, 0.571, 0.5043] 
2023-09-27 09:09:33.972670: Epoch time: 100.29 s 
2023-09-27 09:09:35.289669:  
2023-09-27 09:09:35.290034: Epoch 648 
2023-09-27 09:09:35.290196: Current learning rate: 0.00391 
2023-09-27 09:11:15.342882: train_loss -0.891 
2023-09-27 09:11:15.343172: val_loss -0.6226 
2023-09-27 09:11:15.343271: Pseudo dice [0.8985, 0.5745, 0.6408] 
2023-09-27 09:11:15.343363: Epoch time: 100.05 s 
2023-09-27 09:11:16.682487:  
2023-09-27 09:11:16.682640: Epoch 649 
2023-09-27 09:11:16.682727: Current learning rate: 0.0039 
2023-09-27 09:12:56.622170: train_loss -0.9051 
2023-09-27 09:12:56.622447: val_loss -0.603 
2023-09-27 09:12:56.622535: Pseudo dice [0.8914, 0.5419, 0.6238] 
2023-09-27 09:12:56.622612: Epoch time: 99.94 s 
2023-09-27 09:12:59.340098:  
2023-09-27 09:12:59.340336: Epoch 650 
2023-09-27 09:12:59.340452: Current learning rate: 0.00389 
2023-09-27 09:14:39.548991: train_loss -0.9035 
2023-09-27 09:14:39.549268: val_loss -0.5728 
2023-09-27 09:14:39.549351: Pseudo dice [0.8988, 0.4809, 0.5919] 
2023-09-27 09:14:39.549467: Epoch time: 100.21 s 
2023-09-27 09:14:41.419453:  
2023-09-27 09:14:41.419973: Epoch 651 
2023-09-27 09:14:41.420229: Current learning rate: 0.00388 
2023-09-27 09:16:21.703051: train_loss -0.9099 
2023-09-27 09:16:21.703730: val_loss -0.6346 
2023-09-27 09:16:21.703819: Pseudo dice [0.9008, 0.5935, 0.6696] 
2023-09-27 09:16:21.703932: Epoch time: 100.29 s 
2023-09-27 09:16:23.099135:  
2023-09-27 09:16:23.099534: Epoch 652 
2023-09-27 09:16:23.099815: Current learning rate: 0.00387 
2023-09-27 09:18:03.274394: train_loss -0.9141 
2023-09-27 09:18:03.274688: val_loss -0.6397 
2023-09-27 09:18:03.274768: Pseudo dice [0.9055, 0.5814, 0.6819] 
2023-09-27 09:18:03.274845: Epoch time: 100.18 s 
2023-09-27 09:18:04.582348:  
2023-09-27 09:18:04.582856: Epoch 653 
2023-09-27 09:18:04.583061: Current learning rate: 0.00386 
2023-09-27 09:19:44.605714: train_loss -0.9133 
2023-09-27 09:19:44.605985: val_loss -0.612 
2023-09-27 09:19:44.606063: Pseudo dice [0.9002, 0.5216, 0.6265] 
2023-09-27 09:19:44.606173: Epoch time: 100.03 s 
2023-09-27 09:19:45.891692:  
2023-09-27 09:19:45.892061: Epoch 654 
2023-09-27 09:19:45.892161: Current learning rate: 0.00385 
2023-09-27 09:21:25.901775: train_loss -0.9159 
2023-09-27 09:21:25.902452: val_loss -0.6459 
2023-09-27 09:21:25.902539: Pseudo dice [0.8975, 0.6095, 0.68] 
2023-09-27 09:21:25.902650: Epoch time: 100.01 s 
2023-09-27 09:21:27.232201:  
2023-09-27 09:21:27.232430: Epoch 655 
2023-09-27 09:21:27.232569: Current learning rate: 0.00384 
2023-09-27 09:23:07.422161: train_loss -0.9043 
2023-09-27 09:23:07.422417: val_loss -0.5726 
2023-09-27 09:23:07.422495: Pseudo dice [0.8935, 0.4682, 0.5994] 
2023-09-27 09:23:07.422572: Epoch time: 100.19 s 
2023-09-27 09:23:08.813980:  
2023-09-27 09:23:08.814357: Epoch 656 
2023-09-27 09:23:08.814451: Current learning rate: 0.00383 
2023-09-27 09:24:47.661607: train_loss -0.9003 
2023-09-27 09:24:47.661876: val_loss -0.582 
2023-09-27 09:24:47.661952: Pseudo dice [0.8969, 0.5492, 0.5476] 
2023-09-27 09:24:47.662024: Epoch time: 98.85 s 
2023-09-27 09:24:49.263236:  
2023-09-27 09:24:49.263397: Epoch 657 
2023-09-27 09:24:49.263486: Current learning rate: 0.00382 
2023-09-27 09:26:29.433946: train_loss -0.9061 
2023-09-27 09:26:29.434251: val_loss -0.5585 
2023-09-27 09:26:29.434335: Pseudo dice [0.8904, 0.4712, 0.5723] 
2023-09-27 09:26:29.434415: Epoch time: 100.17 s 
2023-09-27 09:26:30.810238:  
2023-09-27 09:26:30.810647: Epoch 658 
2023-09-27 09:26:30.810763: Current learning rate: 0.00381 
2023-09-27 09:28:10.662819: train_loss -0.9054 
2023-09-27 09:28:10.663256: val_loss -0.5952 
2023-09-27 09:28:10.663352: Pseudo dice [0.8951, 0.5213, 0.6034] 
2023-09-27 09:28:10.663451: Epoch time: 99.86 s 
2023-09-27 09:28:12.132721:  
2023-09-27 09:28:12.133347: Epoch 659 
2023-09-27 09:28:12.133584: Current learning rate: 0.0038 
2023-09-27 09:29:52.216363: train_loss -0.9115 
2023-09-27 09:29:52.216637: val_loss -0.6113 
2023-09-27 09:29:52.216717: Pseudo dice [0.8981, 0.5463, 0.6347] 
2023-09-27 09:29:52.216805: Epoch time: 100.09 s 
2023-09-27 09:29:53.562081:  
2023-09-27 09:29:53.562261: Epoch 660 
2023-09-27 09:29:53.562355: Current learning rate: 0.00379 
2023-09-27 09:31:33.868497: train_loss -0.9137 
2023-09-27 09:31:33.868778: val_loss -0.602 
2023-09-27 09:31:33.868856: Pseudo dice [0.9076, 0.5345, 0.6122] 
2023-09-27 09:31:33.868930: Epoch time: 100.31 s 
2023-09-27 09:31:35.260052:  
2023-09-27 09:31:35.260324: Epoch 661 
2023-09-27 09:31:35.260422: Current learning rate: 0.00378 
2023-09-27 09:33:15.451705: train_loss -0.9156 
2023-09-27 09:33:15.451974: val_loss -0.6187 
2023-09-27 09:33:15.452054: Pseudo dice [0.9038, 0.5565, 0.6293] 
2023-09-27 09:33:15.452149: Epoch time: 100.19 s 
2023-09-27 09:33:16.781708:  
2023-09-27 09:33:16.781895: Epoch 662 
2023-09-27 09:33:16.782000: Current learning rate: 0.00377 
2023-09-27 09:34:57.065371: train_loss -0.9048 
2023-09-27 09:34:57.065774: val_loss -0.5957 
2023-09-27 09:34:57.065862: Pseudo dice [0.8993, 0.5428, 0.6137] 
2023-09-27 09:34:57.065946: Epoch time: 100.29 s 
2023-09-27 09:34:58.601159:  
2023-09-27 09:34:58.601327: Epoch 663 
2023-09-27 09:34:58.601411: Current learning rate: 0.00376 
2023-09-27 09:36:38.810869: train_loss -0.901 
2023-09-27 09:36:38.811410: val_loss -0.5463 
2023-09-27 09:36:38.811494: Pseudo dice [0.8897, 0.4486, 0.5629] 
2023-09-27 09:36:38.811611: Epoch time: 100.21 s 
2023-09-27 09:36:40.193486:  
2023-09-27 09:36:40.193746: Epoch 664 
2023-09-27 09:36:40.194030: Current learning rate: 0.00375 
2023-09-27 09:38:20.533784: train_loss -0.9097 
2023-09-27 09:38:20.534420: val_loss -0.5984 
2023-09-27 09:38:20.534544: Pseudo dice [0.899, 0.5355, 0.6232] 
2023-09-27 09:38:20.534640: Epoch time: 100.34 s 
2023-09-27 09:38:21.829420:  
2023-09-27 09:38:21.829710: Epoch 665 
2023-09-27 09:38:21.829919: Current learning rate: 0.00374 
2023-09-27 09:40:01.615504: train_loss -0.9013 
2023-09-27 09:40:01.615763: val_loss -0.6304 
2023-09-27 09:40:01.615844: Pseudo dice [0.8986, 0.5895, 0.6491] 
2023-09-27 09:40:01.615919: Epoch time: 99.79 s 
2023-09-27 09:40:02.902445:  
2023-09-27 09:40:02.902689: Epoch 666 
2023-09-27 09:40:02.902787: Current learning rate: 0.00373 
2023-09-27 09:41:43.368348: train_loss -0.9138 
2023-09-27 09:41:43.368631: val_loss -0.5866 
2023-09-27 09:41:43.368721: Pseudo dice [0.8982, 0.5227, 0.5415] 
2023-09-27 09:41:43.368800: Epoch time: 100.47 s 
2023-09-27 09:41:44.672632:  
2023-09-27 09:41:44.672937: Epoch 667 
2023-09-27 09:41:44.673033: Current learning rate: 0.00372 
2023-09-27 09:43:24.753679: train_loss -0.9039 
2023-09-27 09:43:24.753923: val_loss -0.544 
2023-09-27 09:43:24.754001: Pseudo dice [0.889, 0.4938, 0.4377] 
2023-09-27 09:43:24.754073: Epoch time: 100.08 s 
2023-09-27 09:43:26.092075:  
2023-09-27 09:43:26.092212: Epoch 668 
2023-09-27 09:43:26.092301: Current learning rate: 0.00371 
2023-09-27 09:45:06.035985: train_loss -0.9001 
2023-09-27 09:45:06.036240: val_loss -0.584 
2023-09-27 09:45:06.036412: Pseudo dice [0.8983, 0.5524, 0.5183] 
2023-09-27 09:45:06.036494: Epoch time: 99.95 s 
2023-09-27 09:45:07.549652:  
2023-09-27 09:45:07.549954: Epoch 669 
2023-09-27 09:45:07.550054: Current learning rate: 0.0037 
2023-09-27 09:46:47.305165: train_loss -0.9054 
2023-09-27 09:46:47.305419: val_loss -0.6057 
2023-09-27 09:46:47.305496: Pseudo dice [0.8968, 0.4989, 0.6511] 
2023-09-27 09:46:47.305570: Epoch time: 99.76 s 
2023-09-27 09:46:48.648350:  
2023-09-27 09:46:48.648498: Epoch 670 
2023-09-27 09:46:48.648588: Current learning rate: 0.00369 
2023-09-27 09:48:28.843067: train_loss -0.9032 
2023-09-27 09:48:28.843351: val_loss -0.6404 
2023-09-27 09:48:28.843459: Pseudo dice [0.8993, 0.6234, 0.6324] 
2023-09-27 09:48:28.843556: Epoch time: 100.2 s 
2023-09-27 09:48:30.208950:  
2023-09-27 09:48:30.209090: Epoch 671 
2023-09-27 09:48:30.209194: Current learning rate: 0.00368 
2023-09-27 09:50:10.118619: train_loss -0.9038 
2023-09-27 09:50:10.118852: val_loss -0.6213 
2023-09-27 09:50:10.118930: Pseudo dice [0.9034, 0.61, 0.6114] 
2023-09-27 09:50:10.118999: Epoch time: 99.91 s 
2023-09-27 09:50:11.416493:  
2023-09-27 09:50:11.416749: Epoch 672 
2023-09-27 09:50:11.416838: Current learning rate: 0.00367 
2023-09-27 09:51:51.537540: train_loss -0.9 
2023-09-27 09:51:51.537791: val_loss -0.6326 
2023-09-27 09:51:51.537895: Pseudo dice [0.9045, 0.5898, 0.6294] 
2023-09-27 09:51:51.537978: Epoch time: 100.12 s 
2023-09-27 09:51:52.835464:  
2023-09-27 09:51:52.835704: Epoch 673 
2023-09-27 09:51:52.835799: Current learning rate: 0.00366 
2023-09-27 09:53:32.988020: train_loss -0.9129 
2023-09-27 09:53:32.988285: val_loss -0.6578 
2023-09-27 09:53:32.988370: Pseudo dice [0.907, 0.6131, 0.6495] 
2023-09-27 09:53:32.988451: Epoch time: 100.15 s 
2023-09-27 09:53:34.313485:  
2023-09-27 09:53:34.313741: Epoch 674 
2023-09-27 09:53:34.313833: Current learning rate: 0.00365 
2023-09-27 09:55:14.307464: train_loss -0.8925 
2023-09-27 09:55:14.307725: val_loss -0.5768 
2023-09-27 09:55:14.307813: Pseudo dice [0.8925, 0.5776, 0.5346] 
2023-09-27 09:55:14.307892: Epoch time: 100.0 s 
2023-09-27 09:55:15.771745:  
2023-09-27 09:55:15.771873: Epoch 675 
2023-09-27 09:55:15.771961: Current learning rate: 0.00364 
2023-09-27 09:56:56.125126: train_loss -0.9037 
2023-09-27 09:56:56.125396: val_loss -0.5976 
2023-09-27 09:56:56.125477: Pseudo dice [0.9003, 0.5577, 0.6115] 
2023-09-27 09:56:56.125552: Epoch time: 100.35 s 
2023-09-27 09:56:57.443905:  
2023-09-27 09:56:57.444231: Epoch 676 
2023-09-27 09:56:57.444388: Current learning rate: 0.00363 
2023-09-27 09:58:37.530213: train_loss -0.9002 
2023-09-27 09:58:37.530574: val_loss -0.5636 
2023-09-27 09:58:37.530675: Pseudo dice [0.898, 0.4795, 0.5119] 
2023-09-27 09:58:37.530769: Epoch time: 100.09 s 
2023-09-27 09:58:39.159500:  
2023-09-27 09:58:39.159680: Epoch 677 
2023-09-27 09:58:39.159784: Current learning rate: 0.00362 
2023-09-27 10:00:19.090122: train_loss -0.9029 
2023-09-27 10:00:19.090376: val_loss -0.6267 
2023-09-27 10:00:19.090452: Pseudo dice [0.8963, 0.4996, 0.6604] 
2023-09-27 10:00:19.090526: Epoch time: 99.93 s 
2023-09-27 10:00:20.379765:  
2023-09-27 10:00:20.379901: Epoch 678 
2023-09-27 10:00:20.380126: Current learning rate: 0.00361 
2023-09-27 10:02:00.861462: train_loss -0.9086 
2023-09-27 10:02:00.861724: val_loss -0.574 
2023-09-27 10:02:00.861802: Pseudo dice [0.8995, 0.5369, 0.5126] 
2023-09-27 10:02:00.861874: Epoch time: 100.48 s 
2023-09-27 10:02:02.174716:  
2023-09-27 10:02:02.174863: Epoch 679 
2023-09-27 10:02:02.174951: Current learning rate: 0.0036 
2023-09-27 10:03:42.508486: train_loss -0.9099 
2023-09-27 10:03:42.508744: val_loss -0.6378 
2023-09-27 10:03:42.508828: Pseudo dice [0.9009, 0.5474, 0.6781] 
2023-09-27 10:03:42.508902: Epoch time: 100.33 s 
2023-09-27 10:03:43.850008:  
2023-09-27 10:03:43.850771: Epoch 680 
2023-09-27 10:03:43.850956: Current learning rate: 0.00359 
2023-09-27 10:05:24.270466: train_loss -0.9149 
2023-09-27 10:05:24.270752: val_loss -0.6167 
2023-09-27 10:05:24.270848: Pseudo dice [0.8951, 0.5005, 0.6702] 
2023-09-27 10:05:24.270936: Epoch time: 100.42 s 
2023-09-27 10:05:25.659253:  
2023-09-27 10:05:25.659419: Epoch 681 
2023-09-27 10:05:25.659513: Current learning rate: 0.00358 
2023-09-27 10:07:05.815834: train_loss -0.9058 
2023-09-27 10:07:05.816097: val_loss -0.5327 
2023-09-27 10:07:05.816178: Pseudo dice [0.8912, 0.5028, 0.4876] 
2023-09-27 10:07:05.816256: Epoch time: 100.16 s 
2023-09-27 10:07:07.289360:  
2023-09-27 10:07:07.289733: Epoch 682 
2023-09-27 10:07:07.290029: Current learning rate: 0.00357 
2023-09-27 10:08:47.830168: train_loss -0.9017 
2023-09-27 10:08:47.830484: val_loss -0.5979 
2023-09-27 10:08:47.830594: Pseudo dice [0.9019, 0.5178, 0.6246] 
2023-09-27 10:08:47.830694: Epoch time: 100.54 s 
2023-09-27 10:08:49.412182:  
2023-09-27 10:08:49.412333: Epoch 683 
2023-09-27 10:08:49.412425: Current learning rate: 0.00356 
2023-09-27 10:10:29.237942: train_loss -0.9085 
2023-09-27 10:10:29.238213: val_loss -0.5317 
2023-09-27 10:10:29.238293: Pseudo dice [0.9103, 0.4511, 0.542] 
2023-09-27 10:10:29.238365: Epoch time: 99.83 s 
2023-09-27 10:10:30.536486:  
2023-09-27 10:10:30.536815: Epoch 684 
2023-09-27 10:10:30.536906: Current learning rate: 0.00355 
2023-09-27 10:12:10.424311: train_loss -0.9197 
2023-09-27 10:12:10.424557: val_loss -0.6195 
2023-09-27 10:12:10.424633: Pseudo dice [0.9034, 0.5168, 0.6318] 
2023-09-27 10:12:10.424717: Epoch time: 99.89 s 
2023-09-27 10:12:11.745910:  
2023-09-27 10:12:11.746283: Epoch 685 
2023-09-27 10:12:11.746426: Current learning rate: 0.00354 
2023-09-27 10:13:51.937221: train_loss -0.911 
2023-09-27 10:13:51.937479: val_loss -0.5824 
2023-09-27 10:13:51.937563: Pseudo dice [0.9042, 0.5769, 0.5771] 
2023-09-27 10:13:51.937635: Epoch time: 100.19 s 
2023-09-27 10:13:53.421876:  
2023-09-27 10:13:53.422023: Epoch 686 
2023-09-27 10:13:53.422155: Current learning rate: 0.00353 
2023-09-27 10:15:33.555607: train_loss -0.9168 
2023-09-27 10:15:33.555902: val_loss -0.611 
2023-09-27 10:15:33.556002: Pseudo dice [0.903, 0.5438, 0.6298] 
2023-09-27 10:15:33.556093: Epoch time: 100.13 s 
2023-09-27 10:15:35.291334:  
2023-09-27 10:15:35.291494: Epoch 687 
2023-09-27 10:15:35.291602: Current learning rate: 0.00352 
2023-09-27 10:17:15.397876: train_loss -0.919 
2023-09-27 10:17:15.398134: val_loss -0.606 
2023-09-27 10:17:15.398219: Pseudo dice [0.9055, 0.5909, 0.573] 
2023-09-27 10:17:15.398292: Epoch time: 100.11 s 
2023-09-27 10:17:16.698500:  
2023-09-27 10:17:16.698647: Epoch 688 
2023-09-27 10:17:16.698732: Current learning rate: 0.00351 
2023-09-27 10:18:56.650159: train_loss -0.9156 
2023-09-27 10:18:56.650419: val_loss -0.5511 
2023-09-27 10:18:56.650499: Pseudo dice [0.9002, 0.4948, 0.5209] 
2023-09-27 10:18:56.650575: Epoch time: 99.95 s 
2023-09-27 10:18:57.976667:  
2023-09-27 10:18:57.976815: Epoch 689 
2023-09-27 10:18:57.976900: Current learning rate: 0.0035 
2023-09-27 10:20:38.021809: train_loss -0.9091 
2023-09-27 10:20:38.022054: val_loss -0.6402 
2023-09-27 10:20:38.022156: Pseudo dice [0.9081, 0.6063, 0.6376] 
2023-09-27 10:20:38.022236: Epoch time: 100.05 s 
2023-09-27 10:20:39.345417:  
2023-09-27 10:20:39.345583: Epoch 690 
2023-09-27 10:20:39.345673: Current learning rate: 0.00349 
2023-09-27 10:22:19.642788: train_loss -0.9184 
2023-09-27 10:22:19.643048: val_loss -0.607 
2023-09-27 10:22:19.643127: Pseudo dice [0.9028, 0.523, 0.6399] 
2023-09-27 10:22:19.643202: Epoch time: 100.3 s 
2023-09-27 10:22:20.933233:  
2023-09-27 10:22:20.933367: Epoch 691 
2023-09-27 10:22:20.933459: Current learning rate: 0.00348 
2023-09-27 10:24:01.146818: train_loss -0.9098 
2023-09-27 10:24:01.147059: val_loss -0.6146 
2023-09-27 10:24:01.147136: Pseudo dice [0.9059, 0.5973, 0.6144] 
2023-09-27 10:24:01.147209: Epoch time: 100.21 s 
2023-09-27 10:24:02.717966:  
2023-09-27 10:24:02.718226: Epoch 692 
2023-09-27 10:24:02.718320: Current learning rate: 0.00346 
2023-09-27 10:25:42.618908: train_loss -0.9145 
2023-09-27 10:25:42.619171: val_loss -0.6263 
2023-09-27 10:25:42.619253: Pseudo dice [0.9068, 0.565, 0.6692] 
2023-09-27 10:25:42.619326: Epoch time: 99.9 s 
2023-09-27 10:25:43.946602:  
2023-09-27 10:25:43.946780: Epoch 693 
2023-09-27 10:25:43.946870: Current learning rate: 0.00345 
2023-09-27 10:27:24.237869: train_loss -0.9125 
2023-09-27 10:27:24.238136: val_loss -0.6204 
2023-09-27 10:27:24.238220: Pseudo dice [0.902, 0.5432, 0.6844] 
2023-09-27 10:27:24.238295: Epoch time: 100.29 s 
2023-09-27 10:27:25.720452:  
2023-09-27 10:27:25.720614: Epoch 694 
2023-09-27 10:27:25.720708: Current learning rate: 0.00344 
2023-09-27 10:29:05.861088: train_loss -0.9148 
2023-09-27 10:29:05.861335: val_loss -0.5983 
2023-09-27 10:29:05.861413: Pseudo dice [0.9068, 0.5395, 0.6425] 
2023-09-27 10:29:05.861485: Epoch time: 100.14 s 
2023-09-27 10:29:07.186661:  
2023-09-27 10:29:07.186813: Epoch 695 
2023-09-27 10:29:07.186900: Current learning rate: 0.00343 
2023-09-27 10:30:46.995624: train_loss -0.9145 
2023-09-27 10:30:46.995873: val_loss -0.6147 
2023-09-27 10:30:46.995950: Pseudo dice [0.9063, 0.5375, 0.6145] 
2023-09-27 10:30:46.996022: Epoch time: 99.81 s 
2023-09-27 10:30:48.316386:  
2023-09-27 10:30:48.316856: Epoch 696 
2023-09-27 10:30:48.316959: Current learning rate: 0.00342 
2023-09-27 10:32:28.655991: train_loss -0.9123 
2023-09-27 10:32:28.656249: val_loss -0.6366 
2023-09-27 10:32:28.656324: Pseudo dice [0.8964, 0.5455, 0.6785] 
2023-09-27 10:32:28.656398: Epoch time: 100.34 s 
2023-09-27 10:32:29.980582:  
2023-09-27 10:32:29.980726: Epoch 697 
2023-09-27 10:32:29.980810: Current learning rate: 0.00341 
2023-09-27 10:34:10.017078: train_loss -0.9086 
2023-09-27 10:34:10.017345: val_loss -0.6082 
2023-09-27 10:34:10.017441: Pseudo dice [0.8875, 0.5727, 0.615] 
2023-09-27 10:34:10.017528: Epoch time: 100.04 s 
2023-09-27 10:34:11.513124:  
2023-09-27 10:34:11.513308: Epoch 698 
2023-09-27 10:34:11.513405: Current learning rate: 0.0034 
2023-09-27 10:35:51.551086: train_loss -0.9038 
2023-09-27 10:35:51.551337: val_loss -0.5678 
2023-09-27 10:35:51.551413: Pseudo dice [0.8929, 0.5024, 0.5338] 
2023-09-27 10:35:51.551483: Epoch time: 100.04 s 
2023-09-27 10:35:52.822956:  
2023-09-27 10:35:52.823092: Epoch 699 
2023-09-27 10:35:52.823180: Current learning rate: 0.00339 
2023-09-27 10:37:33.066217: train_loss -0.9018 
2023-09-27 10:37:33.066484: val_loss -0.6165 
2023-09-27 10:37:33.066563: Pseudo dice [0.8993, 0.612, 0.5455] 
2023-09-27 10:37:33.066638: Epoch time: 100.24 s 
2023-09-27 10:37:35.772348:  
2023-09-27 10:37:35.772625: Epoch 700 
2023-09-27 10:37:35.772717: Current learning rate: 0.00338 
2023-09-27 10:39:16.092732: train_loss -0.906 
2023-09-27 10:39:16.093153: val_loss -0.591 
2023-09-27 10:39:16.093238: Pseudo dice [0.8963, 0.5067, 0.6537] 
2023-09-27 10:39:16.093312: Epoch time: 100.32 s 
2023-09-27 10:39:17.393964:  
2023-09-27 10:39:17.394122: Epoch 701 
2023-09-27 10:39:17.394229: Current learning rate: 0.00337 
2023-09-27 10:40:57.627475: train_loss -0.9113 
2023-09-27 10:40:57.627733: val_loss -0.562 
2023-09-27 10:40:57.627812: Pseudo dice [0.8976, 0.5258, 0.5449] 
2023-09-27 10:40:57.627889: Epoch time: 100.23 s 
2023-09-27 10:40:58.925537:  
2023-09-27 10:40:58.925937: Epoch 702 
2023-09-27 10:40:58.926030: Current learning rate: 0.00336 
2023-09-27 10:42:39.221035: train_loss -0.9136 
2023-09-27 10:42:39.221297: val_loss -0.597 
2023-09-27 10:42:39.221381: Pseudo dice [0.9014, 0.5612, 0.6101] 
2023-09-27 10:42:39.221459: Epoch time: 100.3 s 
2023-09-27 10:42:40.570381:  
2023-09-27 10:42:40.570570: Epoch 703 
2023-09-27 10:42:40.570670: Current learning rate: 0.00335 
2023-09-27 10:44:21.073841: train_loss -0.9113 
2023-09-27 10:44:21.074091: val_loss -0.6077 
2023-09-27 10:44:21.074194: Pseudo dice [0.8848, 0.6031, 0.521] 
2023-09-27 10:44:21.074268: Epoch time: 100.51 s 
2023-09-27 10:44:22.790754:  
2023-09-27 10:44:22.790908: Epoch 704 
2023-09-27 10:44:22.791020: Current learning rate: 0.00334 
2023-09-27 10:46:03.231284: train_loss -0.9155 
2023-09-27 10:46:03.231548: val_loss -0.6202 
2023-09-27 10:46:03.231750: Pseudo dice [0.8987, 0.5862, 0.6047] 
2023-09-27 10:46:03.231828: Epoch time: 100.44 s 
2023-09-27 10:46:04.519337:  
2023-09-27 10:46:04.519485: Epoch 705 
2023-09-27 10:46:04.519573: Current learning rate: 0.00333 
2023-09-27 10:47:44.916267: train_loss -0.9137 
2023-09-27 10:47:44.916629: val_loss -0.6053 
2023-09-27 10:47:44.916706: Pseudo dice [0.9037, 0.614, 0.589] 
2023-09-27 10:47:44.916779: Epoch time: 100.4 s 
2023-09-27 10:47:46.274354:  
2023-09-27 10:47:46.274577: Epoch 706 
2023-09-27 10:47:46.274670: Current learning rate: 0.00332 
2023-09-27 10:49:24.713405: train_loss -0.9108 
2023-09-27 10:49:24.713811: val_loss -0.6467 
2023-09-27 10:49:24.714303: Pseudo dice [0.9046, 0.6115, 0.6617] 
2023-09-27 10:49:24.714401: Epoch time: 98.44 s 
2023-09-27 10:49:26.051699:  
2023-09-27 10:49:26.052003: Epoch 707 
2023-09-27 10:49:26.052097: Current learning rate: 0.00331 
2023-09-27 10:51:06.353977: train_loss -0.9135 
2023-09-27 10:51:06.354608: val_loss -0.6174 
2023-09-27 10:51:06.354726: Pseudo dice [0.8924, 0.6135, 0.5495] 
2023-09-27 10:51:06.354852: Epoch time: 100.3 s 
2023-09-27 10:51:08.060531:  
2023-09-27 10:51:08.060743: Epoch 708 
2023-09-27 10:51:08.061170: Current learning rate: 0.0033 
2023-09-27 10:52:48.381336: train_loss -0.9192 
2023-09-27 10:52:48.381921: val_loss -0.6201 
2023-09-27 10:52:48.382209: Pseudo dice [0.9018, 0.5721, 0.609] 
2023-09-27 10:52:48.382382: Epoch time: 100.32 s 
2023-09-27 10:52:49.779254:  
2023-09-27 10:52:49.779899: Epoch 709 
2023-09-27 10:52:49.780128: Current learning rate: 0.00329 
2023-09-27 10:54:30.114048: train_loss -0.9117 
2023-09-27 10:54:30.114360: val_loss -0.5904 
2023-09-27 10:54:30.114450: Pseudo dice [0.8926, 0.549, 0.5397] 
2023-09-27 10:54:30.114527: Epoch time: 100.34 s 
2023-09-27 10:54:31.597919:  
2023-09-27 10:54:31.598061: Epoch 710 
2023-09-27 10:54:31.598161: Current learning rate: 0.00328 
2023-09-27 10:56:12.157155: train_loss -0.9108 
2023-09-27 10:56:12.157438: val_loss -0.6212 
2023-09-27 10:56:12.157529: Pseudo dice [0.8984, 0.5456, 0.6271] 
2023-09-27 10:56:12.157609: Epoch time: 100.56 s 
2023-09-27 10:56:13.504006:  
2023-09-27 10:56:13.504493: Epoch 711 
2023-09-27 10:56:13.504611: Current learning rate: 0.00327 
2023-09-27 10:57:53.542322: train_loss -0.9181 
2023-09-27 10:57:53.542582: val_loss -0.6128 
2023-09-27 10:57:53.542664: Pseudo dice [0.8911, 0.6204, 0.6143] 
2023-09-27 10:57:53.542739: Epoch time: 100.04 s 
2023-09-27 10:57:54.853637:  
2023-09-27 10:57:54.853808: Epoch 712 
2023-09-27 10:57:54.853913: Current learning rate: 0.00326 
2023-09-27 10:59:35.528975: train_loss -0.9184 
2023-09-27 10:59:35.529578: val_loss -0.6208 
2023-09-27 10:59:35.529665: Pseudo dice [0.8891, 0.6199, 0.6019] 
2023-09-27 10:59:35.529774: Epoch time: 100.68 s 
2023-09-27 10:59:36.922621:  
2023-09-27 10:59:36.923176: Epoch 713 
2023-09-27 10:59:36.923330: Current learning rate: 0.00325 
2023-09-27 11:01:17.766185: train_loss -0.9195 
2023-09-27 11:01:17.766461: val_loss -0.6326 
2023-09-27 11:01:17.766542: Pseudo dice [0.9021, 0.5892, 0.6323] 
2023-09-27 11:01:17.766615: Epoch time: 100.84 s 
2023-09-27 11:01:19.433831:  
2023-09-27 11:01:19.434349: Epoch 714 
2023-09-27 11:01:19.434510: Current learning rate: 0.00324 
2023-09-27 11:03:00.240661: train_loss -0.9217 
2023-09-27 11:03:00.241272: val_loss -0.6279 
2023-09-27 11:03:00.241359: Pseudo dice [0.8994, 0.6016, 0.5999] 
2023-09-27 11:03:00.241467: Epoch time: 100.81 s 
2023-09-27 11:03:01.888131:  
2023-09-27 11:03:01.888485: Epoch 715 
2023-09-27 11:03:01.888665: Current learning rate: 0.00323 
2023-09-27 11:04:42.741724: train_loss -0.9196 
2023-09-27 11:04:42.742025: val_loss -0.6593 
2023-09-27 11:04:42.742129: Pseudo dice [0.9035, 0.6024, 0.6675] 
2023-09-27 11:04:42.742222: Epoch time: 100.86 s 
2023-09-27 11:04:44.250858:  
2023-09-27 11:04:44.251249: Epoch 716 
2023-09-27 11:04:44.251340: Current learning rate: 0.00322 
2023-09-27 11:06:25.207795: train_loss -0.9163 
2023-09-27 11:06:25.208041: val_loss -0.6142 
2023-09-27 11:06:25.208122: Pseudo dice [0.8969, 0.5717, 0.6351] 
2023-09-27 11:06:25.208194: Epoch time: 100.96 s 
2023-09-27 11:06:26.520914:  
2023-09-27 11:06:26.521462: Epoch 717 
2023-09-27 11:06:26.521566: Current learning rate: 0.00321 
2023-09-27 11:08:07.578224: train_loss -0.914 
2023-09-27 11:08:07.578456: val_loss -0.5965 
2023-09-27 11:08:07.578533: Pseudo dice [0.8905, 0.6119, 0.5699] 
2023-09-27 11:08:07.578602: Epoch time: 101.06 s 
2023-09-27 11:08:08.849003:  
2023-09-27 11:08:08.849344: Epoch 718 
2023-09-27 11:08:08.849437: Current learning rate: 0.0032 
2023-09-27 11:09:50.594857: train_loss -0.9165 
2023-09-27 11:09:50.595100: val_loss -0.6007 
2023-09-27 11:09:50.595180: Pseudo dice [0.9013, 0.5353, 0.6091] 
2023-09-27 11:09:50.595253: Epoch time: 101.75 s 
2023-09-27 11:09:51.911667:  
2023-09-27 11:09:51.911936: Epoch 719 
2023-09-27 11:09:51.912028: Current learning rate: 0.00319 
2023-09-27 11:11:33.214538: train_loss -0.9001 
2023-09-27 11:11:33.214806: val_loss -0.5991 
2023-09-27 11:11:33.214886: Pseudo dice [0.8986, 0.5776, 0.5542] 
2023-09-27 11:11:33.214960: Epoch time: 101.3 s 
2023-09-27 11:11:34.895023:  
2023-09-27 11:11:34.895175: Epoch 720 
2023-09-27 11:11:34.895278: Current learning rate: 0.00318 
2023-09-27 11:13:16.495362: train_loss -0.9145 
2023-09-27 11:13:16.495637: val_loss -0.5854 
2023-09-27 11:13:16.495717: Pseudo dice [0.9036, 0.5141, 0.5192] 
2023-09-27 11:13:16.495790: Epoch time: 101.6 s 
2023-09-27 11:13:18.014572:  
2023-09-27 11:13:18.015101: Epoch 721 
2023-09-27 11:13:18.015237: Current learning rate: 0.00317 
2023-09-27 11:14:58.940596: train_loss -0.912 
2023-09-27 11:14:58.940864: val_loss -0.5876 
2023-09-27 11:14:58.940946: Pseudo dice [0.895, 0.5677, 0.5461] 
2023-09-27 11:14:58.941022: Epoch time: 100.93 s 
2023-09-27 11:15:00.250971:  
2023-09-27 11:15:00.251117: Epoch 722 
2023-09-27 11:15:00.251204: Current learning rate: 0.00316 
2023-09-27 11:16:40.490673: train_loss -0.9195 
2023-09-27 11:16:40.490935: val_loss -0.6004 
2023-09-27 11:16:40.491014: Pseudo dice [0.9027, 0.5243, 0.5652] 
2023-09-27 11:16:40.491089: Epoch time: 100.24 s 
2023-09-27 11:16:42.202414:  
2023-09-27 11:16:42.202991: Epoch 723 
2023-09-27 11:16:42.203276: Current learning rate: 0.00315 
2023-09-27 11:18:20.628278: train_loss -0.9114 
2023-09-27 11:18:20.628558: val_loss -0.6161 
2023-09-27 11:18:20.628660: Pseudo dice [0.9109, 0.5287, 0.6277] 
2023-09-27 11:18:20.628750: Epoch time: 98.43 s 
2023-09-27 11:18:22.286646:  
2023-09-27 11:18:22.286909: Epoch 724 
2023-09-27 11:18:22.287017: Current learning rate: 0.00314 
2023-09-27 11:20:00.185835: train_loss -0.918 
2023-09-27 11:20:00.186082: val_loss -0.6198 
2023-09-27 11:20:00.186174: Pseudo dice [0.898, 0.5733, 0.6288] 
2023-09-27 11:20:00.186249: Epoch time: 97.9 s 
2023-09-27 11:20:01.525628:  
2023-09-27 11:20:01.525863: Epoch 725 
2023-09-27 11:20:01.525954: Current learning rate: 0.00313 
2023-09-27 11:21:40.093083: train_loss -0.9169 
2023-09-27 11:21:40.093330: val_loss -0.6187 
2023-09-27 11:21:40.093412: Pseudo dice [0.901, 0.5592, 0.6343] 
2023-09-27 11:21:40.093485: Epoch time: 98.57 s 
2023-09-27 11:21:41.424189:  
2023-09-27 11:21:41.424420: Epoch 726 
2023-09-27 11:21:41.424508: Current learning rate: 0.00312 
2023-09-27 11:23:19.896165: train_loss -0.9268 
2023-09-27 11:23:19.896411: val_loss -0.6101 
2023-09-27 11:23:19.896489: Pseudo dice [0.9032, 0.4752, 0.6025] 
2023-09-27 11:23:19.896562: Epoch time: 98.47 s 
2023-09-27 11:23:21.413819:  
2023-09-27 11:23:21.414026: Epoch 727 
2023-09-27 11:23:21.414142: Current learning rate: 0.00311 
2023-09-27 11:25:01.239148: train_loss -0.9199 
2023-09-27 11:25:01.239388: val_loss -0.6006 
2023-09-27 11:25:01.239472: Pseudo dice [0.9039, 0.5452, 0.5991] 
2023-09-27 11:25:01.239546: Epoch time: 99.83 s 
2023-09-27 11:25:02.536049:  
2023-09-27 11:25:02.536208: Epoch 728 
2023-09-27 11:25:02.536304: Current learning rate: 0.0031 
2023-09-27 11:26:41.291585: train_loss -0.9248 
2023-09-27 11:26:41.291909: val_loss -0.5825 
2023-09-27 11:26:41.292024: Pseudo dice [0.9007, 0.5353, 0.6137] 
2023-09-27 11:26:41.292130: Epoch time: 98.76 s 
2023-09-27 11:26:42.635887:  
2023-09-27 11:26:42.636033: Epoch 729 
2023-09-27 11:26:42.636118: Current learning rate: 0.00309 
2023-09-27 11:28:22.289860: train_loss -0.9203 
2023-09-27 11:28:22.290170: val_loss -0.5837 
2023-09-27 11:28:22.290271: Pseudo dice [0.9063, 0.5311, 0.618] 
2023-09-27 11:28:22.290365: Epoch time: 99.66 s 
2023-09-27 11:28:23.693293:  
2023-09-27 11:28:23.693430: Epoch 730 
2023-09-27 11:28:23.693515: Current learning rate: 0.00308 
2023-09-27 11:30:03.815249: train_loss -0.9143 
2023-09-27 11:30:03.815521: val_loss -0.6166 
2023-09-27 11:30:03.815603: Pseudo dice [0.9005, 0.5242, 0.6859] 
2023-09-27 11:30:03.815676: Epoch time: 100.12 s 
2023-09-27 11:30:05.136391:  
2023-09-27 11:30:05.136806: Epoch 731 
2023-09-27 11:30:05.136913: Current learning rate: 0.00307 
2023-09-27 11:31:45.314701: train_loss -0.9168 
2023-09-27 11:31:45.314959: val_loss -0.608 
2023-09-27 11:31:45.315035: Pseudo dice [0.9007, 0.5207, 0.6269] 
2023-09-27 11:31:45.315108: Epoch time: 100.18 s 
2023-09-27 11:31:46.627803:  
2023-09-27 11:31:46.627945: Epoch 732 
2023-09-27 11:31:46.628033: Current learning rate: 0.00306 
2023-09-27 11:33:26.374023: train_loss -0.922 
2023-09-27 11:33:26.374346: val_loss -0.6446 
2023-09-27 11:33:26.374446: Pseudo dice [0.9049, 0.6031, 0.6324] 
2023-09-27 11:33:26.374531: Epoch time: 99.75 s 
2023-09-27 11:33:27.962054:  
2023-09-27 11:33:27.962298: Epoch 733 
2023-09-27 11:33:27.962457: Current learning rate: 0.00305 
2023-09-27 11:35:07.813340: train_loss -0.9245 
2023-09-27 11:35:07.813613: val_loss -0.6224 
2023-09-27 11:35:07.813692: Pseudo dice [0.9033, 0.5794, 0.6271] 
2023-09-27 11:35:07.813766: Epoch time: 99.85 s 
2023-09-27 11:35:09.155812:  
2023-09-27 11:35:09.155965: Epoch 734 
2023-09-27 11:35:09.156054: Current learning rate: 0.00304 
2023-09-27 11:36:49.268599: train_loss -0.9204 
2023-09-27 11:36:49.268887: val_loss -0.5964 
2023-09-27 11:36:49.268982: Pseudo dice [0.8984, 0.5211, 0.5855] 
2023-09-27 11:36:49.269070: Epoch time: 100.11 s 
2023-09-27 11:36:50.958337:  
2023-09-27 11:36:50.958543: Epoch 735 
2023-09-27 11:36:50.958708: Current learning rate: 0.00303 
2023-09-27 11:38:30.803740: train_loss -0.923 
2023-09-27 11:38:30.804013: val_loss -0.6012 
2023-09-27 11:38:30.804091: Pseudo dice [0.9014, 0.5916, 0.5975] 
2023-09-27 11:38:30.804167: Epoch time: 99.85 s 
2023-09-27 11:38:32.477922:  
2023-09-27 11:38:32.478198: Epoch 736 
2023-09-27 11:38:32.478334: Current learning rate: 0.00302 
2023-09-27 11:40:12.912863: train_loss -0.9226 
2023-09-27 11:40:12.913125: val_loss -0.5986 
2023-09-27 11:40:12.913205: Pseudo dice [0.8987, 0.5615, 0.5523] 
2023-09-27 11:40:12.913279: Epoch time: 100.44 s 
2023-09-27 11:40:14.390514:  
2023-09-27 11:40:14.390782: Epoch 737 
2023-09-27 11:40:14.390881: Current learning rate: 0.00301 
2023-09-27 11:41:54.611073: train_loss -0.9171 
2023-09-27 11:41:54.611378: val_loss -0.5994 
2023-09-27 11:41:54.611486: Pseudo dice [0.8964, 0.5644, 0.6145] 
2023-09-27 11:41:54.611578: Epoch time: 100.22 s 
2023-09-27 11:41:55.968295:  
2023-09-27 11:41:55.968463: Epoch 738 
2023-09-27 11:41:55.968559: Current learning rate: 0.003 
2023-09-27 11:43:36.123213: train_loss -0.9219 
2023-09-27 11:43:36.123463: val_loss -0.6043 
2023-09-27 11:43:36.123538: Pseudo dice [0.9035, 0.567, 0.6001] 
2023-09-27 11:43:36.123610: Epoch time: 100.16 s 
2023-09-27 11:43:37.615165:  
2023-09-27 11:43:37.615341: Epoch 739 
2023-09-27 11:43:37.615435: Current learning rate: 0.00299 
2023-09-27 11:45:17.676418: train_loss -0.9209 
2023-09-27 11:45:17.676654: val_loss -0.6091 
2023-09-27 11:45:17.676735: Pseudo dice [0.9053, 0.5766, 0.6035] 
2023-09-27 11:45:17.676809: Epoch time: 100.06 s 
2023-09-27 11:45:19.378610:  
2023-09-27 11:45:19.378764: Epoch 740 
2023-09-27 11:45:19.378870: Current learning rate: 0.00297 
2023-09-27 11:46:59.574093: train_loss -0.9217 
2023-09-27 11:46:59.574393: val_loss -0.6274 
2023-09-27 11:46:59.574473: Pseudo dice [0.8994, 0.5661, 0.6943] 
2023-09-27 11:46:59.574548: Epoch time: 100.2 s 
2023-09-27 11:47:01.242981:  
2023-09-27 11:47:01.243152: Epoch 741 
2023-09-27 11:47:01.243254: Current learning rate: 0.00296 
2023-09-27 11:48:40.645901: train_loss -0.9267 
2023-09-27 11:48:40.646172: val_loss -0.641 
2023-09-27 11:48:40.646253: Pseudo dice [0.9001, 0.578, 0.6708] 
2023-09-27 11:48:40.646327: Epoch time: 99.4 s 
2023-09-27 11:48:42.180309:  
2023-09-27 11:48:42.180520: Epoch 742 
2023-09-27 11:48:42.180627: Current learning rate: 0.00295 
2023-09-27 11:50:21.906386: train_loss -0.9174 
2023-09-27 11:50:21.906643: val_loss -0.623 
2023-09-27 11:50:21.906719: Pseudo dice [0.9075, 0.551, 0.6429] 
2023-09-27 11:50:21.906788: Epoch time: 99.73 s 
2023-09-27 11:50:23.520290:  
2023-09-27 11:50:23.520448: Epoch 743 
2023-09-27 11:50:23.520537: Current learning rate: 0.00294 
2023-09-27 11:52:03.088215: train_loss -0.9153 
2023-09-27 11:52:03.088481: val_loss -0.6255 
2023-09-27 11:52:03.088566: Pseudo dice [0.9004, 0.5291, 0.6417] 
2023-09-27 11:52:03.088644: Epoch time: 99.57 s 
2023-09-27 11:52:04.601273:  
2023-09-27 11:52:04.601419: Epoch 744 
2023-09-27 11:52:04.601510: Current learning rate: 0.00293 
2023-09-27 11:53:44.328663: train_loss -0.9178 
2023-09-27 11:53:44.329216: val_loss -0.6228 
2023-09-27 11:53:44.329407: Pseudo dice [0.8966, 0.5578, 0.648] 
2023-09-27 11:53:44.329565: Epoch time: 99.73 s 
2023-09-27 11:53:45.671871:  
2023-09-27 11:53:45.672005: Epoch 745 
2023-09-27 11:53:45.672094: Current learning rate: 0.00292 
2023-09-27 11:55:25.608316: train_loss -0.9168 
2023-09-27 11:55:25.608614: val_loss -0.5944 
2023-09-27 11:55:25.608697: Pseudo dice [0.8958, 0.5351, 0.5995] 
2023-09-27 11:55:25.608785: Epoch time: 99.94 s 
2023-09-27 11:55:26.988823:  
2023-09-27 11:55:26.989180: Epoch 746 
2023-09-27 11:55:26.989289: Current learning rate: 0.00291 
2023-09-27 11:57:07.008187: train_loss -0.9224 
2023-09-27 11:57:07.008445: val_loss -0.6046 
2023-09-27 11:57:07.008523: Pseudo dice [0.9003, 0.5327, 0.641] 
2023-09-27 11:57:07.008596: Epoch time: 100.02 s 
2023-09-27 11:57:08.464010:  
2023-09-27 11:57:08.464191: Epoch 747 
2023-09-27 11:57:08.464292: Current learning rate: 0.0029 
2023-09-27 11:58:48.493601: train_loss -0.9248 
2023-09-27 11:58:48.493868: val_loss -0.6101 
2023-09-27 11:58:48.493949: Pseudo dice [0.9088, 0.5669, 0.5556] 
2023-09-27 11:58:48.494035: Epoch time: 100.03 s 
2023-09-27 11:58:50.147515:  
2023-09-27 11:58:50.147791: Epoch 748 
2023-09-27 11:58:50.147965: Current learning rate: 0.00289 
2023-09-27 12:00:30.046203: train_loss -0.9233 
2023-09-27 12:00:30.046502: val_loss -0.6282 
2023-09-27 12:00:30.046581: Pseudo dice [0.9012, 0.5761, 0.5933] 
2023-09-27 12:00:30.046655: Epoch time: 99.9 s 
2023-09-27 12:00:31.353750:  
2023-09-27 12:00:31.353960: Epoch 749 
2023-09-27 12:00:31.354059: Current learning rate: 0.00288 
2023-09-27 12:02:10.819752: train_loss -0.9199 
2023-09-27 12:02:10.820009: val_loss -0.5939 
2023-09-27 12:02:10.820089: Pseudo dice [0.9016, 0.5388, 0.5872] 
2023-09-27 12:02:10.820160: Epoch time: 99.47 s 
2023-09-27 12:02:14.055294:  
2023-09-27 12:02:14.055449: Epoch 750 
2023-09-27 12:02:14.055560: Current learning rate: 0.00287 
2023-09-27 12:03:53.773042: train_loss -0.9235 
2023-09-27 12:03:53.773336: val_loss -0.6159 
2023-09-27 12:03:53.773430: Pseudo dice [0.9029, 0.5568, 0.6474] 
2023-09-27 12:03:53.773509: Epoch time: 99.72 s 
2023-09-27 12:03:55.550092:  
2023-09-27 12:03:55.550550: Epoch 751 
2023-09-27 12:03:55.550726: Current learning rate: 0.00286 
2023-09-27 12:05:35.101936: train_loss -0.9239 
2023-09-27 12:05:35.102672: val_loss -0.6327 
2023-09-27 12:05:35.102793: Pseudo dice [0.8973, 0.5845, 0.6166] 
2023-09-27 12:05:35.102909: Epoch time: 99.56 s 
2023-09-27 12:05:36.473501:  
2023-09-27 12:05:36.473744: Epoch 752 
2023-09-27 12:05:36.473840: Current learning rate: 0.00285 
2023-09-27 12:07:15.972453: train_loss -0.9267 
2023-09-27 12:07:15.972745: val_loss -0.6205 
2023-09-27 12:07:15.972838: Pseudo dice [0.9035, 0.565, 0.6364] 
2023-09-27 12:07:15.972928: Epoch time: 99.5 s 
2023-09-27 12:07:17.295783:  
2023-09-27 12:07:17.296198: Epoch 753 
2023-09-27 12:07:17.296294: Current learning rate: 0.00284 
2023-09-27 12:08:57.104784: train_loss -0.9248 
2023-09-27 12:08:57.105057: val_loss -0.6113 
2023-09-27 12:08:57.105136: Pseudo dice [0.9054, 0.5888, 0.5622] 
2023-09-27 12:08:57.105211: Epoch time: 99.81 s 
2023-09-27 12:08:58.433656:  
2023-09-27 12:08:58.433848: Epoch 754 
2023-09-27 12:08:58.433936: Current learning rate: 0.00283 
2023-09-27 12:10:38.155384: train_loss -0.9253 
2023-09-27 12:10:38.155654: val_loss -0.6104 
2023-09-27 12:10:38.155735: Pseudo dice [0.9001, 0.531, 0.6595] 
2023-09-27 12:10:38.155811: Epoch time: 99.72 s 
2023-09-27 12:10:39.526500:  
2023-09-27 12:10:39.526785: Epoch 755 
2023-09-27 12:10:39.526908: Current learning rate: 0.00282 
2023-09-27 12:12:19.243809: train_loss -0.9238 
2023-09-27 12:12:19.244083: val_loss -0.604 
2023-09-27 12:12:19.244164: Pseudo dice [0.903, 0.5379, 0.5989] 
2023-09-27 12:12:19.244237: Epoch time: 99.72 s 
2023-09-27 12:12:20.852406:  
2023-09-27 12:12:20.852831: Epoch 756 
2023-09-27 12:12:20.852935: Current learning rate: 0.00281 
2023-09-27 12:14:00.630569: train_loss -0.9176 
2023-09-27 12:14:00.631105: val_loss -0.6097 
2023-09-27 12:14:00.631194: Pseudo dice [0.8989, 0.5001, 0.5986] 
2023-09-27 12:14:00.631297: Epoch time: 99.78 s 
2023-09-27 12:14:02.025512:  
2023-09-27 12:14:02.025984: Epoch 757 
2023-09-27 12:14:02.026148: Current learning rate: 0.0028 
2023-09-27 12:15:40.292163: train_loss -0.9222 
2023-09-27 12:15:40.292441: val_loss -0.6091 
2023-09-27 12:15:40.292520: Pseudo dice [0.9038, 0.5531, 0.6471] 
2023-09-27 12:15:40.292595: Epoch time: 98.27 s 
2023-09-27 12:15:41.599415:  
2023-09-27 12:15:41.599637: Epoch 758 
2023-09-27 12:15:41.599727: Current learning rate: 0.00279 
2023-09-27 12:17:21.014185: train_loss -0.9176 
2023-09-27 12:17:21.014446: val_loss -0.6205 
2023-09-27 12:17:21.014523: Pseudo dice [0.9039, 0.5532, 0.6565] 
2023-09-27 12:17:21.014644: Epoch time: 99.42 s 
2023-09-27 12:17:22.634365:  
2023-09-27 12:17:22.634543: Epoch 759 
2023-09-27 12:17:22.634646: Current learning rate: 0.00278 
2023-09-27 12:19:02.287551: train_loss -0.9184 
2023-09-27 12:19:02.287811: val_loss -0.6074 
2023-09-27 12:19:02.287892: Pseudo dice [0.8936, 0.5075, 0.688] 
2023-09-27 12:19:02.287966: Epoch time: 99.65 s 
2023-09-27 12:19:03.631156:  
2023-09-27 12:19:03.631604: Epoch 760 
2023-09-27 12:19:03.631772: Current learning rate: 0.00277 
2023-09-27 12:20:43.049680: train_loss -0.9265 
2023-09-27 12:20:43.049955: val_loss -0.6342 
2023-09-27 12:20:43.050053: Pseudo dice [0.8972, 0.5458, 0.6716] 
2023-09-27 12:20:43.050162: Epoch time: 99.42 s 
2023-09-27 12:20:44.736622:  
2023-09-27 12:20:44.736820: Epoch 761 
2023-09-27 12:20:44.736937: Current learning rate: 0.00276 
2023-09-27 12:22:24.363661: train_loss -0.922 
2023-09-27 12:22:24.363915: val_loss -0.6441 
2023-09-27 12:22:24.363995: Pseudo dice [0.9069, 0.5952, 0.6375] 
2023-09-27 12:22:24.364067: Epoch time: 99.63 s 
2023-09-27 12:22:25.847266:  
2023-09-27 12:22:25.847411: Epoch 762 
2023-09-27 12:22:25.847499: Current learning rate: 0.00275 
2023-09-27 12:24:05.652310: train_loss -0.9258 
2023-09-27 12:24:05.652601: val_loss -0.5894 
2023-09-27 12:24:05.652701: Pseudo dice [0.8968, 0.4975, 0.6078] 
2023-09-27 12:24:05.652797: Epoch time: 99.81 s 
2023-09-27 12:24:07.380103:  
2023-09-27 12:24:07.380348: Epoch 763 
2023-09-27 12:24:07.380463: Current learning rate: 0.00274 
2023-09-27 12:25:47.213203: train_loss -0.9254 
2023-09-27 12:25:47.213449: val_loss -0.6174 
2023-09-27 12:25:47.213527: Pseudo dice [0.906, 0.5567, 0.6858] 
2023-09-27 12:25:47.213602: Epoch time: 99.83 s 
2023-09-27 12:25:48.525303:  
2023-09-27 12:25:48.525624: Epoch 764 
2023-09-27 12:25:48.525714: Current learning rate: 0.00273 
2023-09-27 12:27:27.950477: train_loss -0.9098 
2023-09-27 12:27:27.950863: val_loss -0.6435 
2023-09-27 12:27:27.951005: Pseudo dice [0.8929, 0.5846, 0.6817] 
2023-09-27 12:27:27.951133: Epoch time: 99.43 s 
2023-09-27 12:27:29.337058:  
2023-09-27 12:27:29.337513: Epoch 765 
2023-09-27 12:27:29.337617: Current learning rate: 0.00272 
2023-09-27 12:29:08.985138: train_loss -0.9251 
2023-09-27 12:29:08.985430: val_loss -0.6403 
2023-09-27 12:29:08.985523: Pseudo dice [0.9022, 0.6277, 0.6723] 
2023-09-27 12:29:08.985611: Epoch time: 99.65 s 
2023-09-27 12:29:10.355601:  
2023-09-27 12:29:10.355749: Epoch 766 
2023-09-27 12:29:10.355841: Current learning rate: 0.00271 
2023-09-27 12:30:50.300242: train_loss -0.9243 
2023-09-27 12:30:50.300500: val_loss -0.6092 
2023-09-27 12:30:50.300579: Pseudo dice [0.9059, 0.5889, 0.5943] 
2023-09-27 12:30:50.300652: Epoch time: 99.95 s 
2023-09-27 12:30:51.884314:  
2023-09-27 12:30:51.884459: Epoch 767 
2023-09-27 12:30:51.884553: Current learning rate: 0.0027 
2023-09-27 12:32:31.201026: train_loss -0.9204 
2023-09-27 12:32:31.201285: val_loss -0.581 
2023-09-27 12:32:31.201383: Pseudo dice [0.8975, 0.5173, 0.5753] 
2023-09-27 12:32:31.201462: Epoch time: 99.32 s 
2023-09-27 12:32:32.824869:  
2023-09-27 12:32:32.825039: Epoch 768 
2023-09-27 12:32:32.825152: Current learning rate: 0.00268 
2023-09-27 12:34:12.254984: train_loss -0.9199 
2023-09-27 12:34:12.255269: val_loss -0.6079 
2023-09-27 12:34:12.255372: Pseudo dice [0.8972, 0.5409, 0.6383] 
2023-09-27 12:34:12.255466: Epoch time: 99.43 s 
2023-09-27 12:34:13.692364:  
2023-09-27 12:34:13.692625: Epoch 769 
2023-09-27 12:34:13.692728: Current learning rate: 0.00267 
2023-09-27 12:35:53.532031: train_loss -0.9211 
2023-09-27 12:35:53.532295: val_loss -0.5632 
2023-09-27 12:35:53.532414: Pseudo dice [0.8984, 0.5121, 0.5484] 
2023-09-27 12:35:53.532493: Epoch time: 99.84 s 
2023-09-27 12:35:55.002681:  
2023-09-27 12:35:55.003121: Epoch 770 
2023-09-27 12:35:55.003442: Current learning rate: 0.00266 
2023-09-27 12:37:35.041624: train_loss -0.9288 
2023-09-27 12:37:35.041890: val_loss -0.5972 
2023-09-27 12:37:35.041969: Pseudo dice [0.9012, 0.5809, 0.5346] 
2023-09-27 12:37:35.042043: Epoch time: 100.04 s 
2023-09-27 12:37:36.370807:  
2023-09-27 12:37:36.370956: Epoch 771 
2023-09-27 12:37:36.371048: Current learning rate: 0.00265 
2023-09-27 12:39:16.152854: train_loss -0.9273 
2023-09-27 12:39:16.153655: val_loss -0.602 
2023-09-27 12:39:16.153766: Pseudo dice [0.905, 0.5359, 0.6057] 
2023-09-27 12:39:16.153899: Epoch time: 99.78 s 
2023-09-27 12:39:17.579410:  
2023-09-27 12:39:17.579717: Epoch 772 
2023-09-27 12:39:17.579819: Current learning rate: 0.00264 
2023-09-27 12:40:57.556621: train_loss -0.9263 
2023-09-27 12:40:57.556906: val_loss -0.5933 
2023-09-27 12:40:57.556986: Pseudo dice [0.8997, 0.5205, 0.6339] 
2023-09-27 12:40:57.557058: Epoch time: 99.98 s 
2023-09-27 12:40:59.157789:  
2023-09-27 12:40:59.157984: Epoch 773 
2023-09-27 12:40:59.158121: Current learning rate: 0.00263 
2023-09-27 12:42:38.985997: train_loss -0.9268 
2023-09-27 12:42:38.987287: val_loss -0.59 
2023-09-27 12:42:38.987569: Pseudo dice [0.9036, 0.542, 0.5596] 
2023-09-27 12:42:38.987847: Epoch time: 99.83 s 
2023-09-27 12:42:40.296997:  
2023-09-27 12:42:40.297499: Epoch 774 
2023-09-27 12:42:40.297600: Current learning rate: 0.00262 
2023-09-27 12:44:20.096080: train_loss -0.9251 
2023-09-27 12:44:20.096335: val_loss -0.5654 
2023-09-27 12:44:20.096416: Pseudo dice [0.8854, 0.6233, 0.4823] 
2023-09-27 12:44:20.096493: Epoch time: 99.8 s 
2023-09-27 12:44:21.753927:  
2023-09-27 12:44:21.754239: Epoch 775 
2023-09-27 12:44:21.754363: Current learning rate: 0.00261 
2023-09-27 12:46:01.472883: train_loss -0.9213 
2023-09-27 12:46:01.473169: val_loss -0.5971 
2023-09-27 12:46:01.473265: Pseudo dice [0.8959, 0.5762, 0.5824] 
2023-09-27 12:46:01.473351: Epoch time: 99.72 s 
2023-09-27 12:46:03.137319:  
2023-09-27 12:46:03.137510: Epoch 776 
2023-09-27 12:46:03.137620: Current learning rate: 0.0026 
2023-09-27 12:47:42.897752: train_loss -0.9273 
2023-09-27 12:47:42.898071: val_loss -0.5618 
2023-09-27 12:47:42.898202: Pseudo dice [0.8878, 0.5296, 0.4761] 
2023-09-27 12:47:42.898297: Epoch time: 99.76 s 
2023-09-27 12:47:44.618311:  
2023-09-27 12:47:44.618517: Epoch 777 
2023-09-27 12:47:44.618625: Current learning rate: 0.00259 
2023-09-27 12:49:24.241990: train_loss -0.9242 
2023-09-27 12:49:24.242412: val_loss -0.5975 
2023-09-27 12:49:24.242517: Pseudo dice [0.8938, 0.5444, 0.5944] 
2023-09-27 12:49:24.242606: Epoch time: 99.63 s 
2023-09-27 12:49:25.638632:  
2023-09-27 12:49:25.638909: Epoch 778 
2023-09-27 12:49:25.639120: Current learning rate: 0.00258 
2023-09-27 12:51:05.821113: train_loss -0.9255 
2023-09-27 12:51:05.821394: val_loss -0.5689 
2023-09-27 12:51:05.821492: Pseudo dice [0.8974, 0.556, 0.5479] 
2023-09-27 12:51:05.821580: Epoch time: 100.18 s 
2023-09-27 12:51:07.729700:  
2023-09-27 12:51:07.729875: Epoch 779 
2023-09-27 12:51:07.730008: Current learning rate: 0.00257 
2023-09-27 12:52:47.123352: train_loss -0.9259 
2023-09-27 12:52:47.123603: val_loss -0.5969 
2023-09-27 12:52:47.123680: Pseudo dice [0.9005, 0.532, 0.5903] 
2023-09-27 12:52:47.123752: Epoch time: 99.4 s 
2023-09-27 12:52:48.437441:  
2023-09-27 12:52:48.437719: Epoch 780 
2023-09-27 12:52:48.437811: Current learning rate: 0.00256 
2023-09-27 12:54:28.274674: train_loss -0.9299 
2023-09-27 12:54:28.274919: val_loss -0.6192 
2023-09-27 12:54:28.274997: Pseudo dice [0.9025, 0.542, 0.6058] 
2023-09-27 12:54:28.275073: Epoch time: 99.84 s 
2023-09-27 12:54:29.609796:  
2023-09-27 12:54:29.609976: Epoch 781 
2023-09-27 12:54:29.610070: Current learning rate: 0.00255 
2023-09-27 12:56:09.433780: train_loss -0.9264 
2023-09-27 12:56:09.434169: val_loss -0.5841 
2023-09-27 12:56:09.434256: Pseudo dice [0.903, 0.5317, 0.5618] 
2023-09-27 12:56:09.434346: Epoch time: 99.83 s 
2023-09-27 12:56:10.784299:  
2023-09-27 12:56:10.784567: Epoch 782 
2023-09-27 12:56:10.784661: Current learning rate: 0.00254 
2023-09-27 12:57:51.083460: train_loss -0.9201 
2023-09-27 12:57:51.083705: val_loss -0.6049 
2023-09-27 12:57:51.083784: Pseudo dice [0.9026, 0.6059, 0.5874] 
2023-09-27 12:57:51.083856: Epoch time: 100.3 s 
2023-09-27 12:57:52.408540:  
2023-09-27 12:57:52.408945: Epoch 783 
2023-09-27 12:57:52.409037: Current learning rate: 0.00253 
2023-09-27 12:59:32.529176: train_loss -0.928 
2023-09-27 12:59:32.529653: val_loss -0.5366 
2023-09-27 12:59:32.529754: Pseudo dice [0.895, 0.47, 0.4877] 
2023-09-27 12:59:32.529837: Epoch time: 100.12 s 
2023-09-27 12:59:34.248816:  
2023-09-27 12:59:34.249237: Epoch 784 
2023-09-27 12:59:34.249371: Current learning rate: 0.00252 
2023-09-27 13:01:13.983049: train_loss -0.9255 
2023-09-27 13:01:13.983306: val_loss -0.6278 
2023-09-27 13:01:13.983385: Pseudo dice [0.8989, 0.5839, 0.5923] 
2023-09-27 13:01:13.983457: Epoch time: 99.74 s 
2023-09-27 13:01:15.330182:  
2023-09-27 13:01:15.330328: Epoch 785 
2023-09-27 13:01:15.330414: Current learning rate: 0.00251 
2023-09-27 13:02:55.391916: train_loss -0.9255 
2023-09-27 13:02:55.392352: val_loss -0.6069 
2023-09-27 13:02:55.392437: Pseudo dice [0.9064, 0.5406, 0.6149] 
2023-09-27 13:02:55.392510: Epoch time: 100.06 s 
2023-09-27 13:02:56.759326:  
2023-09-27 13:02:56.759717: Epoch 786 
2023-09-27 13:02:56.759834: Current learning rate: 0.0025 
2023-09-27 13:04:36.510068: train_loss -0.934 
2023-09-27 13:04:36.510377: val_loss -0.6362 
2023-09-27 13:04:36.510474: Pseudo dice [0.9058, 0.6037, 0.6247] 
2023-09-27 13:04:36.510560: Epoch time: 99.75 s 
2023-09-27 13:04:37.892889:  
2023-09-27 13:04:37.893254: Epoch 787 
2023-09-27 13:04:37.893349: Current learning rate: 0.00249 
2023-09-27 13:06:17.536260: train_loss -0.922 
2023-09-27 13:06:17.536659: val_loss -0.6031 
2023-09-27 13:06:17.536746: Pseudo dice [0.8941, 0.6024, 0.5578] 
2023-09-27 13:06:17.536832: Epoch time: 99.64 s 
2023-09-27 13:06:18.959588:  
2023-09-27 13:06:18.959847: Epoch 788 
2023-09-27 13:06:18.960145: Current learning rate: 0.00248 
2023-09-27 13:07:58.468544: train_loss -0.9204 
2023-09-27 13:07:58.468793: val_loss -0.5788 
2023-09-27 13:07:58.468870: Pseudo dice [0.9013, 0.5891, 0.5777] 
2023-09-27 13:07:58.468942: Epoch time: 99.51 s 
2023-09-27 13:07:59.813840:  
2023-09-27 13:07:59.814128: Epoch 789 
2023-09-27 13:07:59.814224: Current learning rate: 0.00247 
2023-09-27 13:09:39.344584: train_loss -0.9305 
2023-09-27 13:09:39.344855: val_loss -0.6073 
2023-09-27 13:09:39.344934: Pseudo dice [0.9009, 0.5243, 0.6088] 
2023-09-27 13:09:39.345013: Epoch time: 99.53 s 
2023-09-27 13:09:40.880755:  
2023-09-27 13:09:40.880893: Epoch 790 
2023-09-27 13:09:40.880985: Current learning rate: 0.00245 
2023-09-27 13:11:20.723243: train_loss -0.9279 
2023-09-27 13:11:20.723560: val_loss -0.5903 
2023-09-27 13:11:20.723674: Pseudo dice [0.9001, 0.5609, 0.5747] 
2023-09-27 13:11:20.723763: Epoch time: 99.84 s 
2023-09-27 13:11:22.493521:  
2023-09-27 13:11:22.493718: Epoch 791 
2023-09-27 13:11:22.493838: Current learning rate: 0.00244 
2023-09-27 13:13:02.079966: train_loss -0.9292 
2023-09-27 13:13:02.080212: val_loss -0.6012 
2023-09-27 13:13:02.080289: Pseudo dice [0.8981, 0.5924, 0.5498] 
2023-09-27 13:13:02.080360: Epoch time: 99.59 s 
2023-09-27 13:13:03.428773:  
2023-09-27 13:13:03.429260: Epoch 792 
2023-09-27 13:13:03.429369: Current learning rate: 0.00243 
2023-09-27 13:14:43.043773: train_loss -0.9191 
2023-09-27 13:14:43.044017: val_loss -0.6021 
2023-09-27 13:14:43.044116: Pseudo dice [0.8987, 0.5436, 0.6025] 
2023-09-27 13:14:43.044192: Epoch time: 99.62 s 
2023-09-27 13:14:44.370871:  
2023-09-27 13:14:44.371235: Epoch 793 
2023-09-27 13:14:44.371329: Current learning rate: 0.00242 
2023-09-27 13:16:24.495226: train_loss -0.9188 
2023-09-27 13:16:24.495476: val_loss -0.5632 
2023-09-27 13:16:24.495553: Pseudo dice [0.8898, 0.5259, 0.5711] 
2023-09-27 13:16:24.495627: Epoch time: 100.13 s 
2023-09-27 13:16:25.879051:  
2023-09-27 13:16:25.879204: Epoch 794 
2023-09-27 13:16:25.879296: Current learning rate: 0.00241 
2023-09-27 13:18:06.818504: train_loss -0.9248 
2023-09-27 13:18:06.818762: val_loss -0.6198 
2023-09-27 13:18:06.818838: Pseudo dice [0.8953, 0.5063, 0.6312] 
2023-09-27 13:18:06.818908: Epoch time: 100.94 s 
2023-09-27 13:18:08.278808:  
2023-09-27 13:18:08.279156: Epoch 795 
2023-09-27 13:18:08.279259: Current learning rate: 0.0024 
2023-09-27 13:19:49.835519: train_loss -0.9173 
2023-09-27 13:19:49.835785: val_loss -0.6202 
2023-09-27 13:19:49.835868: Pseudo dice [0.9021, 0.5857, 0.6289] 
2023-09-27 13:19:49.835944: Epoch time: 101.56 s 
2023-09-27 13:19:51.431405:  
2023-09-27 13:19:51.431553: Epoch 796 
2023-09-27 13:19:51.431641: Current learning rate: 0.00239 
2023-09-27 13:21:32.962639: train_loss -0.9201 
2023-09-27 13:21:32.962913: val_loss -0.6017 
2023-09-27 13:21:32.963007: Pseudo dice [0.9018, 0.5523, 0.6001] 
2023-09-27 13:21:32.963091: Epoch time: 101.53 s 
2023-09-27 13:21:34.654887:  
2023-09-27 13:21:34.655127: Epoch 797 
2023-09-27 13:21:34.655233: Current learning rate: 0.00238 
2023-09-27 13:23:15.849483: train_loss -0.9223 
2023-09-27 13:23:15.849738: val_loss -0.5779 
2023-09-27 13:23:15.849817: Pseudo dice [0.9007, 0.5464, 0.5259] 
2023-09-27 13:23:15.849890: Epoch time: 101.2 s 
2023-09-27 13:23:17.169850:  
2023-09-27 13:23:17.170238: Epoch 798 
2023-09-27 13:23:17.170334: Current learning rate: 0.00237 
2023-09-27 13:24:57.576113: train_loss -0.9231 
2023-09-27 13:24:57.576353: val_loss -0.6067 
2023-09-27 13:24:57.576429: Pseudo dice [0.9037, 0.5668, 0.6086] 
2023-09-27 13:24:57.576499: Epoch time: 100.41 s 
2023-09-27 13:24:58.909292:  
2023-09-27 13:24:58.909461: Epoch 799 
2023-09-27 13:24:58.909559: Current learning rate: 0.00236 
2023-09-27 13:26:38.712461: train_loss -0.915 
2023-09-27 13:26:38.712715: val_loss -0.6013 
2023-09-27 13:26:38.712793: Pseudo dice [0.8994, 0.5498, 0.6048] 
2023-09-27 13:26:38.712863: Epoch time: 99.8 s 
2023-09-27 13:26:41.421895:  
2023-09-27 13:26:41.422153: Epoch 800 
2023-09-27 13:26:41.422244: Current learning rate: 0.00235 
2023-09-27 13:28:21.721385: train_loss -0.9216 
2023-09-27 13:28:21.721638: val_loss -0.6349 
2023-09-27 13:28:21.721716: Pseudo dice [0.9045, 0.6058, 0.6479] 
2023-09-27 13:28:21.721786: Epoch time: 100.3 s 
2023-09-27 13:28:23.224905:  
2023-09-27 13:28:23.225043: Epoch 801 
2023-09-27 13:28:23.225130: Current learning rate: 0.00234 
2023-09-27 13:30:03.000788: train_loss -0.9238 
2023-09-27 13:30:03.001069: val_loss -0.5796 
2023-09-27 13:30:03.001148: Pseudo dice [0.8991, 0.4954, 0.5909] 
2023-09-27 13:30:03.001222: Epoch time: 99.78 s 
2023-09-27 13:30:04.328770:  
2023-09-27 13:30:04.328994: Epoch 802 
2023-09-27 13:30:04.329080: Current learning rate: 0.00233 
2023-09-27 13:31:44.660546: train_loss -0.9293 
2023-09-27 13:31:44.661080: val_loss -0.6136 
2023-09-27 13:31:44.661165: Pseudo dice [0.8969, 0.5892, 0.6189] 
2023-09-27 13:31:44.661270: Epoch time: 100.33 s 
2023-09-27 13:31:46.130609:  
2023-09-27 13:31:46.131073: Epoch 803 
2023-09-27 13:31:46.131257: Current learning rate: 0.00232 
2023-09-27 13:33:26.206250: train_loss -0.9263 
2023-09-27 13:33:26.206767: val_loss -0.583 
2023-09-27 13:33:26.206869: Pseudo dice [0.8971, 0.517, 0.5438] 
2023-09-27 13:33:26.206957: Epoch time: 100.08 s 
2023-09-27 13:33:27.581886:  
2023-09-27 13:33:27.582138: Epoch 804 
2023-09-27 13:33:27.582234: Current learning rate: 0.00231 
2023-09-27 13:35:07.339631: train_loss -0.9248 
2023-09-27 13:35:07.339877: val_loss -0.6237 
2023-09-27 13:35:07.339956: Pseudo dice [0.9118, 0.5806, 0.59] 
2023-09-27 13:35:07.340029: Epoch time: 99.76 s 
2023-09-27 13:35:08.758760:  
2023-09-27 13:35:08.759374: Epoch 805 
2023-09-27 13:35:08.759565: Current learning rate: 0.0023 
2023-09-27 13:36:48.993267: train_loss -0.9231 
2023-09-27 13:36:48.993563: val_loss -0.618 
2023-09-27 13:36:48.993652: Pseudo dice [0.902, 0.5768, 0.6414] 
2023-09-27 13:36:48.993730: Epoch time: 100.24 s 
2023-09-27 13:36:50.374637:  
2023-09-27 13:36:50.375125: Epoch 806 
2023-09-27 13:36:50.375257: Current learning rate: 0.00229 
2023-09-27 13:38:30.208977: train_loss -0.9219 
2023-09-27 13:38:30.209749: val_loss -0.6089 
2023-09-27 13:38:30.209841: Pseudo dice [0.9007, 0.5434, 0.6212] 
2023-09-27 13:38:30.209954: Epoch time: 99.84 s 
2023-09-27 13:38:31.813104:  
2023-09-27 13:38:31.813332: Epoch 807 
2023-09-27 13:38:31.813433: Current learning rate: 0.00228 
2023-09-27 13:40:11.916524: train_loss -0.9305 
2023-09-27 13:40:11.917021: val_loss -0.6114 
2023-09-27 13:40:11.917112: Pseudo dice [0.9008, 0.565, 0.5795] 
2023-09-27 13:40:11.917193: Epoch time: 100.11 s 
2023-09-27 13:40:13.342319:  
2023-09-27 13:40:13.342480: Epoch 808 
2023-09-27 13:40:13.342572: Current learning rate: 0.00226 
2023-09-27 13:41:51.709387: train_loss -0.9216 
2023-09-27 13:41:51.709736: val_loss -0.61 
2023-09-27 13:41:51.709839: Pseudo dice [0.9064, 0.6223, 0.6067] 
2023-09-27 13:41:51.709929: Epoch time: 98.37 s 
2023-09-27 13:41:53.149238:  
2023-09-27 13:41:53.149392: Epoch 809 
2023-09-27 13:41:53.149498: Current learning rate: 0.00225 
2023-09-27 13:43:32.992533: train_loss -0.9136 
2023-09-27 13:43:32.993087: val_loss -0.5811 
2023-09-27 13:43:32.993172: Pseudo dice [0.9017, 0.5003, 0.6162] 
2023-09-27 13:43:32.993287: Epoch time: 99.84 s 
2023-09-27 13:43:34.420115:  
2023-09-27 13:43:34.420435: Epoch 810 
2023-09-27 13:43:34.420541: Current learning rate: 0.00224 
2023-09-27 13:45:14.270767: train_loss -0.9262 
2023-09-27 13:45:14.271353: val_loss -0.602 
2023-09-27 13:45:14.271458: Pseudo dice [0.9036, 0.5649, 0.5463] 
2023-09-27 13:45:14.271546: Epoch time: 99.85 s 
2023-09-27 13:45:15.806629:  
2023-09-27 13:45:15.806803: Epoch 811 
2023-09-27 13:45:15.806893: Current learning rate: 0.00223 
2023-09-27 13:46:55.863550: train_loss -0.9248 
2023-09-27 13:46:55.864059: val_loss -0.6336 
2023-09-27 13:46:55.864155: Pseudo dice [0.902, 0.6038, 0.6444] 
2023-09-27 13:46:55.864275: Epoch time: 100.06 s 
2023-09-27 13:46:57.245213:  
2023-09-27 13:46:57.245457: Epoch 812 
2023-09-27 13:46:57.245550: Current learning rate: 0.00222 
2023-09-27 13:48:37.063956: train_loss -0.925 
2023-09-27 13:48:37.064441: val_loss -0.5754 
2023-09-27 13:48:37.064528: Pseudo dice [0.8995, 0.5729, 0.6017] 
2023-09-27 13:48:37.064604: Epoch time: 99.82 s 
2023-09-27 13:48:38.663540:  
2023-09-27 13:48:38.663841: Epoch 813 
2023-09-27 13:48:38.663949: Current learning rate: 0.00221 
2023-09-27 13:50:18.286186: train_loss -0.9178 
2023-09-27 13:50:18.286723: val_loss -0.624 
2023-09-27 13:50:18.286808: Pseudo dice [0.9057, 0.531, 0.653] 
2023-09-27 13:50:18.286914: Epoch time: 99.62 s 
2023-09-27 13:50:19.693814:  
2023-09-27 13:50:19.693978: Epoch 814 
2023-09-27 13:50:19.694069: Current learning rate: 0.0022 
2023-09-27 13:51:59.368576: train_loss -0.9232 
2023-09-27 13:51:59.368874: val_loss -0.6097 
2023-09-27 13:51:59.368953: Pseudo dice [0.9034, 0.5189, 0.6629] 
2023-09-27 13:51:59.369030: Epoch time: 99.68 s 
2023-09-27 13:52:00.789404:  
2023-09-27 13:52:00.789559: Epoch 815 
2023-09-27 13:52:00.789660: Current learning rate: 0.00219 
2023-09-27 13:53:40.307775: train_loss -0.9315 
2023-09-27 13:53:40.308033: val_loss -0.6136 
2023-09-27 13:53:40.308113: Pseudo dice [0.9073, 0.5721, 0.6674] 
2023-09-27 13:53:40.308187: Epoch time: 99.52 s 
2023-09-27 13:53:41.992013:  
2023-09-27 13:53:41.992184: Epoch 816 
2023-09-27 13:53:41.992299: Current learning rate: 0.00218 
2023-09-27 13:55:21.855854: train_loss -0.925 
2023-09-27 13:55:21.856110: val_loss -0.6316 
2023-09-27 13:55:21.856185: Pseudo dice [0.9023, 0.5999, 0.6507] 
2023-09-27 13:55:21.856258: Epoch time: 99.87 s 
2023-09-27 13:55:23.239152:  
2023-09-27 13:55:23.239309: Epoch 817 
2023-09-27 13:55:23.239405: Current learning rate: 0.00217 
2023-09-27 13:57:03.123213: train_loss -0.9267 
2023-09-27 13:57:03.123471: val_loss -0.6093 
2023-09-27 13:57:03.123549: Pseudo dice [0.8995, 0.5495, 0.6396] 
2023-09-27 13:57:03.123621: Epoch time: 99.89 s 
2023-09-27 13:57:04.847681:  
2023-09-27 13:57:04.847845: Epoch 818 
2023-09-27 13:57:04.847949: Current learning rate: 0.00216 
2023-09-27 13:58:44.878970: train_loss -0.9243 
2023-09-27 13:58:44.879253: val_loss -0.6338 
2023-09-27 13:58:44.879341: Pseudo dice [0.9028, 0.5579, 0.6362] 
2023-09-27 13:58:44.879422: Epoch time: 100.03 s 
2023-09-27 13:58:46.269257:  
2023-09-27 13:58:46.269505: Epoch 819 
2023-09-27 13:58:46.269603: Current learning rate: 0.00215 
2023-09-27 14:00:26.188857: train_loss -0.9279 
2023-09-27 14:00:26.189487: val_loss -0.6255 
2023-09-27 14:00:26.189575: Pseudo dice [0.9079, 0.5596, 0.6654] 
2023-09-27 14:00:26.189681: Epoch time: 99.92 s 
2023-09-27 14:00:27.600366:  
2023-09-27 14:00:27.600606: Epoch 820 
2023-09-27 14:00:27.600718: Current learning rate: 0.00214 
2023-09-27 14:02:07.150359: train_loss -0.9227 
2023-09-27 14:02:07.150627: val_loss -0.6266 
2023-09-27 14:02:07.150706: Pseudo dice [0.9034, 0.5968, 0.6247] 
2023-09-27 14:02:07.150780: Epoch time: 99.55 s 
2023-09-27 14:02:08.509508:  
2023-09-27 14:02:08.509802: Epoch 821 
2023-09-27 14:02:08.509924: Current learning rate: 0.00213 
2023-09-27 14:03:48.171550: train_loss -0.9232 
2023-09-27 14:03:48.171871: val_loss -0.5908 
2023-09-27 14:03:48.171971: Pseudo dice [0.907, 0.5459, 0.6124] 
2023-09-27 14:03:48.172068: Epoch time: 99.66 s 
2023-09-27 14:03:49.560308:  
2023-09-27 14:03:49.560485: Epoch 822 
2023-09-27 14:03:49.560576: Current learning rate: 0.00212 
2023-09-27 14:05:29.371093: train_loss -0.924 
2023-09-27 14:05:29.371330: val_loss -0.6168 
2023-09-27 14:05:29.371406: Pseudo dice [0.9016, 0.5137, 0.6577] 
2023-09-27 14:05:29.371480: Epoch time: 99.81 s 
2023-09-27 14:05:30.689104:  
2023-09-27 14:05:30.689249: Epoch 823 
2023-09-27 14:05:30.689343: Current learning rate: 0.0021 
2023-09-27 14:07:10.824045: train_loss -0.9269 
2023-09-27 14:07:10.824355: val_loss -0.6028 
2023-09-27 14:07:10.824457: Pseudo dice [0.8996, 0.5627, 0.6243] 
2023-09-27 14:07:10.824542: Epoch time: 100.14 s 
2023-09-27 14:07:12.393756:  
2023-09-27 14:07:12.393926: Epoch 824 
2023-09-27 14:07:12.394033: Current learning rate: 0.00209 
2023-09-27 14:08:52.119974: train_loss -0.926 
2023-09-27 14:08:52.120275: val_loss -0.5973 
2023-09-27 14:08:52.120355: Pseudo dice [0.8976, 0.5725, 0.6015] 
2023-09-27 14:08:52.120439: Epoch time: 99.73 s 
2023-09-27 14:08:53.434814:  
2023-09-27 14:08:53.434984: Epoch 825 
2023-09-27 14:08:53.435081: Current learning rate: 0.00208 
2023-09-27 14:10:33.394881: train_loss -0.9043 
2023-09-27 14:10:33.395190: val_loss -0.5639 
2023-09-27 14:10:33.395295: Pseudo dice [0.8856, 0.5489, 0.513] 
2023-09-27 14:10:33.395389: Epoch time: 99.96 s 
2023-09-27 14:10:35.048488:  
2023-09-27 14:10:35.048725: Epoch 826 
2023-09-27 14:10:35.048820: Current learning rate: 0.00207 
2023-09-27 14:12:14.964120: train_loss -0.9175 
2023-09-27 14:12:14.964800: val_loss -0.5951 
2023-09-27 14:12:14.964891: Pseudo dice [0.9049, 0.5328, 0.5933] 
2023-09-27 14:12:14.965005: Epoch time: 99.92 s 
2023-09-27 14:12:16.331588:  
2023-09-27 14:12:16.331857: Epoch 827 
2023-09-27 14:12:16.332002: Current learning rate: 0.00206 
2023-09-27 14:13:55.509418: train_loss -0.9213 
2023-09-27 14:13:55.509697: val_loss -0.5794 
2023-09-27 14:13:55.509777: Pseudo dice [0.8828, 0.5584, 0.5096] 
2023-09-27 14:13:55.509853: Epoch time: 99.18 s 
2023-09-27 14:13:56.863096:  
2023-09-27 14:13:56.863244: Epoch 828 
2023-09-27 14:13:56.863338: Current learning rate: 0.00205 
2023-09-27 14:15:36.851888: train_loss -0.9182 
2023-09-27 14:15:36.852209: val_loss -0.5942 
2023-09-27 14:15:36.852307: Pseudo dice [0.9027, 0.5554, 0.5993] 
2023-09-27 14:15:36.852397: Epoch time: 99.99 s 
2023-09-27 14:15:38.232275:  
2023-09-27 14:15:38.232444: Epoch 829 
2023-09-27 14:15:38.232581: Current learning rate: 0.00204 
2023-09-27 14:17:18.221669: train_loss -0.928 
2023-09-27 14:17:18.222324: val_loss -0.5963 
2023-09-27 14:17:18.222414: Pseudo dice [0.8958, 0.5126, 0.5809] 
2023-09-27 14:17:18.222519: Epoch time: 99.99 s 
2023-09-27 14:17:19.807776:  
2023-09-27 14:17:19.808267: Epoch 830 
2023-09-27 14:17:19.808382: Current learning rate: 0.00203 
2023-09-27 14:18:59.821674: train_loss -0.9332 
2023-09-27 14:18:59.821946: val_loss -0.6173 
2023-09-27 14:18:59.822023: Pseudo dice [0.897, 0.5807, 0.6585] 
2023-09-27 14:18:59.822107: Epoch time: 100.02 s 
2023-09-27 14:19:01.384214:  
2023-09-27 14:19:01.384360: Epoch 831 
2023-09-27 14:19:01.384449: Current learning rate: 0.00202 
2023-09-27 14:20:41.346439: train_loss -0.9224 
2023-09-27 14:20:41.346737: val_loss -0.6263 
2023-09-27 14:20:41.346828: Pseudo dice [0.9067, 0.6021, 0.6183] 
2023-09-27 14:20:41.346908: Epoch time: 99.96 s 
2023-09-27 14:20:42.613091:  
2023-09-27 14:20:42.613415: Epoch 832 
2023-09-27 14:20:42.613516: Current learning rate: 0.00201 
2023-09-27 14:22:21.931936: train_loss -0.9222 
2023-09-27 14:22:21.932208: val_loss -0.6142 
2023-09-27 14:22:21.932288: Pseudo dice [0.8947, 0.5708, 0.6289] 
2023-09-27 14:22:21.932360: Epoch time: 99.32 s 
2023-09-27 14:22:23.224301:  
2023-09-27 14:22:23.224528: Epoch 833 
2023-09-27 14:22:23.224622: Current learning rate: 0.002 
2023-09-27 14:24:03.099743: train_loss -0.9315 
2023-09-27 14:24:03.100019: val_loss -0.612 
2023-09-27 14:24:03.100104: Pseudo dice [0.9056, 0.5663, 0.5988] 
2023-09-27 14:24:03.100180: Epoch time: 99.88 s 
2023-09-27 14:24:04.357010:  
2023-09-27 14:24:04.357144: Epoch 834 
2023-09-27 14:24:04.357243: Current learning rate: 0.00199 
2023-09-27 14:25:43.945765: train_loss -0.9185 
2023-09-27 14:25:43.946058: val_loss -0.599 
2023-09-27 14:25:43.946153: Pseudo dice [0.9012, 0.5612, 0.5688] 
2023-09-27 14:25:43.946230: Epoch time: 99.59 s 
2023-09-27 14:25:45.487073:  
2023-09-27 14:25:45.487228: Epoch 835 
2023-09-27 14:25:45.487330: Current learning rate: 0.00198 
2023-09-27 14:27:25.374594: train_loss -0.9255 
2023-09-27 14:27:25.374854: val_loss -0.6254 
2023-09-27 14:27:25.374933: Pseudo dice [0.9004, 0.5426, 0.6559] 
2023-09-27 14:27:25.375007: Epoch time: 99.89 s 
2023-09-27 14:27:26.742600:  
2023-09-27 14:27:26.742747: Epoch 836 
2023-09-27 14:27:26.742838: Current learning rate: 0.00196 
2023-09-27 14:29:06.201562: train_loss -0.9294 
2023-09-27 14:29:06.201932: val_loss -0.6116 
2023-09-27 14:29:06.202013: Pseudo dice [0.9037, 0.5491, 0.6359] 
2023-09-27 14:29:06.202087: Epoch time: 99.46 s 
2023-09-27 14:29:07.661883:  
2023-09-27 14:29:07.662023: Epoch 837 
2023-09-27 14:29:07.662120: Current learning rate: 0.00195 
2023-09-27 14:30:47.360456: train_loss -0.9182 
2023-09-27 14:30:47.360725: val_loss -0.6239 
2023-09-27 14:30:47.360803: Pseudo dice [0.8955, 0.5408, 0.6053] 
2023-09-27 14:30:47.360878: Epoch time: 99.7 s 
2023-09-27 14:30:48.647214:  
2023-09-27 14:30:48.647386: Epoch 838 
2023-09-27 14:30:48.647522: Current learning rate: 0.00194 
2023-09-27 14:32:28.248346: train_loss -0.9269 
2023-09-27 14:32:28.248626: val_loss -0.6577 
2023-09-27 14:32:28.248719: Pseudo dice [0.8964, 0.5952, 0.6677] 
2023-09-27 14:32:28.248796: Epoch time: 99.6 s 
2023-09-27 14:32:29.540014:  
2023-09-27 14:32:29.540353: Epoch 839 
2023-09-27 14:32:29.540462: Current learning rate: 0.00193 
2023-09-27 14:34:09.478063: train_loss -0.9277 
2023-09-27 14:34:09.478319: val_loss -0.6336 
2023-09-27 14:34:09.478398: Pseudo dice [0.9022, 0.5591, 0.6541] 
2023-09-27 14:34:09.478472: Epoch time: 99.94 s 
2023-09-27 14:34:10.999762:  
2023-09-27 14:34:10.999927: Epoch 840 
2023-09-27 14:34:11.000038: Current learning rate: 0.00192 
2023-09-27 14:35:50.780383: train_loss -0.9318 
2023-09-27 14:35:50.780653: val_loss -0.6088 
2023-09-27 14:35:50.780730: Pseudo dice [0.9021, 0.5009, 0.6155] 
2023-09-27 14:35:50.780806: Epoch time: 99.78 s 
2023-09-27 14:35:52.419724:  
2023-09-27 14:35:52.419883: Epoch 841 
2023-09-27 14:35:52.419991: Current learning rate: 0.00191 
2023-09-27 14:37:32.347102: train_loss -0.9292 
2023-09-27 14:37:32.347421: val_loss -0.6014 
2023-09-27 14:37:32.347503: Pseudo dice [0.9043, 0.5196, 0.609] 
2023-09-27 14:37:32.347579: Epoch time: 99.93 s 
2023-09-27 14:37:33.627221:  
2023-09-27 14:37:33.627481: Epoch 842 
2023-09-27 14:37:33.627756: Current learning rate: 0.0019 
2023-09-27 14:39:13.266295: train_loss -0.9196 
2023-09-27 14:39:13.266560: val_loss -0.6442 
2023-09-27 14:39:13.266641: Pseudo dice [0.8988, 0.5724, 0.6677] 
2023-09-27 14:39:13.266716: Epoch time: 99.64 s 
2023-09-27 14:39:14.699591:  
2023-09-27 14:39:14.699713: Epoch 843 
2023-09-27 14:39:14.699809: Current learning rate: 0.00189 
2023-09-27 14:40:54.679595: train_loss -0.9281 
2023-09-27 14:40:54.679860: val_loss -0.6108 
2023-09-27 14:40:54.679939: Pseudo dice [0.9061, 0.5104, 0.6461] 
2023-09-27 14:40:54.680011: Epoch time: 99.98 s 
2023-09-27 14:40:56.021111:  
2023-09-27 14:40:56.021258: Epoch 844 
2023-09-27 14:40:56.021350: Current learning rate: 0.00188 
2023-09-27 14:42:35.834590: train_loss -0.9328 
2023-09-27 14:42:35.834921: val_loss -0.6164 
2023-09-27 14:42:35.835035: Pseudo dice [0.902, 0.5569, 0.6576] 
2023-09-27 14:42:35.835140: Epoch time: 99.81 s 
2023-09-27 14:42:37.159279:  
2023-09-27 14:42:37.159541: Epoch 845 
2023-09-27 14:42:37.159640: Current learning rate: 0.00187 
2023-09-27 14:44:16.891552: train_loss -0.9236 
2023-09-27 14:44:16.891809: val_loss -0.5973 
2023-09-27 14:44:16.891887: Pseudo dice [0.9023, 0.5203, 0.5516] 
2023-09-27 14:44:16.891959: Epoch time: 99.73 s 
2023-09-27 14:44:18.144625:  
2023-09-27 14:44:18.144781: Epoch 846 
2023-09-27 14:44:18.144873: Current learning rate: 0.00186 
2023-09-27 14:45:57.492680: train_loss -0.9249 
2023-09-27 14:45:57.492933: val_loss -0.5944 
2023-09-27 14:45:57.493008: Pseudo dice [0.8936, 0.4573, 0.6393] 
2023-09-27 14:45:57.493078: Epoch time: 99.35 s 
2023-09-27 14:45:58.754700:  
2023-09-27 14:45:58.754830: Epoch 847 
2023-09-27 14:45:58.754917: Current learning rate: 0.00185 
2023-09-27 14:47:38.295017: train_loss -0.912 
2023-09-27 14:47:38.295290: val_loss -0.5541 
2023-09-27 14:47:38.295367: Pseudo dice [0.892, 0.5272, 0.4386] 
2023-09-27 14:47:38.295446: Epoch time: 99.54 s 
2023-09-27 14:47:39.553789:  
2023-09-27 14:47:39.554018: Epoch 848 
2023-09-27 14:47:39.554118: Current learning rate: 0.00184 
2023-09-27 14:49:19.058736: train_loss -0.914 
2023-09-27 14:49:19.059001: val_loss -0.6334 
2023-09-27 14:49:19.059089: Pseudo dice [0.8949, 0.5869, 0.6292] 
2023-09-27 14:49:19.059175: Epoch time: 99.51 s 
2023-09-27 14:49:20.499903:  
2023-09-27 14:49:20.500042: Epoch 849 
2023-09-27 14:49:20.500135: Current learning rate: 0.00182 
2023-09-27 14:51:00.369028: train_loss -0.9196 
2023-09-27 14:51:00.369291: val_loss -0.5991 
2023-09-27 14:51:00.369369: Pseudo dice [0.8865, 0.5693, 0.5503] 
2023-09-27 14:51:00.369443: Epoch time: 99.87 s 
2023-09-27 14:51:03.058041:  
2023-09-27 14:51:03.058196: Epoch 850 
2023-09-27 14:51:03.058285: Current learning rate: 0.00181 
2023-09-27 14:52:42.715261: train_loss -0.9248 
2023-09-27 14:52:42.715533: val_loss -0.5934 
2023-09-27 14:52:42.715612: Pseudo dice [0.9017, 0.5314, 0.6022] 
2023-09-27 14:52:42.715687: Epoch time: 99.66 s 
2023-09-27 14:52:44.260504:  
2023-09-27 14:52:44.260754: Epoch 851 
2023-09-27 14:52:44.260875: Current learning rate: 0.0018 
2023-09-27 14:54:23.780363: train_loss -0.922 
2023-09-27 14:54:23.780615: val_loss -0.5889 
2023-09-27 14:54:23.780690: Pseudo dice [0.9015, 0.4956, 0.5986] 
2023-09-27 14:54:23.780761: Epoch time: 99.52 s 
2023-09-27 14:54:25.030954:  
2023-09-27 14:54:25.031091: Epoch 852 
2023-09-27 14:54:25.031179: Current learning rate: 0.00179 
2023-09-27 14:56:04.483152: train_loss -0.9266 
2023-09-27 14:56:04.483421: val_loss -0.6221 
2023-09-27 14:56:04.483503: Pseudo dice [0.8987, 0.5477, 0.6646] 
2023-09-27 14:56:04.483580: Epoch time: 99.45 s 
2023-09-27 14:56:05.727483:  
2023-09-27 14:56:05.727626: Epoch 853 
2023-09-27 14:56:05.727715: Current learning rate: 0.00178 
2023-09-27 14:57:45.602611: train_loss -0.9251 
2023-09-27 14:57:45.602921: val_loss -0.6159 
2023-09-27 14:57:45.603005: Pseudo dice [0.9095, 0.563, 0.655] 
2023-09-27 14:57:45.603092: Epoch time: 99.88 s 
2023-09-27 14:57:46.927689:  
2023-09-27 14:57:46.927868: Epoch 854 
2023-09-27 14:57:46.927962: Current learning rate: 0.00177 
2023-09-27 14:59:26.884185: train_loss -0.9275 
2023-09-27 14:59:26.884575: val_loss -0.6245 
2023-09-27 14:59:26.884695: Pseudo dice [0.9041, 0.5586, 0.6853] 
2023-09-27 14:59:26.884786: Epoch time: 99.96 s 
2023-09-27 14:59:28.742802:  
2023-09-27 14:59:28.742958: Epoch 855 
2023-09-27 14:59:28.743070: Current learning rate: 0.00176 
2023-09-27 15:01:08.552702: train_loss -0.9276 
2023-09-27 15:01:08.553344: val_loss -0.6107 
2023-09-27 15:01:08.553431: Pseudo dice [0.8972, 0.5929, 0.6339] 
2023-09-27 15:01:08.553538: Epoch time: 99.81 s 
2023-09-27 15:01:09.934518:  
2023-09-27 15:01:09.935114: Epoch 856 
2023-09-27 15:01:09.935341: Current learning rate: 0.00175 
2023-09-27 15:02:49.807099: train_loss -0.9197 
2023-09-27 15:02:49.807415: val_loss -0.6045 
2023-09-27 15:02:49.807517: Pseudo dice [0.8953, 0.5456, 0.6281] 
2023-09-27 15:02:49.807623: Epoch time: 99.88 s 
2023-09-27 15:02:51.179910:  
2023-09-27 15:02:51.180054: Epoch 857 
2023-09-27 15:02:51.180148: Current learning rate: 0.00174 
2023-09-27 15:04:30.946861: train_loss -0.9308 
2023-09-27 15:04:30.947598: val_loss -0.6162 
2023-09-27 15:04:30.947685: Pseudo dice [0.8957, 0.5644, 0.6714] 
2023-09-27 15:04:30.947796: Epoch time: 99.77 s 
2023-09-27 15:04:32.260934:  
2023-09-27 15:04:32.261145: Epoch 858 
2023-09-27 15:04:32.261239: Current learning rate: 0.00173 
2023-09-27 15:06:10.582574: train_loss -0.9311 
2023-09-27 15:06:10.582836: val_loss -0.5884 
2023-09-27 15:06:10.582916: Pseudo dice [0.9087, 0.5949, 0.5478] 
2023-09-27 15:06:10.582989: Epoch time: 98.32 s 
2023-09-27 15:06:11.876753:  
2023-09-27 15:06:11.876880: Epoch 859 
2023-09-27 15:06:11.876969: Current learning rate: 0.00172 
2023-09-27 15:07:51.870402: train_loss -0.923 
2023-09-27 15:07:51.870939: val_loss -0.5955 
2023-09-27 15:07:51.871023: Pseudo dice [0.8967, 0.5282, 0.6178] 
2023-09-27 15:07:51.871121: Epoch time: 99.99 s 
2023-09-27 15:07:53.184187:  
2023-09-27 15:07:53.184473: Epoch 860 
2023-09-27 15:07:53.184622: Current learning rate: 0.0017 
2023-09-27 15:09:33.134549: train_loss -0.9328 
2023-09-27 15:09:33.134871: val_loss -0.5902 
2023-09-27 15:09:33.134953: Pseudo dice [0.903, 0.5647, 0.529] 
2023-09-27 15:09:33.135025: Epoch time: 99.95 s 
2023-09-27 15:09:34.396206:  
2023-09-27 15:09:34.396469: Epoch 861 
2023-09-27 15:09:34.396591: Current learning rate: 0.00169 
2023-09-27 15:11:14.206681: train_loss -0.9293 
2023-09-27 15:11:14.207208: val_loss -0.6086 
2023-09-27 15:11:14.207307: Pseudo dice [0.9077, 0.6048, 0.6007] 
2023-09-27 15:11:14.207410: Epoch time: 99.81 s 
2023-09-27 15:11:15.806517:  
2023-09-27 15:11:15.806760: Epoch 862 
2023-09-27 15:11:15.806867: Current learning rate: 0.00168 
2023-09-27 15:12:55.275233: train_loss -0.9324 
2023-09-27 15:12:55.275564: val_loss -0.5992 
2023-09-27 15:12:55.275651: Pseudo dice [0.9048, 0.5748, 0.5497] 
2023-09-27 15:12:55.275729: Epoch time: 99.47 s 
2023-09-27 15:12:56.980443:  
2023-09-27 15:12:56.981096: Epoch 863 
2023-09-27 15:12:56.981246: Current learning rate: 0.00167 
2023-09-27 15:14:36.473086: train_loss -0.9292 
2023-09-27 15:14:36.473362: val_loss -0.5999 
2023-09-27 15:14:36.473440: Pseudo dice [0.897, 0.5043, 0.6396] 
2023-09-27 15:14:36.473514: Epoch time: 99.5 s 
2023-09-27 15:14:37.783017:  
2023-09-27 15:14:37.783185: Epoch 864 
2023-09-27 15:14:37.783322: Current learning rate: 0.00166 
2023-09-27 15:16:17.788392: train_loss -0.9322 
2023-09-27 15:16:17.788813: val_loss -0.6634 
2023-09-27 15:16:17.788901: Pseudo dice [0.9036, 0.611, 0.6894] 
2023-09-27 15:16:17.788991: Epoch time: 100.01 s 
2023-09-27 15:16:19.068105:  
2023-09-27 15:16:19.068250: Epoch 865 
2023-09-27 15:16:19.068339: Current learning rate: 0.00165 
2023-09-27 15:17:59.294680: train_loss -0.9335 
2023-09-27 15:17:59.295235: val_loss -0.6481 
2023-09-27 15:17:59.295323: Pseudo dice [0.9006, 0.5726, 0.7247] 
2023-09-27 15:17:59.295431: Epoch time: 100.23 s 
2023-09-27 15:18:00.623283:  
2023-09-27 15:18:00.623588: Epoch 866 
2023-09-27 15:18:00.623956: Current learning rate: 0.00164 
2023-09-27 15:19:40.442231: train_loss -0.9267 
2023-09-27 15:19:40.442514: val_loss -0.645 
2023-09-27 15:19:40.442642: Pseudo dice [0.9027, 0.5783, 0.6975] 
2023-09-27 15:19:40.442768: Epoch time: 99.82 s 
2023-09-27 15:19:42.048689:  
2023-09-27 15:19:42.048858: Epoch 867 
2023-09-27 15:19:42.048965: Current learning rate: 0.00163 
2023-09-27 15:21:21.622667: train_loss -0.9308 
2023-09-27 15:21:21.622953: val_loss -0.6334 
2023-09-27 15:21:21.623050: Pseudo dice [0.9073, 0.6017, 0.6877] 
2023-09-27 15:21:21.623136: Epoch time: 99.58 s 
2023-09-27 15:21:23.379205:  
2023-09-27 15:21:23.379356: Epoch 868 
2023-09-27 15:21:23.379470: Current learning rate: 0.00162 
2023-09-27 15:23:03.631385: train_loss -0.9312 
2023-09-27 15:23:03.631620: val_loss -0.6489 
2023-09-27 15:23:03.631696: Pseudo dice [0.9031, 0.5893, 0.662] 
2023-09-27 15:23:03.631767: Epoch time: 100.25 s 
2023-09-27 15:23:04.884672:  
2023-09-27 15:23:04.884804: Epoch 869 
2023-09-27 15:23:04.884892: Current learning rate: 0.00161 
2023-09-27 15:24:45.207550: train_loss -0.9293 
2023-09-27 15:24:45.207806: val_loss -0.6244 
2023-09-27 15:24:45.207885: Pseudo dice [0.8974, 0.4909, 0.6936] 
2023-09-27 15:24:45.207957: Epoch time: 100.32 s 
2023-09-27 15:24:46.446302:  
2023-09-27 15:24:46.446437: Epoch 870 
2023-09-27 15:24:46.446528: Current learning rate: 0.00159 
2023-09-27 15:26:27.703796: train_loss -0.9291 
2023-09-27 15:26:27.704041: val_loss -0.6389 
2023-09-27 15:26:27.704118: Pseudo dice [0.9056, 0.5523, 0.6442] 
2023-09-27 15:26:27.704190: Epoch time: 101.26 s 
2023-09-27 15:26:28.928790:  
2023-09-27 15:26:28.928929: Epoch 871 
2023-09-27 15:26:28.929014: Current learning rate: 0.00158 
2023-09-27 15:28:09.739415: train_loss -0.925 
2023-09-27 15:28:09.739668: val_loss -0.5865 
2023-09-27 15:28:09.739742: Pseudo dice [0.899, 0.5206, 0.6114] 
2023-09-27 15:28:09.739810: Epoch time: 100.81 s 
2023-09-27 15:28:11.262382:  
2023-09-27 15:28:11.262531: Epoch 872 
2023-09-27 15:28:11.262633: Current learning rate: 0.00157 
2023-09-27 15:29:51.698474: train_loss -0.9311 
2023-09-27 15:29:51.698824: val_loss -0.6466 
2023-09-27 15:29:51.698906: Pseudo dice [0.8973, 0.5826, 0.6603] 
2023-09-27 15:29:51.698982: Epoch time: 100.44 s 
2023-09-27 15:29:53.047418:  
2023-09-27 15:29:53.047562: Epoch 873 
2023-09-27 15:29:53.047654: Current learning rate: 0.00156 
2023-09-27 15:31:33.342934: train_loss -0.932 
2023-09-27 15:31:33.343193: val_loss -0.6074 
2023-09-27 15:31:33.343270: Pseudo dice [0.9011, 0.5415, 0.6096] 
2023-09-27 15:31:33.343340: Epoch time: 100.3 s 
2023-09-27 15:31:35.185773:  
2023-09-27 15:31:35.185961: Epoch 874 
2023-09-27 15:31:35.186095: Current learning rate: 0.00155 
2023-09-27 15:33:15.335817: train_loss -0.9336 
2023-09-27 15:33:15.336064: val_loss -0.6013 
2023-09-27 15:33:15.336142: Pseudo dice [0.9098, 0.5228, 0.603] 
2023-09-27 15:33:15.336216: Epoch time: 100.15 s 
2023-09-27 15:33:16.635297:  
2023-09-27 15:33:16.635455: Epoch 875 
2023-09-27 15:33:16.635586: Current learning rate: 0.00154 
2023-09-27 15:34:56.627903: train_loss -0.9377 
2023-09-27 15:34:56.628165: val_loss -0.6198 
2023-09-27 15:34:56.628246: Pseudo dice [0.9081, 0.5116, 0.6641] 
2023-09-27 15:34:56.628321: Epoch time: 99.99 s 
2023-09-27 15:34:57.865345:  
2023-09-27 15:34:57.865485: Epoch 876 
2023-09-27 15:34:57.865570: Current learning rate: 0.00153 
2023-09-27 15:36:37.751311: train_loss -0.9323 
2023-09-27 15:36:37.751628: val_loss -0.6334 
2023-09-27 15:36:37.751728: Pseudo dice [0.9036, 0.5521, 0.6587] 
2023-09-27 15:36:37.751817: Epoch time: 99.89 s 
2023-09-27 15:36:39.493144:  
2023-09-27 15:36:39.493684: Epoch 877 
2023-09-27 15:36:39.493827: Current learning rate: 0.00152 
2023-09-27 15:38:19.439345: train_loss -0.9278 
2023-09-27 15:38:19.439643: val_loss -0.5889 
2023-09-27 15:38:19.439727: Pseudo dice [0.9033, 0.5183, 0.646] 
2023-09-27 15:38:19.439805: Epoch time: 99.95 s 
2023-09-27 15:38:20.698658:  
2023-09-27 15:38:20.698812: Epoch 878 
2023-09-27 15:38:20.698900: Current learning rate: 0.00151 
2023-09-27 15:40:00.829463: train_loss -0.9306 
2023-09-27 15:40:00.830058: val_loss -0.6164 
2023-09-27 15:40:00.830150: Pseudo dice [0.9052, 0.5203, 0.661] 
2023-09-27 15:40:00.830262: Epoch time: 100.13 s 
2023-09-27 15:40:02.089391:  
2023-09-27 15:40:02.089867: Epoch 879 
2023-09-27 15:40:02.090082: Current learning rate: 0.00149 
2023-09-27 15:41:42.292306: train_loss -0.9361 
2023-09-27 15:41:42.292557: val_loss -0.6281 
2023-09-27 15:41:42.292635: Pseudo dice [0.9033, 0.5343, 0.6508] 
2023-09-27 15:41:42.292705: Epoch time: 100.21 s 
2023-09-27 15:41:43.551528:  
2023-09-27 15:41:43.551664: Epoch 880 
2023-09-27 15:41:43.551750: Current learning rate: 0.00148 
2023-09-27 15:43:23.084508: train_loss -0.9367 
2023-09-27 15:43:23.084805: val_loss -0.6281 
2023-09-27 15:43:23.084913: Pseudo dice [0.904, 0.5597, 0.6793] 
2023-09-27 15:43:23.085016: Epoch time: 99.53 s 
2023-09-27 15:43:24.886719:  
2023-09-27 15:43:24.886883: Epoch 881 
2023-09-27 15:43:24.886984: Current learning rate: 0.00147 
2023-09-27 15:45:04.894437: train_loss -0.931 
2023-09-27 15:45:04.894687: val_loss -0.6381 
2023-09-27 15:45:04.894762: Pseudo dice [0.9029, 0.4861, 0.6729] 
2023-09-27 15:45:04.894835: Epoch time: 100.01 s 
2023-09-27 15:45:06.252754:  
2023-09-27 15:45:06.252912: Epoch 882 
2023-09-27 15:45:06.253003: Current learning rate: 0.00146 
2023-09-27 15:46:45.936481: train_loss -0.9318 
2023-09-27 15:46:45.936730: val_loss -0.6245 
2023-09-27 15:46:45.936810: Pseudo dice [0.9003, 0.5706, 0.6668] 
2023-09-27 15:46:45.936881: Epoch time: 99.68 s 
2023-09-27 15:46:47.190389:  
2023-09-27 15:46:47.190515: Epoch 883 
2023-09-27 15:46:47.190600: Current learning rate: 0.00145 
2023-09-27 15:48:26.668670: train_loss -0.9317 
2023-09-27 15:48:26.668947: val_loss -0.6192 
2023-09-27 15:48:26.669024: Pseudo dice [0.9087, 0.5236, 0.6419] 
2023-09-27 15:48:26.669096: Epoch time: 99.48 s 
2023-09-27 15:48:27.911500:  
2023-09-27 15:48:27.911636: Epoch 884 
2023-09-27 15:48:27.911721: Current learning rate: 0.00144 
2023-09-27 15:50:07.666742: train_loss -0.9327 
2023-09-27 15:50:07.667075: val_loss -0.5852 
2023-09-27 15:50:07.667156: Pseudo dice [0.9011, 0.4629, 0.6034] 
2023-09-27 15:50:07.667235: Epoch time: 99.76 s 
2023-09-27 15:50:08.925178:  
2023-09-27 15:50:08.925332: Epoch 885 
2023-09-27 15:50:08.925434: Current learning rate: 0.00143 
2023-09-27 15:51:49.026362: train_loss -0.9318 
2023-09-27 15:51:49.026604: val_loss -0.6056 
2023-09-27 15:51:49.026683: Pseudo dice [0.9065, 0.5862, 0.5923] 
2023-09-27 15:51:49.026758: Epoch time: 100.1 s 
2023-09-27 15:51:50.299396:  
2023-09-27 15:51:50.299637: Epoch 886 
2023-09-27 15:51:50.299782: Current learning rate: 0.00142 
2023-09-27 15:53:30.555734: train_loss -0.9345 
2023-09-27 15:53:30.555969: val_loss -0.5907 
2023-09-27 15:53:30.556045: Pseudo dice [0.9017, 0.531, 0.6079] 
2023-09-27 15:53:30.556116: Epoch time: 100.26 s 
2023-09-27 15:53:31.994851:  
2023-09-27 15:53:31.994998: Epoch 887 
2023-09-27 15:53:31.995095: Current learning rate: 0.00141 
2023-09-27 15:55:11.934029: train_loss -0.9315 
2023-09-27 15:55:11.934308: val_loss -0.5518 
2023-09-27 15:55:11.934387: Pseudo dice [0.8958, 0.5201, 0.4938] 
2023-09-27 15:55:11.934463: Epoch time: 99.94 s 
2023-09-27 15:55:13.208320:  
2023-09-27 15:55:13.208572: Epoch 888 
2023-09-27 15:55:13.208708: Current learning rate: 0.00139 
2023-09-27 15:56:53.295333: train_loss -0.9262 
2023-09-27 15:56:53.295703: val_loss -0.6201 
2023-09-27 15:56:53.295783: Pseudo dice [0.901, 0.5487, 0.6813] 
2023-09-27 15:56:53.295856: Epoch time: 100.09 s 
2023-09-27 15:56:54.808050:  
2023-09-27 15:56:54.808285: Epoch 889 
2023-09-27 15:56:54.808389: Current learning rate: 0.00138 
2023-09-27 15:58:34.678329: train_loss -0.9396 
2023-09-27 15:58:34.678580: val_loss -0.6556 
2023-09-27 15:58:34.678657: Pseudo dice [0.8993, 0.554, 0.6946] 
2023-09-27 15:58:34.678726: Epoch time: 99.87 s 
2023-09-27 15:58:35.937984:  
2023-09-27 15:58:35.938156: Epoch 890 
2023-09-27 15:58:35.938270: Current learning rate: 0.00137 
2023-09-27 16:00:16.138326: train_loss -0.935 
2023-09-27 16:00:16.138815: val_loss -0.6042 
2023-09-27 16:00:16.138903: Pseudo dice [0.8968, 0.5558, 0.6156] 
2023-09-27 16:00:16.138988: Epoch time: 100.2 s 
2023-09-27 16:00:17.466020:  
2023-09-27 16:00:17.466361: Epoch 891 
2023-09-27 16:00:17.466465: Current learning rate: 0.00136 
2023-09-27 16:01:57.323593: train_loss -0.9319 
2023-09-27 16:01:57.323846: val_loss -0.6352 
2023-09-27 16:01:57.323923: Pseudo dice [0.9033, 0.5965, 0.689] 
2023-09-27 16:01:57.323997: Epoch time: 99.86 s 
2023-09-27 16:01:58.606894:  
2023-09-27 16:01:58.607085: Epoch 892 
2023-09-27 16:01:58.607181: Current learning rate: 0.00135 
2023-09-27 16:03:38.954749: train_loss -0.9345 
2023-09-27 16:03:38.955206: val_loss -0.5959 
2023-09-27 16:03:38.955317: Pseudo dice [0.904, 0.5292, 0.574] 
2023-09-27 16:03:38.955428: Epoch time: 100.35 s 
2023-09-27 16:03:40.295370:  
2023-09-27 16:03:40.295551: Epoch 893 
2023-09-27 16:03:40.295653: Current learning rate: 0.00134 
2023-09-27 16:05:20.528168: train_loss -0.9341 
2023-09-27 16:05:20.528443: val_loss -0.6164 
2023-09-27 16:05:20.528523: Pseudo dice [0.897, 0.5706, 0.6406] 
2023-09-27 16:05:20.528594: Epoch time: 100.23 s 
2023-09-27 16:05:21.768986:  
2023-09-27 16:05:21.769145: Epoch 894 
2023-09-27 16:05:21.769239: Current learning rate: 0.00133 
2023-09-27 16:07:02.086844: train_loss -0.9381 
2023-09-27 16:07:02.087101: val_loss -0.5985 
2023-09-27 16:07:02.087184: Pseudo dice [0.896, 0.5434, 0.6038] 
2023-09-27 16:07:02.087258: Epoch time: 100.32 s 
2023-09-27 16:07:03.345615:  
2023-09-27 16:07:03.345748: Epoch 895 
2023-09-27 16:07:03.345836: Current learning rate: 0.00132 
2023-09-27 16:08:43.397673: train_loss -0.933 
2023-09-27 16:08:43.397938: val_loss -0.6215 
2023-09-27 16:08:43.398019: Pseudo dice [0.901, 0.5625, 0.6045] 
2023-09-27 16:08:43.398091: Epoch time: 100.05 s 
2023-09-27 16:08:44.672080:  
2023-09-27 16:08:44.672223: Epoch 896 
2023-09-27 16:08:44.672311: Current learning rate: 0.0013 
2023-09-27 16:10:24.746626: train_loss -0.9308 
2023-09-27 16:10:24.746883: val_loss -0.5865 
2023-09-27 16:10:24.746961: Pseudo dice [0.8976, 0.5112, 0.5949] 
2023-09-27 16:10:24.747035: Epoch time: 100.08 s 
2023-09-27 16:10:26.245668:  
2023-09-27 16:10:26.245835: Epoch 897 
2023-09-27 16:10:26.245950: Current learning rate: 0.00129 
2023-09-27 16:12:06.576195: train_loss -0.9339 
2023-09-27 16:12:06.576462: val_loss -0.6354 
2023-09-27 16:12:06.576545: Pseudo dice [0.907, 0.5546, 0.6519] 
2023-09-27 16:12:06.576620: Epoch time: 100.33 s 
2023-09-27 16:12:07.842443:  
2023-09-27 16:12:07.842582: Epoch 898 
2023-09-27 16:12:07.842668: Current learning rate: 0.00128 
2023-09-27 16:13:48.154584: train_loss -0.9256 
2023-09-27 16:13:48.154884: val_loss -0.5975 
2023-09-27 16:13:48.154982: Pseudo dice [0.9035, 0.5725, 0.5491] 
2023-09-27 16:13:48.155071: Epoch time: 100.31 s 
2023-09-27 16:13:49.739702:  
2023-09-27 16:13:49.739875: Epoch 899 
2023-09-27 16:13:49.739983: Current learning rate: 0.00127 
2023-09-27 16:15:30.045674: train_loss -0.9331 
2023-09-27 16:15:30.045925: val_loss -0.5771 
2023-09-27 16:15:30.046001: Pseudo dice [0.8992, 0.5482, 0.5275] 
2023-09-27 16:15:30.046072: Epoch time: 100.31 s 
2023-09-27 16:15:32.931963:  
2023-09-27 16:15:32.932125: Epoch 900 
2023-09-27 16:15:32.932266: Current learning rate: 0.00126 
2023-09-27 16:17:13.271426: train_loss -0.9348 
2023-09-27 16:17:13.271701: val_loss -0.6122 
2023-09-27 16:17:13.271801: Pseudo dice [0.9032, 0.5593, 0.6145] 
2023-09-27 16:17:13.271890: Epoch time: 100.34 s 
2023-09-27 16:17:14.574560:  
2023-09-27 16:17:14.574694: Epoch 901 
2023-09-27 16:17:14.574779: Current learning rate: 0.00125 
2023-09-27 16:18:54.706184: train_loss -0.9269 
2023-09-27 16:18:54.706474: val_loss -0.6143 
2023-09-27 16:18:54.706569: Pseudo dice [0.9089, 0.5412, 0.6404] 
2023-09-27 16:18:54.706658: Epoch time: 100.13 s 
2023-09-27 16:18:55.978959:  
2023-09-27 16:18:55.979508: Epoch 902 
2023-09-27 16:18:55.979612: Current learning rate: 0.00124 
2023-09-27 16:20:35.584972: train_loss -0.9292 
2023-09-27 16:20:35.585227: val_loss -0.6171 
2023-09-27 16:20:35.585304: Pseudo dice [0.8995, 0.564, 0.6366] 
2023-09-27 16:20:35.585376: Epoch time: 99.61 s 
2023-09-27 16:20:36.826601:  
2023-09-27 16:20:36.826747: Epoch 903 
2023-09-27 16:20:36.826847: Current learning rate: 0.00122 
2023-09-27 16:22:17.020366: train_loss -0.9311 
2023-09-27 16:22:17.020660: val_loss -0.6345 
2023-09-27 16:22:17.020757: Pseudo dice [0.9009, 0.577, 0.625] 
2023-09-27 16:22:17.020848: Epoch time: 100.19 s 
2023-09-27 16:22:18.614448:  
2023-09-27 16:22:18.614671: Epoch 904 
2023-09-27 16:22:18.614806: Current learning rate: 0.00121 
2023-09-27 16:23:58.655519: train_loss -0.9288 
2023-09-27 16:23:58.655796: val_loss -0.604 
2023-09-27 16:23:58.655876: Pseudo dice [0.9007, 0.5148, 0.6575] 
2023-09-27 16:23:58.655949: Epoch time: 100.04 s 
2023-09-27 16:23:59.923292:  
2023-09-27 16:23:59.923425: Epoch 905 
2023-09-27 16:23:59.923512: Current learning rate: 0.0012 
2023-09-27 16:25:39.832878: train_loss -0.9329 
2023-09-27 16:25:39.833149: val_loss -0.6317 
2023-09-27 16:25:39.833229: Pseudo dice [0.9007, 0.5671, 0.6641] 
2023-09-27 16:25:39.833302: Epoch time: 99.91 s 
2023-09-27 16:25:41.260202:  
2023-09-27 16:25:41.260599: Epoch 906 
2023-09-27 16:25:41.260695: Current learning rate: 0.00119 
2023-09-27 16:27:21.500298: train_loss -0.9324 
2023-09-27 16:27:21.500568: val_loss -0.6418 
2023-09-27 16:27:21.500653: Pseudo dice [0.9059, 0.5682, 0.6754] 
2023-09-27 16:27:21.500726: Epoch time: 100.24 s 
2023-09-27 16:27:22.818846:  
2023-09-27 16:27:22.818970: Epoch 907 
2023-09-27 16:27:22.819058: Current learning rate: 0.00118 
2023-09-27 16:29:02.520111: train_loss -0.9317 
2023-09-27 16:29:02.520403: val_loss -0.6294 
2023-09-27 16:29:02.520509: Pseudo dice [0.902, 0.529, 0.6751] 
2023-09-27 16:29:02.520607: Epoch time: 99.7 s 
2023-09-27 16:29:04.139639:  
2023-09-27 16:29:04.139902: Epoch 908 
2023-09-27 16:29:04.140109: Current learning rate: 0.00117 
2023-09-27 16:30:44.305427: train_loss -0.9354 
2023-09-27 16:30:44.305665: val_loss -0.6142 
2023-09-27 16:30:44.305739: Pseudo dice [0.9017, 0.5387, 0.6425] 
2023-09-27 16:30:44.305808: Epoch time: 100.17 s 
2023-09-27 16:30:45.541703:  
2023-09-27 16:30:45.541853: Epoch 909 
2023-09-27 16:30:45.541943: Current learning rate: 0.00116 
2023-09-27 16:32:23.863416: train_loss -0.9349 
2023-09-27 16:32:23.863674: val_loss -0.6346 
2023-09-27 16:32:23.863752: Pseudo dice [0.9092, 0.5805, 0.6433] 
2023-09-27 16:32:23.863827: Epoch time: 98.32 s 
2023-09-27 16:32:25.090226:  
2023-09-27 16:32:25.090368: Epoch 910 
2023-09-27 16:32:25.090458: Current learning rate: 0.00115 
2023-09-27 16:34:05.064030: train_loss -0.9334 
2023-09-27 16:34:05.064277: val_loss -0.5886 
2023-09-27 16:34:05.064355: Pseudo dice [0.9024, 0.5818, 0.5713] 
2023-09-27 16:34:05.064429: Epoch time: 99.97 s 
2023-09-27 16:34:06.318574:  
2023-09-27 16:34:06.318700: Epoch 911 
2023-09-27 16:34:06.318794: Current learning rate: 0.00113 
2023-09-27 16:35:46.557678: train_loss -0.9398 
2023-09-27 16:35:46.557940: val_loss -0.625 
2023-09-27 16:35:46.558035: Pseudo dice [0.9026, 0.5401, 0.6622] 
2023-09-27 16:35:46.558129: Epoch time: 100.24 s 
2023-09-27 16:35:48.036659:  
2023-09-27 16:35:48.036972: Epoch 912 
2023-09-27 16:35:48.037123: Current learning rate: 0.00112 
2023-09-27 16:37:28.292554: train_loss -0.9327 
2023-09-27 16:37:28.292833: val_loss -0.5965 
2023-09-27 16:37:28.292914: Pseudo dice [0.9018, 0.4768, 0.6294] 
2023-09-27 16:37:28.292990: Epoch time: 100.26 s 
2023-09-27 16:37:29.562218:  
2023-09-27 16:37:29.562417: Epoch 913 
2023-09-27 16:37:29.562509: Current learning rate: 0.00111 
2023-09-27 16:39:09.246991: train_loss -0.9363 
2023-09-27 16:39:09.247264: val_loss -0.6213 
2023-09-27 16:39:09.247348: Pseudo dice [0.8991, 0.54, 0.6067] 
2023-09-27 16:39:09.247426: Epoch time: 99.69 s 
2023-09-27 16:39:10.517682:  
2023-09-27 16:39:10.517864: Epoch 914 
2023-09-27 16:39:10.517956: Current learning rate: 0.0011 
2023-09-27 16:40:50.638498: train_loss -0.9336 
2023-09-27 16:40:50.638752: val_loss -0.6158 
2023-09-27 16:40:50.638831: Pseudo dice [0.9018, 0.5747, 0.5946] 
2023-09-27 16:40:50.638901: Epoch time: 100.12 s 
2023-09-27 16:40:51.884284:  
2023-09-27 16:40:51.884423: Epoch 915 
2023-09-27 16:40:51.884512: Current learning rate: 0.00109 
2023-09-27 16:42:31.657572: train_loss -0.9399 
2023-09-27 16:42:31.657850: val_loss -0.6307 
2023-09-27 16:42:31.657944: Pseudo dice [0.907, 0.6006, 0.5971] 
2023-09-27 16:42:31.658027: Epoch time: 99.77 s 
2023-09-27 16:42:32.937018:  
2023-09-27 16:42:32.937232: Epoch 916 
2023-09-27 16:42:32.937346: Current learning rate: 0.00108 
2023-09-27 16:44:13.119294: train_loss -0.9327 
2023-09-27 16:44:13.119550: val_loss -0.6218 
2023-09-27 16:44:13.119628: Pseudo dice [0.9054, 0.5396, 0.6727] 
2023-09-27 16:44:13.119701: Epoch time: 100.18 s 
2023-09-27 16:44:14.427466:  
2023-09-27 16:44:14.427624: Epoch 917 
2023-09-27 16:44:14.427716: Current learning rate: 0.00106 
2023-09-27 16:45:54.690162: train_loss -0.938 
2023-09-27 16:45:54.690438: val_loss -0.6242 
2023-09-27 16:45:54.690517: Pseudo dice [0.8989, 0.5489, 0.647] 
2023-09-27 16:45:54.690592: Epoch time: 100.26 s 
2023-09-27 16:45:56.126524:  
2023-09-27 16:45:56.126665: Epoch 918 
2023-09-27 16:45:56.126759: Current learning rate: 0.00105 
2023-09-27 16:47:36.358626: train_loss -0.9344 
2023-09-27 16:47:36.358981: val_loss -0.5837 
2023-09-27 16:47:36.359079: Pseudo dice [0.8999, 0.4902, 0.6516] 
2023-09-27 16:47:36.359171: Epoch time: 100.23 s 
2023-09-27 16:47:37.629261:  
2023-09-27 16:47:37.629565: Epoch 919 
2023-09-27 16:47:37.629659: Current learning rate: 0.00104 
2023-09-27 16:49:17.706434: train_loss -0.9401 
2023-09-27 16:49:17.706692: val_loss -0.6145 
2023-09-27 16:49:17.706799: Pseudo dice [0.9069, 0.5876, 0.581] 
2023-09-27 16:49:17.706897: Epoch time: 100.08 s 
2023-09-27 16:49:18.972568:  
2023-09-27 16:49:18.972708: Epoch 920 
2023-09-27 16:49:18.972795: Current learning rate: 0.00103 
2023-09-27 16:50:58.952872: train_loss -0.9392 
2023-09-27 16:50:58.953129: val_loss -0.6022 
2023-09-27 16:50:58.953206: Pseudo dice [0.9008, 0.5375, 0.6169] 
2023-09-27 16:50:58.953278: Epoch time: 99.98 s 
2023-09-27 16:51:00.260381:  
2023-09-27 16:51:00.260516: Epoch 921 
2023-09-27 16:51:00.260610: Current learning rate: 0.00102 
2023-09-27 16:52:39.954520: train_loss -0.9341 
2023-09-27 16:52:39.954769: val_loss -0.6458 
2023-09-27 16:52:39.954849: Pseudo dice [0.9048, 0.5888, 0.643] 
2023-09-27 16:52:39.954921: Epoch time: 99.7 s 
2023-09-27 16:52:41.219485:  
2023-09-27 16:52:41.219700: Epoch 922 
2023-09-27 16:52:41.219831: Current learning rate: 0.00101 
2023-09-27 16:54:21.321332: train_loss -0.9265 
2023-09-27 16:54:21.321595: val_loss -0.6349 
2023-09-27 16:54:21.321678: Pseudo dice [0.8992, 0.585, 0.6474] 
2023-09-27 16:54:21.321750: Epoch time: 100.11 s 
2023-09-27 16:54:22.584603:  
2023-09-27 16:54:22.584743: Epoch 923 
2023-09-27 16:54:22.584829: Current learning rate: 0.001 
2023-09-27 16:56:02.774648: train_loss -0.9361 
2023-09-27 16:56:02.774934: val_loss -0.6195 
2023-09-27 16:56:02.775010: Pseudo dice [0.902, 0.5788, 0.6159] 
2023-09-27 16:56:02.775080: Epoch time: 100.19 s 
2023-09-27 16:56:04.074886:  
2023-09-27 16:56:04.075037: Epoch 924 
2023-09-27 16:56:04.075128: Current learning rate: 0.00098 
2023-09-27 16:57:44.082277: train_loss -0.9335 
2023-09-27 16:57:44.082553: val_loss -0.6132 
2023-09-27 16:57:44.082630: Pseudo dice [0.907, 0.5153, 0.6598] 
2023-09-27 16:57:44.082700: Epoch time: 100.01 s 
2023-09-27 16:57:45.607349:  
2023-09-27 16:57:45.607521: Epoch 925 
2023-09-27 16:57:45.607623: Current learning rate: 0.00097 
2023-09-27 16:59:25.460002: train_loss -0.9386 
2023-09-27 16:59:25.460260: val_loss -0.6144 
2023-09-27 16:59:25.460339: Pseudo dice [0.9017, 0.5508, 0.6178] 
2023-09-27 16:59:25.460411: Epoch time: 99.85 s 
2023-09-27 16:59:26.707431:  
2023-09-27 16:59:26.707595: Epoch 926 
2023-09-27 16:59:26.707686: Current learning rate: 0.00096 
2023-09-27 17:01:06.148195: train_loss -0.9324 
2023-09-27 17:01:06.148438: val_loss -0.6123 
2023-09-27 17:01:06.148515: Pseudo dice [0.9035, 0.5498, 0.6352] 
2023-09-27 17:01:06.148588: Epoch time: 99.44 s 
2023-09-27 17:01:07.448853:  
2023-09-27 17:01:07.448995: Epoch 927 
2023-09-27 17:01:07.449082: Current learning rate: 0.00095 
2023-09-27 17:02:46.624131: train_loss -0.9363 
2023-09-27 17:02:46.624384: val_loss -0.5917 
2023-09-27 17:02:46.624460: Pseudo dice [0.8971, 0.5907, 0.5543] 
2023-09-27 17:02:46.624536: Epoch time: 99.18 s 
2023-09-27 17:02:47.874880:  
2023-09-27 17:02:47.875030: Epoch 928 
2023-09-27 17:02:47.875117: Current learning rate: 0.00094 
2023-09-27 17:04:25.787525: train_loss -0.9341 
2023-09-27 17:04:25.787888: val_loss -0.5819 
2023-09-27 17:04:25.788020: Pseudo dice [0.905, 0.5125, 0.574] 
2023-09-27 17:04:25.788129: Epoch time: 97.91 s 
2023-09-27 17:04:27.118517:  
2023-09-27 17:04:27.118750: Epoch 929 
2023-09-27 17:04:27.118840: Current learning rate: 0.00092 
2023-09-27 17:06:07.160552: train_loss -0.9267 
2023-09-27 17:06:07.160813: val_loss -0.6186 
2023-09-27 17:06:07.160893: Pseudo dice [0.9066, 0.5699, 0.6037] 
2023-09-27 17:06:07.160968: Epoch time: 100.04 s 
2023-09-27 17:06:08.398990:  
2023-09-27 17:06:08.399138: Epoch 930 
2023-09-27 17:06:08.399225: Current learning rate: 0.00091 
2023-09-27 17:07:46.792820: train_loss -0.938 
2023-09-27 17:07:46.793083: val_loss -0.6051 
2023-09-27 17:07:46.793161: Pseudo dice [0.8957, 0.5271, 0.6399] 
2023-09-27 17:07:46.793232: Epoch time: 98.4 s 
2023-09-27 17:07:48.225265:  
2023-09-27 17:07:48.225410: Epoch 931 
2023-09-27 17:07:48.225497: Current learning rate: 0.0009 
2023-09-27 17:09:27.767678: train_loss -0.9376 
2023-09-27 17:09:27.767928: val_loss -0.575 
2023-09-27 17:09:27.768007: Pseudo dice [0.903, 0.5521, 0.6008] 
2023-09-27 17:09:27.768079: Epoch time: 99.54 s 
2023-09-27 17:09:29.027186:  
2023-09-27 17:09:29.027337: Epoch 932 
2023-09-27 17:09:29.027423: Current learning rate: 0.00089 
2023-09-27 17:11:09.030953: train_loss -0.9319 
2023-09-27 17:11:09.031232: val_loss -0.6175 
2023-09-27 17:11:09.031327: Pseudo dice [0.9044, 0.5508, 0.6218] 
2023-09-27 17:11:09.031415: Epoch time: 100.0 s 
2023-09-27 17:11:10.376618:  
2023-09-27 17:11:10.376757: Epoch 933 
2023-09-27 17:11:10.376848: Current learning rate: 0.00088 
2023-09-27 17:12:50.232823: train_loss -0.9396 
2023-09-27 17:12:50.233088: val_loss -0.6207 
2023-09-27 17:12:50.233172: Pseudo dice [0.9073, 0.61, 0.5852] 
2023-09-27 17:12:50.233245: Epoch time: 99.86 s 
2023-09-27 17:12:51.482353:  
2023-09-27 17:12:51.482494: Epoch 934 
2023-09-27 17:12:51.482582: Current learning rate: 0.00087 
2023-09-27 17:14:31.039556: train_loss -0.9301 
2023-09-27 17:14:31.039818: val_loss -0.6346 
2023-09-27 17:14:31.039900: Pseudo dice [0.9039, 0.5981, 0.6665] 
2023-09-27 17:14:31.039976: Epoch time: 99.56 s 
2023-09-27 17:14:32.350659:  
2023-09-27 17:14:32.350799: Epoch 935 
2023-09-27 17:14:32.350890: Current learning rate: 0.00085 
2023-09-27 17:16:12.354558: train_loss -0.9374 
2023-09-27 17:16:12.355098: val_loss -0.6253 
2023-09-27 17:16:12.355181: Pseudo dice [0.9023, 0.5285, 0.6369] 
2023-09-27 17:16:12.355289: Epoch time: 100.01 s 
2023-09-27 17:16:13.699026:  
2023-09-27 17:16:13.699242: Epoch 936 
2023-09-27 17:16:13.699383: Current learning rate: 0.00084 
2023-09-27 17:17:53.967245: train_loss -0.9428 
2023-09-27 17:17:53.967554: val_loss -0.6007 
2023-09-27 17:17:53.967634: Pseudo dice [0.9012, 0.4886, 0.6462] 
2023-09-27 17:17:53.967716: Epoch time: 100.27 s 
2023-09-27 17:17:55.263239:  
2023-09-27 17:17:55.263498: Epoch 937 
2023-09-27 17:17:55.263600: Current learning rate: 0.00083 
2023-09-27 17:19:35.282885: train_loss -0.9252 
2023-09-27 17:19:35.283569: val_loss -0.58 
2023-09-27 17:19:35.283669: Pseudo dice [0.8986, 0.5207, 0.6235] 
2023-09-27 17:19:35.283760: Epoch time: 100.02 s 
2023-09-27 17:19:36.972309:  
2023-09-27 17:19:36.972553: Epoch 938 
2023-09-27 17:19:36.972695: Current learning rate: 0.00082 
2023-09-27 17:21:16.970467: train_loss -0.9422 
2023-09-27 17:21:16.970754: val_loss -0.6512 
2023-09-27 17:21:16.970833: Pseudo dice [0.9018, 0.5811, 0.6578] 
2023-09-27 17:21:16.970909: Epoch time: 100.0 s 
2023-09-27 17:21:18.566811:  
2023-09-27 17:21:18.566998: Epoch 939 
2023-09-27 17:21:18.567106: Current learning rate: 0.00081 
2023-09-27 17:22:58.538089: train_loss -0.9313 
2023-09-27 17:22:58.538437: val_loss -0.6207 
2023-09-27 17:22:58.538518: Pseudo dice [0.9007, 0.5752, 0.6225] 
2023-09-27 17:22:58.538595: Epoch time: 99.97 s 
2023-09-27 17:23:00.103901:  
2023-09-27 17:23:00.104046: Epoch 940 
2023-09-27 17:23:00.104136: Current learning rate: 0.00079 
2023-09-27 17:24:39.501353: train_loss -0.931 
2023-09-27 17:24:39.501602: val_loss -0.6367 
2023-09-27 17:24:39.501682: Pseudo dice [0.9083, 0.6063, 0.6257] 
2023-09-27 17:24:39.501755: Epoch time: 99.4 s 
2023-09-27 17:24:40.807705:  
2023-09-27 17:24:40.807870: Epoch 941 
2023-09-27 17:24:40.807964: Current learning rate: 0.00078 
2023-09-27 17:26:20.345496: train_loss -0.936 
2023-09-27 17:26:20.345758: val_loss -0.577 
2023-09-27 17:26:20.345836: Pseudo dice [0.9025, 0.4955, 0.5876] 
2023-09-27 17:26:20.345959: Epoch time: 99.54 s 
2023-09-27 17:26:21.621936:  
2023-09-27 17:26:21.622079: Epoch 942 
2023-09-27 17:26:21.622189: Current learning rate: 0.00077 
2023-09-27 17:28:01.689146: train_loss -0.9362 
2023-09-27 17:28:01.689408: val_loss -0.6168 
2023-09-27 17:28:01.689487: Pseudo dice [0.91, 0.5557, 0.6187] 
2023-09-27 17:28:01.689561: Epoch time: 100.07 s 
2023-09-27 17:28:02.957082:  
2023-09-27 17:28:02.957231: Epoch 943 
2023-09-27 17:28:02.957322: Current learning rate: 0.00076 
2023-09-27 17:29:42.661359: train_loss -0.9378 
2023-09-27 17:29:42.661611: val_loss -0.5945 
2023-09-27 17:29:42.661690: Pseudo dice [0.9066, 0.53, 0.6241] 
2023-09-27 17:29:42.661764: Epoch time: 99.71 s 
2023-09-27 17:29:44.287005:  
2023-09-27 17:29:44.287179: Epoch 944 
2023-09-27 17:29:44.287283: Current learning rate: 0.00075 
2023-09-27 17:31:23.926860: train_loss -0.9396 
2023-09-27 17:31:23.927123: val_loss -0.6166 
2023-09-27 17:31:23.927202: Pseudo dice [0.9046, 0.5788, 0.5818] 
2023-09-27 17:31:23.927277: Epoch time: 99.64 s 
2023-09-27 17:31:25.221970:  
2023-09-27 17:31:25.222150: Epoch 945 
2023-09-27 17:31:25.222245: Current learning rate: 0.00074 
2023-09-27 17:33:05.076731: train_loss -0.932 
2023-09-27 17:33:05.077000: val_loss -0.5706 
2023-09-27 17:33:05.077079: Pseudo dice [0.9005, 0.5179, 0.5993] 
2023-09-27 17:33:05.077155: Epoch time: 99.86 s 
2023-09-27 17:33:06.614813:  
2023-09-27 17:33:06.614972: Epoch 946 
2023-09-27 17:33:06.615072: Current learning rate: 0.00072 
2023-09-27 17:34:46.649819: train_loss -0.9286 
2023-09-27 17:34:46.650072: val_loss -0.6058 
2023-09-27 17:34:46.650159: Pseudo dice [0.9063, 0.5421, 0.6045] 
2023-09-27 17:34:46.650236: Epoch time: 100.04 s 
2023-09-27 17:34:48.238264:  
2023-09-27 17:34:48.238427: Epoch 947 
2023-09-27 17:34:48.238531: Current learning rate: 0.00071 
2023-09-27 17:36:28.168197: train_loss -0.9292 
2023-09-27 17:36:28.168454: val_loss -0.6094 
2023-09-27 17:36:28.168534: Pseudo dice [0.9046, 0.5485, 0.605] 
2023-09-27 17:36:28.168608: Epoch time: 99.93 s 
2023-09-27 17:36:29.492968:  
2023-09-27 17:36:29.493209: Epoch 948 
2023-09-27 17:36:29.493373: Current learning rate: 0.0007 
2023-09-27 17:38:09.242763: train_loss -0.935 
2023-09-27 17:38:09.243016: val_loss -0.6275 
2023-09-27 17:38:09.243097: Pseudo dice [0.9091, 0.6215, 0.597] 
2023-09-27 17:38:09.243174: Epoch time: 99.75 s 
2023-09-27 17:38:10.529400:  
2023-09-27 17:38:10.529536: Epoch 949 
2023-09-27 17:38:10.529628: Current learning rate: 0.00069 
2023-09-27 17:39:51.083801: train_loss -0.9392 
2023-09-27 17:39:51.084038: val_loss -0.6142 
2023-09-27 17:39:51.084117: Pseudo dice [0.9061, 0.5571, 0.6406] 
2023-09-27 17:39:51.084190: Epoch time: 100.56 s 
2023-09-27 17:39:53.917537:  
2023-09-27 17:39:53.917675: Epoch 950 
2023-09-27 17:39:53.917768: Current learning rate: 0.00067 
2023-09-27 17:41:33.811407: train_loss -0.9414 
2023-09-27 17:41:33.811665: val_loss -0.616 
2023-09-27 17:41:33.811746: Pseudo dice [0.9013, 0.5975, 0.6239] 
2023-09-27 17:41:33.811821: Epoch time: 99.9 s 
2023-09-27 17:41:35.119925:  
2023-09-27 17:41:35.120104: Epoch 951 
2023-09-27 17:41:35.120197: Current learning rate: 0.00066 
2023-09-27 17:43:16.080722: train_loss -0.9373 
2023-09-27 17:43:16.081043: val_loss -0.5957 
2023-09-27 17:43:16.081170: Pseudo dice [0.8988, 0.5374, 0.5666] 
2023-09-27 17:43:16.081287: Epoch time: 100.96 s 
2023-09-27 17:43:17.392344:  
2023-09-27 17:43:17.392775: Epoch 952 
2023-09-27 17:43:17.392979: Current learning rate: 0.00065 
2023-09-27 17:44:59.066210: train_loss -0.9266 
2023-09-27 17:44:59.066446: val_loss -0.5912 
2023-09-27 17:44:59.066524: Pseudo dice [0.9097, 0.5446, 0.6] 
2023-09-27 17:44:59.066597: Epoch time: 101.68 s 
2023-09-27 17:45:00.333355:  
2023-09-27 17:45:00.333618: Epoch 953 
2023-09-27 17:45:00.333708: Current learning rate: 0.00064 
2023-09-27 17:46:41.742873: train_loss -0.9375 
2023-09-27 17:46:41.743143: val_loss -0.628 
2023-09-27 17:46:41.743223: Pseudo dice [0.9023, 0.5468, 0.6208] 
2023-09-27 17:46:41.743299: Epoch time: 101.41 s 
2023-09-27 17:46:43.031017:  
2023-09-27 17:46:43.031158: Epoch 954 
2023-09-27 17:46:43.031257: Current learning rate: 0.00063 
2023-09-27 17:48:23.515674: train_loss -0.9343 
2023-09-27 17:48:23.515932: val_loss -0.5977 
2023-09-27 17:48:23.516008: Pseudo dice [0.8937, 0.4995, 0.6334] 
2023-09-27 17:48:23.516083: Epoch time: 100.49 s 
2023-09-27 17:48:24.797889:  
2023-09-27 17:48:24.798044: Epoch 955 
2023-09-27 17:48:24.798147: Current learning rate: 0.00061 
2023-09-27 17:50:04.626623: train_loss -0.9358 
2023-09-27 17:50:04.626890: val_loss -0.608 
2023-09-27 17:50:04.626979: Pseudo dice [0.9014, 0.5497, 0.6065] 
2023-09-27 17:50:04.627060: Epoch time: 99.83 s 
2023-09-27 17:50:06.096659:  
2023-09-27 17:50:06.096803: Epoch 956 
2023-09-27 17:50:06.096888: Current learning rate: 0.0006 
2023-09-27 17:51:45.621667: train_loss -0.9366 
2023-09-27 17:51:45.621943: val_loss -0.6416 
2023-09-27 17:51:45.622023: Pseudo dice [0.9079, 0.592, 0.6296] 
2023-09-27 17:51:45.622110: Epoch time: 99.53 s 
2023-09-27 17:51:46.993403:  
2023-09-27 17:51:46.993535: Epoch 957 
2023-09-27 17:51:46.993636: Current learning rate: 0.00059 
2023-09-27 17:53:27.036528: train_loss -0.938 
2023-09-27 17:53:27.036781: val_loss -0.598 
2023-09-27 17:53:27.036854: Pseudo dice [0.902, 0.5556, 0.5741] 
2023-09-27 17:53:27.036924: Epoch time: 100.04 s 
2023-09-27 17:53:28.312760:  
2023-09-27 17:53:28.312904: Epoch 958 
2023-09-27 17:53:28.313007: Current learning rate: 0.00058 
2023-09-27 17:55:08.138346: train_loss -0.9381 
2023-09-27 17:55:08.138605: val_loss -0.5737 
2023-09-27 17:55:08.138683: Pseudo dice [0.8958, 0.4621, 0.6196] 
2023-09-27 17:55:08.138759: Epoch time: 99.83 s 
2023-09-27 17:55:09.427718:  
2023-09-27 17:55:09.427868: Epoch 959 
2023-09-27 17:55:09.427953: Current learning rate: 0.00056 
2023-09-27 17:56:49.388251: train_loss -0.9362 
2023-09-27 17:56:49.388501: val_loss -0.6464 
2023-09-27 17:56:49.388581: Pseudo dice [0.9059, 0.567, 0.6665] 
2023-09-27 17:56:49.388652: Epoch time: 99.96 s 
2023-09-27 17:56:50.683654:  
2023-09-27 17:56:50.683810: Epoch 960 
2023-09-27 17:56:50.683900: Current learning rate: 0.00055 
2023-09-27 17:58:28.823134: train_loss -0.941 
2023-09-27 17:58:28.823393: val_loss -0.6086 
2023-09-27 17:58:28.823472: Pseudo dice [0.8975, 0.5756, 0.6349] 
2023-09-27 17:58:28.823545: Epoch time: 98.14 s 
2023-09-27 17:58:30.095236:  
2023-09-27 17:58:30.095407: Epoch 961 
2023-09-27 17:58:30.095499: Current learning rate: 0.00054 
2023-09-27 18:00:09.883334: train_loss -0.9392 
2023-09-27 18:00:09.883608: val_loss -0.6048 
2023-09-27 18:00:09.883686: Pseudo dice [0.9041, 0.5509, 0.6162] 
2023-09-27 18:00:09.883757: Epoch time: 99.79 s 
2023-09-27 18:00:11.433964:  
2023-09-27 18:00:11.434212: Epoch 962 
2023-09-27 18:00:11.434464: Current learning rate: 0.00053 
2023-09-27 18:01:51.179896: train_loss -0.9331 
2023-09-27 18:01:51.180149: val_loss -0.6406 
2023-09-27 18:01:51.180229: Pseudo dice [0.9036, 0.5557, 0.6633] 
2023-09-27 18:01:51.180300: Epoch time: 99.75 s 
2023-09-27 18:01:52.465239:  
2023-09-27 18:01:52.465569: Epoch 963 
2023-09-27 18:01:52.465663: Current learning rate: 0.00051 
2023-09-27 18:03:32.210741: train_loss -0.9433 
2023-09-27 18:03:32.210995: val_loss -0.624 
2023-09-27 18:03:32.211074: Pseudo dice [0.8883, 0.5445, 0.6742] 
2023-09-27 18:03:32.211159: Epoch time: 99.75 s 
2023-09-27 18:03:33.487669:  
2023-09-27 18:03:33.487905: Epoch 964 
2023-09-27 18:03:33.487999: Current learning rate: 0.0005 
2023-09-27 18:05:12.906266: train_loss -0.938 
2023-09-27 18:05:12.906528: val_loss -0.612 
2023-09-27 18:05:12.906621: Pseudo dice [0.9041, 0.5923, 0.6364] 
2023-09-27 18:05:12.906699: Epoch time: 99.42 s 
2023-09-27 18:05:14.181799:  
2023-09-27 18:05:14.181945: Epoch 965 
2023-09-27 18:05:14.182031: Current learning rate: 0.00049 
2023-09-27 18:06:53.703344: train_loss -0.9341 
2023-09-27 18:06:53.703605: val_loss -0.6067 
2023-09-27 18:06:53.703685: Pseudo dice [0.8997, 0.5192, 0.6478] 
2023-09-27 18:06:53.703761: Epoch time: 99.52 s 
2023-09-27 18:06:55.026483:  
2023-09-27 18:06:55.026623: Epoch 966 
2023-09-27 18:06:55.026726: Current learning rate: 0.00048 
2023-09-27 18:08:34.782890: train_loss -0.9384 
2023-09-27 18:08:34.783187: val_loss -0.6501 
2023-09-27 18:08:34.783284: Pseudo dice [0.905, 0.6168, 0.6752] 
2023-09-27 18:08:34.783375: Epoch time: 99.76 s 
2023-09-27 18:08:36.163911:  
2023-09-27 18:08:36.164070: Epoch 967 
2023-09-27 18:08:36.164179: Current learning rate: 0.00046 
2023-09-27 18:10:16.281142: train_loss -0.9415 
2023-09-27 18:10:16.281399: val_loss -0.6253 
2023-09-27 18:10:16.281479: Pseudo dice [0.906, 0.5539, 0.6245] 
2023-09-27 18:10:16.281552: Epoch time: 100.12 s 
2023-09-27 18:10:17.592177:  
2023-09-27 18:10:17.592389: Epoch 968 
2023-09-27 18:10:17.592527: Current learning rate: 0.00045 
2023-09-27 18:11:57.330251: train_loss -0.9399 
2023-09-27 18:11:57.330517: val_loss -0.5829 
2023-09-27 18:11:57.330596: Pseudo dice [0.9024, 0.4801, 0.6204] 
2023-09-27 18:11:57.330670: Epoch time: 99.74 s 
2023-09-27 18:11:58.940339:  
2023-09-27 18:11:58.940504: Epoch 969 
2023-09-27 18:11:58.940593: Current learning rate: 0.00044 
2023-09-27 18:13:39.023761: train_loss -0.9406 
2023-09-27 18:13:39.024030: val_loss -0.6484 
2023-09-27 18:13:39.024114: Pseudo dice [0.912, 0.6038, 0.639] 
2023-09-27 18:13:39.024189: Epoch time: 100.08 s 
2023-09-27 18:13:40.399835:  
2023-09-27 18:13:40.400133: Epoch 970 
2023-09-27 18:13:40.400252: Current learning rate: 0.00043 
2023-09-27 18:15:20.282291: train_loss -0.9426 
2023-09-27 18:15:20.282581: val_loss -0.6286 
2023-09-27 18:15:20.282681: Pseudo dice [0.9056, 0.568, 0.6478] 
2023-09-27 18:15:20.282771: Epoch time: 99.88 s 
2023-09-27 18:15:21.604568:  
2023-09-27 18:15:21.604851: Epoch 971 
2023-09-27 18:15:21.604950: Current learning rate: 0.00041 
2023-09-27 18:17:01.539241: train_loss -0.9377 
2023-09-27 18:17:01.539506: val_loss -0.5991 
2023-09-27 18:17:01.539586: Pseudo dice [0.9028, 0.5601, 0.5901] 
2023-09-27 18:17:01.539662: Epoch time: 99.94 s 
2023-09-27 18:17:02.837376:  
2023-09-27 18:17:02.837517: Epoch 972 
2023-09-27 18:17:02.837614: Current learning rate: 0.0004 
2023-09-27 18:18:42.384458: train_loss -0.9415 
2023-09-27 18:18:42.384817: val_loss -0.6137 
2023-09-27 18:18:42.384905: Pseudo dice [0.9021, 0.5868, 0.6082] 
2023-09-27 18:18:42.384990: Epoch time: 99.55 s 
2023-09-27 18:18:43.705242:  
2023-09-27 18:18:43.705495: Epoch 973 
2023-09-27 18:18:43.705635: Current learning rate: 0.00039 
2023-09-27 18:20:23.444567: train_loss -0.9348 
2023-09-27 18:20:23.444834: val_loss -0.5995 
2023-09-27 18:20:23.444913: Pseudo dice [0.9014, 0.5485, 0.6443] 
2023-09-27 18:20:23.444988: Epoch time: 99.74 s 
2023-09-27 18:20:24.717611:  
2023-09-27 18:20:24.717788: Epoch 974 
2023-09-27 18:20:24.717895: Current learning rate: 0.00037 
2023-09-27 18:22:04.857578: train_loss -0.9391 
2023-09-27 18:22:04.857833: val_loss -0.6241 
2023-09-27 18:22:04.857911: Pseudo dice [0.9106, 0.5632, 0.6687] 
2023-09-27 18:22:04.857981: Epoch time: 100.14 s 
2023-09-27 18:22:06.364414:  
2023-09-27 18:22:06.364604: Epoch 975 
2023-09-27 18:22:06.364702: Current learning rate: 0.00036 
2023-09-27 18:23:46.095199: train_loss -0.9419 
2023-09-27 18:23:46.095481: val_loss -0.6296 
2023-09-27 18:23:46.095559: Pseudo dice [0.9082, 0.5968, 0.6606] 
2023-09-27 18:23:46.095633: Epoch time: 99.73 s 
2023-09-27 18:23:47.379134:  
2023-09-27 18:23:47.379280: Epoch 976 
2023-09-27 18:23:47.379370: Current learning rate: 0.00035 
2023-09-27 18:25:27.218371: train_loss -0.9438 
2023-09-27 18:25:27.218636: val_loss -0.6174 
2023-09-27 18:25:27.218714: Pseudo dice [0.8987, 0.5424, 0.6393] 
2023-09-27 18:25:27.218786: Epoch time: 99.84 s 
2023-09-27 18:25:28.684339:  
2023-09-27 18:25:28.684526: Epoch 977 
2023-09-27 18:25:28.684635: Current learning rate: 0.00034 
2023-09-27 18:27:08.567168: train_loss -0.9338 
2023-09-27 18:27:08.567401: val_loss -0.6505 
2023-09-27 18:27:08.567478: Pseudo dice [0.9122, 0.5383, 0.7022] 
2023-09-27 18:27:08.567546: Epoch time: 99.88 s 
2023-09-27 18:27:09.845092:  
2023-09-27 18:27:09.845247: Epoch 978 
2023-09-27 18:27:09.845341: Current learning rate: 0.00032 
2023-09-27 18:28:49.411981: train_loss -0.9398 
2023-09-27 18:28:49.412224: val_loss -0.6324 
2023-09-27 18:28:49.412302: Pseudo dice [0.9069, 0.5888, 0.6348] 
2023-09-27 18:28:49.412373: Epoch time: 99.57 s 
2023-09-27 18:28:50.708696:  
2023-09-27 18:28:50.708847: Epoch 979 
2023-09-27 18:28:50.708936: Current learning rate: 0.00031 
2023-09-27 18:30:30.403599: train_loss -0.9355 
2023-09-27 18:30:30.403852: val_loss -0.6107 
2023-09-27 18:30:30.403929: Pseudo dice [0.8985, 0.5485, 0.6084] 
2023-09-27 18:30:30.404000: Epoch time: 99.7 s 
2023-09-27 18:30:31.728445:  
2023-09-27 18:30:31.728605: Epoch 980 
2023-09-27 18:30:31.728702: Current learning rate: 0.0003 
2023-09-27 18:32:09.742004: train_loss -0.9375 
2023-09-27 18:32:09.742341: val_loss -0.6126 
2023-09-27 18:32:09.742426: Pseudo dice [0.9054, 0.5621, 0.6081] 
2023-09-27 18:32:09.742511: Epoch time: 98.01 s 
2023-09-27 18:32:11.244892:  
2023-09-27 18:32:11.245043: Epoch 981 
2023-09-27 18:32:11.245145: Current learning rate: 0.00028 
2023-09-27 18:33:49.495265: train_loss -0.9371 
2023-09-27 18:33:49.495520: val_loss -0.603 
2023-09-27 18:33:49.495598: Pseudo dice [0.9051, 0.5701, 0.5862] 
2023-09-27 18:33:49.495670: Epoch time: 98.25 s 
2023-09-27 18:33:50.790613:  
2023-09-27 18:33:50.790763: Epoch 982 
2023-09-27 18:33:50.790848: Current learning rate: 0.00027 
2023-09-27 18:35:28.647232: train_loss -0.9407 
2023-09-27 18:35:28.647487: val_loss -0.6242 
2023-09-27 18:35:28.647564: Pseudo dice [0.9081, 0.572, 0.6405] 
2023-09-27 18:35:28.647635: Epoch time: 97.86 s 
2023-09-27 18:35:29.982835:  
2023-09-27 18:35:29.982982: Epoch 983 
2023-09-27 18:35:29.983067: Current learning rate: 0.00026 
2023-09-27 18:37:09.413224: train_loss -0.9407 
2023-09-27 18:37:09.413495: val_loss -0.6118 
2023-09-27 18:37:09.413576: Pseudo dice [0.9065, 0.549, 0.6463] 
2023-09-27 18:37:09.413650: Epoch time: 99.43 s 
2023-09-27 18:37:10.700055:  
2023-09-27 18:37:10.700232: Epoch 984 
2023-09-27 18:37:10.700323: Current learning rate: 0.00024 
2023-09-27 18:38:50.329718: train_loss -0.9397 
2023-09-27 18:38:50.330053: val_loss -0.6089 
2023-09-27 18:38:50.330145: Pseudo dice [0.9053, 0.5766, 0.5848] 
2023-09-27 18:38:50.330227: Epoch time: 99.63 s 
2023-09-27 18:38:51.622557:  
2023-09-27 18:38:51.622728: Epoch 985 
2023-09-27 18:38:51.622824: Current learning rate: 0.00023 
2023-09-27 18:40:31.388528: train_loss -0.9416 
2023-09-27 18:40:31.388812: val_loss -0.6366 
2023-09-27 18:40:31.388974: Pseudo dice [0.9021, 0.587, 0.6589] 
2023-09-27 18:40:31.389060: Epoch time: 99.77 s 
2023-09-27 18:40:32.669235:  
2023-09-27 18:40:32.669405: Epoch 986 
2023-09-27 18:40:32.669501: Current learning rate: 0.00021 
2023-09-27 18:42:12.090286: train_loss -0.935 
2023-09-27 18:42:12.090550: val_loss -0.6072 
2023-09-27 18:42:12.090633: Pseudo dice [0.9013, 0.525, 0.5957] 
2023-09-27 18:42:12.090706: Epoch time: 99.42 s 
2023-09-27 18:42:13.564502:  
2023-09-27 18:42:13.564903: Epoch 987 
2023-09-27 18:42:13.565055: Current learning rate: 0.0002 
2023-09-27 18:43:53.582733: train_loss -0.9424 
2023-09-27 18:43:53.582996: val_loss -0.6083 
2023-09-27 18:43:53.583074: Pseudo dice [0.9043, 0.5443, 0.657] 
2023-09-27 18:43:53.583145: Epoch time: 100.02 s 
2023-09-27 18:43:54.894030:  
2023-09-27 18:43:54.894222: Epoch 988 
2023-09-27 18:43:54.894319: Current learning rate: 0.00019 
2023-09-27 18:45:34.943027: train_loss -0.9347 
2023-09-27 18:45:34.943484: val_loss -0.6207 
2023-09-27 18:45:34.943577: Pseudo dice [0.9043, 0.6044, 0.6345] 
2023-09-27 18:45:34.943661: Epoch time: 100.05 s 
2023-09-27 18:45:36.305451:  
2023-09-27 18:45:36.306025: Epoch 989 
2023-09-27 18:45:36.306438: Current learning rate: 0.00017 
2023-09-27 18:47:16.306529: train_loss -0.9374 
2023-09-27 18:47:16.307006: val_loss -0.5953 
2023-09-27 18:47:16.307092: Pseudo dice [0.8976, 0.5264, 0.6051] 
2023-09-27 18:47:16.307196: Epoch time: 100.0 s 
2023-09-27 18:47:17.602124:  
2023-09-27 18:47:17.602300: Epoch 990 
2023-09-27 18:47:17.602402: Current learning rate: 0.00016 
2023-09-27 18:48:57.059586: train_loss -0.9407 
2023-09-27 18:48:57.059888: val_loss -0.6046 
2023-09-27 18:48:57.059968: Pseudo dice [0.9022, 0.5604, 0.6327] 
2023-09-27 18:48:57.060045: Epoch time: 99.46 s 
2023-09-27 18:48:58.430219:  
2023-09-27 18:48:58.430828: Epoch 991 
2023-09-27 18:48:58.430972: Current learning rate: 0.00014 
2023-09-27 18:50:36.793112: train_loss -0.9336 
2023-09-27 18:50:36.793716: val_loss -0.6087 
2023-09-27 18:50:36.793809: Pseudo dice [0.9055, 0.5058, 0.6092] 
2023-09-27 18:50:36.793919: Epoch time: 98.37 s 
2023-09-27 18:50:38.115811:  
2023-09-27 18:50:38.115960: Epoch 992 
2023-09-27 18:50:38.116051: Current learning rate: 0.00013 
2023-09-27 18:52:16.280799: train_loss -0.9378 
2023-09-27 18:52:16.281055: val_loss -0.6201 
2023-09-27 18:52:16.281131: Pseudo dice [0.899, 0.557, 0.6274] 
2023-09-27 18:52:16.281202: Epoch time: 98.17 s 
2023-09-27 18:52:17.829288:  
2023-09-27 18:52:17.829487: Epoch 993 
2023-09-27 18:52:17.829578: Current learning rate: 0.00011 
2023-09-27 18:53:57.215729: train_loss -0.9439 
2023-09-27 18:53:57.216260: val_loss -0.5978 
2023-09-27 18:53:57.216563: Pseudo dice [0.9028, 0.5583, 0.6416] 
2023-09-27 18:53:57.216675: Epoch time: 99.39 s 
2023-09-27 18:53:58.627865:  
2023-09-27 18:53:58.628050: Epoch 994 
2023-09-27 18:53:58.628146: Current learning rate: 0.0001 
2023-09-27 18:55:38.441521: train_loss -0.9436 
2023-09-27 18:55:38.441788: val_loss -0.6177 
2023-09-27 18:55:38.441872: Pseudo dice [0.902, 0.5474, 0.6454] 
2023-09-27 18:55:38.441952: Epoch time: 99.82 s 
2023-09-27 18:55:39.794667:  
2023-09-27 18:55:39.794990: Epoch 995 
2023-09-27 18:55:39.795097: Current learning rate: 8e-05 
2023-09-27 18:57:19.645004: train_loss -0.9405 
2023-09-27 18:57:19.645437: val_loss -0.6299 
2023-09-27 18:57:19.645538: Pseudo dice [0.9096, 0.5604, 0.6662] 
2023-09-27 18:57:19.645628: Epoch time: 99.85 s 
2023-09-27 18:57:21.025121:  
2023-09-27 18:57:21.025279: Epoch 996 
2023-09-27 18:57:21.025371: Current learning rate: 7e-05 
2023-09-27 18:59:01.022985: train_loss -0.94 
2023-09-27 18:59:01.023360: val_loss -0.6277 
2023-09-27 18:59:01.023444: Pseudo dice [0.9061, 0.573, 0.6415] 
2023-09-27 18:59:01.023527: Epoch time: 100.0 s 
2023-09-27 18:59:02.384725:  
2023-09-27 18:59:02.384896: Epoch 997 
2023-09-27 18:59:02.384990: Current learning rate: 5e-05 
2023-09-27 19:00:42.339758: train_loss -0.9328 
2023-09-27 19:00:42.340016: val_loss -0.6331 
2023-09-27 19:00:42.340093: Pseudo dice [0.9063, 0.5706, 0.6611] 
2023-09-27 19:00:42.340164: Epoch time: 99.96 s 
2023-09-27 19:00:43.625245:  
2023-09-27 19:00:43.625411: Epoch 998 
2023-09-27 19:00:43.625501: Current learning rate: 4e-05 
2023-09-27 19:02:23.545345: train_loss -0.9341 
2023-09-27 19:02:23.545834: val_loss -0.5889 
2023-09-27 19:02:23.545921: Pseudo dice [0.9039, 0.5304, 0.6021] 
2023-09-27 19:02:23.546022: Epoch time: 99.92 s 
2023-09-27 19:02:24.865375:  
2023-09-27 19:02:24.865601: Epoch 999 
2023-09-27 19:02:24.865765: Current learning rate: 2e-05 
2023-09-27 19:04:04.616542: train_loss -0.9354 
2023-09-27 19:04:04.616837: val_loss -0.6384 
2023-09-27 19:04:04.616931: Pseudo dice [0.9057, 0.5786, 0.6381] 
2023-09-27 19:04:04.617012: Epoch time: 99.75 s 
2023-09-27 19:04:07.315626: Using splits from existing split file: /data/chuan/nnUNet/nnUNet_preprocessed/Dataset015_DeepLacune/splits_final.json 
2023-09-27 19:04:07.316270: The split file contains 5 splits. 
2023-09-27 19:04:07.316333: Desired fold for training: 1 
2023-09-27 19:04:07.316368: This split has 76 training and 19 validation cases. 
2023-09-27 19:04:07.316603: predicting DeepLacune_00001 
2023-09-27 19:04:09.507638: predicting DeepLacune_00003 
2023-09-27 19:04:10.276056: predicting DeepLacune_00007 
2023-09-27 19:04:11.198409: predicting DeepLacune_00008 
2023-09-27 19:04:12.120578: predicting DeepLacune_00014 
2023-09-27 19:04:13.054394: predicting DeepLacune_00017 
2023-09-27 19:04:14.491343: predicting DeepLacune_00018 
2023-09-27 19:04:15.380776: predicting DeepLacune_00029 
2023-09-27 19:04:16.228868: predicting DeepLacune_00038 
2023-09-27 19:04:17.810304: predicting DeepLacune_00041 
2023-09-27 19:04:18.669542: predicting DeepLacune_00045 
2023-09-27 19:04:19.594532: predicting DeepLacune_00049 
2023-09-27 19:04:20.532698: predicting DeepLacune_00051 
2023-09-27 19:04:21.884902: predicting DeepLacune_00058 
2023-09-27 19:04:22.637841: predicting DeepLacune_00061 
2023-09-27 19:04:23.452579: predicting DeepLacune_00065 
2023-09-27 19:04:24.241909: predicting DeepLacune_00071 
2023-09-27 19:04:25.180997: predicting DeepLacune_00080 
2023-09-27 19:04:26.121216: predicting DeepLacune_00085 
2023-09-27 19:04:30.568793: Validation complete 
2023-09-27 19:04:30.568968: Mean Validation Dice:  0.5105484222232454 
